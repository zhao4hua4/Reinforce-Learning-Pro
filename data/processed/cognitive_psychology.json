{
  "id": "cognitive_psychology",
  "title": "someTitle",
  "source_path": "C:\\Users\\intel\\Desktop\\Reinforce Learning Pro\\data\\raw\\cognitive_psychology.pdf",
  "pages": [
    "Created from usyd on 2022-02-13 13:17:53.",
    "“This edition of Eysenck and Keane has further enhanced the status of\nCognitive Psychology: A Student’s Handbook, as a high benchmark that\nother textbooks on this topic fail to achieve. It is informative and innova-\ntive, without losing any of its hallmark coverage and readability.”\nProfessor Robert Logie, School of Philosophy, Psychology and Language\nSciences, University of Edinburgh, United Kingdom\n“The best student’s handbook on cognitive psychology – an indispensable\nvolume brought up-to-date in this latest edition. It explains everything from\nlow-level vision to high-level consciousness, and it can serve as an introduc-\ntory text.”\nProfessor Philip Johnson-Laird, Stuart Professor of Psychology, Emeritus,\nPrinceton University, United States\n“I frst read Eysenck and Keane’s Cognitive Psychology: A Student’s\nHandbook in its third edition, during my own undergraduate studies. Over\nthe course of its successive editions since then, the content – like the feld of\ncognition itself – has evolved and grown to encompass current trends, novel\napproaches and supporting learning resources. It remains, in my opinion,\nthe gold standard for cognitive psychology textbooks.”\nDr Richard Roche, Senior Lecturer, Department of Psychology, Maynooth\nUniversity, Ireland\n“Eysenck and Keane have once again done an excellent job, not only in\nterms of keeping the textbook up-to-date with the latest studies, issues and\ndebates; but also by making the content even more accessible and clear\nwithout compromising accuracy or underestimating the reader’s intelligence.\nAfter all these years, this book remains an essential tool for students of cog-\nnitive psychology, covering the topic in the appropriate breadth and depth.”\nDr Gerasimos Markopoulos, Senior Lecturer, School of Science, Bath Spa\nUniversity, United Kingdom\n“Eysenck and Keane’s popular textbook ofers comprehensive coverage of\nwhat psychology students need to know about human cognition. The text-\nbook introduces the core topics of cognitive psychology that serve as the\nfundamental building blocks to our understanding of human behaviour.\nThe authors integrate contemporary developments in the feld and provide\nan accessible entry to neighboring disciplines such as cognitive neuroscience\nand neuropsychology.”\nDr Motonori Yamaguchi, Senior Lecturer, Department of Psychology,\nUniversity of Essex, United Kingdom\nCreated from usyd on 2022-02-13 13:20:04.",
    "“The eighth edition of Cognitive Psychology by Eysenck and Keane pro-\nvides possibly the most comprehensive coverage of cognition currently\navailable. The text is clear and easy to read with clear links to theory across\nthe chapters. A real highlight is the creative use of up-to-date real-world\nexamples throughout the book.”\nAssociate Professor Rhonda Shaw, Head of the School of Psychology,\nCharles Sturt University, Australia\n“Unmatched in breadth and scope, it is the authoritative textbook on cog-\nnitive psychology. It outlines the history and major developments within\nthe feld, while discussing state-of-the-art experimental research in depth.\nThe integration of online resources keeps the material fresh and engaging.”\nAssociate Professor Søren Risløv Staugaard, Department of Psychology and\nBehavioural Sciences, Aarhus University, Denmark\n“Eysenck and Keane’s Cognitive Psychology provides comprehensive topic\ncoverage and up-to-date research. The writing style is concise and easy to\nfollow, which makes the book suitable for both undergraduate and gradu-\nate students. The authors use real-life examples that are easily relatable to\nstudents, making the book very enjoyable to read.”\nAssociate Professor Lin Agler, School of Psychology, University of Southern\nMississippi Gulf Coast, United States\nCreated from usyd on 2022-02-13 13:20:04.",
    "Cognitive Psychology\nThe fully updated eighth edition of Cognitive Psychology: A Student’s\nHandbook provides comprehensive yet accessible coverage of all the key\nareas in the feld ranging from visual perception and attention through to\nmemory and language. Each chapter is complete with key defnitions, prac-\ntical real-life applications, chapter summaries and suggested further reading\nto help students develop an understanding of this fascinating but complex\nfeld.\nThe new edition includes:\n●\nan increased emphasis on neuroscience\n●\nupdated references to refect the latest research\n●\napplied ‘in the real world’ case studies and examples.\nWidely regarded as the leading undergraduate textbook in the feld of\ncognitive psychology, this new edition comes complete with an enhanced\naccompanying companion website. The website includes a suite of learning\nresources including simulation experiments, multiple-choice questions, and\naccess to Primal Pictures’ interactive 3D atlas of the brain. The companion\nwebsite can be accessed at: www.routledge.com/cw/eysenck.\nMichael W. Eysenck is Professor Emeritus in Psychology at Royal\nHolloway, University of London, United Kingdom. He is also Professorial\nFellow at Roehampton University, London. He is the best-selling author\nof several textbooks including Fundamentals of Cognition (2018), Memory\n(with Alan Baddeley and Michael Anderson, 2020) and Fundamentals of\nPsychology (2009).\nMark T. Keane is Chair of Computer Science at University College Dublin,\nIreland.\nCreated from usyd on 2022-02-13 13:20:18.",
    "www.routledge.com/cw/eysenck\nIncludes access to Primal Pictures’\ninteractive 3D brain\nVisit the Companion Website\nto access a range of interactive\nteaching and learning resources\nPRIMAL PICTURES\nRevolutionizing medical education with anatomical solutions to fit every need\nFor over 27 years, Primal Pictures has led the way in offering premier 3D digital human anatomy solutions,\ntransforming how educators teach and students learn the complexities of human anatomy and medicine.\nOur pioneering scientific approach puts quality, accuracy and detail at the heart of everything we do.\nPrimal’s experts have created the world’s most medically accurate and detailed 3D reconstruction of human\nanatomy using real scan data from the NLM Visible Human Project®, as well as CT images and MRIs. With\nadvanced academic research and thousands of development hours underpinning its creation, our model\nsurpasses all other anatomical resources available.\nTo learn more about Primal’s cutting-edge solution for better learning outcomes and increased student\nengagement visit www.primalpictures.com/students\nCreated from usyd on 2022-02-13 13:20:31.",
    "COGNITIVE PSYCHOLOGY\nA Student’s Handbook\nEighth Edition\nMICHAEL W. EYSENCK\nAND MARK T. KEANE\nCreated from usyd on 2022-02-13 13:20:52.",
    "Eighth edition published 2020\nby Routledge\n2 Park Square, Milton Park, Abingdon, Oxon OX14 4RN\nand by Routledge\n52 Vanderbilt Avenue, New York, NY 10017\n© 2020 Michael W. Eysenck and Mark T. Keane\nThe right of Michael W. Eysenck and Mark T. Keane to be\nidentifed as authors of this work has been asserted by them\nDesigns and Patents Act 1988.\nor reproduced or utilised in any form or by any electronic,\nmechanical, or other means, now known or hereafter\ninvented, including photocopying and recording, or in any\ninformation storage or retrieval system, without permission\nin writing from the publishers.\nTrademark notice: Product or corporate names may be\ntrademarks or registered trademarks, and are used only for\nidentifcation and explanation without intent to infringe.\nFirst edition published by Lawrence Erlbaum Associates 1984\nSeventh edition Published by Routledge 2015\nPlease advise the publisher of any errors or omissions, and\nthese will be corrected in subsequent editions.\nBritish Library Cataloguing-in-Publication Data\nA catalogue record for this book is available from the British Library\nLibrary of Congress Cataloging-in-Publication Data\nA catalog record has been requested for this book\nISBN: 978-1-13848-221-0 (hbk)\nISBN: 978-1-13848-223-4 (pbk)\nISBN: 978-1-35105-851-3 (ebk)\nTypeset in Times New Roman by\nServis Filmsetting Ltd, Stockport, Cheshire\nVisit the companion website: www.routledge.com/cw/eysenck.\nCreated from usyd on 2022-02-13 13:21:23.",
    "To Christine with love\n(M.W.E.)\nWhat moves science forward is argument, debate,\nand the testing of alternative theories . . . A science without\ncontroversy is a science without progress.\n(Jerry Coyne)\nCreated from usyd on 2022-02-13 13:22:39.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-13 13:22:39.",
    "Contents\nList of illustrations\nxiv\nPreface\nxxix\nVisual tour (how to use this book)\nxxxi\n1 Approaches to human cognition\n1\nIntroduction 1\nCognitive psychology 3\nCognitive neuropsychology 7\nCognitive neuroscience: the brain in action 12\nComputational cognitive science 26\nComparisons of major approaches 33\nIs there a replication crisis? 34\nOutline of this book 36\nChapter summary 37\nFurther reading 39\nPART I\nVisual perception and attention\n41\n2 Basic processes in visual perception\n43\nIntroduction 43\nVision and the brain 44\nTwo visual systems: perception-action model 55\nColour vision 64\nDepth perception 71\nPerception without awareness: subliminal perception 81\nChapter summary 90\nFurther reading 92\n3 Object and face recognition\n94\nIntroduction 94\nPattern recognition 95\nPerceptual organisation 96\nCreated from usyd on 2022-02-13 13:22:54.",
    "x\nContents\nApproaches to object recognition 103\nObject recognition: top-down processes 111\nFace recognition 116\nVisual imagery 130\nChapter summary 137\nFurther reading 139\n4  Motion perception and action\n140\nIntroduction 140\nDirect perception 141\nVisually guided movement 145\nVisually guided action: contemporary approaches 152\nPerception of human motion 157\nChange blindness 163\nChapter summary 175\nFurther reading 176\n5 Attention and performance\n178\nIntroduction 178\nFocused auditory attention 179\nFocused visual attention 183\nDisorders of visual attention 196\nVisual search 200\nCross-modal efects 208\nDivided attention: dual-task performance 212\n“Automatic” processing 226\nChapter summary 231\nFurther reading 233\nPART II\nMemory\n237\n6 Learning, memory and forgetting\n239\nIntroduction 239\nShort-term vs long-term memory 240\nWorking memory: Baddeley and Hitch 246\nWorking memory: individual diferences and executive\nfunctions 254\nLevels of processing (and beyond) 262\nLearning through retrieval 265\nImplicit learning 269\nForgetting from long-term memory 278\nChapter summary 293\nFurther reading 295\nCreated from usyd on 2022-02-13 13:22:54.",
    "Contents\nxi\n7 Long-term memory systems\n296\nIntroduction 296\nDeclarative memory 300\nEpisodic memory 305\nSemantic memory 313\nNon-declarative memory 325\nBeyond memory systems and declarative vs non-declarative\nmemory 332\nChapter summary 340\nFurther reading 342\n8 Everyday memory\n344\nIntroduction 344\nAutobiographical memory: introduction 346\nMemories across the lifetime 351\nTheoretical approaches to autobiographical memory 355\nEyewitness testimony 363\nEnhancing eyewitness memory 372\nProspective memory 375\nTheoretical perspectives on prospective memory 381\nChapter summary 389\nFurther reading 391\nPART III\nLanguage\n393\n9 Speech perception and reading\n403\nIntroduction 403\nSpeech (and music) perception 404\nListening to speech 408\nContext efects 412\nTheories of speech perception 417\nCognitive neuropsychology 429\nReading: introduction 432\nWord recognition 436\nReading aloud 442\nReading: eye-movement research 453\nChapter summary 457\nFurther reading 460\n10 Language comprehension\n461\nIntroduction 461\nParsing: overview 462\nTheoretical approaches: parsing and prediction 464\nPragmatics 478\nCreated from usyd on 2022-02-13 13:22:54.",
    "xii\nContents\nIndividual diferences: working memory capacity 487\nDiscourse processing: inferences 490\nDiscourse comprehension: theoretical approaches 498\nChapter summary 510\nFurther reading 512\n11 Language production\n514\nIntroduction 514\nBasic aspects of speech production 516\nSpeech planning 519\nSpeech errors 521\nTheories of speech production 525\nCognitive neuropsychology: speech production 536\nSpeech as communication 543\nWriting: the main processes 549\nSpelling 558\nChapter summary 564\nFurther reading 566\nPART IV\nThinking and reasoning\n569\n12 Problem solving and expertise\n573\nIntroduction 573\nProblem solving: introduction 574\nGestalt approach and beyond: insight and role of experience 576\nProblem-solving strategies 588\nAnalogical problem solving and reasoning 593\nExpertise 600\nChess-playing expertise 601\nMedical expertise 604\nBrain plasticity 609\nDeliberate practice and beyond 612\nChapter summary 619\nFurther reading 621\n13 Judgement and decision-making\n622\nIntroduction 622\nJudgement research 623\nTheories of judgement 633\nDecision-making under risk 640\nDecision-making: emotional and social factors 649\nApplied and complex decision-making 654\nChapter summary 663\nFurther reading 665\nCreated from usyd on 2022-02-13 13:22:54.",
    "Contents\nxiii\n14\nReasoning and hypothesis testing\n666\nIntroduction 666\nHypothesis testing 667\nDeductive reasoning 672\nTheories of “deductive” reasoning 680\nBrain systems in reasoning 690\nInformal reasoning 694\nAre humans rational? 701\nChapter summary 708\nFurther reading 710\nPART V\nBroadening horizons\n713\n15 Cognition and emotion\n715\nIntroduction 715\nAppraisal theories 719\nEmotion regulation 723\nAfect and cognition: attention and memory 730\nAfect and cognition: judgement and decision-making 738\nJudgement and decision-making: theoretical approaches 750\nAnxiety, depression and cognitive biases 753\nCognitive bias modifcation and beyond 761\nChapter summary 764\nFurther reading 766\n16 Consciousness\n767\nIntroduction 767\nFunctions of consciousness 768\nAssessing consciousness and conscious experience 775\nGlobal workspace and global neuronal workspace theories 783\nIs consciousness unitary? 792\nChapter summary 798\nFurther reading 799\nGlossary\n801\nReferences\n824\nAuthor index\n915\nSubject index\n931\nCreated from usyd on 2022-02-13 13:22:54.",
    "Illustrations\nTABLES\n1.1\nApproaches to human cognition\n3\n1.2\nMajor techniques used to study the brain\n16\n1.3\nStrengths and limitations of major approaches to human\ncognition\n35\n11.1\nInvolvement of working memory components in various\nwriting processes\n556\n15.1\nEfects of anxiety and depression on attentional bias\n(engagement and disengagement)\n757\nPHOTOS\nChapter 1\n•\nMax Coltheart\n8\n•\nThe magnetic resonance imaging (MRI) scanner\n18\n•\nTranscranial magnetic stimulation coil\n21\n•\nThe IBM Watson and two human contestants\n(Ken Jennings and Brad Rutter)\n27\nChapter 3\n•\nIrving Biederman\n107\n•\nHeather Sellers\n118\nChapter 6\n•\nAlan Baddeley and Graham Hitch\n246\n•\nEndel Tulving\n287\nChapter 7\n•\nHenry Molaison\n297\nChapter 8\n•\nJill Price\n348\n•\nWorld Trade Center attacks on 9/11\n349\n•\nJennifer Thompson and Ronald Cotton\n364\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxv\nChapter 11\n•\nIris Murdoch\n550\nChapter 12\n•\nMonty Hall\n575\n•\nFernand Gobet\n602\n•\nMagnus Carlsen\n613\nChapter 13\n•\nPat Croskerry\n625\n•\nNik Wallenda\n647\nFIGURES\n1.1\nAn early version of the information processing approach\n4\n1.2\nDiagram to demonstrate top–down processing\n4\n1.3\nTest yourself by naming the colours in each column\n5\n1.4\nThe four lobes, or divisions, of the cerebral cortex in the left\nhemisphere\n13\n1.5\nBrodmann brain areas on the lateral and medial surfaces\n13\n1.6\nThe brain network and cost efciency\n14\n1.7\nThe organisation of the “rich club”\n15\n1.8\nThe spatial and temporal resolution of major techniques and\nmethods used to study brain functioning\n17\n1.9\nAreas showing greater activation in a dead salmon when\npresented with photographs of people than when at rest\n25\n1.10 The primitive mock neuroimaging device used by Ali et al.\n(2014)\n26\n1.11 Architecture of a basic three-layer connectionist network\n28\n1.12 The main modules of the ACT-R cognitive architecture with\ntheir locations within the brain\n30\n1.13 The basic structure of the standard model of the mind\ninvolving fve independent modules\n31\n2.1\nComplex scene that requires prolonged perceptual processing\nto understand fully\n43\n2.2\nRoute of visual signals\n45\n2.3\nSimultaneous contrast involving lateral inhibition\n46\n2.4\nSome distinctive features of the largest visual cortical areas\n47\n2.5\nConnectivity within the ventral pathway on the lateral surface\nof the macaque brain\n48\n2.6\n(a) The single hierarchical model; (b) the parallel hierarchical\nmodel; (c) the three parallel hierarchical feedforward systems\nmodel\n49\n2.7\nThe percentage of cells in six diferent visual cortical areas\nresponding selectively to orientation, direction of motion,\ndisparity and colour\n52\n2.8\nVisual motion inputs\n53\n2.9\nGoodale and Milner’s (1992) perception-action model showing\nthe dorsal and ventral streams\n56\n2.10 Lesion overlap in patients with optic ataxia\n57\nCreated from usyd on 2022-02-13 13:23:12.",
    "xvi\nIllustrations\n2.11 The Müller-Lyer illusion\n58\n2.12 The Ebbinghaus illusion\n59\n2.13 The hollow-face illusion. Left: normal and hollow faces with\nsmall target magnets on the forehead and cheek of the normal\nface; right: front view of the hollow mask that appears as an\nillusory face projecting forwards\n60\n2.14 Disruption of size judgements when estimated perceptually\n(estimation) or produced by grasping (grasping) in full or\nrestricted vision\n61\n2.15 Historical developments in theories linking perception and\naction\n63\n2.16 Schematic diagram of the early stages of neural colour\nprocessing\n66\n2.17 Photograph of a mug showing enormous variation in the\nproperties of the refected light across the mug’s surface\n67\n2.18 “The Dress” made famous by its appearance on the internet\n69\n2.19 Observers’ perceptions of “The Dress”\n69\n2.20 An engraving by de Vries (1604/1970) in which linear\nperspective creates an efective three-dimensional efect\nwhen viewed from very close but not from further away\n72\n2.21 Examples of texture gradients that can be perceived as surfaces\nreceding into the distance\n73\n2.22 Kanizsa’s (1976) illusory square\n73\n2.23 Accuracy of size judgements as a function of object type\n78\n2.24 (a) A representation of the Ames room; (b) an actual Ames\nroom showing the efect achieved with two adults\n79\n2.25 Perceived distance. Top: stimuli presented to participants;\nbottom: example of the stimulus display\n81\n2.26 The body size efect: what participants in the doll experiment\ncould see\n81\n2.27 Estimated contributions of conscious and subconscious\nprocessing to GY’s performance in exclusion and inclusion\nconditions in his normal and blind felds\n84\n2.28 The areas of most relevance to blindsight are the lateral\ngeniculate nucleus and middle temporal visual area\n86\n2.29 The relationship between response bias in reporting conscious\nawareness and enhanced N200 on no-awareness correct trials\ncompared to no-awareness incorrect trials (UC)\n89\n3.1\nThe kind of stimulus used by Navon (1977) to demonstrate\nthe importance of global features in perception\n95\n3.2\nThe CAPTCHA used by Yahoo\n97\n3.3\nThe FBI’s mistaken identifcation of the Madrid bomber\n98\n3.4\nExamples of the Gestalt laws of perceptual organisation:\n(a) the law of proximity; (b) the law of similarity; (c) the law\nof good continuation; and (d) the law of closure\n99\n3.5\nAn ambiguous drawing that can be seen as either two faces\nor as a goblet\n100\n3.6\nThe tendency to perceive an array of empty circles as (A)\na rotated square or (B) a diamond\n101\n3.7\nA task to decide which region in each stimulus is the fgure\n102\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxvii\n3.8\nHigh and low spatial frequency versions of a place\n(a building)\n104\n3.9\nImage of Mona Lisa revealing very low spatial  frequencies\n(left), low spatial frequencies (centre) and high spatial\nfrequencies (right)\n105\n3.10 An outline of Biederman’s recognition-by-components theory\n107\n3.11 Ambiguous fgures\n112\n3.12 A brick wall that can be seen as something else\n114\n3.13 Object recognition involving two diferent routes: (1) a top-\ndown route in which information proceeds rapidly to the\norbitofrontal cortex; (2) a bottom-up route using the slower\nventral visual stream\n115\n3.14 Interactive-iterative framework for object recognition\n115\n3.15 Recognising an elephant when a key feature (its trunk) is\npartially hidden\n116\n3.16 Accuracy and speed of object recognition for birds, boats,\ncars, chairs and faces by patient GG and healthy controls\n120\n3.17 Face-selective areas in the right hemisphere\n121\n3.18 An array of 40 faces to be matched for identity\n124\n3.19 The model of face recognition put forward by Bruce and\nYoung (1986)\n126\n3.20 Damage to regions of the inferior occipito-temporal cortex,\nthe anterior inferior temporal cortex and the anterior\ntemporal pole\n127\n3.21 The approximate locations of the visual bufer in BA17 and\nBA18, of long-term memories of shapes in the inferior\ntemporal lobe, and of spatial representations in the posterior\nparietal cortex\n132\n3.22 Dwell time for the four quadrants of a picture during\nperception and imagery\n133\n3.23 Slezak’s (1991, 1995) investigations into the efects of rotation\non object recognition\n134\n3.24 The extent to which perceived or imagined objects could be\nclassifed accurately on the basis of brain activity in the early\nvisual cortex and object-selective cortex\n135\n3.25 Connectivity during perception and imagery involving\n(a) bottom-up processing; and (b) top-down processing\n135\n4.1\nThe optic-fow feld as a pilot comes in to land, with the focus\nof expansion in the middle\n142\n4.2\nGraspable and non-graspable objects having similar\nasymmetrical features\n143\n4.3\nThe visual features of a road viewed in perspective\n147\n4.4\nThe far road “triangle” in (A) a left turn and (B) a right\nturn\n148\n4.5\nErrors in time-to-contact judgements for the smaller and the\nlarger object as a function of whether they were presented in\ntheir standard size, the reverse size (of-size) or lacking texture\n(no-texture)\n150\n4.6\nThe dorso-dorsal and ventro-dorsal streams showing their\nbrain locations and forms of processing\n156\nCreated from usyd on 2022-02-13 13:23:12.",
    "xviii\nIllustrations\n4.7\nPoint-light sequences (a) with the walker visible and (b) with\nthe walker not visible\n157\n4.8\nHuman detection and discrimination efciency for human\nwalkers presented in contour, point lights, silhouette and\nskeleton\n158\n4.9\nBrain areas involved in biological motion processing\n159\n4.10 The main brain areas associated with the mirror neuron\nsystem plus their interconnections\n161\n4.11 The unicycling clown who cycled close to students walking\nacross a large square\n164\n4.12 The sequence of events in the disappearing lighter trick\n166\n4.13 Participants’ fxation points at the time of dropping the\nlighter\n166\n4.14 Change blindness: an example\n168\n4.15 (a) Percentage of correct change detection as a function of\nform of change and time of fxation; also false alarm rate when\nthere was no change. (b) Mean percentage correct change\ndetection as a function of the number of fxations between\ntarget fxation and change of target and form of change\n169\n4.16 (a) Change-detection accuracy as a function of task difculty\nand visual eccentricity. (b) The eccentricity at which change-\ndetection accuracy was 85% correct as a function of task\ndifculty\n170\n4.17 An example of inattentional blindness: a woman in a gorilla\nsuit in the middle of a game of passing the ball\n172\n4.18 An example of inattentional blindness: the sequence of events\non the initial baseline trials and the critical trial\n174\n5.1\nA comparison of Broadbent’s theory, Treisman’s theory, and\nDeutsch and Deutsch’s theory\n181\n5.2\nSplit attention. (a) Shaded areas indicate the cued locations;\nthe near and far locations are not cued. (b) Probability of\ntarget detection at valid (left or right) and invalid (near or\nfar) locations\n185\n5.3\nA comparison of object-based and space-based attention\n187\n5.4\nObject-based and space-based attention. (a) Possible target\nlocations for a given cue. (b) Performance accuracy at the\nvarious target locations\n188\n5.5\nSample displays for three low perceptual load conditions\nin which the task required deciding whether a target X or N\nwas presented\n190\n5.6\nThe brain areas associated with the dorsal or goal-directed\nattention network and the ventral or stimulus-driven network\n193\n5.7\nA theoretical approach based on several functional networks\nof relevance to attention: fronto-parietal; default mode;\ncingulo-opercular; and ventral attention\n195\n5.8\nAn example of object-centred or allocentric neglect\n197\n5.9\nIllegal and dangerous items captured by an airport security\nscreener\n201\n5.10 Frequency of selection and identifcation errors when targets\nwere present at trials\n201\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxix\n5.11  Performance speed on a detection task as a function of target\ndefnition (conjunctive vs single feature) and display size\n203\n5.12 Eye fxations made by observers searching for pedestrians\n204\n5.13 A two-pathway model of visual search\n205\n5.14 An example of a visual search task when considering feature\nintegration theory\n208\n5.15 An example of temporal ventriloquism in which the apparent\ntime of onset of a fash is shifted towards that of a sound\npresented at a slightly diferent timing from the fash\n210\n5.16 Wickens’s four-dimensional multiple-resource model\n216\n5.17 Threaded cognition theory\n218\n5.18 Patterns of brain activation: (a) underadditive activation;\n(b) additive activation; (c) overadditive activation\n220\n5.19 Efects of an audio distraction task on brain activity associated\nwith a straight driving task\n221\n5.20 Dual-task (auditory and visual tasks) and single-task (auditory\nor visual task) conditions: reaction times for correct responses\nonly over eight experimental sessions\n224\n5.21 Response times on a decision task as a function of\nmemory-set size, display-set size and consistent vs\nvaried mapping\n227\n5.22 Factors that are hypothesised to infuence representational\nquality within Moors’ (2016) theoretical approach\n229\n6.1\nThe multi-store model of memory as proposed by Atkinson\nand Shifrin (1968)\n240\n6.2\nShort-term memory performance in conditions designed to\ncreate interference (repeated condition) or minimise\ninterference (unique condition)\n243\n6.3\nThe working memory model showing the connections among\nits four components and their relationship to long-term\nmemory\n246\n6.4\nPhonological loop system as envisaged by Baddeley (1990)\n248\n6.5\nSites where direct electrical stimulation disrupted digit-span\nperformance\n249\n6.6\nAmount of interference on a spatial task and a visual task\nas a function of a secondary task (spatial: movement vs visual:\ncolour discrimination)\n250\n6.7\nScreen displays for the digit 6\n253\n6.8\nMean reaction times quintile-by-quintile on the anti-saccade\ntask by groups high and low in working memory capacity\n256\n6.9\nSchematic representation of the unity and diversity of three\nexecutive functions\n259\n6.10 Activated brain regions across all executive functions in a\nmeta-analysis of 193 studies\n260\n6.11 Recognition memory performance as a function of processing\ndepth (shallow vs deep) for three types of stimuli: doors,\nclocks, and menus\n263\n6.12 Distinctiveness. Percentage recall of the critical item\n(e.g., kiwi) and of the preceding and following items in the\nencoding, retrieval and control conditions\n264\nCreated from usyd on 2022-02-13 13:23:12.",
    "xx\nIllustrations\n6.13 (a) Restudy causes strengthening of the memory trace formed\nafter initial study; (b) testing with feedback causes strengthening\nof the memory trace; and (c) the formation of a second\nmemory trace\n266\n6.14 (a) Final recall for restudy-only and test-restudy group\nparticipants; (b) recall performance in the CMR group as a\nfunction of whether the mediators were or were not\nretrieved\n267\n6.15 Mean recall percentage in Session 2 on Test 1 and Test 2 as\nfunction of retrieval practice or restudy practice in Session 1\n268\n6.16 Schematic representation of a traditional keyboard\n270\n6.17 Mean number of completions in inclusion and exclusion\nconditions as a function of number of trials\n273\n6.18 Response times for participants showing a sudden drop\nin reaction times or not showing such a drop\n273\n6.19 The striatum is of central importance in implicit learning\n274\n6.20 A model of motor sequence learning\n275\n6.21 Sequential motor skill learning dependencies\n276\n6.22 Skilled typists’ performance when tested on a traditional\nkeyboard\n277\n6.23 Forgetting over time as indexed by reduced savings\n279\n6.24 Methods of testing for proactive and retroactive interference\n281\n6.25 Percentage of items recalled over time for the conditions:\nno proactive interference, remember and forget\n282\n6.26 Percentage of words correctly recalled across 32 articles\nin the respond, baseline and suppress conditions\n286\n6.27 Proportion of words recalled in high- and low-overload\nconditions with intra-list cues, strong extra-list cues and weak\nextra-list cues\n289\n7.1\nDamage to brain areas within and close to the medial\ntemporal lobes producing amnesia\n298\n7.2\nThe standard account based on dividing long-term memory\ninto two broad classes: declarative and non-declarative\n300\n7.3\nInteractions between episodic memories, semantic memories\nand gist memories\n305\n7.4\n(a) Locations of the hippocampus, the perirhinal cortex and\nthe parahippocampal cortex; (b) the binding-of-item-and-\ncontext model\n307\n7.5\n(A) Left lateral, (B), medial and (C) anterior views of\nprefrontal areas having greater activation to familiarity-based\nthan  recollection-based processes and areas showing the\nopposite pattern\n309\n7.6\nSample pictures on the recognition-memory test\n309\n7.7\n(A) Areas activated for both episodic simulation and episodic\nmemory; (B) areas more activated for episodic simulation than\nepisodic memory\n312\n7.8\nAccuracy of (a) object categorisation and (b) speed of\ncategorisation at the superordinate, basic and subordinate\nlevels\n315\n7.9\nThe hub-and-spoke model\n319\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxxi\n7.10 Performance accuracy on tool function and tool manipulation\ntasks with anodal transcranial direct current stimulation to the\nanterior temporal lobe or to the inferior parietal lobule and in\na control condition\n321\n7.11 Categorisation performance for pictures and words by\nhealthy controls and patients with semantic dementia\n324\n7.12 Percentages of priming efect and recognition-memory\nperformance of healthy controls and patients\n326\n7.13 Brain regions showing repetition suppression or response\nenhancement in a meta-analysis\n328\n7.14 Mean reaction times on the serial reaction time task by\nParkinson’s disease patients and healthy controls\n330\n7.15 A processing-based memory model\n334\n7.16 Recognition memory for faces presented and tested in a\nfxed or variable viewpoint\n335\n7.17 Brain areas whose activity during episodic learning predicted\nincreased recognition-memory performance (task-positive) or\ndecreased performance (task-negative)\n337\n7.18 A three-dimensional model of memory: (1) conceptually\nor perceptually driven; (2) relational or item stimulus\nrepresentation; (3) controlled or automatic/involuntary\nintention\n339\n7.19 Process-specifc alliances including the left angular gyrus are\ninvolved in recollection of episodic memories and semantic\nprocessing\n339\n8.1\nBrain regions activated by autobiographical, episodic retrieval\nand mentalising tasks including regions of overlap\n347\n8.2\nNumber of internal details specifc to an autobiographical\nevent recalled at various time delays (by controls and\nindividuals with highly superior autobiographical memory)\n348\n8.3\nChildhood amnesia based on data reported by Rubin and\nSchulkind (1997)\n352\n8.4\nTemporal distribution of autobiographical memories across\nthe lifespan\n354\n8.5\nThe knowledge structures within autobiographical memory,\nas proposed by Conway (2005)\n357\n8.6\nThe mean number of events participants could remember from\nthe past 5 days and those they imagined were likely over the\nnext 5 days\n358\n8.7\nA model of the bidirectional relationships between neural\nnetworks involved in the construction and/or elaboration of\nautobiographical memories\n360\n8.8\nLife structure scores (proportion negative,\ncompartmentalisation, positive redundancy, negative\nredundancy) for patients with major depressive disorder,\npatients in remission from major  depressive disorder\nand healthy controls\n361\n8.9\nFour cognitive biases related to autobiographical memory\nrecall that maintain depression and increase the risk of\nrecurrence  following remission\n362\nCreated from usyd on 2022-02-13 13:23:12.",
    "xxii\nIllustrations\n8.10 Examples of Egyptian and UK face-matching arrays\n366\n8.11 Size of the misinformation efect as a function of detail\nmemorability in the neutral condition\n367\n8.12 Extent of misinformation efects as a function of condition\nfor the original memory and endorsement of the\nmisinformation presented previously\n371\n8.13 Eyewitness identifcation: test of face-recognition\nperformance\n371\n8.14 A model of the component processes involved in prospective\nmemory\n378\n8.15 Mean failures to resume an interrupted task and mean\nresumption times for the conditions: no-interruption,\nblank-screen interruption and secondary air trafc control\ntask interruption\n379\n8.16 Self-reported memory vividness, memory details and\nconfdence in memory for individuals with good and poor\ninhibitory control before and after repeated checking\n381\n8.17 The dual-pathways model of prospective memory (based\non the multi-process framework) for non-focal and focal tasks\nseparately\n383\n8.18 Example 1: top-down monitoring processes operating in\nisolation. Example 2: bottom-up spontaneous retrieval processes\noperating in isolation. Example 3: dual processes operating\ndynamically\n383\n8.19 (a) Sustained and (b) transient activity in the (c) left anterior\nprefrontal cortex for non-focal and focal prospective memory\ntasks\n385\n8.20 Frequency of cue-driven monitoring following the presentation\nof semantically related or unrelated cues\n386\n8.21 Diferent ways the instruction to press Q for fruit words was\nencoded\n388\n9.1\n(a) Areas activated during passive music listening and passive\nspeech listening; (b) areas activated more by listening to music\nthan speech or the opposite\n406\n9.2\nThe main processes involved in speech perception and\ncomprehension\n407\n9.3\nA hierarchical approach to speech segmentation involving\nthree levels or tiers\n410\n9.4\nA model of spoken-word comprehension\n412\n9.5\nGaze probability for critical objects over the frst 1,000 ms\nsince target word onset for target neutral, competitor\nneutral, competitor constraining and unrelated neutral\nconditions\n414\n9.6\nMean target duration required for target recognition for words\nand sounds presented in isolation or within a general sentence\ncontext\n420\n9.7\nThe basic TRACE model, showing how activation between the\nthree levels (word, phoneme and feature) is infuenced by\nbottom-up and top-down processing.\n421\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxxiii\n9.8\n(a) Actual eye fxations on the object corresponding to a\nspoken word or related to it; (b) predicted eye fxations from\nthe TRACE model\n422\n9.9\nMean reaction times for recognition of /t/ and /k/ phonemes\nin words and non-words\n423\n9.10 Fixation proportions to high-frequency target words during\nthe frst 1,000 ms after target onset\n428\n9.11 A sample display showing two nouns (“bench” and “rug”)\nand two verbs (“pray” and “run”).\n428\n9.12 Processing and repetition of spoken words according to the\nthree-route framework\n430\n9.13 A general framework of the processes and structures involved\nin reading comprehension\n433\n9.14 Estimated reading ability over a 30-month period with initial\ntesting at a mean age of 66 months for English, Spanish and\nCzech children\n434\n9.15 McClelland and Rumelhart’s (1981) interactive activation\nmodel of visual word recognition\n437\n9.16 The time course of inhibitory and facilitatory efects of\npriming\n440\n9.17 Basic architecture of the dual-route cascaded model\n443\n9.18 The three components of the triangle model and their\nassociated neural regions: orthography, phonology\nand semantics\n448\n9.19 Mean naming latencies for high-frequency and\nlow-frequency words that were irregular or regular\nand inconsistent\n451\n9.20 Key assumptions of the E-Z Reader model\n455\n10.1\nTotal sentence processing time as a function of sentence\ntype\n471\n10.2\nA model of language processing involving heuristic and\nalgorithmic routes\n473\n10.3\nSentence reading times as a function of the way in which\ncomprehension was assessed: detailed questions; superfcial\nquestions on all trials; or occasional superfcial questions\n474\n10.4\nThe N400 responses to a critical word in correct and\nincorrect sentences\n476\n10.5\nResponse times for literally false, scrambled metaphor, and\nmetaphor sentences in (a) written and (b) spoken conditions)\n480\n10.6\nMean reaction times to verify metaphor-relevant and\nmetaphor-irrelevant properties\n482\n10.7\nMean proportion of statements rated comprehensible with a\nresponse deadline of 500 or 1600 ms: literal, forward\nmetaphors, reversed metaphors and scrambled metaphors\n483\n10.8\nSample displays seen from the listener’s perspective\n485\n10.9\nProportion of fxation on four objects over time\n486\n10.10 A theoretical framework for reading comprehension\ninvolving interacting passive and reader-initiated\nprocesses\n492\nCreated from usyd on 2022-02-13 13:23:12.",
    "xxiv\nIllustrations\n10.11 Reaction times to name colours when the word presented in\ncolour was predictable from the preceding text compared to a\ncontrol condition\n496\n10.12 The construction–integration model\n502\n10.13 Forgetting functions for situation, proposition and surface\ninformation over a 4-day period\n503\n10.14 The RI-Val model showing the efects on comprehension of\nresonance, integration and validation over time\n506\n11.1\nBrain areas activated during speech comprehension and\nproduction\n517\n11.2\nCorrelations between aphasic patients’ speech-production\nabilities and their ability to detect their own speech-production\nerrors\n524\n11.3\nSpeech-production processes for picture naming, with\nmedian peak activation times\n532\n11.4\nSpeech-production processes: the timing of activation\nassociated with diferent cognitive functions\n534\n11.5\nLanguage-related regions and their connections in the left\nhemisphere\n536\n11.6\nSemantic and syntactic errors made by: healthy controls and\npatients with no damage to the dorsal or ventral pathway,\ndamage to the ventral pathway only, damage to the dorsal\npathway only and damage to both pathways\n540\n11.7\nA sample array with six diferent garments coloured blue\nor green\n544\n11.8\nArchitecture of the forward modelling approach to explaining\naudience design efects\n546\n11.9\nHayes’ (2012) writing model: (1) control level; (2) writing\nprocess level; and (3) resource level\n552\n11.10 The frequency of three major writing processes (planning,\ntranslating and revising) across the three phases of writing\n553\n11.11 Kellogg’s three-stage theory of the development of\nwriting skill\n554\n11.12 Brain areas activated during handwriting tasks\n559\n11.13 The cognitive architectures for (a) reading and (b) spelling\n560\n11.14 Brain areas in the left hemisphere associated with reading,\nletter perception and writing\n563\n12.1\nExplanation of the solution to the Monty Hall problem\n575\n12.2\nBrain areas involved in (a) mathematical problem solving; (b)\nverbal problem solving; (c) visuo-spatial problem solving; and\n(d) areas common to all three problem types (conjunction)\n577\n12.3\nThe mutilated draughtboard problem\n577\n12.4\nFlow chart of insight problem solving\n580\n12.5\n(a) The nine-dot problem and (b) its solution\n580\n12.6\nTwo of the matchstick problems used by Knoblich et al. (1999)\nwith cumulative solution rates\n581\n12.7\nThe multiplying billiard balls trick\n582\n12.8\nThe two-string problem\n583\n12.9\nSome of the materials for participants instructed to mount a\ncandle on a vertical wall in Duncker’s (1945) study\n585\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxxv\n12.10 Mean percentages of correct solutions as a function of\nproblem type and working memory capacity\n587\n12.11 The initial state of the fve-disc version of the Tower of Hanoi\nproblem\n588\n12.12 Tower of London task (two-move and fve-move problems)\n590\n12.13 A problem resembling those used on the Raven’s Progressive\nMatrices\n594\n12.14 Relational reasoning: the probabilities of successful encoding,\ninferring, mapping and applying for lower and high\nperformers\n597\n12.15 Major processes involved in performance of numerous\ncognitive tasks\n598\n12.16 Summary of key brain regions and their associated functions\nin relational reasoning based on patient and neuroimaging\nstudies\n599\n12.17 Mean strength of the frst-mentioned chess move and the\nmove chosen as a function of problem difculty by experts\nand by tournament players\n603\n12.18 A theoretical framework of the main cognitive processes and\npotential errors in medical decision-making\n605\n12.19 Eye fxations of a pathologist given the same biopsy\nwhole-slide image (a) starting in year 1 and (d) ending\nin year 4\n606\n12.20 Brain activation while diagnosing lesions in X-rays, naming\nanimals and naming letters\n608\n12.21 Brain image showing areas in the primary motor cortex with\ndiferences in relative voxel size between trained children and\nnon-trained controls: (a) changes in relative voxel size over time;\n(b) correlation between improvement in motor-test performance\nand change in relative voxel size\n611\n12.22 Brain image showing areas in the primary auditory area with\ndiferences in relative voxel size between trained children and\nnon-trained controls: (a) changes in relative voxel size over time;\n(b) correlation between improvement in a melody-rhythm test\nand change in relative voxel size\n612\n12.23 Mean chess ratings of candidates, non-candidate grandmasters\nand all non-grandmasters as a function of number of games\nplayed\n616\n12.24 The main factors (genetic and environmental) infuencing the\ndevelopment of expertise\n617\n13.1\nPercentages of correct responses and various incorrect\nresponses with the false-positive and benign cyst scenarios\n627\n13.2\nPercentage of correct predictions of the judged frequencies of\ndiferent causes of death based on the afect heuristic (overall\ndread score), afect heuristic and availability\n628\n13.3\nPercentage of correct inferences on four tasks\n632\n13.4\nA hypothetical value function\n642\n13.5\nRatings of competence satisfaction for the sunk-cost option\nand the alternative option for those selecting each option\n644\nCreated from usyd on 2022-02-13 13:23:12.",
    "xxvi\nIllustrations\n13.6\nRisk aversion for gains and risk seeking for losses on a\nmoney-based task by fnancial professionals and students\n645\n13.7\nPercentages of participants adhering to cumulative prospect\ntheory, the minimax rule, or unclassifed with afect-poor and\nafect-rich problems (a) with or (b) without numerical\ninformation concerning willingness to pay for\nmedication\n650\n13.8\nProportion of politicians and population samples in Belgium,\nCanada and Israel voting to extend a loan programme\n654\n13.9\nA model of selective exposure: defence motivation and\naccuracy motivation\n659\n13.10 The fve phases of decision-making according to Galotti’s\ntheory\n660\n13.11 Klein’s recognition-primed decision model\n661\n14.1\nMean number of modus ponens inferences accepted as a\nfunction of relative strength of the evidence and strategy\n676\n14.2\nThe Wason selection task\n676\n14.3\nPercentage acceptance of conclusions as a function of\nperceived base rate (low vs high), believability of conclusions\nand validity of conclusions\n679\n14.4\nThree models of the relationship between the intuitive and\ndeliberate systems: (a) serial model; (b) parallel model;\nand (c) logical intuition model\n685\n14.5\nProportion correct on incongruent syllogisms as a function of\ninstructions and cognitive ability\n687\n14.6\nThe approximate time courses of reasoning and meta-\nreasoning processes during reasoning and problem solving\n689\n14.7\nBrain regions most consistently activated across 28 studies of\ndeductive reasoning\n690\n14.8\nRelationships between reasoning task performance (accuracy)\nand inferior frontal cortex activity in the left hemisphere and\nthe right hemisphere in (a) the low-load condition and (b) the\nhigh-load condition\n692\n14.9\nMean responses to the question, “How much risk do you\nbelieve climate change poses to human health, safety or\nprosperity?”\n696\n14.10 Efects of trustworthiness and others’ opinions on\nconvincingness ratings\n700\n14.11 Mean-rated argument strength as a function of the probability\nof the outcome and how negative the outcome would be\n701\n14.12 Stanovich’s tripartite model of reasoning\n706\n15.1\nThe two-dimensional framework for emotion showing the two\ndimensions of pleasure–misery and arousal–sleep and the two\ndimensions of positive afect and negative afect\n716\n15.2\nBrain areas activated by positive, negative and neutral stimuli  717\n15.3\nBrain areas showing greater activity for top-down than for\nbottom-up processing and those showing greater activity for\nbottom-up than for top-down processes\n718\n15.4\nMultiple appraisal mechanisms used in emotion generation\n720\nCreated from usyd on 2022-02-13 13:23:12.",
    "Illustrations\nxxvii\n15.5\nChanges in self-reported horror and distress and in galvanic\nskin response between pre-training and post-training (for the\nwatch condition and the appraisal condition)\n721\n15.6\nA process model of emotion regulation based on fve major\ntypes of strategy (situation selection, situation modifcation,\nattention deployment, cognitive change and response\nmodulation)\n725\n15.7\nMean level of depression as a function of stress severity and\ncognitive reappraisal ability\n727\n15.8\nA three-stage neural network model of emotion regulation\n728\n15.9\nThe incompatibility fanker efect (incompatible trials –\ncompatible trials) on reaction times as a function of mood\n(happy or sad) and whether a global, local or mixed focus\nhad been primed on a previous task\n733\n15.10 Two main brain mechanisms involved in the memory-\nenhancing efects of emotion: (1) the medial temporal\nlobes; (2) the medial, dorsolateral and ventrolateral\nprefrontal cortex\n735\n15.11 (a) Free and (b) cued recall as a function of mood state\n(happy or sad) at learning and at recall\n737\n15.12 Two well-known moral dilemma problems: (a) the trolley\nproblem; and (b) the footbridge problem\n738\n15.13 The dorsolateral prefrontal cortex, located approximately in\nBrodmann areas 9 and 46 and the ventromedial prefrontal\ncortex located approximately in Brodmann areas 10 and 11\n739\n15.14 Sensitivity to consequences, sensitivity to moral norms and\npreference for inaction vs action as a function of psychopathy\n(low vs high)\n741\n15.15 Driverless cars: moral decisions\n742\n15.16 Efects of mood manipulation (anxiety, sadness or neutral)\non percentages of people choosing a high-risk job option\n745\n15.17 Mean buying price for a water bottle as a function of mood\n(neutral vs sad) and self-focus (low vs high)\n746\n15.18 The positive emotion “family tree” with the trunk representing\nthe neural reward system and the branches representing nine\nsemi-distinct positive emotions\n748\n15.19 Probability of selecting a candy bar by participants in a happy\nor sad mood as a function of implicit attitudes on the Implicit\nAssociation Test\n750\n15.20 Efects of mood states on judgement and decision-making.\n750\n15.21 The emotion-imbued choice model\n752\n15.22 The dot-probe task\n756\n15.23 The emotional Stroop task\n756\n15.24 The impaired cognitive control account put forward by\nJoormann et al. (2007)\n761\n16.1\nMean scores for error detection on a proofreading task\ncomparing unconscious goal vs no-goal control and low vs.\nhigh goal importance\n770\n16.2\nAwareness as a social perceptual model of attention\n771\nCreated from usyd on 2022-02-13 13:23:12.",
    "xxviii\nIllustrations\n16.3\n(a) Region in left fronto-polar cortex for which decoding of\nupcoming motor decisions was possible. (b) Decoding\naccuracy of these decisions\n774\n16.4\nUndistorted and distorted photographs of the Brunnen der\nLebensfreude in Rostock, Germany\n777\n16.5\nModulation of the appropriate frequency bands of the EEG\nsignal associated with motor imagery in one healthy control\nand three patients\n779\n16.6\nActivation patterns on a binocular-rivalry task when observers\n(A) reported what they perceived or (B) passively experienced\nrivalry\n781\n16.7\nThree successive stages of visual processing following\nstimulus presentation\n782\n16.8\nPercentage of trials on which participants reported\nawareness of the content of photographs under masked\nand unmasked conditions for animal and non-animal\nphotographs\n783\n16.9\nFive hypotheses about the relationship between\nattention and conscious awareness identifed by Webb\nand Graziano\n785\n16.10 Event-related potential waveforms in the aware-correct,\nunaware-correct and unaware-incorrect conditions\n786\n16.11 Synchronisation of neural activity across cortical areas for\nconsciously perceived words (visible condition) and non-\nperceived words (invisible condition) during diferent time\nperiods\n787\n16.12 Integrated brain activity: (a) overall information sharing or\nintegration across the brain for vegetative state, minimally\nconscious and conscious brain-damaged patients and healthy\ncontrols); (b) information sharing (integration) across short,\nmedium and long distances within the brain for the four\ngroups\n788\n16.13 Event-related potentials in the left and right hemispheres\nto the frst of two stimuli by AC (a patient with\nsevere corpus callosum damage)\n796\n16.14 Detection and localisation of circles presented to the left\nor right visual felds by two patients responding verbally,\nwith the left or right hand\n797\nCreated from usyd on 2022-02-13 13:23:12.",
    "Preface\nProducing regular editions of this textbook gives us a front-row seat from\nwhich to observe all the exciting developments in our understanding of\nhuman cognition. What are the main reasons for the rapid rate of progress\nwithin cognitive psychology since the seventh edition of this textbook?\nBelow we identify two factors that have been especially important.\nFirst, the overarching assumption that the optimal way to enhance our\nunderstanding of cognition is by combining data and insights from several\ndiferent approaches remains exceptionally fruitful. These approaches\ninclude traditional cognitive psychology; cognitive neuropsychology (study\nof brain-damaged patients); computational cognitive science (development\nof computational models of human cognition); and cognitive neuroscience\n(combining information from behaviour and from brain activity). Note\nthat we use the term “cognitive psychology” in a broad or general sense to\ncover all these approaches.\nThe above approaches all continue to make extremely valuable con-\ntributions. However, cognitive neuroscience deserves to be singled out  –\nit has increasingly been used with great success to resolve theoretical\ncontroversies and to provide novel empirical data that foster theoretical\ndevelopments.\nSecond, there has been a steady increase in cognitive research of\ndirect relevance to real life. This is refected in a substantial increase in\nthe number of boxes labelled “in the real world” in this edition com-\npared to the previous one. Examples include eyewitness confdence, mis-\nhearing of song lyrics, multi-tasking, airport security checks and causes of\nplane crashes. What is noteworthy is the increased quality of real-world\nresearch (e.g., more sophisticated experimental designs; enhanced theoret-\nical relevance).\nWith every successive edition of this textbook, the authors have had\nto work harder and harder to keep with huge increase in the number of\nresearch publications in cognitive psychology. For example, the frst author\nwrote parts of the book in far-fung places including Botswana, New\nZealand, Malaysia and Cambodia. His only regret is that book writing has\nsometimes had to take precedence over sightseeing!\nWe would both like to thank the very friendly and efcient staf at\nPsychology Press including Sadé Lee and Ceri McLardy.\nCreated from usyd on 2022-02-13 13:23:26.",
    "xxx\nPreface\nWe would also like to thank the anonymous reviewers, that  commented\non various chapters. Their comments were very useful when we embarked\non the task of revising the frst draft of the manuscript. Of course, we are\nresponsible for any errors and/or misunderstandings that remain.\nMichael Eysenck and Mark Keane\nCreated from usyd on 2022-02-13 13:23:26.",
    "Visual tour\n(how to use this book)\nTEXTBOOK FEATURES\nListed below are the various pedagogical features that can be found both in\nthe margins and within the main text, with visual examples of the boxes to\nlook out for, and descriptions of what you can expect them to contain.\nKey terms\nThroughout the book, key terms are highlighted in the text and defned in\nboxes in the margins, helping you to get to grips with the vocabulary funda-\nmental to the subject being covered.\nIn the real world\nEach chapter contains boxes within the main text that explore “real world”\nexamples, providing context and demonstrating how some of the theories\nand concepts covered in the chapter work in practice.\nChapter summary\nEach chapter concludes with a brief summary of each section of the chapter,\nhelping you to consolidate your learning by making sure you have taken in\nall of the concepts covered.\nFurther reading\nAlso at the end of each chapter is an annotated list of key scholarly books,\nbook chapters, and journal articles that it is recommended you explore\nthrough independent study to expand upon the knowledge you have gained\nfrom the chapter and plan for your assignments.\nCreated from usyd on 2022-02-13 13:24:14.",
    "xxxii\nVisual tour (how to use this book)\nLinks to companion website features\nWhenever you see this symbol, look out for related supplementary material\namongst the resources for that chapter on the companion website at www.\nroutledge.com/cw/eysenck.\nGlossary\nAn extensive glossary appears at the end of the book, ofering a compre-\nhensive list that includes all the key terms boxes in the main text.\nCreated from usyd on 2022-02-13 13:24:14.",
    "Approaches to\nhuman cognition\nINTRODUCTION\nWe are now well into the third millennium and there is ever-increasing\ninterest in unravelling the mysteries of the human brain and mind. This\ninterest is refected in the substantial upsurge of scientifc research within\ncognitive psychology and cognitive neuroscience. In addition, the cognitive\napproach has become increasingly infuential within clinical psychology.\nIn that area, it is recognised that cognitive processes (especially cognitive\nbiases) play a major role in the development (and successful treatment) of\nmental  disorders (see Chapter 15).\nIn similar fashion, social psychologists increasingly focus on social\ncognition. This focuses on the role of cognitive processes in infuencing\nindividuals’ behaviour in social situations. For example, suppose other\npeople respond with laughter when you tell them a joke. This laughter\nis often ambiguous  – they may be laughing with you or at you (Walsh\net al., 2015). Your subsequent behaviour is likely to be infuenced by your\ncognitive interpretation of their laughter.\nWhat is cognitive psychology? It is concerned with the internal pro-\ncesses involved in making sense of the environment and deciding on\nappropriate action. These processes include attention, perception, learn-\ning, memory, language, problem solving, reasoning and thinking. We can\ndefne cognitive psychology as aiming to understand human cognition\nby observing the behaviour of people performing various cognitive tasks.\nHowever, the term “cognitive psychology” can also be used more broadly\nto include brain activity and structure as relevant information for under-\nstanding human cognition. It is in this broader sense that it is used in the\ntitle of this book.\nHere is a simple example of cognitive psychology in action. Frederick\n(2005) developed a test (the Cognitive Refection Test) that included the\nfollowing item:\nA bat and a ball cost $1.10 in total. The bat costs $1.00 more than the\nball. How much does the ball cost? ___ cents\nChapter\n1\nKEY TERMS\nSocial cognition\nAn approach within social\npsychology in which\nthe emphasis is on the\ncognitive processing\nof information about\nother people and social\nsituations.\nCognitive psychology\nAn approach that aims\nto understand human\ncognition by the study\nof behaviour; a broader\ndefnition also includes\nthe study of brain activity\nand structure.\nCreated from usyd on 2022-02-13 13:24:37.",
    "2\nApproaches to human cognition\nWhat do you think is the correct answer? Braňas-Garza et al. (2015)\nfound in a review of fndings from 41,004 individuals that 68% produced\nthe wrong answer (typically 10 cents) and only 32% gave the right answer\n(5 cents). Even providing fnancial incentives to produce the correct answer\nfailed to improve performance.\nThe above fndings suggest most people will rapidly produce an incor-\nrect answer (i.e., 10 cents) that is easily accessible and are unwilling to\ndevote extra time to checking that they have the right answer. However,\nGangemi et al. (2015) found many individuals producing the wrong\nanswer had a feeling of error suggesting they experienced cognitive uneas-\niness about their answer. In sum, the intriguing fndings on the Cognitive\nRefection Test indicate that we can fail to think efectively even on rela-\ntively simple problems. Subsequent research has clarifed the reasons for\nthese defciencies in our thinking (see Chapter 12).\nThe aims of cognitive neuroscientists overlap with those of cognitive\npsychologists. However, there is one major diference between cognitive\nneuroscience and cognitive psychology in the narrow sense. Cognitive neu-\nroscientists argue convincingly we need to study the brain as well as behav-\niour while people engage in cognitive tasks. After all, the internal processes\ninvolved in human cognition occur in the brain. Cognitive neuroscience\nuses information about behaviour and the brain to understand human cog-\nnition. Thus, the distinction between cognitive neuroscience and cognitive\npsychology in the broader sense is blurred.\nCognitive neuroscientists explore human cognition in several ways.\nFirst, there are brain-imaging techniques of which functional magnetic\nresonance imaging (fMRI) is probably the best-known. Second, there are\nelectrophysiological techniques involving the recording of electrical signals\ngenerated by the brain. Third, many cognitive neuroscientists study the\nefects of brain damage on cognition. It is assumed the patterns of cog-\nnitive impairment shown by brain-damaged patients can inform us about\nnormal cognitive functioning and the brain areas responsible for various\ncognitive processes.\nThe huge increase in scientifc interest in the workings of the brain\nis mirrored in the popular media – numerous books, flms and television\nprogrammes communicate the more accessible and dramatic aspects of\ncognitive neuroscience. Increasingly, media coverage includes coloured pic-\ntures of the brain indicating the areas most activated when people perform\nvarious tasks.\nFour main approaches\nWe can identify four main approaches to human cognition (see Table 1.1).\nNote, however, there has been a substantial increase in research combin-\ning two (or even more) of these approaches. We will shortly discuss each\napproach in turn and you will probably fnd it useful to refer back to\nthis chapter when reading the rest of the book. Hopefully, you will fnd\nTable 1.3 (towards the end of this chapter) especially useful because it sum-\nmarises the strengths and limitation of all four approaches.\nKEY TERM\nCognitive neuroscience\nAn approach that aims\nto understand human\ncognition by combining\ninformation from\nbehaviour and the brain.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n3\nCOGNITIVE PSYCHOLOGY\nWe can obtain some perspective on the contribution of cognitive  psychology\nby considering what preceded it. Behaviourism was the dominant approach to\npsychology throughout the frst half of the twentieth century. The American\npsychologist John Watson (1878–1958) is often regarded as the founder of\nbehaviourism. He argued that psychologists should focus on stimuli (aspects\nof the immediate situation) and responses  (behaviour  produced by the par-\nticipants in an experiment). This approach appears “scientifc” because it\nfocuses on stimuli and responses, both of which are observable.\nBehaviourists argued that internal mental processes (e.g., attention)\ncannot be verifed by reference to observable behaviour and so should be\nignored. According to Watson (1913, p. 165), behaviourism should “never\nuse the terms consciousness, mental states, mind, content, introspectively\nverifable and the like”. In stark contrast, as we have already seen, cogni-\ntive psychologists argue it is of crucial importance to study such internal\nmental processes. Hopefully, you will be convinced that cognitive psycholo-\ngists are correct when you read how the concepts of attention (Chapter 5)\nand consciousness (Chapter 16) have been used fruitfully to enhance our\nunderstanding of human cognition.\nIt is often claimed that behaviourism was overthrown by the “cog-\nnitive revolution”. However, the reality was less dramatic (Hobbs &\nBurman, 2009). For example, Tolman (1948) was a behaviourist but he did\nnot believe internal processes should be ignored. He carried out studies in\nwhich rats learned to run through a maze to a goal box containing food.\nWhen Tolman blocked of the path the rats had learned to use, they rapidly\nlearned to follow other paths leading in the right general direction. Tolman\nconcluded the rats had acquired an internal cognitive map indicating the\nmaze’s approximate layout.\nIt is almost as pointless to ask “When did cognitive psychology start?”,\nas to enquire “How long is a piece of string?”. However, 1956 was crucially\nTABLE 1.1 APPROACHES TO HUMAN COGNITION\n1.\nCognitive psychology: this approach involves using behavioural evidence to\nenhance our understanding of human cognition. Since behavioural data are also\nof great importance within cognitive neuroscience and cognitive neuropsychology,\ncognitive psychology’s infuence is enormous.\n2.\nCognitive neuropsychology: this approach involves studying brain-damaged\npatients to understand normal human cognition. It was originally closely linked\nto cognitive psychology but has recently also become linked to cognitive\nneuroscience.\n3.\nCognitive neuroscience: this approach involves using evidence from behaviour and\nthe brain to understand human cognition.\n4.\nComputational cognitive science: this approach involves developing computational\nmodels to further our understanding of human cognition; such models increasingly\nincorporate knowledge of behaviour and the brain. A computational model takes\nthe form of an algorithm, which consists of a precise and detailed specifcation of\nthe steps involved in performing a task. Computational models are designed to\nsimulate or imitate human processing on a given task.\nKEY TERM\nAlgorithm\nA computational\nprocedure providing a\nspecifed set of steps to\nproblem solution; see\nheuristic.\nCreated from usyd on 2022-02-13 13:24:37.",
    "4\nApproaches to human cognition\nimportant. At a meeting at the Massachusetts Institute of Technology,\nNoam Chomsky presented his theory of language, George Miller discussed\nthe magic number seven in short-term memory (Miller, 1956) and Alan\nNewell and Herbert Simon discussed the General Problem Solver (see\nGobet and Lane, 2015). In addition, there was the frst systematic attempt\nto study concept formation from the cognitive perspective (Bruner et al.,\n1956). The history of cognitive psychology from the perspective of its\nclassic studies is discussed in Eysenck and Groome (2015a).\nSeveral decades ago, most cognitive psychologists subscribed to the\ninformation-processing approach based loosely on an analogy between\nthe mind and the computer (see Figure 1.1). A stimulus (e.g., a problem\nor task) is presented, which causes various internal processes to occur,\nleading eventually to the desired response or answer. Processing directly\nafected by the stimulus input is often described as bottom-up processing.\nIt was typically assumed only one process occurs at a time: this is serial\nprocessing, meaning the current process is completed before the onset of\nthe next one.\nThe above approach is drastically over-\nsimplifed. Task processing typically also\ninvolves top-down processing, which is pro-\ncessing infuenced by the individual’s expec-\ntations and knowledge rather than simply by\nthe stimulus itself. Read what it says in the\ntriangle (Figure 1.2). Unless you know the\ntrick, you probably read it as “Paris in the\nspring”. If so, look again: the word “the”\nis repeated. Your expectation it was a well-\nknown phrase (i.e., top-down processing)\ndominated the information available from the\nstimulus (i.e., bottom-up processing).\nThe traditional approach was also over-\nsimplifed in assuming processing is typically\nserial. In fact, more than one process typi-\ncally occurs at the same time – this is parallel\nprocessing. We are much more likely to use\nparallel processing when performing a highly\npractised task than a new one (see Chapter\n5). For example, someone taking their frst\ndriving lesson fnds it very hard to control the\ncar’s speed, steer accurately and pay attention\nto other road users at the same time. In con-\ntrast, an experienced driver fnds it easy.\nThere is also cascade processing: a\nform of parallel processing involving an\noverlap of diferent processing stages when\nsomeone performs a task. More specifcally,\nlater stages of processing are initiated before\none or more earlier stages have fnished. For\nexample, suppose you are trying to work out\nthe meaning of a visually presented word.\nFigure 1.1\nAn early version of the information processing approach.\nFigure 1.2\nDiagram to demonstrate top–down processing.\nKEY TERMS\nBottom-up processing\nProcessing directly\ninfuenced by\nenvironmental stimuli; see\ntop-down processing.\nSerial processing\nProcessing in which one\nprocess is completed\nbefore the next one starts;\nsee parallel processing.\nTop-down processing\nStimulus processing that\nis infuenced by factors\nsuch as the individual’s\npast experience and\nexpectations.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n5\nThe most thorough approach would involve identifying all the letters in the\nword followed by matching the resultant letter string against words you\nhave stored in long-term memory. In fact, people often engage in cascade\nprocessing – they form hypotheses as to the word that has been presented\nbefore identifying all the letters (McClelland, 1979).\nAn important issue for cognitive psychologists is the task-impurity\nproblem – most cognitive tasks require several processes thus making it\nhard to interpret the fndings. One approach to this problem is to con-\nsider various tasks all requiring the same process. For example, Miyake\net al. (2000) used three tasks requiring deliberate inhibition of a dominant\nresponse:\n(1) The Stroop task: name the colour in which colour words are pre-\nsented (e.g., RED printed in green) and avoid saying the colour word\n(which has to be inhibited). You can see for yourself how hard this\ntask is by naming the colours of the words shown in Figure 1.3.\n(2) The anti-cascade task: inhibit the natural tendency to look at a visual\ncue and instead look in the opposite direction. People typically take\nlonger to perform this task than the control task of simply looking at\nthe visual cue.\n(3) The stop-signal task: respond rapidly to indicate whether each of\na series of words is an animal or non-animal; on key trials, there\nwas a computer-emitted tone indicating that the response should be\ninhibited.\nMiyake et al. (2000) found all three tasks involved similar processes. They\nused complex statistical techniques (latent variable analysis) to extract what\nKEY TERMS\nParallel processing\nProcessing in which two or\nmore cognitive processes\noccur at the same time.\nCascade processing\nLater processing stages\nstart before earlier\nprocessing stages have\nbeen completed when\nperforming a task.\nFigure 1.3\nTest yourself by naming the colours in each column. You should name the colours rapidly\nin the frst three columns because there is no colour-word confict. In contrast, colour\nnaming should be slower (and more prone to error) when naming colours in the fourth\nand ffth columns.\nCreated from usyd on 2022-02-13 13:24:37.",
    "6\nApproaches to human cognition\nwas common across the three tasks. This was assumed to represent a rel-\natively pure measure of the inhibitory process. Throughout this book, we\nwill discuss many ingenious strategies used by cognitive psychologists to\nidentify the processes used in numerous tasks.\nStrengths\nCognitive psychology was for many years the engine room of progress in\nunderstanding human cognition and the other three approaches listed in\nTable 1.1 have beneftted from it. For example, cognitive neuropsychology\nbecame important 25 years after cognitive psychology. It was only when\ncognitive psychologists had developed reasonable accounts of healthy\nhuman cognition that the performance of brain-damaged patients could\nbe understood fully. Before that, it was hard to decide which patterns of\ncognitive impairment were theoretically important.\nIn a similar fashion, the computational modelling activities of com-\nputational cognitive scientists are typically heavily infuenced by pre-\ncomputational psychological theories. Finally, the great majority of\ntheories driving research in cognitive neuroscience originated within\ncognitive psychology.\nCognitive psychology has not only had a massive infuence on theoris-\ning across all four major approaches to human cognition. It has also had a\npredominant infuence on the development of cognitive tasks and on task\nanalysis (how a task is accomplished).\nLimitations\nIn spite of cognitive psychology’s enormous contributions, it has several\nlimitations. First, our behaviour in the laboratory may difer from our\nbehaviour in everyday life. Thus, laboratory research sometimes lacks\necological validity – the extent to which laboratory fndings are applicable\nto everyday life. For example, our everyday behaviour is often designed\nto change a situation or to infuence others’ behaviour. In contrast, the\nsequence of events in most laboratory research is based on the experiment-\ner’s predetermined plan and is uninfuenced by participants’ behaviour.\nWachtel (1973) used the term implacable experimenter to describe this\nstate of afairs.\nWe must not exaggerate problems associated with lack of ecological\nvalidity. As we will see in this book, there has been a dramatic increase\nin applied cognitive psychology in which the emphasis is on investigat-\ning topics of general importance. Such research often has good ecological\nvalidity. Note that it is far better to carry out well-controlled experiments\nunder laboratory conditions than poorly controlled experiments under\nnaturalistic conditions. It is precisely because it is considerably easier for\nresearchers to exercise experimental control in the laboratory that so much\nresearch is laboratory-based.\nSecond, theories in cognitive psychology are often expressed only in\nverbal terms (although this is becoming less common). Such theories are\nvague, making it hard to know precisely what predictions follow from\nthem and thus to falsify them. These limitations can largely be overcome by\nKEY TERMS\nEcological validity\nThe applicability (or\notherwise) of the fndings\nof laboratory studies to\neveryday settings.\nImplacable experimenter\nThe situation in\nexperimental research in\nwhich the experimenter’s\nbehaviour is uninfuenced\nby the participant’s\nbehaviour.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n7\ncomputational cognitive scientists developing cognitive models  specifying\nprecisely any given theory’s assumptions.\nThird, difculties in falsifying theories have led to a proliferation of\ndiferent theories on any given topic. For example, there are at least 12\ndiferent theories of working memory (see Chapter 6). Another reason for\nthe proliferation of rather similar theories is the “toothbrush problem”\n(Mischel, 2008): no self-respecting cognitive psychologist wants to use\nanyone else’s theory.\nFourth, the fndings obtained using any given task or paradigm are\nsometimes specifc to that paradigm and do not generalise to other (appar-\nently similar) tasks. This is paradigm specifcity. It means some fndings\nare narrow in scope and applicability (Meiser, 2011). This problem can be\nminimised by developing theories accounting for performance across several\ntasks or paradigms. For example, Anderson et al. (2004; discussed later in\nthis chapter) developed a comprehensive theoretical architecture or frame-\nwork known as the Adaptive Control of Thought-Rational (ACT-R) model.\nFifth, cognitive psychologists typically obtain measures of performance\nspeed and accuracy. These measures are very useful but provide only indi-\nrect evidence about internal cognitive processes. Most tasks are “impure” in\nthat they involve several processes, and it is hard to identify the number and\nnature of processes involved on the basis of speed and accuracy measures.\nCOGNITIVE NEUROPSYCHOLOGY\nCognitive neuropsychology focuses on the patterns of cognitive perfor-\nmance (intact and impaired) of brain-damaged patients having a lesion\n(structural damage to the brain caused by injury or disease). According to\ncognitive neuropsychologists, studying brain-damaged patients can tell us\nmuch about cognition in healthy individuals.\nThe above idea does not sound very promising, does it? In fact,\nhowever, cognitive neuropsychology has contributed substantially to our\nunderstanding of healthy human cognition. For example, in the 1960s,\nmost memory researchers thought the storage of information in long-\nterm memory depended on previous processing in short-term memory (see\nChapter 6). However, Shallice and Warrington (1970) reported the case of\na brain-damaged man, KF. His short-term memory was severely impaired\nbut his long-term memory was intact. These fndings played an important\nrole in changing theories of healthy human memory.\nSince cognitive neuropsychologists study brain-damaged patients,\nwe might imagine they would be interested in the workings of the brain.\nIn fact, many cognitive neuropsychologists pay little attention to the\nbrain itself. According to Coltheart (2015, p. 198), for example, “Even\nthough cognitive neuropsychologists typically study people with brain\ndamage, . . . cognitive neuropsychology is not about the brain: it is about\ninformation-processing models of cognition.”\nAn increasing number of cognitive neuropsychologists disagree with\nColtheart. They believe we should consider the brain, using techniques\nsuch as magnetic resonance imaging to identify the brain areas damaged in\nany given patient. They are also increasingly willing to study the impact of\nbrain damage on brain processes using various neuroimaging techniques.\nKEY TERMS\nParadigm specifcity\nThe fndings with a\ngiven experimental task\nor paradigm are not\nreplicated even when\napparently very similar\ntasks or paradigms are\nused.\nlesion\nDamage within the brain\nresulting from injury or\ndisease; it typically affects\na restricted area.\nCreated from usyd on 2022-02-13 13:24:37.",
    "8\nApproaches to human cognition\nTheoretical assumptions\nColtheart (2001) provided a very clear\naccount of the major assumptions of cogni-\ntive neuropsychology. Here we will discuss\nthese assumptions and briefy consider rele-\nvant evidence.\nOne key assumption is modularity,\nmeaning the cognitive system consists of\nnumerous modules or processors operating\nfairly independently or separately of each\nother. It is assumed these modules exhibit\ndomain specifcity (they respond to only\none given class of stimuli). For example,\nthere may be a face-recognition module that\nresponds only when a face is presented.\nModular\nsystems\ntypically\ninvolve\nserial processing with processing within one\nmodule being completed before processing\nstarts in the next module. As a result, there\nis very limited interaction among modules.\nThere is some support for modularity from\nthe evolutionary approach. Species with\nlarger brains generally have more special-\nised brain regions that could be involved in\nmodular processing. However, the notion\nthat human cognition is heavily modular\nis hard to reconcile with neuroimaging evi-\ndence. The human brain possesses a moder-\nately high level of connectivity (Bullmore &\nSporns, 2012; see p. 14), suggesting there is more parallel processing than\nassumed by most cognitive neuropsychologists.\nThe second major assumption is that of anatomical modularity.\nAccording to this assumption, each module is located in a specifc brain\narea. Why is this assumption important? Cognitive neuropsychologists\nare most likely to make progress when studying brain patients with brain\ndamage limited to a single module. Such patients may not exist if there is\nno anatomical modularity. Suppose all modules were distributed across\nlarge brain areas. If so, the great majority of brain-damaged patients\nwould sufer damage to most modules, making it impossible to work out\nthe number and nature of their modules.\nThere is evidence of anatomical modularity in the visual processing\nsystem (see Chapter 2). However, there is less support for anatomical\nmodularity with most complex tasks. For example, consider the fndings of\nYarkoni et al. (2011). Across over 3,000 neuroimaging studies, some brain\nareas (e.g., dorsolateral prefrontal cortex; anterior cingulate cortex) were\nactivated in 20% of them despite the great diversity of tasks involved.\nThe third major assumption (the “universality assumption”) is that\n“Individuals . . . share a similar or an equivalent organisation of their cog-\nnitive functions, and presumably have the same underlying brain anatomy”\nMax Coltheart.\nCourtesy of Max Coltheart.\nKEY TERM\nModularity\nThe assumption that\nthe cognitive system\nconsists of many fairly\nindependent or separate\nmodules or processors,\neach specialised for a\ngiven type of processing.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n9\n(de Schotten and Shallice, 2017, p. 172). If this assumption (also common\nwithin cognitive neuroscience) is false, we could not readily use the fnd-\nings from individual patients to draw conclusions about the organisation\nof other people’s cognitive systems or functional architecture.\nThere is accumulating evidence against the universality assumption.\nTzourio-Mazoyer et al. (2004) discovered substantial diferences between\nindividuals in the location of brain networks involved in speech and lan-\nguage. Finn et al. (2015) found clear-cut diferences between individuals in\nfunctional connectivity across the brain, concluding that “An individual’s\nfunctional brain connectivity profle is both unique and reliable, similarly\nto a fngerprint” (p. 1669).\nDufau (2017) reviewed interesting research conducted on patients\nduring surgery for epilepsy or a tumour. Direct electrical stimulation,\nwhich causes “a genuine virtual transient lesion” (p. 305) is applied inva-\nsively to the cortex. The patient is awakened and given various cognitive\ntasks while receiving stimulation. Impaired performance when direct elec-\ntrical stimulation is applied to a given area indicates that area is involved\nin the cognitive functions assessed by the current task.\nFindings obtained using direct electrical stimulation and other tech-\nniques (e.g., fMRI) led Dufau (2017) to propose a two-level model. At\nthe cortical level, there is high variability across individuals in structure\nand function of any given brain areas. At the subcortical level (e.g., in pre-\nmotor cortex), in contrast, there is very little variability across individuals.\nThe fndings at the cortical level seem inconsistent with the universality\nassumption.\nThe fourth assumption is subtractivity. The basic idea is that brain\ndamage impairs one or more processing modules but does not change\nor add anything. The ffth assumption (related to subtractivity) is trans-\nparency (Shallice, 2015). According to the transparency assumption, the\nperformance of a brain-damaged patient refects the operation of a theory\ndesigned to explain the performance of healthy individuals minus the\nimpact of their lesion.\nWhy are the subtractivity and transparency assumptions impor-\ntant? Suppose they are incorrect and brain-damaged patients develop\nnew modules to compensate for their cognitive impairments. That would\ngreatly complicate the task of learning about the intact cognitive system\nby studying brain-damaged patients. Consider pure alexia, a condition in\nwhich brain-damaged patients have severe reading problems but otherwise\nintact language abilities. These patients generally have a direct relationship\nbetween word length and reading speed due to letter-by-letter processing\n(Bormann et al., 2015). This indicates the use of a compensatory strategy\ndifering markedly from the reading processes used by healthy adults.\nResearch in cognitive neuropsychology\nHow do cognitive neuropsychologists set about understanding the cognitive\nsystem? Of major importance is the search for dissociations, which occur\nwhen a patient has normal performance on one task (task X) but is impaired\non a second one (task Y). For example, amnesic patients perform almost\nnormally on short-term memory tasks but are greatly impaired on many\nKEY TERM\nPure alexia\nSevere problems with\nreading but not other\nlanguage skills; caused\nby damage to brain\nareas involved in visual\nprocessing.\nCreated from usyd on 2022-02-13 13:24:37.",
    "10\nApproaches to human cognition\nlong-term memory tasks (see Chapter 6). It is tempting (but dangerous!) to\nconclude that the two tasks involve diferent processing modules and that\nthe module(s) needed on long-term memory tasks have been damaged by\nbrain injury.\nWhy must we avoid drawing sweeping conclusions from dissociations?\nPatients may perform well on one task but poorly on a second one simply\nbecause the second task is more complex. Thus, dissociations may refect\ndiferences in task complexity rather than the use of diferent modules.\nOne apparent solution to the above problem is to fnd double disso-\nciations. A double dissociation between two tasks (X and Y) is obtained\nwhen one patient performs normally on task X and is impaired on task Y\nbut another patient shows the opposite pattern. We cannot explain double\ndissociations by arguing that one task is harder. For example, consider the\ndouble dissociation that amnesic patients have impaired long-term memory\nbut intact short-term memory whereas other patients (e.g., KF discussed\nabove) have the opposite pattern. This double dissociation strongly sug-\ngests there is an important distinction between short-term and long-term\nmemory and that they involve diferent brain regions.\nThe approach based on double dissociations has various limitations.\nFirst, it is generally based on the assumption that separate modules exist\n(which may be misguided). Second, double dissociations can often be\nexplained in various ways and so provide only indirect evidence for sepa-\nrate modules underlying each task (Davies, 2010). For example, a double\ndissociation between tasks X and Y implies the cognitive system used on\nX is not identical to the one used on Y. Strictly speaking, the most we\ncan generally conclude is that “Each of the two systems has at least one\nsub-system that the other doesn’t have” (Bergeron, 2016, p. 818). Third,\nit is hard to decide which of the very numerous double dissociations that\nhave been discovered are theoretically important.\nFinally, we consider associations. An association occurs when a\npatient is impaired on tasks X and Y. Associations are sometimes taken\nas evidence for a syndrome (sets of symptoms or impairments often\nfound together). However, there is a serious faw in the syndrome-based\napproach. An association may be found between tasks X and Y because\nthe mechanisms on which they depend are adjacent anatomically in the\nbrain rather than because they depend on the same underlying mechanism.\nThus, the interpretation of associations is fraught with difculty.\nSingle case studies vs case series\nFor many years after the rise of cognitive neuropsychology in the 1970s,\nmost cognitive neuropsychologists made extensive use of single-case\nstudies. There were two main reasons. First, researchers can often gain\naccess to only one patient having a given pattern of cognitive impair-\nment. Second, it was often assumed every patient has a somewhat diferent\npattern of cognitive impairment and so is unique. As a result, it would\nbe misleading and uninformative to average the performance of several\npatients.\nIn recent years, there has been a move towards the case-series study.\nSeveral patients with similar cognitive impairments are tested. After that,\nKEY TERMS\nDouble dissociation\nThe fnding that some\nbrain-damaged individuals\nhave intact performance\non one task but poor\nperformance on another\ntask whereas other\nindividuals exhibit the\nopposite pattern.\nAssociation\nThe fnding that\ncertain symptoms or\nperformance impairments\nare consistently found\ntogether in numerous\nbrain-damaged patients.\nSyndrome\nThe notion that symptoms\nthat often co-occur have a\ncommon origin.\nCase-series study\nA study in which several\npatients with similar\ncognitive impairments\nare tested; this allows\nconsideration of individual\ndata and of variation\nacross individuals.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n11\nthe data of individual patients are compared and variation across patients\nassessed.\nThe case-series approach is generally preferable to the single-case\napproach for various reasons (Lambon Ralph et al., 2011; Bartolomeo\net  al., 2017). First, it provides much richer data. With a case series, we\ncan assess the extent of variation between patients rather than simply being\nconcerned about the impairment (as in the single-case approach). Second,\nwith a case series, we can identify (and then de-emphasise) the fndings\nfrom patients who are “outliers”. With the single-case approach, in con-\ntrast, we do not know whether the one and only patient is representative\nof patients with that condition or is an outlier.\nStrengths\nCognitive neuropsychology has several strengths. First, it has the advan-\ntage that it allows us to draw causal inferences about the relationship\nbetween brain areas and cognitive processes and behaviour. In other\nwords, we can conclude (with moderate but not total confdence) that a\ngiven brain area is crucially involved in performing certain cognitive tasks\n(Genon et al., 2018).\nSecond, as Shallice (2015, pp. 387–388) pointed out, “A key intel-\nlectual strength of neuropsychology . . . is its ability to provide evidence\nfalsifying plausible cognitive theories.” Consider patients reading visually\npresented words and non-words aloud. We might imagine patients with\ndamage to language areas would have problems in reading all words\nand non-words.  However, some patients perform reasonably well when\nreading  regular words (with predictable pronunciations) or non-words,\nbut poorly when reading irregular words (words with unpredictable pro-\nnunciations). Other patients can read regular words but have problems\nwith unfamiliar words and non-words. These fascinating patterns of\nimpairment have transformed theories of reading (Coltheart, 2015; see\nChapter 9).\nThird, cognitive neuropsychology “produces large-magnitude phenom-\nena which can be initially theoretically highly counterintuitive” (Shallice,\n2015, p. 405). For example, amnesic patients typically have severely\nimpaired long-term memory for personal events and experiences but an\nessentially intact ability to acquire and retain motor skills (Chapter 7).\nThese strong efects played a major role in memory researchers abandon-\ning the notion of a single long-term memory system and replacing it with\nmore complex theories.\nFourth, in recent years, cognitive neuropsychology has increasingly\nbeen combined fruitfully with cognitive neuroscience. For example, cog-\nnitive neuroscience has revealed that a given brain injury or lesion often\nhas widespread efects within the brain. This phenomenon is known as\ndiaschisis: “the distant neurophysiological changes directly caused by a\nfocal injury . . . these changes should correlate with behaviour” (Carrera\n& Tononi, 2014, p. 2410). Discovering the true extent of the brain areas\nadversely afected by a lesion facilitates the task of relating brain function-\ning to cognitive processing and task performance.\nKEY TERM\nDiaschisis\nThe disruption to distant\nbrain areas caused by a\nlocalised brain injury or\nlesion.\nCreated from usyd on 2022-02-13 13:24:37.",
    "12\nApproaches to human cognition\nLimitations\nWhat are the limitations of the cognitive neuropsychological approach?\nFirst, the crucial assumption that the cognitive system is fundamentally\nmodular is reasonable but too strong. There is less evidence for modularity\namong higher-level cognitive processes (e.g., consciousness; focused atten-\ntion) than among lower-level processes (e.g., colour processing; motion\nprocessing). If the modularity assumption is incorrect, this has implica-\ntions for the whole enterprise of cognitive neuropsychology (Patterson &\nPlaut, 2009).\nSecond, other theoretical assumptions also seem too extreme. For\nexample, evidence discussed earlier casts considerable doubts on the\nassumption of anatomical modularity and the universality assumption.\nThird, the common assumption that the task performance of patients\nprovides relatively direct evidence concerning the impact of brain damage\non previously intact cognitive systems is problematic. Brain-damaged\npatients often make use of compensatory strategies to reduce or eliminate\nthe negative efects of brain damage on cognitive performance. We saw an\nexample of such compensatory strategies earlier – patients with pure alexia\nmanage to read words by using a letter-by-letter strategy rarely used by\nhealthy individuals.\nHartwigsen (2018) proposed a model to predict when compensatory\nprocesses will and will not be successful. According to this model, general\nprocesses (e.g., attention; cognitive control; error monitoring) can be used\nto compensate for the disruption of specifc processes (e.g., phonological\nprocessing) by brain injury. However, specifc processes cannot be used to\ncompensate for the disruption of general processes. Hartwigsen discussed\nevidence supporting his model.\nFourth, lesions can alter the organisation of the brain in several ways.\nDramatic evidence for brain plasticity is discussed in Chapter 16. Patients\nwhose entire left brain hemisphere was removed at an early age (known\nas hemispherectomy) often develop good language skills even though lan-\nguage is typically centred in the left hemisphere (Blackmon, 2016).\nThere is the additional problem that a brain lesion can lead to changes\nin the functional connectivity between the area of the lesion and distant,\nintact brain areas (Bartolomeo et al., 2017). Thus, impaired cognitive per-\nformance following brain damage may refect widespread reduced brain\nconnectivity as well as direct damage to a specifc brain area. This com-\nplicates the task of interpreting the fndings obtained from brain-damaged\npatients.\nCOGNITIVE NEUROSCIENCE: THE BRAIN\nIN ACTION\nCognitive neuroscience involves the intensive study of brain activity as well\nas behaviour. Alas, the brain is extremely complicated (to put it mildly!).\nIt consists of 100 billion neurons connected in very complex ways. We\nmust consider how the brain is organised and how the diferent areas are\ndescribed to understand research involving functional neuroimaging. Below\nwe discuss various ways of describing specifc brain areas.\nKEY TERMS\nSulcus\nA groove or furrow in the\nsurface of the brain.\nGyrus\nProminent elevated area\nor ridge on the brain’s\nsurface; “gyri” is the\nplural.\nDorsal\nTowards the top.\nVentral\nTowards the bottom.\nRostral\nTowards the front of the\nbrain.\nPosterior\nTowards the back of the\nbrain.\nLateral\nSituated at the side of the\nbrain.\nMedial\nSituated in the middle of\nthe brain.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n13\nFirst, the cerebral cortex is divided into\nfour main divisions or lobes (see Figure 1.4).\nThere are four lobes in each brain hemisphere:\nfrontal; parietal; temporal; and occipital. The\nfrontal lobes are divided from the parietal\nlobes by the central sulcus (sulcus means\nfurrow or groove), and the lateral fssure sep-\narates the temporal lobes from the parietal\nand frontal lobes. In addition, the parieto-\noccipital sulcus and pre-occipital notch divide\nthe occipital lobes from the parietal and tem-\nporal lobes. The main gyri (or ridges; gyrus\nis the singular) within the cerebral cortex are\nshown in Figure 1.4.\nResearchers use various terms to describe\naccurately the brain area(s) activated during\ntask performance:\n●\ndorsal (or superior): towards the top\n●\nventral (or inferior): towards the bottom\n●\nanterior (or rostral): towards the front\n●\nposterior: towards the back\n●\nlateral: situated at the side\n●\nmedial: situated in the middle.\nThe\nGerman\nneurologist\nKorbinian\nBrodmann (1868–1918) produced a brain map\nbased on diferences in the distributions of cell\ntypes across cortical layers (see Figure 1.5).\nFigure 1.4\nThe four lobes, or divisions,\nof the cerebral cortex in the\nleft hemisphere.\nFigure 1.5\nBrodmann brain areas on the lateral (top fgure) and medial\n(bottom fgure) surfaces.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-13 13:24:37.",
    "14\nApproaches to human cognition\nHe identifed 52 areas. We will often refer to areas, for example, as BA17,\nwhich means Brodmann Area 17, rather than Brain Area 17!\nWithin cognitive neuroscience, brain areas are often described with ref-\nerence to their main functions. For example, Brodmann Area 17 (BA17) is\ncommonly called the primary visual cortex because it is strongly associated\nwith the early processing of visual stimuli.\nBrain organisation\nIn recent years, there has been considerable progress in identifying the\nconnectome: this is a “wiring diagram” providing a complete map of the\nbrain’s neural connections. Why is it important to identify the connectome?\nFirst, as we will see, it advances our understanding of how the brain is\norganised. Second, identifying the brain’s structural connections facilitates\nthe task of understanding how it functions. More specifcally, the brain’s\nfunctioning is strongly constrained by its structural connections. Third,\nas we will see, we can understand some individual diferences in cognitive\nfunctioning with reference to individual diferences in the connectome.\nBullmore and Sporns (2012) used information about the connectome\nto address issues about brain organisation. They argued two major prin-\nciples might determine its organisation. First, there is the principle of cost\ncontrol: costs (e.g., use of energy and space) would be minimised if the brain\nconsisted of limited, short-distance connections (see Figure 1.6). Second,\nthere is the principle of efciency (efciency is the ability to integrate infor-\nmation across the brain). This can be achieved by having very numerous\nconnections, many of which are long-distance (see Figure 1.6). These two\nprinciples are in confict – you cannot have high efciency at low cost.\nYou might imagine it would be best if our brains were organised pri-\nmarily on the basis of efciency. However, this would be incredibly costly –\nif all 100 billion brain neurons were interconnected, the brain would need\nto be 12½ miles wide (Ward, 2015)! In fact, neurons mostly connect with\nnearby neurons and no neuron is connected to more than about 10,000\nother neurons. As a result, the human brain has a near-optimal trade-of\nbetween cost and efciency (see Figure 1.6). Thus, our brains are reasona-\nbly efcient while incurring a manageable cost.\nFigure 1.6\nThe left panel shows a\nbrain network low in cost\neffciency; the right panel\nshows a brain network\nhigh in cost effciency; the\nmiddle panel shows the\nactual human brain in which\nthere is moderate effciency\nat moderate cost. Nodes\nare shown as orange circles.\nFrom Bullmore and Sporns\n(2012). Reprinted with\npermission of Nature Reviews.\nKEY TERM\nConnectome\nA comprehensive wiring\ndiagram of neural\nconnections within the\nbrain.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n15\nThere is an important distinction between modules (small areas of\ntightly clustered connections) and hubs (regions having large numbers\nof connections to other regions). This is an efcient organisation as can\nbe seen by analogy to the world’s airports – the needs of passengers are\nbest met by having numerous local airports (modules) and relatively few\nmajor hubs (e.g., Heathrow in London; Changi in Singapore; Los Angeles\nInternational Airport).\nCollin et al. (2014) argued the brain’s hubs are strongly interconnected\nand used the term “rich club” to refer to this state of afairs. The organ-\nisation of the rich club is shown in Figure 1.7: it includes the precuneus,\nthe superior frontal cortex, insular cortex and superior parietal cortex.\nThe fgure also shows connections between rich club nodes, connections\nbetween non-rich club nodes (local connections), and connections between\nrich club and non-rich club nodes (feeder connections).\nWhat light does a focus on brain network organisation shed on indi-\nvidual diferences in cognitive ability? Hilger et al. (2017) distinguished\nbetween global efciency (i.e., efciency of the overall brain network) and\nnodal efciency (i.e., efciency of specifc hubs or nodes). Intelligence was\nunrelated to global efciency. However, it was positively associated with\nthe efciency of two hubs or nodes: the anterior insula and dorsal anterior\ncingulate cortex. The anterior insula is involved in the detection of task-\nrelevant stimuli whereas the dorsal anterior cingulate cortex is involved in\nperformance monitoring.\nTechniques for studying brain activity: introduction\nTechnological advances mean we have numerous exciting ways of obtaining\ndetailed information about the brain’s functioning and structure. In princi-\nple, we can work out where and when specifc cognitive processes occur in\nthe brain. This allows us to determine the order in which diferent brain\nareas become active when someone performs a task. It also allows us to dis-\ncover the extent to which two tasks involve the same brain areas.\nInformation concerning the main techniques for studying brain activity\nis contained in Table 1.2. Which technique is the best? There is no single\n(or simple) answer. Each technique has its own strengths and limitations,\nFigure 1.7\nThe organisation of the\n“rich club”. It includes the\nprecuneus, the superior\nfrontal cortex, insular\ncortex, and superior\nparietal cortex. The fgure\nalso shows connections\nbetween rich club nodes,\nconnections between\nnon-rich club nodes\n(local connections), and\nconnections between rich\nclub and non-rich club\nnodes (feeder connections).\nфnorm\nrich club\nsuperior frontal\ninsula\nsuperior parietal\nprecuneus\nk\n<6\n>14\nnon-rich club\nrich club\nfeeder\nlocal\n1.15\n1.10\n1.05\n1.00\n0.95\nCreated from usyd on 2022-02-13 13:24:37.",
    "16\nApproaches to human cognition\nand so experimenters match the technique to the research question. Of key\nimportance, these techniques vary in the precision with which they identify\nthe brain areas active when a task is performed (spatial resolution) and\nthe time course of such activation (temporal resolution). Thus, they difer\nin their ability to provide precise information concerning where and when\nbrain activity occurs.\nTABLE 1.2 MAJOR TECHNIQUES USED TO STUDY THE BRAIN\n•\nSingle-unit recording: This technique (also known as single-cell recording) involves\ninserting a micro-electrode 1/10,000th of a millimetre in diameter into the brain to\nstudy activity in single neurons. It is very sensitive: electrical charges of as little as\none-millionth of a volt can be detected.\n•\nEvent-related potentials (ERPs): The same stimulus (or very similar ones) are\npresented repeatedly, and the pattern of electrical brain activity recorded by several\nscalp electrodes is averaged to produce a single waveform. This technique allows\nus to work out the timing of various cognitive processes very precisely but its spatial\nresolution is poor.\n•\nPositron emission tomography (PET): This technique involves the detection of\npositrons (atomic particles emitted from some radioactive substances). PET has\nreasonable spatial resolution but poor temporal resolution and measures neural\nactivity only indirectly.\n•\nFunctional magnetic resonance imaging (fMRI): This technique involves imaging\nblood oxygenation using a magnetic resonance imaging (MRI) machine (described\non p. 19). fMRI has superior spatial and temporal resolution to PET, but also provides\nan indirect measure of neural activity.\n•\nEvent-related functional magnetic resonance imaging (efMRI): This “involves\nseparating the elements of an experiment into discrete points in time, so that the\ncognitive processes (and associated brain responses) associated with each element\ncan be analysed independently” (Huettel, 2012, p. 1152). Event-related fMRI is\ngenerally very informative and has become more popular recently.\n•\nMagneto-encephalography (MEG): This technique involves measuring the magnetic\nfelds produced by electrical brain activity. It provides fairly detailed information at\nthe millisecond level about the time course of cognitive processes, and its spatial\nresolution is reasonably good.\n•\nTranscranial magnetic stimulation (TMS): This is a technique in which a coil is\nplaced close to the participant’s head and a very brief pulse of current is run through\nit. This produces a short-lived magnetic feld that generally (but not always) inhibits\nprocessing in the brain area affected. When the pulse is repeated several times in\nrapid succession, we have repetitive transcranial magnetic stimulation (rTMS). rTMS is\nused very widely.\nIt has often been argued that TMS or rTMS causes a very brief “lesion”. This\ntechnique has (jokingly!) been compared to hitting someone’s brain with a hammer.\nMore accurately, TMS often causes interference because the brain area to which it is\napplied is involved in task processing as well as the activity resulting from the TMS\nstimulation.\n•\nTranscranial direct current stimulation (tDCS): A weak electric current is passed\nthrough a given brain area for some time. The electric charge fows from a positive\nsite (an anode) to a negative one (a cathode). Anodal tDCS increases cortical\nexcitability and generally enhances performance. In contrast, cathodal tDCS\ndecreases cortical excitability and mostly impairs performance.\nKEY TERMS\nSingle-unit recording\nAn invasive technique for\nstudying brain function,\npermitting the study of\nactivity in single neurons.\nEvent-related potentials\n(ERPs)\nThe pattern of\nelectroencephalograph\n(EEG) activity obtained\nby averaging the brain\nresponses to the same\nstimulus (or very similar\nstimuli) presented\nrepeatedly.\nPositron emission\ntomography (PET)\nA brain-scanning\ntechnique based on the\ndetection of positrons;\nit has reasonable spatial\nresolution but poor\ntemporal resolution.\nFunctional magnetic\nresonance imaging\n(fMRI)\nA technique based\non imaging blood\noxygenation using an\nMRI machine; it provides\ninformation about the\nlocation and time course\nof brain processes.\nEvent-related functional\nmagnetic resonance\nimaging (efMRI)\nThis is a form of\nfunctional magnetic\nresonance imaging in\nwhich patterns of brain\nactivity associated with\nspecifc events (e.g.,\ncorrect vs incorrect\nresponses on a memory\ntest) are compared.\nMagneto-\nencephalography (MEG)\nA non-invasive brain-\nscanning technique\nbased on recording the\nmagnetic felds generated\nby brain activity; it has\ngood spatial and temporal\nresolution.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n17\nFigure 1.8\nThe spatial and temporal\nresolution of major\ntechniques and methods\nused to study brain\nfunctioning.\nFrom Ward (2006), adapted\nfrom Churchland & Sejnowski\n(1988).\nTechniques for studying the brain: detailed analysis\nWe have introduced the main techniques for studying the brain. In what\nfollows, we consider them in more detail.\nSingle-unit recording\nThe single-unit (or cell) recording technique is more fne-grain than any\nother technique (see Chapter 2). However, it is invasive and so rarely used\nwith humans. An interesting exception is a study by Quiroga et al. (2005) on\nepileptic patients with implanted electrodes to identify the focus of seizure\nonset (see Chapter 3). A neuron in the medial temporal lobe responded\nstrongly to pictures of Jennifer Aniston (the actor from Friends) but not\nto pictures of other famous people. We need to interpret this fnding care-\nfully. Only a tiny fraction of the neurons in that brain area were studied\nand it is highly improbable that none of the others would have responded\nto Jennifer Aniston.\nEvent-related potentials\nElectroencephalography (EEG) is based on recordings of electrical brain\nactivity measured at several locations on the surface of the scalp. Very\nsmall changes in electrical activity within the brain are picked up by scalp\nelectrodes and can be seen on a computer screen. However, spontaneous or\nbackground brain activity can obscure the impact of stimulus processing on\nthe EEG recording.\nThe answer to the above problem is to present the same stimulus (or\nvery similar stimuli) many times. After that, the segment of the EEG fol-\nlowing each stimulus is extracted and lined up with respect to the time\nof stimulus onset. These EEG segments are then averaged together to\nKEY TERMS\nTranscranial magnetic\nstimulation (TMS)\nA technique in which\nmagnetic pulses briefy\ndisrupt the functioning\nof a given brain area.\nIt is often claimed\nthat it creates a short-\nlived “lesion”. More\naccurately, TMS causes\ninterference when the\nbrain area to which it is\napplied is involved in\ntask processing as well as\nactivity produced by the\napplied stimulation.\nTranscranial direct\ncurrent stimulation\n(tDCS)\nA technique in which\na very weak electrical\ncurrent is passed through\nan area of the brain (often\nfor several minutes);\nanodal tDCS often\nenhances performance,\nwhereas cathodal tDCS\noften impairs it.\nElectroencephalography\n(EEG)\nRecording the brain’s\nelectrical potentials\nthrough a series of scalp\nelectrodes.\nCreated from usyd on 2022-02-13 13:24:37.",
    "18\nApproaches to human cognition\nThe magnetic resonance\nimaging (MRI) scanner\nhas proved an extremely\nvaluable source of data in\npsychology.\nJuice Images/Alamy Stock\nPhoto.\nproduce a single waveform. This method produces event-related potentials\nfrom EEG recordings and allows us to distinguish the genuine efects of\nstimulation from background brain activity.\nERPs have excellent temporal resolution, often indicating when a\ngiven process occurred to within a few milliseconds. The ERP waveform\nconsists of a series of positive (P) and negative (N) peaks, each described\nwith reference to the time in milliseconds after stimulus onset. Thus, for\nexample, N400 is a negative wave peaking at about 400 ms.\nBehavioural measures (e.g., reaction times) typically provide only a\nsingle measure of time on each trial, whereas ERPs provide a continuous\nmeasure. However, ERPs do not indicate with precision which brain regions\nare most involved in processing, in part because skull and brain tissue\ndistort the brain’s electrical felds. In addition, ERPs are mainly of value\nwhen stimuli are simple and the task involves basic processes (e.g., target\ndetection) triggered by task stimuli. Finally, we cannot study the most\ncomplex forms of cognition (e.g., problem solving) with ERPs because the\nprocesses by participants would typically change with increased practice.\nPositron emission tomography (PET)\nPositron emission tomography (PET) is based on the detection of\npositrons  – atomic particles emitted by some radioactive substances.\nRadioactively labelled water (the tracer) is injected into the body and\nrapidly gathers in the brain’s blood vessels. When part of the cortex\nbecomes active, the labelled water moves there rapidly. A scanning device\nmeasures the positrons emitted from the radioactive water which leads to\npictures of the activity levels in diferent brain regions.\nPET has reasonable spatial resolution in that any active brain area\ncan be located to within 5–10 mm. However, it has very poor temporal\nresolution – PET scans indicate the amount of activity in any given brain\nregion over approximately 30 seconds. As a consequence, PET has now\nlargely been superseded by fMRI (see p. 19).\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n19\nMagnetic resonance imaging (MRI and fMRI)\nMagnetic resonance imaging (MRI) involves using an MRI scanner con-\ntaining a very large magnet (weighing up to 11 tons). A strong magnetic\nfeld causes an alignment of protons (subatomic particles) in the brain. A\nbrief radio-frequency pulse is applied, which causes the aligned protons to\nspin and then regain their original orientations giving up a small amount of\nenergy as they do so. The brightest regions in the MRI are those emitting\nthe greatest energy. MRI scans can be obtained from numerous angles but\ntell us only about brain structure rather than its functions.\nHappily, MRI can also be used to provide functional information in the\nform of functional magnetic resonance imaging (fMRI). Oxyhaemoglobin\nis converted into deoxyhaemoglobin when neurons consume oxygen, and\ndeoxyhaemoglobin produces distortions in the local magnetic feld (sorry\nthis is so complex!). This distortion is assessed by fMRI and provides a\nmeasure of the concentration of deoxyhaemoglobin in the blood.\nTechnically, what is measured in fMRI is known as BOLD (blood\noxygen-level-dependent contrast). Changes in the BOLD signal produced\nby increased neural activity take time, so the temporal resolution of fMRI\nis 2 or 3 seconds. However, its spatial resolution is very good (approxi-\nmately 1 mm). Thus, fMRI has superior temporal and spatial resolution\nto PET.\nSuppose we want to understand why people remember some items but\nnot others. We can use event-related fMRI (efMRI), in which we consider\nKEY TERMS\nBOLD\nBlood oxygen-level-\ndependent contrast; this\nis the signal measured by\nfMRI.\nNeural decoding\nUsing computer-based\nanalyses of patterns of\nbrain activity to work\nout which stimulus an\nindividual is processing.\nCAN COGNITIVE NEUROSCIENTISTS READ OUR BRAINS/MINDS?\nThere is much current interest in neural decoding – “determining what stimuli or mental states\nare represented by an observed pattern of neural activity” (Tong & Pratte, 2012, p. 483). This\ndecoding involves complex computer-based analysis of individuals’ patterns of brain activity and\nhas sometimes been described as “brain reading” or “mind reading”.\nKay et al. (2008) obtained impressive fndings using neural decoding techniques. Two participants\nviewed 1,750 natural images and brain-activation patterns were obtained using fMRI. Computer-\nbased approaches then analysed these patterns. After that, the participants were presented with\n120 previously unseen natural images and fMRI data were collected. These fMRI data permitted\ncorrect identifcation of the image being viewed on 92% of the trials for one participant and 72%\nfor the other. This is remarkable since chance performance was only 0.8%!\nHuth et al. (2016) used more complex stimuli. They presented observers with clips taken from\nseveral movies including Star Trek and Pink Panther 2 while using fMRI. Decoding accuracy was\nreasonably successful in identifying general object categories (e.g., animal), specifc object catego-\nries (e.g., canine) and various actions (e.g., talk; run) presented in the movie clips.\nResearch on neural decoding can enhance our understanding of human visual perception.\nHowever, successful decoding of an object using the pattern of brain activation in a given brain\nregion does not necessarily mean that region is causally involved in observers’ identifcation of\nthat object. Several reasons why we need to be cautious when interpreting fndings from neural\ndecoding studies are discussed by Popov et al. (2018). For example, some aspects of brain activ-\nity in response to visual stimuli are irrelevant to the observer’s perceptual representation. In an\nexperiment, computer analysis of brain activity in macaques successfully classifed various stimuli\npresented to them that the macaques themselves could not distinguish (Hung et al., 2005).\nCreated from usyd on 2022-02-13 13:24:37.",
    "20\nApproaches to human cognition\neach participant’s patterns of brain activation for remembered and forgot-\nten items. Wagner et al. (1998) recorded fMRI while participants learned\na list of words. There was more brain activity during learning for words\nsubsequently recognised than those subsequently forgotten. These fndings\nsuggest forgotten words were processed less thoroughly than remembered\nwords during learning.\nEvaluation\nfMRI is the dominant technique within cognitive neuroscience. Its value\nhas increased over the years with the introduction of more powerful\nMRI scanners. Initially, most scanners had a feld strength of 1.5 T but\nrecently  scanners with feld strengths of up to 7 T have become availa-\nble. As a result, submillimetre spatial resolution is now possible (Turner,\n2016).\nWhat are fMRI’s limitations? The main ones are as follows:\n(1) It has relatively poor temporal resolution. As a result, it is unin-\nformative about the order in which diferent brain regions (and cog-\nnitive processes) are used during performance of a task. However,\nother techniques within cognitive neuroscience can be used in con-\njunction  with fMRI in order to achieve good spatial and temporal\nresolution.\n(2) It provides an indirect measure of underlying neural activity. “The\nBOLD signal primarily measures the input and processing of neural\ninformation . . . but not the output signal transmitted to other brain\nregions” (Shiferman, 2015, p. 60).\n(3) Various complex processes are used by researchers to take account of\nthe fact that all brains difer. This involves researchers changing the\nraw fMRI data and poses the danger that “BOLD-fMRI neuroimages\nrepresent mathematical constructs rather than physiological reality”\n(Shiferman, 2015).\n(4) There are important constraints on the visual stimuli that can be\npresented to participants when lying in the scanner and on the types\nof responses they can make. There can be particular problems with\nauditory stimuli because the scanner is noisy.\nMagneto-encephalography\nThe electric currents that the brain generates are associated with a magnetic\nfeld. This magnetic feld is assessed by magneto-encephalography (MEG)\ninvolving at least 200 devices on the scalp. This technique has very good\nspatial and temporal resolution. However, it is extremely expensive and this\nhas limited its use.\nTranscranial magnetic stimulation\nTranscranial magnetic stimulation (TMS) is a technique in which a coil\n(often in the shape of a fgure of eight) is placed close to the participant’s\nhead. A very brief (under 1 ms) but large magnetic pulse of current is run\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n21\nthrough it. This creates a short-lived magnetic feld\ngenerally leading to inhibited processing in the directly\nafected area (about 1 cc in extent). More specifcally,\nthe magnetic feld created leads to electrical stimula-\ntion in the brain. In practice, several magnetic pulses\nare typically given in rapid succession – this is repet-\nitive transcranial magnetic stimulation (rTMS). Most\nresearch has used rTMS but we will often simply use\nthe more general term TMS.\nWhat is an appropriate control condition against\nwhich to compare the efects of TMS or rTMS? We\ncould compare task performance with and without\nTMS. However, TMS creates a loud noise and muscle\ntwitching at the side of the forehead and these efects\nmight lead to impaired performance. Applying TMS\nto a non-critical brain area (irrelevant for task perfor-\nmance) often provides a suitable control condition. It is typically predicted\ntask performance will be worse when TMS is applied to a critical area\nrather than a non-critical one because it produces a temporary “lesion” or\ninterference to the area targeted.\nEvaluation\nWhat are TMS’s strengths? First, it permits causal inferences – if TMS\napplied to a particular brain area impairs task performance, we can infer\nthat brain area is necessary for task performance. Conversely, if TMS has\nno efects on task performance, we can conclude the brain area afected by\nit is irrelevant. In that respect, it resembles cognitive neuropsychology.\nSecond, TMS research is more fexible than cognitive neuropsychology.\nFor example, we can compare any given individual’s performance with and\nwithout a “lesion” with TMS. This is rarely possible with brain-damaged\npatients.\nThird, TMS research is also more fexible than cognitive neuropsychol-\nogy because the researcher controls the brain area(s) afected. In addition,\nthe temporary “lesions” created by TMS typically cover a smaller brain\narea than patients’ lesions. This is important because the smaller the brain\nafected, the easier it generally is to interpret task-performance fndings.\nFourth, with TMS research, we can ascertain when a brain area is\nmost activated. For example, the presentation of a visual stimulus leads\nto processing proceeding rapidly to higher visual levels (feedforward pro-\ncessing). According to Lamme (2010), conscious visual perception typically\nrequires subsequent recurrent processing proceeding in the opposite direc-\ntion from higher levels to lower ones. Koivisto et al. (2011) used TMS to\ndisrupt recurrent processing. As predicted, this impaired conscious visual\nperception.\nWhat are the limitations of TMS research? First, the efects of TMS\nare complex and not fully understood. When TMS was frst introduced,\nit was assumed it would disrupt performance. That is, the most common\nfnding. However, Luber and Lisanby (2014) reviewed 61 studies in which\nperformance speed and/or accuracy was enhanced!\nTranscranial magnetic stimulation coil.\nUniversity of Durham/Simon Fraser/Science Photo\nLibrary.\nCreated from usyd on 2022-02-13 13:24:37.",
    "22\nApproaches to human cognition\nHow can TMS enhance performance? It sometimes increases neural\nactivity in areas adjacent to the one stimulated and so increases their pro-\ncessing efciency (Luber & Lisanby, 2014). There is also much evidence\nfor compensatory fexibility (Hartwigsen, 2018) – disruption to cognitive\nprocessing within a given brain area caused by TMS is compensated for by\nthe recruitment of other brain areas.\nSecond, it is hard to establish the precise brain areas afected by TMS.\nFor example, adverse efects of TMS on performance might occur because\nit interferes with communication between two brain areas at some dis-\ntance from the stimulation point. This issue can be addressed by combin-\ning TMS with neuroimaging techniques to clarify its efects (Valero-Cabré\net al., 2017).\nThird, TMS can only be applied to brain areas lying beneath the skull\nbut with overlying muscle. That limits its overall usefulness.\nFourth, there are safety issues with TMS. It has very occasionally\ncaused seizures in participants despite stringent rules designed to ensure\ntheir safety.\nTranscranial direct current stimulation (tDCS)\nAs mentioned earlier, anodal tDCS increases cortical excitability whereas\ncathodal tDCS decreases cortical excitability. The temporal and spatial res-\nolution of tDCS is less than TMS (Stagg & Nitsche, 2011). However, anodal\ntDCS has a signifcant advantage over TMS in that it often facilitates or\nenhances cognitive functioning. As a result, anodal tDCS is increasingly\nused to reduce adverse efects of brain damage on cognitive functioning\n(Stagg et al., 2018). Some of these benefcial efects on cognition are rela-\ntively long-lasting. Another advantage of tDCS is that it typically causes\nlittle or no discomfort.\nMuch progress has been made in understanding the complex mecha-\nnisms associated with tDCS. However, “Knowledge about the physiologi-\ncal efects of tDCS is still not complete” (Stagg et al., 2018, p. 144).\nOverall strengths\nCognitive neuroscience has contributed substantially to our understand-\ning of human cognition. We discuss supporting evidence for that statement\nthroughout the book in areas that include perception, attention, learning,\nmemory, language comprehension, language production, problem solving,\nreasoning, decision-making and consciousness. Here we identify its major\nstrengths.\nFirst, cognitive neuroscience has helped to resolve theoretical con-\ntroversies and issues that had proved intractable with purely behavioural\nstudies (Mather et al., 2013). The main reason is that cognitive neuroscience\nadds considerably to the information available to researchers (Poldrack &\nYarkoni, 2016). Below we briefy consider two examples:\n(1) Listeners hearing degraded speech fnd it much more intelligible when\nit is accompanied by visually presented words matching (rather than\nnot matching) the auditory input. There has been much theoretical\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n23\ncontroversy concerning when this visually presented information infu-\nences speech perception (see Chapter 9). Does it occur early and so\ndirectly infuence basic auditory processes or does it occur late (after\nbasic auditory processing has fnished)? Wild et al. (2012) found there\nwas more activity in brain areas involved in early auditory processing\nwhen the visual input matched the auditory input. This strongly sug-\ngests visual information directly infuences basic auditory processes.\n(2) There has been much theoretical controversy as to whether visual\nimagery resembles visual perception (see Chapter 3). Behavioural evi-\ndence has proved inconclusive. However, neuroimaging has shown\ntwo-thirds of the brain areas activated during visual perception are\nalso activated during visual imagery (Kosslyn, 2005). Even brain\nareas involved in the early stages of visual perception are often acti-\nvated during visual imagery tasks (Kosslyn & Thompson, 2003).\nThus, there are important similarities. Functional neuroimaging has\nalso revealed important diferences between the processes involved in\nvisual perception and imagery (Dijkstra et al., 2017b).\nSecond, the incredible richness of neuroimaging data means cognitive neu-\nroscientists can (at least in principle) construct theoretical models accurately\nmimicking the complexities of brain functioning. In contrast, cognitive\nneuropsychology, for example, is less fexible and more committed to the\nnotion of a modular brain organisation.\nThird, over 10,000 fMRI studies within cognitive neuroscience have\nbeen published. Many meta-analyses based on these studies have been\ncarried out to understand brain-cognition relationships (Poldrack &\nYarkoni, 2016). Such meta-analyses “provide highly robust estimates of the\nneural correlates of relatively specifc cognitive tasks” (p. 592). At present,\nthis approach is limited because we do not know the pattern of activation\nassociated with any given cognitive process – data are coded with respect\nto particular tasks rather than underlying cognitive processes.\nFourth, neuroimaging data can often be re-analysed based on the-\noretical developments. For example, early neuroimaging research on\nface processing suggested it occurs mostly within the fusiform face\narea (see Chapter 3). However, the assumption that face processing\ninvolves  a  network  of  brain regions provides a more accurate account\n(Grill-Spector et al., 2017). Thus, cognitive neuroscience can be self-\ncorrecting.\nMore generally, cognitive neuroscience has shown the assumption of\nfunctional specialisation (each brain area is specialised for a diferent func-\ntion) is oversimplifed. We can contrast the notions of functional special-\nisation and functional integration (positive correlations of various brain\nareas within a network). For example, conscious perception depends on\ncoordinated activity across several brain regions and so involves functional\nintegration (see Chapter 16).\nOverall limitations\nWe turn now to general issues raised by cognitive neuroscience. We empha-\nsise fMRI research because that technique has been used most often.\nKEY TERM\nFunctional specialisation\nThe assumption that\neach brain area or\nregion is specialised for\na specifc function (e.g.,\ncolour processing; face\nprocessing).\nCreated from usyd on 2022-02-13 13:24:37.",
    "24\nApproaches to human cognition\nFirst, many cognitive neuroscientists over-interpret their fndings by assum-\ning one-to-one links between cognitive processes and brain areas. For\nexample, activation in a particular small brain region (a “blob”) is inter-\npreted as being the “love area” and another small region was interpreted as\nbeing the “face processing area”. This approach has been described (unfat-\nteringly) as “blobology”.\nBlobology is in decline. However, there is still undue reliance on\nreverse inference – the involvement of a given cognitive process is inferred\nfrom activation within a given brain region. For example, face recognition\nis typically associated with activation within the fusiform face area, which\nled many researchers to identify that area as specifcally involved in face\nprocessing. This is incorrect in two ways (see Chapter 3): (1) the fusiform\nface area is activated in response to many diferent kinds of objects as well\nas faces (Downing et al., 2006); and (2) several other brain areas (e.g.,\noccipital face area) are also activated during face processing.\nSecond, cognitive neuroscience is rarely used to test cognitive theo-\nries. For example, Tressoldi et al. (2012) reviewed 199 studies published\nin 8 journals. They found 89% of these studies focused on localising the\nbrain areas associated with brain processes and only 11% tested a theory\nof cognition.\nThere is some validity to Tressoldi et al.’s (2012) argument. However,\nit has become less persuasive because of the rapidly increasing emphasis\nwithin cognitive neuroscience on theory testing.\nThird, it is hard to bridge the divide between psychological processes\nand concepts and patterns of brain activation. As Harley (2012) pointed\nout, we may never fnd brain patterns corresponding closely to psycholog-\nical processes such as “attention” or “planning”. Harley (2012, p. 1372)\nconcluded as follows: “Our language and thought may not divide up in the\nway in which the brain implements these processes.”\nFourth, it is sometimes hard to replicate fndings within cognitive neu-\nroscience. For example, Uttal (2012) compared the fndings from diferent\nbrain-imaging meta-analyses on a given cognitive function. More specif-\nically, he identifed the Brodmann areas associated with a given cogni-\ntive function in two meta-analyses. Uttal then worked out the Brodmann\nareas activated in both meta-analyses and divided this by the total number\nof Brodmann areas identifed in at least one meta-analysis. If the two\nmeta-analyses were in total agreement, the resultant fgure would be 100%.\nThe actual fgure varied between 14% and 51%!\nUttal’s (2012) fndings seem devastating – after all, we might expect\nmeta-analyses based on numerous studies to provide very reliable evi-\ndence. However, many apparent discrepancies occurred mainly because\none meta-analysis reported activation in fewer brain areas than the other.\nThis often happened because of stricter criteria for deciding a given brain\narea was activated (Klein, 2014).\nFifth, false-positive fndings (i.e., mistakenly concluding that random\nactivity in a given brain area is task-relevant) are common (Yarkoni et\nal., 2010; see discussion later on p. 25). There are several reasons for this.\nFor example, researchers have numerous options when deciding precisely\nhow to analyse their fMRI data (Poldrack et al., 2017). In addition, most\nneuroimaging studies produce huge amounts of data and researchers\nKEY TERM\nReverse inference\nAs applied to functional\nneuroimaging, it involves\narguing backwards from a\npattern of brain activation\nto the presence of a given\ncognitive process.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n25\nsometimes fail to adjust required signifcance\nlevels appropriately.\nBennett et al. (2009) provided an example\nof a false-positive fnding. They asked their\nparticipant to determine the emotions shown\nin photographs. When they did not adjust\nrequired signifcance levels, there was signif-\nicant evidence of brain activation (see Figure\n1.9). Amusingly, the participant was a dead\nsalmon so we can be certain the “fnding”\nwas a false positive.\nSixth, most brain-imaging techniques\nreveal only associations between patterns of\nbrain activation and behaviour. Such asso-\nciations are purely correlational and do not\nestablish the brain regions activated are nec-\nessary for task performance. For example,\nbrain activation might also be caused by participants engaging in unnec-\nessary monitoring of their performance or attending to non-task stimuli.\nSeventh, many cognitive neuroscientists previously assumed most\nbrain activity is driven by environmental or task demands. As a result, we\nmight expect relatively large increases in brain activity in response to such\ndemands. That is not the case. The increased brain activity when someone\nperforms a cognitive task typically adds less than 5% to resting brain activ-\nity. Surprisingly several brain areas exhibit decreased activity when a cog-\nnitive task is performed. Of importance here is the default mode network\n(Raichle, 2015). It consists of an interconnected set of brain regions (includ-\ning the ventral medial and dorsal medial prefrontal cortex, and the poste-\nrior cingulate cortex) more active during rest than during performance of\na task. Its functions include mind wandering, worrying and daydreaming.\nThe key point is that patterns of brain activity in response to any given\ncognitive task refect increased activity associated with task processing and\ndecreased activity associated with reduced activity within the default mode\nnetwork. Such complexities complicate the interpretation of neuroimaging\ndata.\nEighth, cognitive neuroscience shares with cognitive psychology\nproblems of ecological validity (applicability to everyday life) and para-\ndigm specifcity (fndings not generalising across paradigms). Indeed, the\nproblem of ecological validity may be greater in cognitive neuroscience.\nFor example, participants in fMRI studies lie on their backs in claustro-\nphobic and noisy conditions and have very restricted movement  – not\nmuch like everyday life! Gutchess and Park (2006) found recognition\nmemory was signifcantly worse in an MRI scanner than in an ordi-\nnary laboratory. Presumably the scanner provided a more distracting or\nanxiety-creating environment.\nNinth, we must avoid what Ali et al. (2014) termed  “neuroenchantment” –\nexaggerating the importance of neuroimaging to our understanding of cog-\nnition. Ali et al. provided a striking example of neuroenchantment. College\nstudents were exposed to a crudely built mock brain scanner (including a\ndiscarded hair dryer!) (see Figure 1.10). They were asked to think about\nFigure 1.9\nAreas showing greater activation in a dead salmon when\npresented with photographs of people than when at rest.\nFrom Bennett et al. (2009). With kind permission of the authors.\nKEY TERM\nDefault mode network\nA network of brain\nregions that is active\n“by default” when an\nindividual is not involved\nin a current task; it is\nassociated with internal\nprocesses including mind\nwandering, remembering\nthe past and imagining\nthe future.\nCreated from usyd on 2022-02-13 13:24:37.",
    "26\nApproaches to human cognition\nFigure 1.10\nThe primitive mock\nneuroimaging device used\nby Ali et al. (2014).\nthe answers to various questions (e.g., name a country). The mock neuro-\nimaging device apparently “read their minds” and worked out exactly what\nthey were thinking. Amazingly, three-quarters of the student participants\nbelieved this was genuine rather than being due to the researcher’s trickery?\nCOMPUTATIONAL COGNITIVE SCIENCE\nThere is an important distinction between computational modelling and\nartifcial intelligence. Computational modelling involves programming\ncomputers to model or mimic human cognitive functioning. Thus, cogni-\ntive modellers “have the goal of understanding the human mind through\ncomputer simulation” (Taatgen et al., 2016, p. 1). In contrast, artifcial\nintelligence involves constructing computer systems producing intelligent\noutcomes but typically in ways diferent from humans. Consider Deep Blue,\nthe IBM computer that defeated the world chess champion Garry Kasparov\non 11 May 1997. Deep Blue processed up to 200 million positions per\nsecond, which is vastly more than human chess players (see Chapter 12).\nThe IBM computer Watson also shows the power of artifcial intel-\nligence. This computer competed on the American quiz show Jeopardy\nagainst two of the most successful human contestants ever on that show:\nBrad Rutter and Ken Jennings. The competition took place between\n14 and 16 February 2011, and Watson won the $1 million frst prize.\nWatson had the advantage over Rutter and Jennings of having access to\n10 million documents (200 million pages of content). However, Watson\nhad the disadvantage of being less sensitive to subtleties contained in the\nquestions.\nIn the past (and even nowadays), many experimental cognitive psycholo-\ngists expressed their theories in vague verbal statements (e.g., “Information\nKEY TERMS\nComputational\nmodelling\nThis involves constructing\ncomputer programs that\nsimulate or mimic human\ncognitive processes.\nArtifcial intelligence\nThis involves developing\ncomputer programs\nthat produce intelligent\noutcomes.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n27\nfrom short-term memory is transferred to long-term memory”). This\nmade it hard to provide precise predictions from the theory and to decide\nwhether the evidence ftted the theory. As Murphy (2011) pointed out,\nverbal theories provided theorists with undesirable “wiggle room”. In con-\ntrast, a computational model “requires the researchers to be explicit about\na theory in a way that a verbal theory does not” (Murphy, 2011, p. 300).\nImplementing a theory as a program is a good way to check it contains no\nhidden assumptions or imprecise terms. This often reveals that the theory\nmakes predictions the theorist had not realised!\nThere are issues concerning the relationship between the performance\nof a computer program and human performance (Costello & Keane, 2000).\nFor example, a program’s speed doing a simulated task can be afected\nby psychologically irrelevant features (e.g., the power of the computer).\nNevertheless, the various materials presented to the program should result\nin diferences in program operation time correlating closely with diferences\nin participants’ reaction times with the same materials.\nTypes of models\nMost computational models focus on specifc aspects of human cognition.\nFor example, there are successful computational models providing accounts\nof reading words and non-words aloud (Coltheart et al., 2001; Perry et al.,\n2007, 2014; Plaut et al., 1996) (see Chapter 9).\nMore\nambitious\ncomputational\nmodels\nprovide\ncognitive\narchi tectures – “models of the fxed structure of the mind” (Rosenbloom\net al., 2017, p.  2). Approximately 300 cognitive architectures have been\nproposed over the years (Kotseruba & Tsotsos, 2018).\nNote that a cognitive architecture typically has to be supplemented with\nthe knowledge required to perform a given task to produce a fully fedged\ncomputational model (Byrne, 2012). Anderson et al. (2004) proposed an\nThe IBM Watson and two\nhuman contestants (Ken\nJennings and Brad Rutter).\nBen Hider/Getty Images.\nKEY TERM\nCognitive architecture\nComprehensive framework\nfor understanding human\ncognition in the form of a\ncomputer program.\nCreated from usyd on 2022-02-13 13:24:37.",
    "28\nApproaches to human cognition\nKEY TERMS\nConnectionist models\nModels in computational\ncognitive science\nconsisting of\ninterconnected networks\nof simple units or\nnodes; the networks\nexhibit learning through\nexperience and specifc\nitems of knowledge\nare distributed across\nnumerous units.\nNeural network models\nComputational models\nin which processing\ninvolves the simultaneous\nactivation of numerous\ninterconnected nodes\n(basic units).\nNodes\nThe basic units within a\nneural network model.\nBack-propagation\nA learning mechanism\nin connectionist models\nbased on comparing\nactual responses to\ncorrect ones.\nespecially infuential cognitive architecture in their Adaptive Control of\nThought-Rational (ACT-R) (discussed on p. 30).\nConnectionism\nConnectionist models (also called neural network models) typically\nconsist of interconnected networks of simple units (or nodes) that exhibit\nlearning.\nConnectionist or neural network models use elementary units or nodes\nconnected together in structures or layers (see Figure 1.11). First, a layer\nof input nodes codes the input. Second, activation caused by input coding\nspreads to a layer of hidden nodes. Third, activation spreads to a layer of\noutput nodes.\nOf major importance, the basic model shown in Figure 1.11 can learn\nsimple additions. If input node 1 is active, output node 1 will also become\nactive. If input nodes 1 and 2 are active, output node 3 will become active.\nIf all input nodes are active, output node 10 will become active and so on.\nThe model compares the actual output against the correct output. If there\nis a discrepancy, the model learns to adjust the weights of the connections\nbetween the nodes to produce the correct output. This is known as back-\nward propagation of errors or back-propagation, and it allows the model\nto learn the appropriate responses without being explicitly programmed to\ndo so.\nNumerous connectionist models have been constructed using the basic\narchitecture shown in Figure 1.11. Recent connectionist models often have\nseveral hidden layers (they are called deep neural networks). Connectionist\nmodels involve distributed representations whereas other computational\nmodels involve localist representations (Bowers, 2017a). In the former\ncase, each node or unit responds to multiple stimulus categories and so\na given word or object is represented by the pattern of activation across\nmany nodes or units.\nIn the latter case, each node or unit responds most actively to a single\nmeaningful stimulus category (e.g., a given word or object).\nInterest in the connectionist approach was triggered initially by\nRumelhart et al. (1986) and McClelland et al. (1986) with their parallel\ndistributed processing models. These models (like most models based on\ndistributed representations) exhibit learning. Other infuential connectionist\nmodels are Plaut et al.’s (1996) reading model (Chapter 9) and McClelland\n& Elma’s (1986) TRACE model of spoken word recognition (Chapter 9).\nIn contrast, computational models based\non localist representations often do not exhibit\nlearning because the representations contain\nall the required information. Examples of\nsuch models in this book include Coltheart\net al.’s (2001) reading model (Chapter 9) and\nthe speech production models of Dell (1986)\nand Levelt et al. (1999; see Chapter 11).\nIt has often been assumed localist models\nare biologically implausible because they seem\nto imply a single neuron responds to stimuli\nFigure 1.11\nArchitecture of a basic three-layer connectionist network.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n29\nfrom a given category. However, many neurons show considerable selec-\ntivity because they respond to only a very small fraction of stimuli. For\nexample, consider a study by Quiroga et al. (2005) mentioned earlier. They\npresented epileptic patients with 100 images including famous individuals\nand landmark buildings. On average, responsive neurons responded to\nonly approximately 3% of the images. The issues are complex. However, it\nis not clear localist models are less biologically plausible than distributed\nmodels (Bowers, 2017b).\nEvaluation\nThere are many successful connectionist or neural network models (some\nare mentioned above). Such models (discussed at various points in this\nbook) have provided valuable insights into human cognition and the models\nhave become increasingly sophisticated over time. A general strength of\nneural networks is that they “exhibit robust fexibility in the face of the\nchallenges posed by the real world” (Garson, 2016, p. 3). That is one reason\nwhy neural networks can perform numerous diferent kinds of cognitive\ntasks. Finally, there are intriguing similarities between the brain, with its\nnumerous units (neurons) and synaptic connections, and neural networks,\nwith their units (nodes) and connections.\nWhat are the limitations of connectionist models? First, there is an\nissue with the common assumption that connectionist models are distrib-\nuted. If two words are presented at the same time, this can lead to super-\nimposing two patterns over the same units or nodes making it hard (or\nimpossible) to decide which activated units or nodes belong to which word.\nThis causes superposition catastrophe (Bowers, 2017a).\nSecond, there are many examples of neural networks that can make\nassociations and match patterns. However, it has proved much harder to\ndevelop neural networks that can learn general rules (Garson, 2016).\nThird, the analogy between neural networks and the brain is very\nlimited. In essence, the latter is hugely more complex than the former.\nFourth, back-propagation implies learning will be slow, whereas\nhumans sometimes exhibit one-trial learning (Garson, 2016). Furthermore,\nthere is little or no evidence of back-propagation in the human brain\n(Mayor et al., 2014).\nProduction systems\nProduction systems consist of numerous “IF . . . THEN” production rules.\nProduction rules can take many forms. However, an everyday example is:\n“If the green man is lit up, then cross the road.” There is also a working\nmemory (i.e., a system holding information currently being processed).\nIf information from the environment that “green man is lit up” reaches\nworking memory, it will match the IF part of the rule in long-term memory\nand trigger the THEN part of the rule (i.e., cross the road).\nProduction systems vary but generally have the following characteristics:\n●\nnumerous IF . . . THEN rules;\n●\na working memory containing information;\nKEY TERMS\nProduction systems\nThese consist of very\nlarge numbers of “IF . . .\nTHEN” production rules\nand a working memory\ncontaining information.\nProduction rules\n“IF . . . THEN” or\ncondition-action rules\nin which the action is\ncarried out whenever the\nappropriate condition is\npresent.\nWorking memory\nA limited-capacity system\nused in the processing\nand brief holding of\ninformation.\nCreated from usyd on 2022-02-13 13:24:37.",
    "30\nApproaches to human cognition\n●\na production system that operates by matching the contents of working\nmemory against the IF parts of the rules and then executing the THEN\nparts;\n●\nif information in working memory matches the IF parts of two rules, a\nconfict-resolution strategy selects one.\nAdaptive Control of Thought-Rational (ACT-R) and beyond\nAs mentioned earlier, Anderson et al. (2004) proposed ACT-R, which was\nsubsequently developed (e.g., Anderson et al., 2008). ACT-R assumes the\ncognitive system consists of several modules (relatively independent subsys-\ntems). It combines computational cognitive science with cognitive neuro-\nscience by identifying the brain regions associated with each module (see\nFigure 1.12). Four modules are of special importance:\n(1) Retrieval module: it maintains the retrieval cues needed to access\ninformation; its proposed location is the inferior ventrolateral pre-\nfrontal cortex.\n(2) Imaginal module: it transforms problem representations to assist in\nproblem solving; it is located in the posterior parietal cortex.\n(3) Goal module: it keeps tracks of an individual’s intentions and con-\ntrols information processing; it is located in the anterior cingulate\ncortex.\n(4) Procedural module: it uses production (IF . . . THEN) rules to deter-\nmine what action will be taken next; it is located at the head of the\ncaudate nucleus within the basal ganglia.\nEach module has a bufer associated with it containing a limited amount of\nimportant information. How is information from these bufers integrated?\nAccording to Anderson et al. (2004, p. 1058): “A central production\nsystem can detect patterns in these bufers and take co-ordinated action.”\nFigure 1.12\nThe main modules of the\nACT-R (Adaptive Control of\nThought-Rational) cognitive\narchitecture with their\nlocations within the brain.\nReprinted from Anderson\net al. (2008). Reprinted with\npermission of Elsevier.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n31\nIf several productions could be triggered by the information contained\nin the bufers, one is selected based on the value or gain associated with\neach outcome plus the amount of time or cost incurred in achieving that\noutcome.\nACT-R represents an impressive attempt to provide a theoretical\nframework for understanding information processing and performance on\nnumerous cognitive tasks. It is also impressive in seeking to integrate com-\nputational cognitive science with cognitive neuroscience.\nWhat are ACT-R’s limitations? First, it is very hard to test such a\nwide-ranging theory. Second, areas of prefrontal cortex (e.g., dorsolat-\neral prefrontal cortex) generally assumed to be of major importance in\ncognition are de-emphasised. Third, as discussed earlier, research within\ncognitive neuroscience increasingly reveals the importance to cognitive pro-\ncessing of brain networks rather than specifc regions. Fourth, in common\nwith most other cognitive architectures, ACT-R has a knowledge base that\nis substantially smaller than that possessed by humans (Lieto et al., 2018).\nThis reduces the applicability of ACT-R to human cognitive performance.\nStandard model of the mind\nDozens of cognitive architectures have been proposed and it is difcult to\ncompare them. Laird et al. (2017; see also Rosenbloom et al., 2017) recently\nproposed a standard model emphasising commonalities among major cogni-\ntive architectures including ACT-R (see Figure 1.13).\nFigure 1.13 may look unimpressive because it represents the model at\na very general level. However, the model contains numerous additional\nassumptions (Laird et al., 2017). First, procedural memory has special\nimportance because it has access to the whole of working memory; in con-\ntrast, the other modules have access only to specifc aspects of working\nmemory.\nFigure 1.13\nThe basic structure of the\nstandard model involving\nfve independent modules.\nDeclarative memory (see\nGlossary) stores facts and\nevents whereas procedural\nmemory (see Glossary)\nstores knowledge about\nactions.\nPerception\nMotor\nProcedural\nLong-term Memory\nWorking Memory\nDeclarative\nLong-term Memory\nCreated from usyd on 2022-02-13 13:24:37.",
    "32\nApproaches to human cognition\nSecond, the crucial assumption is that there is a cognitive cycle lasting\napproximately 50 ms per cycle. What happens is that: “Procedural memory\ninduces the selection of a single deliberate act per cycle, which can modify\nworking memory, initiate the retrieval of knowledge from long-term declar-\native memory, initiate motor actions . . ., and provide top-down infuence\nto perception” (Laird et al., 2017, p. 3). The cognitive cycle involves serial\nprocessing but parallel processing can occur within any module as well as\nbetween them.\nThe standard model is useful but incomplete. For example, it does not\ndistinguish between diferent types of declarative memory (e.g., episodic\nand semantic memory; see Chapter 7). In addition, it does not account for\nemotional infuences on cognitive processing.\nLinks with other approaches\nACT-R represents an impressive attempt to apply computational models to\ncognitive neuroscience. There has also been interest in applying such models\nto data from brain-damaged patients. Typically, the starting point is to\ndevelop a computational model accounting for the performance of healthy\nindividuals on some task. After that, aspects of the computational model\nor program are altered to simulate “lesions”, and the efects on task perfor-\nmance are assessed. Finally, the lesioned model’s performance is compared\nagainst that of brain-damaged patients (Dell & Caramazza, 2008).\nOverall strengths\nComputational cognitive science has several strengths. First, the develop-\nment of cognitive architectures can provide an overarching framework for\nunderstanding the cognitive system. This would be a valuable achievement\ngiven that much research in cognitive psychology is limited in scope and\nsufers from paradigm specifcity. Laird et al.’s (2017) standard model rep-\nresents an important step on the way to that achievement.\nSecond, the scope of computational cognitive science has increased.\nInitially, it was applied mainly to behavioural data. More recently, however,\nit has been applied to functional neuroimaging data (e.g., Anderson et al.,\n2004) and EEG data (Anderson et al., 2016a). Why is this important? As\nTaatgen et al. (2016, p. 3) pointed out: “The link to neuroimaging is critical\nin establishing that the hypothesised processing steps in cognitive models\nhave plausibility in reality.”\nThird, rigorous thinking is required to develop computational models\nbecause computer programs must contain detailed information about the\nprocesses involved in performing any given task. In contrast, many theo-\nries within traditional cognitive psychology are vaguely expressed and the\npredictions following from their assumptions are unclear.\nFourth, progress is increasingly made by using nested incremental mod-\nelling. In essence, a new model builds on the strengths of previous related\nmodels while eliminating (or reducing) their weaknesses and accounting for\nadditional data. For example, Perry et al. (2007; Chapter 9) put forward a\nconnectionist dual-process model (CDP+) of reading aloud that improved\non the model on which it was based.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n33\nOverall limitations\nWhat are the main limitations of the computational cognitive science\napproach? First, there is Bonini’s paradox: as models become more accu-\nrate and complete, they can become as hard to understand as the complex\nphenomena they are designed to explain. Conversely, models easy to under-\nstand are typically inaccurate and incomplete. Many computational mod-\nellers have responded to this paradox by focusing on the essence of the\nphenomena and ignoring the minor details (Milkowski, 2016, p. 1459).\nSecond, many computational models are hard to falsify. The ingenuity\nof computational modellers means many models can account for numerous\nbehavioural fndings (Taatgen et al., 2016). This issue can be addressed by\nrequiring computational models to explain neuroimaging fndings as well\nas behavioural ones.\nThird, some computational models are less successful than they appear.\nOne reason is overftting in which a model accounts for noise in the data\nas well as genuine efects (Ziegler et al., 2010). Overftting often means a\nmodel seems to account very well for a given data set but is poor at pre-\ndicting new data (Yarkoni & Westfall, 2017).\nFourth, most computational models ignore motivational and emo-\ntional factors. Norman (1980) distinguished between a cognitive system\n(the Pure Cognitive System) and a biological system (the Regulatory\nSystem). Computational cognitive science typically de-emphasises the\nRegulatory System even though it often strongly infuences the Pure\nCognitive System. This issue can be addressed by developing computa-\ntional models indicating how emotions modulate cognitive processes\n(Rodriguez et al., 2016).\nFifth, many computational models are very hard to understand\n(Taatgen et al., 2016). Why is this so? Addyman and French (2012, p. 332)\nidentifed several reasons:\nEveryone still programs in [their] own favourite programming lan-\nguage, source code is rarely made available, . . . even for other mod-\nellers, the profusion of source code in a multitude of programming\nlanguages, writing without programming guidelines, makes it almost\nimpossible to access, check, explore, re-use or continue to develop\n[models].\nComputational modellers often fail to share their source codes and models\nbecause they have perceived ownership over their own research and are\nconcerned about losing control over it (Fecher et al., 2015).\nCOMPARISONS OF MAJOR APPROACHES\nWe have discussed the major approaches to human cognition at length and\nyou may wonder which is the most useful and informative. However, that is\nnot the best way of thinking about the issues for various reasons:\n(1) An increasing amount of research involves two or more diferent\napproaches.\nCreated from usyd on 2022-02-13 13:24:37.",
    "34\nApproaches to human cognition\nKEY TERMS\nConverging operations\nAn approach in which\nseveral methods with\ndifferent strengths and\nlimitations are used to\naddress a given issue.\nReplication\nThe ability to repeat a\nprevious experiment\nand obtain the same (or\nsimilar) fndings.\n(2) Each approach makes its own distinctive contribution and so all are\nrequired. By analogy, it would be pointless asking whether a driver is\nmore or less useful than a putter for a golfer – both are essential.\n(3) Each approach has its own limitations as well as strengths (see Table\n1.2). The optimal solution in such circumstances is to use converging\noperations – several diferent research methods are used to address\na given theoretical issue with the strengths of one method balancing\nout the limitations of other methods. If diferent methods produce the\nsame answer, that provides stronger evidence than could be obtained\nusing a single method. If diferent methods produce diferent answers,\nfurther research is required to clarify matters. Note that using conver-\ngent operations is more difcult and demanding than using a single\napproach (Brase, 2014).\nIn writing this book, our coverage of each topic emphasises research most\nenhancing our understanding. As a result, any given approach (e.g., cogni-\ntive neuroscience; cognitive neuropsychology) is strongly represented when\nwe discuss some topics but is much less well represented with other topics.\nIS THERE A REPLICATION CRISIS?\nReplication (the ability to repeat the fndings of previous research using the\nsame or similar experimental methods) is of central importance to psychol-\nogy (including cognitive psychology). In recent years, however, there have\nbeen concerns about the extent to which fndings can be replicated, leading\nShrout and Rodgers (2018, p. 487) to refer to “the replication crisis” in\npsychology.\nAn important trigger for these concerns was an infuential article in\nwhich the replicability of 100 studies published in leading psychology\njournals was assessed (Open Science Collaboration, 2015). Only 36% of\nthe fndings reported in these studies were replicated. Within cognitive\npsychology, only 21 out of 42 fndings (50%) were replicated.\nOnly 50% of fndings were reproduced! This is perhaps less problem-\natical than it sounds. The complexities of research mean individual studies\ncan provide only an estimate of the “true” state of afairs rather than\ndefnitive evidence (Stanley & Spence, 2014).\nWhy are there problems with replicating fndings in cognitive psychol-\nogy (and psychology generally)? A major reason is the sheer complexity of\nhuman cognition – cognitive processing and performance are infuenced by\nnumerous factors (many of which are not controlled or manipulated). As a\nresult, even replicated fndings often difer considerably in terms of the size\nof the efects obtained (Stanley et al., 2018).\nAnother reason is that experimenters sometimes use questionable\nresearch practices exaggerating the true statistical signifcance of their data.\nOne example is p-hacking (selective reporting), in which “Researchers\nconduct many analyses on the same data set and just report those that are\nstatistically signifcant” (Simmons et al., 2018, p. 255). Another example\ninvolves researchers proposing hypotheses after research results are known\nrather than before as should be the case (Shrout & Rodgers, 2018).\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n35\nTABLE 1.3 STRENGTHS AND LIMITATIONS OF MAJOR APPROACHES TO HUMAN COGNITION\nStrengths\nLimitations\nExperimental cognitive psychology\n1.  The frst systematic approach to understanding\nhuman cognition\n1.  Most cognitive tasks are complex and involve many\ndifferent processes\n2.  The source of most theories and tasks used by the\nother approaches\n2.  Behavioural evidence provides indirect evidence concerning\ninternal processes\n3.  It is enormously fexible and can be applied to any\naspect of cognition\n3. Theories are sometimes vague and hard to test empirically.\n4.  It has produced numerous important replicated\nfndings\n4.  Findings sometimes do not generalise because of paradigm\nspecifcity\n5.  It has strongly infuenced social, clinical and\ndevelopmental psychology\n5. There is a lack of an overarching theoretical framework\nCognitive neuropsychology\n1.  Double dissociations have provided strong evidence\nfor various processing modules\n1.  Patients may develop compensatory major strategies not\nfound in healthy individuals\n2.  Causal links can be shown between brain damage\nand cognitive performance\n2.  Most of its theoretical assumptions (e.g., the mind is\nmodular) seem too extreme\n3.  It has revealed unexpected complexities in cognition\n(e.g., language)\n3.  Detailed cognitive processes and their interconnectedness\nare often not specifed\n4.  It transformed memory and language research\n4. There has been excessive reliance on single-case studies\n5.  It straddles the divide between cognitive psychology\nand cognitive neuroscience\n5. Brain plasticity complicates interpreting fndings\nCognitive neuroscience: functional neuroimaging + ERPs + TMS\n1.  Great variety of techniques offering excellent\ntemporal or spatial resolution\n1.  Functional neuroimaging techniques provide essentially\ncorrelational data\n2.  Functional specialisation and brain integration can\nbe studied\n2.  Much over-interpretation of data involving reverse\ninferences\n3.  TMS is fexible and permits causal inferences\n3.  There are many false positives and replication failures\n4.  Rich data permit assessment of integrated brain\nprocessing as well as specialised functioning\n4. It has generated very few new theories\n5.  Resolution of complex theoretical issues\n5. Diffculty in relating brain activity to psychological processes\nComputational cognitive science\n1.  Theoretical assumptions are spelled out with\nprecision\n1.  Many computational models do not make new predictions\n2.  Comprehensive cognitive architectures have been\ndeveloped\n2.  There is some overftting, which restricts generalisation to\nother data sets\n3.  Computational models are increasingly used to\nmodel brain damage\n3.  It is sometimes hard to falsify computational effects of\nmodels\n4.  Computational cognitive neuroscience is increasingly\nused to model patterns of brain activity\n4.  Most computational models de-emphasise motivational and\nemotional factors\n5.  The emphasis on parallel processing fts well with\nfunctional neuroimaging data\n5.  Researchers’ reluctance to share source codes and models\ninhibits progress\nCreated from usyd on 2022-02-13 13:24:37.",
    "36\nApproaches to human cognition\nKEY TERM\nMeta-analysis\nA form of statistical\nanalysis based on\ncombining the fndings\nfrom numerous studies on\na given research topic.\nOne answer to problems with replicability is to use meta-analysis,\nin which fndings from many studies are combined and integrated using\nvarious statistical techniques. This approach has the advantage of not\nexaggerating the importance of any single study, but has various potential\nproblems (Sharpe, 1997):\n(1) The “apples and oranges” problem: very diferent studies are often\nincluded within a meta-analysis.\n(2) The “fle drawer” problem: it is hard for researchers to publish\nnon-signifcant fndings. Since meta-analyses often ignore unpublished\nfndings, the studies included may be unrepresentative.\n(3) The “garbage in – garbage out” problem: poorly designed and con-\nducted studies are often included along with high-quality ones.\nThe above problems can be addressed. Precise criteria for studies to be\nincluded can reduce the frst and third problems. The second problem can\nbe reduced by asking researchers to provide relevant unpublished data.\nWatt and Kennedy (2017) identifed a more important problem: many\nresearchers use somewhat subjective criteria for inclusion of studies in\nmeta-analyses, favouring those supporting their theoretical position and\nrejecting those that do not. This creates confrmation bias (see Chapter 14).\nThe good news is that experimental psychologists (including cogni-\ntive psychologists) have responded very positively to the above problems.\nMore specifcally, there has been a large increase in disclosure and pre-\nregistration. Disclosure means that researchers “disclose all of their meas-\nures, manipulations, and exclusions” (Nelson et al., 2018, p. 518). In the\ncase of meta-analyses, it means researchers making available all the fnd-\nings initially considered for inclusion. That would allow other research-\ners to conduct their own meta-analyses and check whether the outcome\nremains the same.\nPre-registration involves researchers making publicly available all\ndecisions about sample size, hypotheses, statistical analyses and so on\nbefore an experimental study is carried out. With respect to meta-analyses,\npre- registration involves making public the inclusion criteria for a meta-\nanalysis, the methods of analysis and so on, before the fndings of included\nstudies are known (Hamlin, 2017).\nIn sum, there are some genuine issues concerning the replicability of\nfndings within cognitive psychology. However, there are various reasons\nwhy there is no “replication crisis”. First, numerous important fndings\nin cognitive psychology have been replicated dozens or even hundreds\nof times as is clear from a very large number of meta-analytic reviews.\nSecond, as Nelson et al. (2018, p. 511) pointed out: “The scientifc practices\nof experimental psychologists have improved dramatically.”\nOUTLINE OF THIS BOOK\nOne problem with writing a textbook of cognitive psychology is that vir-\ntually all the processes and systems in the cognitive system are interde-\npendent. Consider, for example, a student reading a book to prepare for an\nexamination. The student is learning, but several other processes are going\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n37\non as well. Visual perception is involved in the intake of information from\nthe printed page, and there is attention to the content of the book.\nIn order for the student to beneft from the book, they must possess\nconsiderable language skill, and must have extensive relevant knowledge\nstored in long-term memory. There may be an element of problem solving\nin the student’s attempts to relate the book’s content to the possibly con-\nficting information they have learned elsewhere. Decision-making may also\nbe involved when the student decides how much time to devote to each\nchapter.\nIn addition, what the student learns depends on their emotional state.\nFinally, the acid test of whether the student’s learning has been efective\ncomes during the examination itself, when the material from the book\nmust be retrieved and consciously evaluated to decide its relevance to the\nexamination question.\nThe words italicised in the previous three paragraphs indicate major\naspects of human cognition and form the basis of our coverage. In view\nof the interdependence of all aspects of the cognitive system, we empha-\nsise how each process (e.g., perception) depends on other processes and\nstructures (e.g., attention, long-term memory). This should aid the task of\nunderstanding the complexities of human cognition.\nCHAPTER SUMMARY\n•\nIntroduction. Cognitive psychology used to be unifed by an\napproach based on an analogy between the mind and the\ncomputer. This information-processing approach viewed the mind\nas a general-purpose, symbol-processing system of limited capacity.\nToday there are four main approaches to human cognition:\nexperimental cognitive psychology; cognitive neuroscience;\ncognitive neuropsychology; and computational cognitive science.\nThese four approaches are increasingly combined to provide an\nenriched understanding of human cognition.\n•\nCognitive psychology. Cognitive psychology focuses on internal\nmental processes whereas behaviourism focused mostly on\nobservable stimuli and responses. Cognitive psychologists assume\ntop-down and bottom-up processes are both involved in the\nperformance of cognitive tasks. These processes can be serial\nor parallel. Various methods (e.g., latent-variable analysis) have\nbeen used to address the task impurity problem and to identify\nthe processes within cognitive tasks. Cognitive psychology has\nmassively infuenced theorising and the tasks used across all\nmajor approaches to human cognition. In spite of its enormous\ncontributions, cognitive psychology sometimes lacks ecological\nvalidity, suffers from paradigm specifcity and is theoretically vague.\n•\nCognitive neuropsychology. Cognitive neuropsychology is\nbased on various assumptions including modularity, anatomical\nCreated from usyd on 2022-02-13 13:24:37.",
    "38\nApproaches to human cognition\nmodularity, uniformity of functional architecture and subtractivity.\nDouble dissociations provide reasonable (limited) evidence\nfor separate modules or systems. The case-study approach\nis more informative than the single-case approach. Cognitive\nneuropsychology is limited for several reasons: its assumptions are\nmostly too strong; patients can develop compensatory strategies,\nthere is brain plasticity; brain damage can cause widespread\nreduced connectivity within the brain; and it underestimates the\nextent of integrated brain functioning.\n•\nCognitive neuroscience: the brain in action. Cognitive\nneuroscientists study the brain as well as behaviour using\ntechniques varying in spatial and temporal resolution. Functional\nneuroimaging techniques provide basically correlational evidence,\nbut transcranial magnetic stimulation (TMS) can indicate a given\nbrain area is necessarily involved in a given cognitive function. The\nrichness of the data obtained from neuroimaging studies permits\nthe assessment of functional specialisation and brain integration.\nCognitive neuroscience is a fexible and potentially self-correcting\napproach. However, correlational fndings are sometimes over-\ninterpreted, underpowered studies make replication diffcult, and\nrelatively few studies in cognitive neuroscience generate (or even\ntest) cognitive theories.\n•\nComputational cognitive science. Computational cognitive\nscientists develop computational models to understand human\ncognition. Connectionist networks use elementary units or nodes\nconnected together. They can learn using rules such as backward\npropagation. Production systems consist of production or “IF . . .\nTHEN” rules. ACT-R is a highly developed model based on\nproduction systems. Computational models have increased in\nscope to provide detailed theoretical accounts of fndings from\ncognitive neuroscience and cognitive neuropsychology. They have\nshown progress via the use of nested incremental modelling.\nComputational models are often hard to falsify, de-emphasise\nmotivational and emotional factors, and often lack biological\nplausibility.\n•\nComparisons of different approaches. The major approaches\nare increasingly used in combination. Each approach has its own\nstrengths and limitations, which makes it useful to use converging\noperations. When two approaches produce the same fndings, this\nis stronger evidence than can be obtained from a single approach\non its own. If two approaches produce different fndings, this\nindicates further research is needed to clarify what is happening.\n•\nIs there a replication crisis? There is increasing evidence that\nmany fndings in psychology (including cognitive psychology)\nare hard to replicate. However, this does not mean there is a\nCreated from usyd on 2022-02-13 13:24:37.",
    "Approaches to human cognition\n39\nreplication crisis. Meta-analyses indicate that numerous fndings\nhave been successfully replicated many times. In addition,\nexperimental research practices have improved considerably in\nrecent years which should increase successful replications in the\nfuture.\nFURTHER READING\nHartwigsen, G. (2018). Flexible redistribution in cognitive networks. Trends in\nCognitive Sciences, 22, 687–698. Gesa Hartwigsen discusses several compensatory\nstrategies used by brain-damaged patients and healthy individuals administered\ntranscranial magnetic stimulation (TMS).\nLaird, J.E., Lebiere, C. & Rosenbloom, P.S. (2017). A standard model of the mind:\nToward a common computational framework across artifcial intelligence, cog-\nnitive science, neuroscience, and robotics. AI Magazine, 38, 1–19. These authors\nproposed a standard model based on the commonalities found among diferent\nproposed cognitive architectures (e.g., ACT-R; Soar).\nPassingham, R. (2016). Cognitive Neuroscience: A very Short Introduction. Oxford:\nOxford University Press. Richard Passingham provides an accessible account of\nthe essential features of cognitive neuroscience.\nPoldrack, R.A., Baker, C.I., Durnez, J., Gorgolewski, K.J., Matthews, P.M.,\nMunafo, M.R., et al. (2017). Scanning the horizon: Towards transparent and\nreproducible neuroimaging research. Nature Reviews Neuroscience, 18, 115–126.\nProblems with research in cognitive neuroscience are discussed and proposals for\nenhancing the quality and replicability of such research are put forward.\nShallice, T. (2015). Cognitive neuropsychology and its vicissitudes: The fate of\nCaramazza’s axioms. Cognitive Neuropsychology, 32, 385–411. Tim Shallice dis-\ncusses strengths and limitations of various experimental approaches within cogni-\ntive neuropsychology.\nShrout, P.E. & Rodgers, J.L. (2018). Psychology, science, and knowledge con-\nstruction: Broadening perspectives from the replication crisis. Annual Review of\nPsychology, 69, 487–510. Patrick Shrout and Joseph Rodgers discuss the numer-\nous ways in which improving research practices are reducing replication problems.\nTaatgen, N.A., van Vugt, M.K., Borst, J.P. & Melhorn, K. (2016). Cognitive mod-\nelling at ICCM: State of the art and future directions. Topics in Cognitive Science,\n8, 259–263. Niels Taatgen and his colleagues discuss systematic improvements in\ncomputational cognitive models.\nWard, J. (2015). The Student’s Guide to Cognitive Neuroscience (3rd edn). Hove,\nUK: Psychology Press. The frst fve chapters of this textbook provide detailed\ninformation about the main techniques used by cognitive neuroscientists.\nCreated from usyd on 2022-02-13 13:24:37.",
    "Created from usyd on 2022-02-13 13:24:37.",
    "Figure 2.1\nComplex scene that\nrequires prolonged\nperceptual processing to\nunderstand fully. Study the\npicture and identify the\nanimals within it.\nReprinted from Hegdé (2008).\nReprinted with permission of\nElsevier.\nBasic processes in visual\nperception\nINTRODUCTION\nConsiderable progress has been made in understanding visual percep-\ntion in recent years. Much of this progress is due to cognitive neuroscien-\ntists, thanks to whom we now have a good knowledge of the visual brain.\nInitially, we consider the main brain areas involved in vision and their func-\ntions. Then we discuss theories of brain systems in vision, followed by a\ndetailed analysis of basic aspects of visual perception (e.g., colour percep-\ntion; depth perception). Finally, we consider whether perception can occur\nwithout conscious awareness.\nThe specific processes we use in visual perception depend on what we\nare looking at and on our perceptual goals (i.e., what we are looking for)\n(Hegdé, 2008). On the one hand, we can sometimes perceive the gist of a\nChapter\n2\nCreated from usyd on 2022-02-13 13:25:58.",
    "44\nVisual perception and attention\nnatural scene extremely rapidly (Thorpe et al., 1996). Observers saw pho-\ntographs containing (or not containing) an animal for only 20 ms. Event-\nrelated potentials (ERPs: see Glossary) indicated the presence of an animal\nwas detected within about 150 ms. On the other hand, look at the photo-\ngraph in Figure 2.1 and decide how many animals are present. It probably\ntook you several seconds to perform this task. Bear in mind the diversity of\nvisual perception as you read this and the following two chapters.\nVISION AND THE BRAIN\nIn this section we consider the brain systems involved in visual perception.\nVisual processing occurs in at least 30 distinct brain areas (Felleman & Van\nEssen, 1991). The visual cortex consists of the entire occipital cortex at the\nback of the brain and also extends well into the temporal and parietal lobes.\nTo understand visual processing in the brain fully, however, we first need to\nconsider briefly what happens between the eye and the cortex.\nFrom eye to cortex\nThere are two types of visual receptor cells in the retina: cones and rods.\nCones are used for colour vision and sharpness of vision (see section on\ncolour vision, pp. 64–71). Patients with rod monochromatism have no\ndetectable cone function resulting in total colour blindness (Tsano &\nSharma, 2018).\nThere are 125 million rods concentrated in the outer regions of the\nretina. Rods are specialised for vision in dim light. Many differences\nbetween cones and rods stem from the fact that a retinal ganglion cell\nreceives input from only a few cones but from hundreds of rods. Thus,\nonly rods produce much activity in retinal ganglion cells in poor lighting\nconditions.\nThe main pathway between the eye and the cortex is the retina-\ngeniculate-striate pathway. It transmits information from the retina to\nV1 and then V2 (both discussed shortly) via the lateral geniculate nuclei\n(LGNs) of the thalamus. The entire retina-geniculate-striate system is\norganised similarly to the retinal system. For example, two stimuli adja-\ncent to each other in the retinal image will also be adjacent at higher levels\nwithin that system. The technical term is retinopy: retinal receptor cells are\nmapped to points on the surface of the visual cortex.\nEach eye has its own optic nerve and the two optic nerves meet at\nthe optic chiasm. At this point the axons from the outer halves of each\nretina proceed to the hemisphere on the brain hemisphere on the same\nside, whereas those from the inner halves cross over and go to the other\nhemisphere. As a result, each side of visual space is represented within the\nopposite brain hemisphere. Signals then proceed along two optic tracts\nwithin the brain. One tract contains signals from the left half of each eye\nand the other signals from the right half (see Figure 2.2).\nAfter the optic chiasm, the optic radiation proceeds to the lateral\ngeniculate nucleus, which is part of the thalamus. Nerve impulses finally\nreach V1 in primary visual cortex within the occipital lobe at the back of\nthe head before spreading out to nearby visual cortical areas such as V2.\nKEY TERMS\nRetinal ganglion cells\nRetinal cells providing the\noutput signal from the\nretina.\nRetinopy\nThe notion that there\nis mapping between\nreceptor cells in the retina\nand points on the surface\nof the visual cortex.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n45\nThere are two relatively independent channels or pathways within the\nretina-geniculate-striate system:\n(1) The parvocellular (or P) pathway: it is most sensitive to colour and to\nfine detail; most of its input comes from cones.\n(2) The magnocellular (or M) pathway: it is most sensitive to movement\ninformation; most of its input comes from rods.\nAs stated above, these two pathways are only relatively independent. In\nfact, there are numerous interconnections between them and the entire\nvisual system is extremely complex. For example, there is clear intermin-\ngling of the two pathways in V1 (Leopold, 2012). Ryu et al. (2018, p. 707)\nstudied brain activity in V1 when random-dot images were presented: “The\nlocal V1 sites receiving those parallel inputs [from the P and M pathways]\nare densely linked with one another via horizontal connections [which] are\norganised in complicated yet systematic ways to subserve the multitude of\nrepresentational functions of V1.”\nFinally, there is also a Koniocellular pathway. However, its functions\nare still not well understood.\nEarly visual processing: V1 and V2\nWe start with three general points. First, to understand visual process-\ning in the primary visual cortex (V1 or BA17) and the secondary visual\ncortex (V2 or BA18), we must consider the notion of a receptive field. The\nreceptive field for any given neuron is the retinal region where light affects\nits activity. The receptive field can also refer to visual space because it is\nmapped in a one-to-one manner onto the retinal surface.\nFigure 2.2\nRoute of visual signals.\nNote that signals reaching\nthe left visual cortex come\nfrom the left sides of the\ntwo retinas, and signals\nreaching the right visual\ncortex come from the right\nsides of the two retinas.\nKEY TERM\nReceptive field\nThe region of the retina\nin which light influences\nthe activity of a particular\nneuron.\nCreated from usyd on 2022-02-13 13:25:58.",
    "46\nVisual perception and attention\nSecond, neurons often influence each other. For example, there is\nlateral inhibition, where reduced activity in one neuron is caused by activ-\nity in a neighbouring neuron. Lateral inhibition increases the contrast at\nthe edges of objects, making it easier to identify the dividing line between\nobjects. The phenomenon of simultaneous contrast depends on lateral inhi-\nbition (see Figure 2.3). The two central squares are physically identical but\nthe one on the left appears lighter. This differ-\nence is due to simultaneous contrast produced\nbecause the left surround is much darker than\nthe right surround.\nThird, early visual processing involves\nlarge areas within the primary visual cortex\n(V1) and secondary visual cortex (V2).\nFor example, Hegdé and Van Essen (2000)\nfound in macaques that one-third of V2 cells\nresponded to complex shapes and differences\nin size and orientation.\nTwo pathways\nAs we have just seen, neurons from the P and\nM pathways mainly project to V1 (primary\nvisual cortex). What happens after V1? The P\npathway associates with the ventral pathway\nor stream that proceeds to the inferotemporal\ncortex. In contrast, the M pathway associates\nwith the dorsal pathway or stream that proceeds to the posterior parietal\ncortex. Note the above assertions oversimplify a complex reality.\nWe discuss the ventral and dorsal pathways in detail shortly. It is\nassumed the ventral or “what” pathway culminating in the inferotempo-\nral cortex is mainly concerned with form and colour processing and with\nobject recognition. In contrast, the dorsal or “how” pathway culminating\nin the parietal cortex is more concerned with motion processing. As we\nwill see later, there are extensive interactions between the two pathways.\nThe nature of such interactions was reviewed by Rossetti et al. (2017; see\nFigure 2.15 in this chapter).\nGalletti and Fattori (2018) argued that visual processing is more\nflexible than implied by the notion of two interacting pathways or streams.\nWe should not conceive the cortical streams as fixed series of intercon-\nnected cortical areas in which each area belongs to one stream . . ., but\n[rather] as interconnected neuronal networks, often involving the same\nneurons, that are involved in a number of functional processes and\nwhose activation changes  dynamically according to the context.\n(p. 203)\nOrganisation of the visual brain\nA more detailed picture of the brain areas involved in visual process-\ning is given in Figure 2.4. V3 is generally assumed to be involved in form\nKEY TERM\nLateral inhibition\nReduction of activity in\none neuron caused by\nactivity in a neighbouring\nneuron.\nFigure 2.3\nThe square on the right looks darker than the identical square\non the left because of simultaneous contrast involving lateral\ninhibition.\nFrom Lehar (2008). Reproduced with permission of the author.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n47\nprocessing, V4 in colour processing and V5/MT in motion processing (all\ndiscussed in more detail pp. 49–54). The ventral stream includes V1, V2, V3,\nV4 and the inferotemporal cortex, whereas the dorsal stream proceeds from\nV1 via V3 and MT (medial temporal cortex) to MST (medial superior tem-\nporal cortex).\nFigure 2.4 reveals three important points. First, there are complex\ninterconnections among visual cortical areas. Second, the brain areas\nwithin the ventral pathway are more than twice as large as those within\nthe dorsal pathway. Third, cells in the lateral geniculate nucleus respond\nfastest when a visual stimulus is presented followed by activation of cells\nin V1. However, cells are activated in several other areas (V3/V3A; MT;\nMST) very shortly thereafter.\nFigure 2.4 shows the traditional hierarchical view of the major brain\nareas involved in visual processing. It is supported by anatomical evi-\ndence (see proportions of fibres projecting up the hierarchy in the figure).\nNevertheless, this view is oversimplified. Here we consider three of its main\nlimitations.\nFigure 2.4\nSome distinctive features of the largest visual cortical areas. The relative size of the\nboxes reflects the relative area of different regions. The arrows labelled with percentages\nshow the proportion of fibres in each projection pathway. The vertical position of each\nbox represents the response latency of cells in each area, as measured in single-unit\nrecording studies. IT = inferotemporal cortex; MT = medial or middle temporal cortex;\nMST = medial superior temporal cortex. All areas are discussed in detail in the text.\nCreated from usyd on 2022-02-13 13:25:58.",
    "48\nVisual perception and attention\nFirst, Kravitz et al. (2013) disagreed with\nthe traditional view that the ventral pathway\nor stream involves a serial hierarchy pro-\nceeding from simple to complex. Instead,\nhe argued it consists of several overlapping\nrecurrent networks (see Figure 2.5). There are\nconnections in both directions between the\ncomponents within these networks. As Hegdé\n(2018, p. 902) argued, “Various regions of\nthe visual system process information not in\na strict hierarchical manner but as parts of\nvarious dynamic brain-wide networks.”\nSecond, there is an initial “feedfor-\nward  sweep” proceeding through the visual\nareas starting with V1 and then V2 (shown\nby the directional arrows in Figure 2.4).\nThis is followed by recurrent or top-down\nprocessing proceeding in the opposite direc-\ntion (not shown in Figure 2.4). Several the-\norists (e.g., Lamme, 2018; see Chapter 16)\nassume recurrent processing is of major\nimportance for conscious visual perception\nbecause it integrates information across different visual areas. Note that\nvisual imagery depends on several top-down processes resembling those\nused in visual perception (see Chapter 3).\nHurme et al. (2017) obtained support for the above assumptions. They\napplied transcranial magnetic stimulation (TMS; see Glossary) to V1 at 60\nms to suppress feedforward processing and at 90 ms to suppress recurrent\nprocessing. As predicted, early V1 activity was necessary for conscious and\nunconscious vision but late V1 activity was necessary only for conscious\nvision.\nThird, Zeki (2016) distinguished three hierarchical models of the visual\nbrain (see Figure 2.6). Model (a) was proposed first and model (c), the\none favoured by Zeki, was proposed most recently. His central argument\nis that, “Parallel processing . . . is much more ubiquitous than commonly\nsupposed” (p. 2515). Thus, models such as the one shown in Figure 2.4 are\ninadequate because they de-emphasise parallel processing.\nFunctional specialisation\nZeki (1993, 2001) proposed a functional specialisation theory where differ-\nent cortical areas are specialised for different visual functions. The visual\nsystem resembles workers each working alone to solve part of a complex\nproblem, and it is consistent with Zeki’s (2016) emphasis on parallel pro-\ncessing within the visual brain. The results of their labours are then com-\nbined to produce coherent visual perception.\nWhat are the advantages of functional specialisation? First, object\nattributes can occur in unpredictable combinations (Zeki, 2005). For\nexample, a green object may be a car, a sheet of paper or a leaf, and a\ncar can be red, black or green. Thus, we often need to process all of an\nFigure 2.5\nConnectivity within the ventral pathway on the lateral surface\nof the macaque brain. Brain areas involved include V1, V2, V3\nand V4, the middle temporal (MT)/medial superior temporal\n(MST) complex, the superior temporal sulcus (STS) and the\ninferior temporal cortex (TE).\nFrom Kravitz et al. (2013). Reprinted with permission of Elsevier.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n49\nobject’s attributes for accurate perception. Second, the required processing\ndiffers considerably across attributes (Zeki, 2005). For example, motion\nprocessing involves integrating information across time whereas form or\nshape processing involves considering the spatial relationship of elements\nat a given moment.\nHere are the main functions Zeki ascribed to the brain areas shown in\nFigure 2.3:\n●\nV1 and V2: They are involved at an early stage of visual processing.\nThey contain different groups of cells responsive to colour and form.\n●\nV3 and V3A: Cells in these areas respond to form (especially the shapes\nof objects in motion) but not colour.\n●\nV4: The majority of cells in this area respond to colour; many are also\nresponsive to line orientation.\nFigure 2.6\n(a) The single hierarchical\nmodel where all brain areas\nafter V1 are considered\njointly as “visual association\ncortex”; (b) the parallel\nhierarchical model\nwhich is a hierarchy of\nprocessing areas running\nserially from V1 through\nV2 to V3 but with much\nparallel processing; (c) the\nthree parallel hierarchical\nfeedforward systems model\nwith a strong emphasis on\nparallel rather than serial\nprocessing.\nFrom Zeki (2016).\n(a)  Single hierarchical model\n(b)  Parallel hierarchical model through V1\n(c)  Three parallel hierarchical feedforward systems\nRetina\nLGN\nV1\nVisual association cortex\nRetina\nLGN\nV1\nV2\nV3\nV3A\nV4\nV5\nV1\nV2\nV3\nV4\nV5\nLGN\nPulvinar\nRetina\nCreated from usyd on 2022-02-13 13:25:58.",
    "50\nVisual perception and attention\nKEY TERM\nAchromatopsia\nA condition caused by\nbrain damage in which\nthere is very limited colour\nperception but form and\nmotion perception are\nrelatively intact.\n●\nV5: This area is specialised for visual motion. In studies with macaque\nmonkeys, Zeki found all the cells in this area responded to motion\nbut not colour. In humans, the areas specialised for visual motion are\nreferred to as MT and MST.\nZeki assumed colour, motion and form are processed in anatomically sepa-\nrate visual areas. The relevant evidence is discussed below.\nForm processing\nBrain areas involved in form processing in humans include V1, V2, V3 and\nV4, culminating in the inferotemporal cortex (Kourtzi & Connor, 2011).\nNeurons in the inferotemporal cortex respond to specific semantic catego-\nries (e.g., animals; body parts; see Chapter 3). Neurons in the inferotempo-\nral cortex are also involved in form processing. Baldassi et al. (2013) found\nin monkeys that many neurons within the anterior inferotemporal cortex\nresponded on the basis of form or shape (e.g., round; star-like; horizontally\nthin) rather than object category.\nPavan et al. (2017) investigated the role of early visual areas in form\nprocessing using repetitive transcranial magnetic stimulation (rTMS; see\nGlossary) to disrupt processing. With static stimuli, rTMS delivered to\nearly visual areas (V1/V2) disrupted form processing whereas rTMS deliv-\nered to V5/MT did not.\nIf form processing occurs in different brain areas from colour and\nmotion processing, we might anticipate some patients would have severely\nimpaired form processing but intact colour and motion processing. Some\nsupport was reported by Gilaie-Dotan (2016a). She studied LG, a man with\nvisual form agnosia (see Glossary). LG had deficient functioning within\nV2 and V3 (although no obvious brain damage) associated with impaired\nform processing and object recognition, but relatively intact perception of\ncolour and biological motion. However, such cases are very rare. As Zeki\n(1993) pointed out, brain damage sufficient to almost eliminate form per-\nception would typically be so widespread that the patient would be blind.\nColour processing\nThe assumption that V4 (located within the ventral visual pathway) is spe-\ncialised for colour processing has been tested in several ways. These include\nstudying brain-damaged patients, using brain-imaging techniques, and\nusing transcranial magnetic stimulation to produce a temporary “lesion”\n(see pp. 20–22).\nIf V4 is specialised for colour processing, patients with damage to\nthat area should exhibit minimal colour perception with fairly intact\nform and motion perception and ability to see fine detail. This is approx-\nimately the case in achromatopsia (also known as cerebral achromatop-\nsia) although  cases involving total achromatopsia are very rare (Zihl &\nHeywood, 2016).\nBouvier and Engel (2006) found in a meta-analysis that a small brain\narea within the ventral (bottom) occipital cortex in (or close to) area V4\nwas damaged in nearly all cases of achromatopsia. However, the loss of\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n51\nKEY TERM\nAkinetopsia\nA brain-damaged\ncondition in which motion\nperception is severely\nimpaired even though\nstationary objects are\nperceived reasonably well.\ncolour vision was typically only partial, implying other areas are also\ndirectly involved in colour processing.\nLafer-Sousa et al. (2016) identified three brain areas in the ventral\nvisual pathway responding more strongly to video clips of various objects\npresented in colour than in black-and-white. Of importance, different\nbrain areas were associated with colour and shape processing: colour areas\nresponded comparably to intact and scrambled objects.\nBannert and Bartels (2018) studied brain activity in several brain areas\n(including V1, V2, V3 and V4) while participants viewed abstract colour\nstimuli or formed visual images of colour objects (e.g., tomato; banana).\nThe colour of visually presented stimuli could be worked out from brain\nactivity in every brain area studied, whereas the colour of imagined stimuli\ncould only be worked out from brain activity in V4. These findings suggest\nthat a network including several brain areas is involved in colour process-\ning, but V4 is of special importance within that network.\nFinally, note that V4 is a relatively large area. As such, it is involved in\nthe processing of texture, form and surfaces as well as colour (Winawer &\nWitthoft, 2015).\nMotion processing\nArea V5 (also known as motion processing area MT) is heavily involved in\nmotion processing. Functional neuroimaging studies indicate that motion\nprocessing is associated with activity in V5/MT (Zeki, 2015). However, such\nstudies cannot show V5 (or MT) is necessary for motion perception. More\ndirect evidence was reported by McKeefry et al. (2008) using transcranial\nmagnetic stimulation (see Glossary) to disrupt motion perception. TMS,\napplied to V5/MT, produced a subjective slowing of stimulus speed and\nimpaired observers’ ability to discriminate between different speeds.\nFurther evidence of the causal role of V5 in motion perception was\nobtained by Vetter et al. (2015). Observers could not predict the motion of\na moving target when TMS was applied to V5.\nAdditional evidence that the area V5/MT is important in motion pro-\ncessing comes from research on patients with akinetopsia. Akinetopsia\nis an exceptionally rare condition where stationary objects are perceived\nfairly normally but motion perception is grossly deficient (Ardila, 2016).\nZihl et al. (1983) studied LM, a woman with akinetopsia who had suffered\nbilateral damage to the motion area (V5/MT). She could locate stationary\nobjects by sight, had good colour discrimination and her binocular vision\nwas normal. However, her motion perception was grossly deficient:\nShe had difficulty . . . in pouring tea or coffee into a cup because the\nfluid appeared to be frozen, like a glacier. . . . In a room where more\nthan two people were walking, . . . “people were suddenly here or there\nbut I have not seen them moving”.\nZihl and Heywood (2015) discussed additional findings relating to LM.\nEven though her motion perception was extremely poor, she still retained\nlimited ability to distinguish between moving and stationary stimuli.\nHeutink et al. (2018) studied TD, a patient with akinestopsia due to\ndamage to V5. She was severely impaired at perceiving the direction of\nCreated from usyd on 2022-02-13 13:25:58.",
    "52\nVisual perception and attention\nhigh-speed visual motion but not low-speed motion, suggesting V5 is less\nimportant for processing low-speed than high-speed motion.\nV5 (MT) is not the only brain area involved in motion processing.\nThere is also the area MST just above V5/MT. Vaina (1998) studied two\npatients with damage to MST. Both patients had various problems relating\nto motion perception. One patient (RR) “frequently bumped into people,\ncorners and things in his way, particularly into moving targets (e.g., people\nwalking)” (Vaina, 1998, p. 498). These findings suggest MST is involved in\nthe visual guidance of walking. Chaplin et al. (2018) found that the direc-\ntion of motion of a stimulus in healthy individuals could be inferred by\ntaking account of activation within both MT and MST.\nThe notions that motion perception depends almost exclusively on\nV5/MT and MST and that those areas only process information relating\nto motion are both oversimplifications for various reasons. First, several\nareas outside V5/MT and MST are involved in motion perception. For\nexample, consider biological motion perception (see Chapter 4). Such per-\nception involves several additional areas including the superior temporal\nsulcus, superior temporal gyrus and inferior frontal gyrus (Thompson &\nParasuraman, 2012; Pavlova et al., 2017).\nSecond, Heywood and Cowey (1999; see Figure 2.7) found that approx-\nimately 60% of cells within V5/MT respond to binocular disparity (differ-\nence between the retinal images in the left and right eyes; see Glossary)\nand 50% of cells within V5/MT respond to stimulus orientation. However,\nV5/MT is especially important with respect to direction of motion with\napproximately 90% of cells responding.\nThird, we should distinguish between different types of motion percep-\ntion (e.g., first-order and second-order motion perception). With first-order\nFigure 2.7\nThe percentage of cells in\nsix different visual cortical\nareas responding selectively\nto orientation, direction\nof motion, disparity and\ncolour.\nFrom Heywood and Cowey\n(1999).\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n53\ndisplays, the moving shape differs in luminance (intensity of reflected light)\nfrom its background. For example, the shape might be dark whereas the\nbackground is light. With second-order displays, there is no difference in\nluminance between the moving shape and the background.\nIn everyday life, we encounter second-order displays infrequently\n(e.g., movement of grass in a field caused by the wind). Some patients\nhave intact first-order motion perception but impaired second-order\nmotion perception whereas others exhibit the opposite pattern (Gilaie-\nDotan, 2016a). Thus, all forms of motion perception do not involve\nsimilar underlying processes.\nGilaie-Dotan (2016b) studied motion processing within the brain (see\nFigure 2.8). In essence, information about visual motion inputs bypasses\nseveral visual areas (e.g., V2, V4) and rapidly reaches MT/V5. It then con-\ntinues rapidly to MST, after which information is transferred to several\nother areas.\nGilaie-Dotan (2016b, p. 379) pointed out that visual motion perception\n“has been continually associated with and considered part of the dorsal\npathway”. For example, Milner and Goodale’s (1995, 2008) perce ption-\naction model emphasises close links between visual motion processing\nand perception and the dorsal (“how” pathway; see pp. 56–57). Gilaie-\nDotan accepted the dorsal pathway is of major importance. However, she\nargued persuasively that the ventral (“what”) pathway is also involved\nin motion perception. For example, efficient detection of visual motion\nFigure 2.8\nVisual motion inputs\nproceed rapidly from\nsubcortical areas and V1\ndirectly to MT/V5 and from\nthere to MST; information is\nthen transferred to several\nother brain regions. [LGN =\nlateral geniculate nucleus;\nPlv = pulvinar].\nFrom Gilaie-Dotan (2016b).\nReprinted with permission of\nElsevier.\n(a)\n(b)\nDorsal\nMT & MST\nVentral\nSpeeded inputs to MT/V5 bypassing hierarchy\nMT/V5 to MSTd/I\nMotion pathway outputs according to function\nV1\nLGN\nMT/V5\nkinematics\noptic fow\nattention/\naction\neye movements/\nobject tracking\noptic\nfow\nPlv\nventral stream\nobjectness\nMSTd/1\ndorsal stream\nV1\nLGN\nMT/V5\nkinematics\noptic fow\nattention/\naction\neye movements/\nobject tracking\noptic\nfow\nPlv\nleft\nright\nventral stream\nobjectness\nMSTd/1\ndorsal stream\nleft\nright\nCreated from usyd on 2022-02-13 13:25:58.",
    "54\nVisual perception and attention\nrequires having an intact right ventral visual cortex (Gilaie-Dotan et al.,\n2013).\nBinding problem\nZeki’s theoretical approach poses the obvious problem of how informa-\ntion about an object’s motion, colour and form is combined and integrated\nto produce coherent perception. This is the binding problem: “How the\nbrain brings together what it has processed . . . in its different hierarchically\norganised parallel processing systems . . . to give us our unitary experience\nof the visual world” (Zeki, 2016, p. 3521). One aspect of this problem is that\nobject-related processing in different visual areas ends at different times,\nthus making it harder to integrate these outputs in visual perception.\nThere may be continuous integration of information starting during\nearly stages of visual processing. Seymour et al. (2009) presented observ-\ners with red or green dots rotating clockwise or counterclockwise. Colour-\nmotion conjunctions were processed in several brain areas including\nV1, V2, V3, V3A/B, V4 and V5/MT+. Seymour et al. (2016) found that\nbinding of information about object form and colour occurred as early as\nV2. These findings contradict the traditional assumption that “The visual\nsystem initially extracts borders between objects and their background and\nthen ‘fills in’ colour” (Seymour et al., 2016, p. 1997).\nGhose and Ts’o (2017) reviewed research indicating progressively more\nintegration of different kinds of information (and thus less functional spe-\ncialisation) during visual processing. They concluded:\nIn V2, we see an increase in the overlap of cortical generated selectiv-\nities such as orientation and colour . . . in V4 we see extensive overlap\namong colour, size, and form, and the existence of . . . a combination\nof colour and orientation . . . not present in earlier areas.\n(p. 17)\nSo far we have focused on increases in integration of information as pro-\ncessing proceeds from early to late visual areas (  feedforward process-\ning). However, conscious visual perception generally depends crucially on\nrecurrent processing (feedback from higher to lower visual brain areas).\nObservers’ expectations influence recurrent processing and it is arguable\nthat expectations (e.g., bananas will be yellow) facilitate the binding or inte-\ngration of different kinds of visual information.\nThe binding-by-synchrony hypothesis (e.g., Singer & Gray, 1995) pro-\nvides an influential solution to the binding problem. According to this\nhypothesis, detectors responding to features of a single object fire in syn-\nchrony. Of relevance, widespread synchronisation of neural activity is asso-\nciated with conscious visual awareness (e.g., Gaillard et al., 2009; Melloni\net al., 2007; see Chapter 16).\nThe synchrony hypothesis is oversimplified. There is the largely unre-\nsolved issue of explaining why and how synchronised activity occurs across\nvisual areas. The fact that visual object processing occurs in widely distrib-\nuted areas of the brain makes it implausible that precise synchrony could\nbe achieved.\nKEY TERM\nBinding problem\nThe issue of integrating\ndifferent types of\ninformation to produce\ncoherent visual\nperception.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n55\nFinally, note there are various binding problems. As Feldman (2013)\npointed out, one problem is how visual features are bound together.\nAnother problem is how we bind together information over successive eye\nmovements to perceive a stable visual world.\nWithin the above broader context, it is clear several lines of research\nare relevant. For example, observers must decide which parts of the\nvisual information available at any given time belong to the same object.\nThe gestaltists put forward several laws describing how this happens (see\nChapter 3). Research on visual search (detecting target stimuli among dis-\ntractors) is also relevant (see Chapter 5). This research shows the important\nrole of selective attention in combining features close together in time and\nspace.\nEvaluation\nZeki’s functional specialisation theory is an ambitious and influential\nattempt to provide a coherent theoretical framework. As discussed later,\nZeki’s assumption that motion processing typically proceeds somewhat\nindependently of other types of visual process has reasonable empirical\nsupport.\nWhat are the limitations with Zeki’s theoretical approach? First, the\nbrain areas involved in visual processing are less specialised than implied\ntheoretically. As mentioned earlier on p. 52, Heywood and Cowey (1999)\nconsidered the percentage of cells in each visual cortical area respond-\ning selectively to various stimulus characteristics (see Figure 2.7). Cells in\nseveral areas responded to orientation, disparity and colour. Specialisation\nwas found only with respect to responsiveness to direction of stimulus\nmotion in MT.\nSecond, the visual brain is substantially more complex than assumed\nby Zeki. There are far more brain areas devoted to visual processing than\nshown in Figure 2.3, and each brain area has connections to numerous\nother areas (Baker et al., 2018). For example, V1 is connected to at least\n50 other areas! What is also de-emphasised in Zeki’s approach is the impor-\ntance of brain networks and the key role played by recurrent processing.\nThird, the binding problem (or problems) has not been solved. However,\nintegrated visual perception undoubtedly depends on both  bottom-up\n(feedforward) processes and top-down (recurrent) processes (see Chapter 3).\nTWO VISUAL SYSTEMS: PERCEPTION-ACTION\nMODEL\nWhat are the major functions of the visual system? Historically, the most\npopular answer was that it provides us with an internal (and conscious) rep-\nresentation of the external world. In contrast, Goodale and Milner (1992)\nand Milner and Goodale (1995, 2008) argued in their perception-action\nmodel, there are two visual systems each fulfilling a different function or\npurpose. First, there is the vision-for-perception (or “what”) system based\non the ventral stream or pathway. It is used when we decide whether an\nobject is a cat or a buffalo or when admiring a magnificent landscape. Thus,\nit is used to identify objects.\nKEY TERM\nVentral stream\nThe part of the visual\nprocessing system\ninvolved in object\nperception and\nrecognition and the\nformation of perceptual\nrepresentations.\nCreated from usyd on 2022-02-13 13:25:58.",
    "56\nVisual perception and attention\nSecond, there is the vision-for-action (or “how”) system based on the\ndorsal stream or pathway (see Figure 2.9) used for visually guided action.\nIt is used when running to return a ball at tennis or when grasping an\nobject. When we grasp an object, we must calculate its orientation and\nposition with respect to ourselves. Since observers and objects often move\nrelative to each other, orientation and position need to be worked out\nimmediately prior to initiating a movement.\nMilner (2017, p. 1297) summarised key differences between the two\nsystems:\nThe ventral stream . . . mediates the transformations of the contents\nof the visual signal into the mental furniture that guides memory, rec-\nognition and conscious perception. In contrast, the dorsal stream . . .\nmediates the visual guidance of action, primarily in real time.\nSchenk and McIntosh (2010) identified four major differences between the\ntwo processing streams:\n(1) The ventral stream underlies vision for perception whereas the dorsal\nstream underlies vision for action.\n(2) There is allocentric coding (object-centred; coding the locations of\nobjects relative to each other) in the ventral stream but egocentric\ncoding (body-centred; coding relative to the observer’s own body) in\nthe dorsal stream.\n(3) Representations in the ventral stream are sustained over time whereas\nthose in the dorsal stream are short-lasting.\n(4) Processing in the ventral stream generally (but not always) leads to\nconscious awareness, whereas processing in the dorsal stream does\nnot.\nTwo other differences have been suggested. First, processing in the dorsal\nstream is faster. Second, ventral stream processing depends more on input\nfrom the fovea (the central part of the retina used for detecting detail).\nMilner and Goodale originally implied that the dorsal and ventral\nstreams were largely independent of each other. However, they have\nFigure 2.9\nGoodale and Milner’s\n(1992) perception-action\nmodel showing the dorsal\nand ventral streams. (SC =\nsuperior colliculus; LGNd =\ndorsal lateral geniculate\nnucleus; V1+ = early visual\nareas.)\nFrom de Haan et al. (2018).\nReprinted with permission of\nElsevier.\nRetina\nLGNd\nSC\nPulvinar\nDorsal\nstream\nVentral\nstream\nOccipitotemporal\ncortex\nPosterior\nparietal\ncortex\nV1+\nKEY TERMS\nDorsal stream\nThe part of the visual\nprocessing system most\ninvolved in visually guided\naction.\nAllocentric coding\nVisual or spatial coding of\nobjects relative to each\nother; see egocentric\ncoding.\nEgocentric coding\nVisual or spatial coding\ndependent on the\nposition of the observer’s\nbody; see allocentric\ncoding.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n57\nincreasingly accepted that the two streams often interact. For example,\nMilner argued the influence of the ventral stream on dorsal stream process-\ning “seems to carry visual and semantic complexity, thereby allowing us to\nbring meaning to our actions” (Milner, 2017, p. 1305). The key issue of\nthe independence (or interdependence) of the two streams is discussed on\npp. 62–63.\nFindings: brain-damaged patients\nWe can test Milner and Goodale’s theory by studying brain-damaged\npatients. Patients with damage to the dorsal pathway should have reasona-\nbly intact vision for perception but severely impaired vision for action. The\nopposite pattern of intact vision for action but very poor vision for percep-\ntion should be found in patients having damage to the ventral pathway.\nThus, there should be a double dissociation (see Glossary).\nOptic ataxia\nPatients with optic ataxia have damage to the posterior parietal cortex\n(forming part of the dorsal stream; see Figure 2.10). Some evidence suggests\npatients with optic ataxia are poor at making precise visually guided move-\nments although their vision and ability to move their arms are reasonably\nintact. As predicted, Perenin and Vighetto (1988) found patients with optic\nataxia had great difficulty in rotating their hands appropriately when reach-\ning towards (and into) a large oriented slot.\nPatients with optic ataxia do not all conform to the simple picture\ndescribed above. First, somewhat different regions of posterior parietal\ncortex are associated with reaching and grasping movements and some\npatients have greater problems with one type of movement than the other\n(Vesia & Crawford, 2012).\nSecond, it is oversimplified to assume patients have intact visual per-\nception but impaired visually guided action. Pisella et al. (2006) obtained\nmuch less evidence for impaired visually guided action in central compared\nto peripheral vision. This finding is consistent with evidence indicating\nmany optic ataxics can drive effectively.\nFigure 2.10\nLesion overlap (purple =\n>40% overlap; orange =\n>60% overlap) in patients\nwith optic ataxia. (SPL =\nsuperior parietal lobule;\nSOG = superior occipital\ngyrus; Pc = precuneus.)\nFrom Vesia and Crawford\n(2012). Reprinted with\npermission of Springer.\nKEY TERM\nOptic ataxia\nA condition in which\nthere are problems\nmaking visually guided\nmovements in spite of\nreasonably intact visual\nperception.\nCreated from usyd on 2022-02-13 13:25:58.",
    "58\nVisual perception and attention\nKEY TERM\nVisual form agnosia\nA condition in which there\nare severe problems in\nshape perception (what an\nobject is) but apparently\nreasonable ability to\nproduce accurate visually\nguided actions.\nThird, patients with optic ataxia have some impairment in vision for\nperception (especially in peripheral vision). Bartolo et al. (2018) found such\npatients had an impaired ability on the perceptual task of deciding whether\na target was reachable and they also had problems on tasks requiring vision\nfor action. Thus, patients with optic ataxia have difficulties in combining\ninformation from the dorsal and ventral streams.\nFourth, Rossetti and Pisella (2018) concluded as follows from their\nreview: “Optic ataxia is not a visuo-motor deficit and there is no dissoci-\nation between perception and action capacities in optic ataxia” (p. 225).\nVisual form agnosia\nWhat about patients with damage only to the ventral stream? Of relevance\nare some patients with visual form agnosia, a condition involving severe\nproblems with object recognition even though visual information reaches\nthe visual cortex (see Chapter 3). The most-studied visual form agnosic is\nDF, whose brain damage is in the ventral stream (James et al., 2003). For\nexample, her activation in that stream was no greater when presented with\nobject drawings than with scrambled line drawings. However, she showed\nhigh levels of activation in the dorsal stream when grasping for objects.\nGoodale et al. (1994) found DF was very poor at a visual perception\ntask that involved distinguishing between two shapes with irregular con-\ntours. However, she grasped these shapes firmly between her thumb and\nindex finger. Goodale et al. concluded DF “had no difficulty in placing her\nfingers on appropriate opposition points during grasping” (p. 604).\nHimmelbach et al. (2012) re-analysed DF’s performance based on data\nin Goodale et al. (1994). DF’s performance was substantially inferior to\nthat of healthy controls. Similar findings were obtained when DF’s perfor-\nmance on other grasping and reaching tasks was compared against con-\ntrols. Thus, DF had greater difficulties with visually guided action than\npreviously believed.\nRossit et al. (2018) found DF had impaired peripheral (but not central)\nreaching, which is the pattern associated with optic ataxia. DF also had\nsignificant impairment in the fast control of reaching movements (also\nassociated with optic ataxia). Rossit et al. (p. 15) concluded: “We can no\nlonger assume that DF’s dorsal visual stream is intact\nand that she is spared in visuo-motor control tasks, as\nshe also presents clear signs of optic ataxia.”\nVisual illusions\nThere are numerous visual illusions, of which the\nMüller-Lyer (see Figure 2.11) is one of the most famous.\nThe vertical line on the left looks longer than the one\non the right although they are the same length. The\nEbbinghaus illusion (see Figure 2.12) is also well known.\nThe central circle surrounded by smaller circles looks\nsmaller than a central circle of the same size surrounded\nby larger circles although the two central circles are the\nsame size.\nFigure 2.11\nThe Müller-Lyer illusion.\nInteractive exercise:\nMüller-Lyer\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n59\nHow has the human species flourished if\nour visual perceptual processes are apparently\nvery prone to error? Milner and Goodale\n(1995) argued the vision-for-perception system\nprocesses visual illusions and provides visual\njudgements. In contrast, we mostly use the\nvision-for-action system when walking close to\na precipice or dodging cars. These ideas led to\na dramatic prediction: actions (e.g., pointing;\ngrasping) using the vision-for-action system\nshould be unaffected by most visual illusions.\nFindings\nBruno et al. (2008) conducted a meta-analytic\nreview of Müller-Lyer studies where observ-\ners pointed rapidly at one figure (using the\nvision-for-action system). The mean illusion\neffect was 5.5%. In contrast, the mean illusion\neffect was 22.4% when observers provided\nverbal estimations of length (using the vision-\nfor- perception system). The perception-action\nmodel is supported by this large difference.\nHowever, the model seems to predict there\nshould have been no illusion effect at all with\npointing.\nWith the Ebbinghaus illusion, the illusion\nis often much stronger with visual judgements\nusing the vision-for- perception system than with grasping movements using\nthe vision-for-action system (Whitwell & Goodale, 2017). Knol et al. (2017)\nexplored the Ebbinghaus illusion in more detail. As predicted theoretically,\nonly visual judgements were influenced by the distance between the target\nand the context.\nSupport for the perception-action model has been reported with the\nhollow-face illusion, a realistic hollow mask resembling a normal face\n(see Figure 2.13; visit the website: www.richardgregory.org/experiments).\nKróliczak et al. (2006) placed a target (a small magnet) on the face mask\nor a normal face. Here are two tasks they used:\n(1) Draw the target position (using the vision-for-perception system).\n(2) Make a fast, flicking finger movement to the target (using the vision-\nfor-action system).\nThere was a strong illusion effect when observers drew the target position,\nwhereas their performance was very accurate (i.e., illusion-free) when they\nmade a flicking movement. Both findings were as predicted theoretically.\nKróliczak et al. (2006) also had a third condition where observers\nmade a slow pointing finger movement to the target and so the vision-for-\naction system was involved. However, there was a fairly strong illusory\neffect. Why was this? Actions may involve the vision-for-perception system\nFigure 2.12\nThe Ebbinghaus illusion.\nKEY TERM\nHollow-face illusion\nA concave face mask is\nmisperceived as a normal\nface when viewed from\nseveral feet away.\nCreated from usyd on 2022-02-13 13:25:58.",
    "60\nVisual perception and attention\nas well as the vision-for-action system when preceded by conscious cogni-\ntive processes.\nVarious problematical issues for the perception-action model have\naccumulated. First, the type of action is important. Franz and Gegenfurtner\n(2008) found the mean illusory effect with the Müller-Lyer was 11.2% with\nperceptual tasks, compared to 4.4% with full visual guidance of the hand\nmovement. In contrast, grasping when observers could not monitor their\nhand movements was associated with an illusory effect of 9.4%, perhaps\nbecause action programming required the ventral stream.\nSecond, illusion effects assessed by grasping movements often decrease\nwith repeated practice (Kopiske et al., 2017). Kopiske et al. argued people\nuse feedback from their inaccurate grasping movements on early trials to\nreduce illusion effects later on.\nThird, illusion effects are often greater when grasping or pointing move-\nments are made following a delay (Hesse et al., 2016). The ventral stream\n(vision-for-perception) may be more likely to be involved after a delay.\nThe various interpretive problems with previous research led Chen\net al. (2018a) to use a different approach. In their key condition, observers\nhad restricted vision (they viewed a sphere coated in luminescent paint in\ndarkness through a pinhole). They estimated the sphere’s size by matching\nthe distance between their thumb and forefinger to that size (perception)\nor they grasped the sphere (action). Their non-grasping hand was in their\nlap or directly below the sphere. In the latter condition, observers could\nmake use of proprioception (awareness of the position of one’s body\nparts).\nSize judgements were very accurate in perception and action with full\nvision (see Figure 2.14). However, the key finding was that proprioceptive\ninformation about distance produced almost perfect performance when\nobservers grasped the sphere but not when providing a perceptual estimate.\nThese findings indicate a very clear difference in the processes underlying\nvision-for-perception and vision-for-action.\nIn sum, there is some support for the predictions of the original\nvision-action model. However, illusory effects with visual judgements and\nwith actions are more complex and depend on many more factors than\nKEY TERM\nProprioception\nAn individual’s awareness\nof the position and\norientation of parts of\ntheir body.\nFigure 2.13\nLeft: normal and hollow\nfaces with small target\nmagnets on the forehead\nand cheek of the normal\nface. Right: front view of the\nhollow mask that appears as\nan illusory face projecting\nforwards.\nKróliczak et al. (2006). Reprinted\nwith permission of Elsevier.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n61\nassumed by that model. Attempts by Milner\nand Goodale to accommodate such complex-\nities are discussed below.\nAction planning + motor responses\nMilner and Goodale (2008) argued most tasks\nrequiring observers to grasp an object involve\nsome processing in the ventral stream in\naddition to the dorsal stream. They reviewed\nresearch showing that involvement of the\nventral stream is especially likely in the fol-\nlowing circumstances:\n(1) Memory is required (e.g., there is a time\nlag between the offset of the stimulus\nand the start of the grasping movement).\n(2) Time is available to plan the forthcoming\nmovement (e.g., Króliczak et al., 2006).\n(3) Planning which movement to make is\nnecessary.\n(4) The action is unpractised or awkward.\nAccording to the perception-action model, actions are most likely to\nrequire the ventral stream when they involve conscious processes. Creem\nand Proffitt (2001) supported this notion. They started by distinguishing\nbetween effective and appropriate grasping. For example, we can grasp\na toothbrush effectively by its bristles but appropriate grasping involves\naccessing stored knowledge about the object and so often requires the\nventral stream. As predicted, appropriate grasping was much more\nadversely affected than effective grasping by disrupting participants’ ability\nto retrieve object knowledge.\nvan Polanen and Davare (2015) reviewed research on factors con-\ntrolling skilled grasping. They concluded:\nThe ventral stream seems to be gradually more recruited as infor-\nmation about the object from pictorial cues or memory is needed to\ncontrol the grasping movement, or if conceptual knowledge about\nmore complex objects that are used every day or tools needs to be\nretrieved for allowing the most appropriate grasp.\n(p. 188)\nDorsal stream: conscious awareness\nAccording to the two systems approach, ventral stream processing is gen-\nerally accessible to consciousness whereas dorsal stream processing is not.\nFor example, it is assumed that the ventral stream (and conscious process-\ning) are often involved in motor planning (Milner & Goodale, 2008). There\nis some support for these predictions from the model (Milner, 2012). As we\nwill see, however, recent evidence mostly provides contrary evidence.\nFigure 2.14\nDisruption of size judgements when estimated perceptually\n(estimation) or produced by grasping (grasping) in full or\nrestricted vision when there was proprioception (withPro) or no\nproprioception (noPro).\nFrom Chen et al. (2018a). Reprinted with permission of Elsevier.\n0.8\nESTIMATION\n**\n***\n***\n***\n***\nGRASPING\n0.4\n0.0\nDisruption index (DI)\n–0.4\nFull\nRestricted\nFull\nRestricted\nnoPro\nnoPro\nwithPro\nnoPro\nnoPro\nwithPro\nCreated from usyd on 2022-02-13 13:25:58.",
    "62\nVisual perception and attention\nLudwig et al. (2016) assessed the involvement of the dorsal and ventral\nstreams in conscious visual perception using a different approach. The vis-\nibility of visual targets presented to one eye was manipulated by varying\nthe extent to which continuous flash suppression (rapidly changing stimuli\npresented to the other eye) impaired the processing of the targets.\nThere were two main findings. First, there was a tight coupling\nbetween visual awareness of target stimuli and ventral stream processing.\nSecond, there was a much looser coupling between target awareness and\ndorsal stream processing. The first finding is consistent with the two visual\nsystems hypothesis. However, the second finding suggests dorsal process-\ning is more relevant to conscious visual perception than assumed by that\nhypothesis.\nAccording to the perception-action model, manipulations (e.g., contin-\nuous flash suppression) preventing conscious perception should neverthe-\nless permit more processing in the dorsal than the ventral stream. However,\nneuroimaging studies have typically obtained no evidence that neural activ-\nity in the dorsal stream is greater than in the ventral stream when observers\nlack conscious awareness of visual stimuli (Hesselmann et al., 2018).\nTwo pathways: update\nThe perception-action model was originally proposed before neuroimaging\nand other techniques had clearly indicated the great complexity of the brain\nnetworks involved in perception and action (de Haan et al., 2018). Recent\nresearch has led to developments of the perception-action model in two\nmain ways. First, we now know much more about the various interactions\nbetween processing in the dorsal and ventral streams. Second, there are\nmore than two visual processing streams. Rossetti et al. (2017) show how\ntheoretical conceptualisations of the relationship between visual perception\nand action have become more complex (see Figure 2.15).\nWe have seen that the ventral pathway is often involved in visually\nguided action. There is also increasing evidence the dorsal pathway is\ninvolved in visual object recognition (Freud et al., 2016). For example,\npatients with damage to the ventral pathway often retain some sensitivity\nto three-dimensional (3-D) structural object representations (Freud et al.,\n2017a). Zachariou et al. (2017) applied transcranial magnetic stimulation\nto posterior parietal cortex within the dorsal pathway to disrupt process-\ning. TMS disrupted the holistic processing (see Glossary) of faces, suggest-\ning the dorsal pathway is involved in face recognition.\nMore supporting evidence was reported by Freud et al. (2016). They\nstudied shape processing, which is of central importance in object recogni-\ntion and so should depend primarily on the ventral pathway. However, the\nventral and dorsal pathways were both sensitive to shape. The observers’\nability to recognise objects correlated with the shape sensitivity of regions\nwithin the dorsal pathway. Thus, dorsal path activation was of direct rele-\nvance to shape and object processing.\nHow many visual processing streams are there? There is evidence that\nactions towards objects depend on two partially separate dorsal streams\n(Sakreida et al., 2016; see Chapter 4). First, there is a dorso-dorsal stream\n(the “grasp” system) used to grasp objects rapidly. Second, there is a\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n63\nventro-dorsal stream that makes use of memorised object knowledge and\noperates more slowly than the first stream.\nHaak and Beckmann (2018) investigated the connectivity patterns\namong 22 visual areas, discovering these areas “are organised into not\ntwo but three visual pathways: one dorsal, one lateral, and one ventral”\n(p. 82). Their findings thus provide some support for the emphasis within\nthe  perception-action model on dorsal and ventral streams. Haak and\nBeckmann speculated that the new lateral pathway may “incorporate . . .\naspects of vision, action and language” (p. 81).\nOverall evaluation\nMilner and Goodale’s theoretical approach has been hugely influen-\ntial. Their central assumption that there are two visual systems (“what”\nFigure 2.15\nHistorical developments in\ntheories linking perception\nand action. Row 1: the\nintuitive notion that action\nis preceded by conscious\nperception. Row 2: Goodale\nand Milner’s original two\nsystems’ theory. Row 3:\ninteraction between the\ntwo anatomical pathways\nand perceptual and visual\nprocesses. Row 4: evidence\nthat processing in primary\nmotor cortex is preceded\nby interconnections\nbetween dorsal (green) and\nventral (red) pathways.\nFrom Rossetti et al. (2017).\nReprinted with permission of\nElsevier.\nVISION\nRow 1:\nRow 2:\nRow 3:\nRow 4:\nPERCEPTION\nACTION\nV1\nDorsal\nVentral\nVISION\nPERCEPTION\nACTION\nVISION\nPERCEPTION\nACTION\nVentral\nDorsal\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxxxxxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxxx\nxx\nVISION\nPERCEPTION\nACTION\nV3d\nPO\nMT\nV3a\nV2\nV1\nV4\nV3v\nperiphV4\nPre-strlate\nInf. Temporal\nHipp.\nTE\nTEO\nFST\nMSSTP\nAIP\nPost. Parietal\nPOa, UP/IP\n7b\n7a\nMIP\nPFd\nFEF. SEF\nPNd\nSC\nSMA\nPMv\nFrontal\nHand\nFace\nArm\nEye\nM1\nCing\n(46)\nPFv\n(12)\nS.T.S\nPIP\nBS\nCreated from usyd on 2022-02-13 13:25:58.",
    "64\nVisual perception and attention\nand “how”) is partially correct. It has received inconsistent support from\nresearch on patients with optic ataxia and visual agnosia. Earlier we dis-\ncussed achromatopsia (see Glossary) and akinetopsia (see Glossary). The\nformer condition depends on damage to the ventral pathway and the latter\ncondition on damage to the dorsal pathway (Haque et al., 2018). As pre-\ndicted theoretically, many visual illusions are much reduced in extent when\nobservers engage in action-based performance (e.g., pointing; grasping).\nWhat are the model’s limitations? First, evidence from brain- damaged\npatients provides relatively weak support for it. In fact, “The idea of a\ndouble dissociation between optic ataxia and visual form agnosia, as\ncleanly separating visuo-motor from visual perceptual functions, is no\nlonger tenable” (Rossetti et al., 2017, p. 130).\nSecond, findings based on visual illusions provide only partial support\nfor the model. The findings generally indicate that illusory effects are greater\nwith perceptual judgements than actions but there are many exceptions.\nThird, the model exaggerates the independence of the two visual systems.\nFor example, Janssen et al. (2018) reviewed research on 3-D object percep-\ntion and found strong effects of the dorsal stream on the ventral stream.\nAs de Haan et al. indicated,\nThe prevailing evidence suggests that cross-talk [interactions between\nvisual systems] is the norm rather than the exception . . . [There is] a\nflexible and dynamic pattern of interaction between visual processing\nareas in which visually processing networks may be created on-the-fly\nin a highly task-specific manner.\n(de Haan et al., 2018, p. 6)\nFourth, the notion there are only two visual processing streams is an over-\nsimplification. Earlier on pp. 62–63 we discussed two attempts (Haak &\nBeckmann, 2018; Sakreida et al., 2016) to develop more complete accounts.\nCOLOUR VISION\nWhy do we have colour vision? After all, if you watch an old black-and-\nwhite movie on television you can easily understand the moving images.\nOne reason is that colour often makes an object stand out from its sur-\nroundings making it easier to identify. Chameleons very sensibly change\ncolour to blend in with the background, thus reducing their chances of\nbeing detected by predators.\nColour perception also helps us to recognise and categorise objects.\nFor example, it is useful when deciding whether a piece of fruit is under- or\noverripe. Predictive coding (processing primarily aspects of sensory input\nthat violate the observer’s predictions) is also relevant (Huang & Rao,\n2011). Colour vision allows observers to focus rapidly on any aspects of\nthe incoming visual input (e.g., discolouring) discrepant with predictions\nbased on ripe fruit.\nThere are three main qualities associated with colour:\n(1) Hue: the colour itself and what distinguishes red from yellow or blue.\n(2) Brightness: the perceived intensity of light.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n65\n(3) Saturation: this allow us to determine whether a colour is vivid or\npale; it is influenced by the amount of white present.\nTrichromacy theory\nRetinal cones are specialised for colour vision. Cone receptors contain\nlight-sensitive photopigment allowing them to respond to light. According to\nthe trichromatic [three-coloured] theory, there are three kinds of receptors:\n(1) One type is especially sensitive to short-wavelength light and generally\nresponds most strongly to stimuli perceived as blue.\n(2) A second type of cone receptor is most sensitive to medium-wavelength\nlight and responds greatly to stimuli generally seen as yellow-green.\n(3) A third type of cone responds most to long-wavelength light such as\nthat reflected from stimuli perceived as orange-red.\nHow do we see other colours? According to the theory, most stimuli acti-\nvate two or all three cone types. The colour we perceive is determined by\ntheir relative stimulation levels. Evolution has equipped us with three types\nof cones because that produces a very efficient system – we can discriminate\nmillions of colours even with so few cone types.\nMany forms of colour deficiency are consistent with trichromacy\ntheory. Most individuals with colour deficiency have dichromacy, in which\none cone class is missing. In red-green dichromacy (the most common\nform) there are abnormalities in the retinal pigments sensitive to medium\nor long wavelengths. Individuals with red-green dichromacy differ from\nintact observers in perceiving far fewer colours. However, their colour con-\nstancy (see Glossary) is almost at normal levels (Álvaro et al., 2017).\nThe density of cones (the retinal cells responsible for colour vision) is\nfar higher in the fovea (see Glossary) than the periphery. However, there\nare enough cones in the periphery to permit accurate peripheral colour\njudgements if colour patches are reasonably large (Rosenholtz, 2016).\nThe crucial role of cones for colour vision explains the following\ncommon phenomenon: “The sunlit world appears in sparkling colour, but\nwhen night falls . . . we see the world in 50 shades of grey” (Kelber et\nal., 2017, p. 1). In dim light, the cones are not activated and our vision\ndepends almost entirely on rods.\nOpponent-process theory\nTrichromacy theory does not explain what happens after activation of the\ncone receptors. It also fails to account for negative afterimages. If you\nstare at a square of a given colour for several seconds and then shift your\ngaze to a white surface, you see a negative afterimage in the complemen-\ntary colour (complementary colours produce white when combined). For\nexample, a green square produces a red afterimage, whereas a blue square\nproduces a yellow afterimage.\nHering (1878) explained negative afterimages. He identified three types\nof opponent processes in the visual system. One opponent process (red-\ngreen channel) produces perception of green when responding one way\nand red when responding the opposite way. A second opponent process\nKEY TERMS\nDichromacy\nA deficiency in colour\nvision in which one of\nthe three cone classes is\nmissing.\nNegative afterimages\nThe illusory perception\nof the complementary\ncolour to the one that has\njust been fixated; green\nis the complementary\ncolour to red and blue is\ncomplementary to yellow.\nCreated from usyd on 2022-02-13 13:25:58.",
    "66\nVisual perception and attention\n(blue-yellow channel) produces perception of blue or yellow in the same\nway. The third opponent process (achromatic channel) produces the per-\nception of white at one extreme and black at the other.\nWhat is the value of these three opponent processes? The three dimen-\nsions associated with opponent processes provide maximally independent\nrepresentations of colour information. As a result, opponent processes\nprovide very efficient encoding of chromatic stimuli.\nMuch research supports the notion of opponent processes. First,\nthere is strong physiological evidence for the existence of opponent cells\n(Shevell & Martin, 2017). Second, the theory accounts for negative afterim-\nages (discussed above). Third, the theory claims it is impossible to see blue\nand yellow together or red and green, but the other colour combinations\ncan be seen. That is precisely what Abramov and Gordon (1994) found.\nFourth, opponent processes explain some types of colour deficiency. Red-\ngreen deficiency occurs when the red-green channel cannot be used, and\nblue-yellow deficiency occurs when individuals cannot make effective use\nof the blue-yellow channel.\nDual-process theory\nHurvich and Jameson (1957) proposed a dual-process theory combining the\nideas discussed so far. Signals from the three cones types identified by tri-\nchromacy theory are sent to the opponent cells (see Figure 2.16). There are\nthree channels:\n(1) The achromatic [non-colour] channel combines the activity of the\nmedium- and long-wavelength cones.\n(2) The blue-yellow channel represents the difference between the sum\nof the medium-and long-wavelength cones on the one hand and the\nshort-wavelength cones on the other. The direction of difference\ndetermines whether blue or yellow is seen.\nFigure 2.16\nSchematic diagram of the\nearly stages of neural colour\nprocessing. Three cone\nclasses (red = long; green =\nmedium; blue = short)\nsupply three “channels”.\nThe achromatic (light-dark)\nchannel receives non-\nspectrally opponent input\nfrom long- and medium-\ncone classes. The two\nchromatic channels receive\nspectrally opponent inputs\nto create the red-green and\nblue-yellow channels.\n2009 George Mather.\nReproduced with permission.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n67\n(3) The red-green channel represents the difference between activity levels\nin the medium- and long-wavelength cones. The direction of this dif-\nference determines whether red or green is perceived.\nOverall evaluation\nDual-process theory has much experimental support. However, it is\noversimplified in several ways (Shevell & Martin, 2017). First, there are\ncomplex interactions between the channels. For example, short- wavelength\ncones are activated even in conditions where it would be expected that\nonly the red-green channel (involving medium- and long-wavelength\ncones) would be active (Conway et al., 2018). Second, the proportions of\ndifferent cone types vary considerably across individuals but this typically\nhas  surprisingly little effect on colour perception. Third, the arrangement of\ncone types in the eye is fairly random. This seems odd because it  presumably\nmakes it hard for colour-opponent processes to work effectively.\nMore generally, much research has focused on colour perception and\nother research has focused on how nerve cells respond to light of different\nwavelengths. What has proved difficult is to relate these two sets of find-\nings directly to each other. So far there is only limited convergence between\npsychological and physiological research\n(Shevell & Martin, 2017).\nColour constancy\nColour constancy is the tendency for a surface\nor object to be perceived as having the same\ncolour when there are changes in the wave-\nlengths contained in the illuminant (the light\nsource illuminating the surface or object).\nColour constancy indicates colour vision does\nnot depend solely on the wavelengths of the\nlight reflected from objects. Learn more about\ncolour constancy on YouTube: “This is Only\nRed by Vsauce”.\nWhy is colour constancy important? If we\nlacked colour constancy, the apparent colour\nof familiar objects would change dramatically\nwhen the lighting conditions altered. This\nwould make it very hard to recognise objects\nrapidly and accurately.\nAttaining reasonable levels of colour\nconstancy is an impressive achievement.\nLook at the object in Figure 2.17. It is imme-\ndiately  recognisable as a blue mug even\nthough several other colours can be per-\nceived. The wavelengths of light depend on\nthe mug itself, the illuminant and  reflections\nfrom other objects onto the mug’s surface\n(mutual illumination).\nFigure 2.17\nPhotograph of a mug showing enormous variation in the\nproperties of the reflected light across the mug’s surface. The\npatches at the top of the figure show image values from the\nlocations indicated by the arrows.\nFrom Brainard and Maloney (2011). Reprinted with permission of the\nAssociation for Research in Vision and Ophthalmology.\nKEY TERMS\nColour constancy\nThe tendency for an\nobject to be perceived as\nhaving the same colour\nunder widely varying\nviewing conditions.\nIlluminant\nA source of light\nilluminating a surface or\nobject.\nMutual illumination\nThe light reflected from\nthe surface of an object\nimpinges on the surface\nof a second object.\nCreated from usyd on 2022-02-13 13:25:58.",
    "68\nVisual perception and attention\nHow good is colour constancy?\nColour constancy is often reasonably good. For example, Granzier et al.\n(2009a) assessed colour constancy for six similarly coloured papers in\nvarious indoor and outdoor locations differing substantially in lighting con-\nditions. They found 55% of the papers were identified correctly. This rep-\nresents good performance given the similarities among the papers and the\nlarge differences in lighting conditions.\nReeves et al. (2008) distinguished between our subjective experience\nand our judgements about the world. For example, as you walk towards\na fire, it feels increasingly hot subjectively. However, how hot you judge\nthe fire to be is unlikely to change. Reeves et al. found colour constancy\nwith non-naturalistic (artificial stimuli) was much greater when observers\njudged the objective similarity of two stimuli seen under different illumi-\nnants than when rating their subjective similarity. Radonjić and Brainard’s\n(2016) obtained similar findings with naturalistic stimuli. However, colour\nconstancy was higher overall with naturalistic stimuli because such stimuli\nprovided more cues to guide performance.\nEstimating scene illumination\nThe wavelengths of light reflected from an object are greatly influenced\nby the illuminant (light source). High levels of colour constancy could be\nachieved if observers made accurate illuminant estimates. However, they\noften do not, especially when the illuminant’s characteristics are unclear\n(Foster, 2011). For example, there are substantial individual differences in\nthe perceived illuminant (and perceived colour) of the famous dress dis-\ncussed in the Box.\nColour constancy should be high when illuminant estimation is accu-\nrate (Brainard & Maloney, 2011). Bannert and Bartels (2017) tested this\nprediction. Observers were presented with visual scenes using three dif-\nferent illuminants, and cues within the scenes were designed to facilitate\ncolour constancy. Bannert and Bartels used functional magnetic resonance\nimaging (fMRI) to assess the neural encoding of each scene.\nWhat did Bannert and Bartels (2017) find? Their key finding was that,\n“The neural accuracy of encoding the illuminant of a scene [predicted] the\nbehavioural accuracy of constant colour perception” (p. 357). Thus, colour\nconstancy was high when the illuminant was processed accurately.\nLocal colour contrast\nLand (1986) proposed retinex theory, according to which we perceive a\nsurface’s colour by comparing its ability to reflect, short-, medium- and\nlong-wavelength light against that of adjacent surfaces. Thus, we make use\nof local colour contrast. Kraft and Brainard (1999) studied colour con-\nstancy for complex visual scenes. Under full viewing conditions, colour\nconstancy was 83% even with large changes in illumination. When local\ncontrast could not be used, however, colour constancy dropped to 53%.\nFoster and Nascimento (1994) developed Land’s ideas into an influ-\nential theory based on local contrast. We can see the nature of their big\nCase study:\nColour constancy\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n69\ndiscovery through an example. Suppose there are two illuminants and two\nsurfaces. If surface 1 led to the long-wavelength or red cones respond-\ning three times as much with illuminant 1 as illuminant 2, then the same\nthreefold difference was also found with surface 2. Thus, the ratio of cone\nresponses was essentially invariant across different illuminations. Thus,\nIN THE REAL WORLD: WHAT COLOUR IS “THE DRESS”?\nOn 7 February 2015, Cecilia Bleasdale took a photograph of the dress she intended to wear at\nher daughter’s imminent wedding (see below) and posted it on the internet. It caused an almost\nimmediate sensation because observers disagreed vehemently concerning the dress’s colour.\nWhat colour do you think the dress is (see Figure 2.18)? Wallisch (2017) found 59% of observers\nsaid the dress was white and gold and 27% said it was black and blue. How can we explain these\nindividual differences? Wallisch argued the illumination of the dress is ambiguous: the upper part\nof the dress implies illumination by daylight whereas the lower part implies artificial illumination.\nMany theories predict the perceived colour of an object depends on its assumed illumination (dis-\ncussed on p. 62). If so, observers assuming the dress is illuminated by natural light should perceive\nit as white and gold. In contrast, those assuming artificial illumination should perceive it as black\nand blue.\nWhat did Wallisch (2017) find? As predicted, observers assuming the dress was illuminated by\nnatural light were much more likely than those assuming artificial light to perceive the dress as\nwhite/gold (see Figure 2.19).\nFigure 2.18\n“The Dress” made famous by its\nappearance on the internet.\nFrom Rabin et al. (2016).\nFigure 2.19\nThe percentage of observers perceiving “The Dress” to be white\nand gold depended on whether they believed it to be illuminated\nby natural light or by artificial light, and those who were unsure.\nFrom Wallisch et al. (2017).\n45\nNatural\nArtificial\nlight assumption\nUnsure\n50\nPercent reporting white/gold\n55\n60\n65\n70\n75\nCreated from usyd on 2022-02-13 13:25:58.",
    "70\nVisual perception and attention\ncone-excitation ratios can be used to eliminate the illuminant’s effects and\nso increase colour constancy.\nMuch evidence indicates cone-excitation ratios are important (Foster,\n2011, 2018). For example, Nascimento et al. (2004) obtained evidence\nsuggesting the level of colour constancy in different conditions could be\npredicted on the basis of cone-excitation ratios.\nFoster and Nascimento’s (1994) theory provides an elegant account\nof illuminant-independent colour constancy in simple visual environ-\nments. However, it has limited value in complex visual environments. For\nexample, colour constancy for a given object can become harder because of\nreflections from other objects (see Figure 2.17) or because multiple sources\nof illumination are present together.\nThe theory is generally less applicable to natural scenes than artificial\nlaboratory scenes. For example, the illuminant often changes more rapidly\nin natural scenes (e.g., clouds change shape, which influences the shadows\nthey cast) (Nascimento et al., 2016). In addition, there are dramatic changes\nin the level and colour of natural illuminants over the course of the day.\nIn sum, cone-excitation ratios are most likely to be almost invariant,\n“provided that sampling is from points close together in space or time . . .,\nor from points separated arbitrarily but undergoing even changes in\nillumination” (Nascimento et al., 2016, p. 44).\nEffects of familiarity\nColour constancy is influenced by our knowledge of the familiar colours of\nobjects (e.g., bananas are yellow). Hansen et al. (2006) asked observers to\nview photographs of fruits and to adjust their colour until they appeared\ngrey. There was over-adjustment. For example, a banana still looked yel-\nlowish to observers when it was actually grey, leading them to adjust its\ncolour to a slightly bluish hue. Such findings may reflect an influence of\nfamiliar size on subjective colour perception. Alternatively, familiar colour\nmay primarily influence observers’ responses rather than their perception\n(e.g., our knowledge that bananas are yellow may bias us to report them as\nmore yellow than they actually appear).\nVandenbroucke et al. (2016) investigated the above issue. Observers\nviewed an ambiguous colour intermediate between red and green presented\non typically red (e.g., tomato) or green (e.g., pine tree) objects. Familiar\ncolour influenced colour perception. Of most importance, neural responses\nin various visual areas (e.g., V4, which is much involved in colour pro-\ncessing) were influenced by familiar colour. Neural responses corresponded\nmore closely to those associated with red objects when the object was typi-\ncally red than when it was typically green and more closely to those found\nwith green objects when it was typically green. Thus, familiar colour had a\ndirect influence on perception early in visual processing.\nChromatic adaptation\nOne reason we have reasonable colour constancy is because of chromatic\nadaptation – an observer’s visual sensitivity to a given illuminant decreases\nover time. If you stand outside after nightfall, you may be surprised by the\nKEY TERM\nChromatic adaptation\nChanges in visual\nsensitivity to colour stimuli\nwhen the illumination\nalters.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n71\napparent yellowness of the artificial light in people’s houses. However, this\nis not the case if you spend some time in a room illuminated by artificial\nlight. Lee et al. (2012b) found some aspects of chromatic adaptation within\nsix seconds. Such rapid adaptation increases colour constancy.\nEvaluation\nIn view of the complexity of colour constancy, it is unsurprising the visual\nsystem adopts an “all hands on deck” approach in which several factors\ncontribute to colour constancy. Of major importance are zone-excitation\nratios that remain almost invariant across changes in illumination. In\naddition, top-down factors (e.g., our memory for the familiar colours of\ncommon objects) also play a role.\nWhat are the limitations of theory and research on colour constancy?\nFirst, we lack a comprehensive theory of how the various factors combine.\nSecond, most research has focused on relatively simple artificial visual\nenvironments. In contrast, “The natural world is optically unconstrained.\nSurface properties may vary from one point to another, and reflected\nlight may vary from one instant to the next” (Foster, 2018, p. B192). As a\nresult, the processes involved in trying to achieve colour constancy in more\ncomplex environments are poorly understood.\nThird, more research is needed to understand why colour constancy\ndepends greatly on the precise instructions given to observers. Fourth, as\nWebster (2016, p. 195) pointed out, “There are pronounced [individual]\ndifferences in almost all measures of colour appearance . . . the basis for\nthese differences remains uncertain.”\nDEPTH PERCEPTION\nA major accomplishment of visual perception is the transformation of the\ntwo-dimensional retinal image into perception of a three-dimensional world\nseen in depth. The construction of 3-D representations is very important\nif we are to pick up objects, decide whether it is safe to cross the road and\nso on.\nDepth perception depends on numerous visual and other cues (dis-\ncussed below). All cues provide ambiguous information and so we would\nbe ill-advised to place total reliance on any single cue. Moreover, different\ncues often provide conflicting information. When you watch a movie, some\ncues (e.g., stereo ones) indicate everything you see is at the same distance.\nIn contrast, other cues (e.g., perspective; shading) indicate some objects\nare closer.\nIn real life, depth cues are often provided by movement of the observer\nor objects in the visual environment and some cues are non-visual (e.g.,\nobject sounds). Here, however, the main focus will be on visual depth cues\navailable when the observer and environmental objects are static.\nCues to depth perception are monocular, binocular and oculomotor.\nMonocular cues require only one eye but can also be used with two eyes.\nThe fact that the world still retains a sense of depth with one eye closed\nindicates clearly that monocular cues exist. Binocular cues involve both\neyes used together. Finally, oculomotor cues depend on sensations of\nKEY TERMS\nMonocular cues\nCues to depth that can be\nused by one eye but can\nalso be used by both eyes\ntogether.\nBinocular cues\nCues to depth that\nrequire both eyes to be\nused together.\nOculomotor cues\nCues to depth produced\nby muscular contractions\nof the muscles around\nthe eye; use of such cues\ninvolves kinaesthesia (also\nknown as the muscle\nsense).\nCreated from usyd on 2022-02-13 13:25:58.",
    "72\nVisual perception and attention\nmuscular contractions of the muscles around the eye. Use of these cues\ninvolves kinaesthesia (the muscle sense).\nMonocular cues\nMonocular cues to depth are called pictorial cues because they are used by\nartists. Of particular importance is linear perspective, which artists use to\ncreate the impression of three-dimensional scenes on two-dimensional can-\nvases. Linear perspective (based on laws of optics and geometry) is based\non various principles. For example, parallel lines pointing away from us\nconverge (e.g., motorway edges) and objects reduce in size as they recede\ninto the distance.\nTyler (2015) argued that linear perspective is only really effective in\ncreating a powerful 3-D effect when viewed from the point from which the\nartist constructed the perspective. This is typically very close to the picture\nas can be seen in a drawing by the Dutch artist Jan Vredeman de Vries\n(see Figure 2.20).\nTexture is another monocular cue. Most objects (e.g., carpets; cobble-\nstone roads) possess texture, and textured objects slanting away from us\nhave a texture gradient (Gibson, 1979; see Figure 2.21). This is a gradient\n(rate of change) of texture density as you look from the front to the back\nof a slanting object with the gradient changing more rapidly for objects\nslanted steeply away from the observer. Sinai et al. (1998) found observers\njudged the distances of nearby objects better when the ground was uni-\nformly textured than when there was a gap (e.g., a ditch) in the texture\npattern.\nTexture gradient is a limited cue because the perceived slant depends\non the direction of the gradient. For reasons that are unclear, ground\npatterns are perceived as less slanted than equivalent ceiling or sidewall\npatterns (Higashiyama & Yamazaki, 2016).\nFigure 2.20\nAn engraving by de Vries\n(1604/1970) in which linear\nperspective creates an\neffective three-dimensional\neffect when viewed from\nvery close but not from\nfurther away.\nFrom Todorovic´ (2009).\nPublications. Reprinted with\npermission from Springer.\nKEY TERMS\nTexture gradient\nThe rate of change of\ntexture density from the\nfront to the back of a\nslanting object.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n73\nAnother monocular cue is interposition where a nearer\nobject hides part of a more distant one. The strength of\nthis cue can be seen in Kanizsa’s (1976) illusory square\n(see Figure 2.22). There is a strong impression of a\nyellow square in front of four purple circles even though\nmany of  its contours are missing. This depends on pro-\ncesses  that relatively “automatically” complete bound-\naries using the available information (e.g.,  incomplete\ncircles).\nAnother useful cue is familiar size (discussed more\nfully later). If we know an object’s size, we can use its\nretinal image size to estimate its distance. However, we\ncan be misled. Ittelson (1951) had observers view playing\ncards through a peephole restricting them to monocular\nvision. The perceived distance was determined almost\nentirely by familiar size. For example, playing cards\ndouble the usual size were perceived as being twice as far\naway from the observers than was actually the case.\nWe turn now to blur. There is no blur at fixation\npoint and it increases more rapidly at closer distances\nthan ones further away. Held et al. (2012)  found blur\nwas an effective depth cue (especially at longer distances).\nHowever, observers may simply have learned to respond\nthat the blurrier stimulus was further away. Langer and\nSiciliano (2015) provided minimal training and obtained\nlittle evidence blur was used as a depth cue. They argued\nblur provides ambiguous information: an object can\nappear blurred because it is in peripheral vision rather\nthan because it is far away.\nFinally, there is motion parallax, which involves\n“transformations of the retinal image that are created . . .\nboth when the observer moves (observer- produced\nparallax) and when objects move with respect to the\nobserver (object-produced parallax)” (Rogers, 2016,\np.  1267). For example, when you look out of the\nwindow  of a moving train, nearby objects appear to\nmove  in the opposite direction but distant objects in\nthe same  direction. Rogers and Graham (1979) found\nmotion parallax on its own can produce accurate depth\njudgements. Most research demonstrating the value of motion paral-\nlax as a depth cue has used very simple random-dot displays. However,\nBuckthought et al. (2017) found comparable effects in more complex and\nnaturalistic conditions.\nCues such as linear perspective, texture gradient and interposition\nallow observers to perceive depth even in two-dimensional displays.\nHowever, research with  computer-generated two-dimensional displays has\nfound depth is often underestimated (Domini et al., 2011). Such displays\nprovide cues to flatness (e.g., binocular  disparity, accommodation and\nvergence, all discussed on pp. 74–75) that may reduce the impact of cues\nsuggesting depth.\nKEY TERMS\nMotion parallax\nA depth cue based on\nmovement in one part of\nthe retinal image relative\nto another.\nFigure 2.21\nExamples of texture gradients that can be\nperceived as surfaces receding into the\ndistance.\nFrom Bruce et al. (2003).\nFigure 2.22\nKanizsa’s (1976) illusory square.\nCreated from usyd on 2022-02-13 13:25:58.",
    "74\nVisual perception and attention\nBinocular cues\nDepth perception does not depend solely on monocular and oculomotor\ncues. It can also be achieved by binocular disparity, which is the slight dif-\nference or disparity in the images projected on the retinas of the two eyes\nwhen you view a scene (Welchman, 2016). Binocular disparity produces\nstereopsis (the ability to perceive the world three-dimensionally).\nThe great subjective advantage of binocular vision was described by\nSusan Barry (2009, pp. 94–132), a neuroscientist who recovered binocular\nvision in late adulthood:\n[I saw] palpable volume[s] of empty space . . . I could see, not just infer,\nthe volume of space between tree limbs . . . the grape was rounder and\nmore solid than any grape I had ever seen . . . Objects seemed more\nsolid, vibrant, and real.\nStereopsis is very powerful at short distances. However, the disparity or dis-\ncrepancy in the retinal images of objects decreases by a factor of 100 as\ntheir distance from an observer increases from 2 to 20 metres. Thus, stere-\nopsis rapidly becomes less available at greater distances. While stereopsis\nprovides valuable information at short distances, we must not exagger-\nate its importance. Bülthoff et al. (1998) found observers’ recognition of\nfamiliar objects was not adversely affected when stereoscopic information\nwas scrambled. Indeed, observers were unaware the depth information was\nscrambled!\nStereopsis involves matching features in the inputs to the two eyes.\nThis process is fallible. For example, consider an autostereogram (a\ntwo- dimensional image containing depth information so it appears three-\ndimensional when viewed appropriately; the Wikipedia entry for autostere-\nogram provides examples).\nWith autostereograms, the same repeating 2-D pattern is presented to\neach eye. If there is a dissociation of vergence and accommodation, two\nadjacent patterns will form an object apparently at a different depth from\nthe background. Some individuals are better than others at perceiving 3-D\nobjects in autostereograms because of individual differences in binocular\ndisparity, vergence and accommodation (Gómez et al., 2012).\nThe most common reason for impaired stereoscopic depth percep-\ntion is amblyopia (one eye exhibits poor visual acuity; also known as lazy\neye). However, deficient stereoscopic depth perception can also result from\ndamage to various cortical areas (Bridge, 2016). As Bridge concluded,\nintact stereoscopic depth perception requires the following: “(i) both eyes\naligned and functional; (ii) control over the eye muscles and vergence to\nthe images into alignment; (iii) initial matching of retinal images; and (iv)\nintegration of disparity information” (p. 2).\nOculomotor cues\nThe pictorial cues discussed so far can all be used equally well by one-\neyed individuals as by those with intact vision. Depth perception also\ndepends on oculomotor cues based on perceiving muscle contractions\nKEY TERMS\nBinocular disparity\nA depth cue based on the\nslight disparity in the two\nretinal images when an\nobserver views a scene; it\nis the basis for stereopsis.\nStereopsis\nDepth perception based\non the small discrepancy\nin the two retinal images\nwhen a visual scene is\nobserved (binocular\ndisparity).\nAutostereogram\nA complex two-\ndimensional image\nperceived as three-\ndimensional when not\nfocused on for a period\nof time.\nAmblyopia\nA condition in which one\neye sends an inadequate\ninput to the visual cortex;\ncolloquially known as\nlazy eye.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n75\naround the eyes. One such cue is vergence (the eyes turn inwards to\nfocus on very close objects than those further away). Another oculomotor\ncue is   accommodation. It refers to the variation in optical power produced\nby the thickening of the eye’s lens when someone focuses on a close object.\nVergence and accommodation are both very limited. First, they only\nprovide information about the distance of a single object at any given time.\nSecond, they are both of value only when judging the distance of close\nobjects. Even then, the information they provide is not very accurate.\nCue combination or integration\nSo far we have considered depth cues one by one. In the real world,\nhowever, we typically have access to many depth cues. How do we use these\ncues? One possibility is additivity (combining or integrating information\nfrom all cues) and another possibility is selection (using information from\nonly a single cue) (Bruno & Cutting, 1988).\nHow could we maximise the accuracy of our depth perception? Jacobs\n(2002) argued we should assign more weight to reliable cues. Since cues\nreliable in one context may be less so in a different context, we should be\nflexible when assessing cue reliability. These considerations led Jacobs to\npropose two hypotheses:\n(1) Less ambiguous cues (i.e., those providing consistent information) are\nregarded as more reliable than more ambiguous ones.\n(2) A cue is regarded as reliable if inferences based on it are consistent\nwith those based on other available cues.\nOther theoretical approaches resemble that of Jacobs (2002). For example,\nRohde et al. (2016, p. 36) discuss Maximum Likelihood Estimation, which\nis “a rule used . . . to optimally combine redundant estimates of a varia-\nble [e.g., object distance] by taking into consideration the reliability of each\nestimate and weighting them accordingly”. We can extend this approach\nto include prior knowledge (e.g., natural light typically comes from above;\nmany familiar objects have a typical size).\nFinally, there are ideal-observer models (e.g., Landy et al., 2011;\nJones, 2016). Many of these models are based on the Bayesian approach\n(see Chapter 13), in which initial probabilities are altered by new data\nor information (e.g., presentation of cues). Ideal-observer models involve\nmaking assumptions about the optimal way of combining the cue and\nother  information available and comparing that against observers’ actual\nperformance.\nAs we will see, experimentation has benefitted from advances in virtual\nreality technologies. These advances permit researchers to control visual\ncues very precisely, thus permitting clear-cut tests of many hypotheses.\nFindings\nEvidence supporting Jacobs’ (2002) first hypothesis was reported by Triesch\net al. (2002). Observers in a virtual reality situation tracked an object\ndefined by colour, shape and size. On each trial, two attributes were unre-\nliable or inconsistent (their values changed frequently). Observers attached\nKEY TERMS\nVergence\nA cue to depth based on\nthe inward focus of the\neyes with close objects.\nAccommodation\nA depth cue based on\nchanges in optical power\nproduced by thickening\nof the eye’s lens when an\nobserver focuses on close\nobjects.\nCreated from usyd on 2022-02-13 13:25:58.",
    "76\nVisual perception and attention\nincreasing weight to the reliable or consistent cue and less to the unreliable\ncues during each trial.\nEvidence supporting Jacobs’ (2002) second hypothesis was reported\nby Atkins et al. (2001). Observers in a virtual reality environment viewed\nand grasped elliptical cylinders. There were three cues to cylinder depth:\ntexture, motion and haptic (relating to the sense of touch).\nWhen the haptic and texture cues indicated the same cylinder depth\nbut the motion cue indicated a different depth, observers made increasing\nuse of the texture cue and decreasing use of the motion cue. When the\nhaptic and motion cues indicated the same cylinder depth but the texture\ncue did not, observers increasingly relied on the motion cue rather than the\ntexture cue. Thus, whichever visual cue correlated with the haptic cue was\npreferred, and this preference increased with practice.\nMuch research suggests observers integrate cue information according\nto the additivity notion: they take account of most (or all) cues but attach\nadditional weight to more reliable ones (Landy et al., 2011). However, these\nconclusions are based primarily on studies involving only small  conflicts in\nthe information provided by each cue.\nWhat happens when two or more cues are in strong conflict? Observers\ntypically rely heavily (or even exclusively) on only one cue, i.e., they use\nthe selection strategy as defined by Bruno and Cutting (1988; see p. 75).\nThis makes sense. Suppose one cue suggests an object is 10 metres away\nbut another cue suggests it is 90 metres away. It is probably not sensible\nto split the difference and decide it is 50 metres away! We use the  selection\nstrategy at the movies – perspective and texture cues produce a 3-D\neffect, whereas we largely ignore cues (e.g., binocular disparity) indicating\neverything on the screen is the same distance from us.\nRelevant evidence was reported by Girshick and Banks (2009) in a\nstudy on slant perception. When there was a small conflict between the\ninformation provided by binocular disparity and texture gradient cues,\nobservers used information from both. However, when there was a large\nconflict between these cues, perceived slant was determined  exclusively by\none cue (binocular disparity or texture gradient). Interestingly,\nthe   observers were not consciously aware of the large conflict between\nthe cues.\nDo observers combine information from different cues to produce\noptimal performance (i.e., accurate depth perception)? Lovell et al. (2012)\ncompared the effects of binocular disparity and shading on depth percep-\ntion. Overall, binocular disparity was the more informative cue to depth,\nbut Lovell et al. tested the effects of making it less reliable. Information\nfrom the cues was combined optimally, with observers consistently\nattaching more weight to reliable cues.\nMany other studies have also reported that observers’ depth percep-\ntion is close to optimal. However, there are several studies where observers\nperformed less impressively (Rahnev & Denison, 2018). For example, Chen\nand Tyler (2015) carried out a similar study to that of Lovell et al. (2012).\nObservers’ depth judgements were strongly influenced by shading but made\nvery little use of binocular disparity information.\nKEY TERM\nHaptic\nRelating to the sense of\ntouch.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n77\nEvaluation\nMuch has been learned about the numerous cues observers use to estimate\ndepth or distance. Information from different depth cues is typically com-\nbined or integrated in studies assessing depth perception. There is also evi-\ndence that one cue often dominates the others when different cues conflict\nstrongly.\nOverall, as Brenner and Smeets (2018, p. 385) concluded, “By com-\nbining the many sources of information in a clever manner people obtain\nquite reliable judgments that are not too sensitive to violations of the\nassumptions of the individual sources of depth information.” More spe-\ncifically, observers generally attach most weight to cues providing reliable\ninformation consistent with that provided by other cues. If a cue becomes\nmore or less reliable over time, observers generally increase or decrease its\nweighting appropriately. Overall, depth perception often appears close to\noptimal.\nWhat are the limitations of theory and research on cue integration?\nFirst, we typically estimate distance in real-life settings where numerous\ncues are present and there are no large conflicts among them. In contrast,\nlaboratory settings often provide only a few cues and these cues some-\ntimes provide very discrepant information. The unfamiliarity of laboratory\nsettings may sometimes cause suboptimal performance by observers and\nreduce generalisation to everyday life (Landy et al., 2011).\nSecond, the assumption that observers process several essentially\nindependent cues before integrating all the information is dubious. It may\napply when observers view a very limited and artificial visual display.\nHowever, natural environments typically provide observers with very rich\ninformation. In such environments, visual processing probably depends\nmore on a global assessment of the overall structure of the environ-\nment and less on processing of specific depth cues than usually assumed\n(Sedgwick & Gillam, 2017). There are also issues concerning the meaning\nof the word “cue”. For example, “Stereopsis is not a cue. It encompasses\nall the ways images of a scene differ in the two eyes” (Sedgwick & Gillam,\n2017, p. 81).\nThird, ideal-observer models differ in the assumptions used to compute\n“ideal” performance and the meaning of “optimal” combining of cues in\ndepth perception (Rahnev & Denison, 2018). Most models focus on the\naccuracy of depth-perception judgements. However, there are circum-\nstances (e.g., presence of a fierce wild animal) where rapid if somewhat\ninaccurate judgements are preferable. More generally, humans focus on\n“computational efficiency” – our goal is to maximise reward while min-\nimising the computational costs of visual processing (Summerfield & Li,\n2018). Thus, optimality of depth-perception judgements does not depend\nsolely on performance accuracy.\nSize constancy\nSize constancy is the tendency for any given object to appear the same\nsize whether its size in the retinal image is large or small. For example, if\nKEY TERM\nSize constancy\nObjects are perceived\nto have a given size\nregardless of the size of\nthe retinal image.\nCreated from usyd on 2022-02-13 13:25:58.",
    "78\nVisual perception and attention\nsomeone walks towards you, their retinal image increases progressively but\ntheir apparent size remains the same.\nWhy do we show size constancy? Many factors are involved. An\nobject’s apparent distance is especially important when judging its size. For\nexample, an object may be judged to be large even though its retinal image\nis very small provided it is far away. According to the size-distance invari-\nance hypothesis (Kilpatrick & Ittelson, 1953), perceived size is  proportional\nto perceived distance.\nFindings\nHaber and Levin (2001) argued that an object’s perceived size depends on\nmemory of its familiar size as well as perceptual information concerning its\ndistance. Initially, observers estimated the sizes of common objects with great\naccuracy from memory. Then they saw various objects at close (0–50 metres)\nor distant (50–100 metres) viewing range and made size judgements. Some\nfamiliar objects were almost invariant in size (e.g., bicycle) or of varying size\n(e.g., television set); there were also unfamiliar stimuli (e.g., ovals).\nWhat findings would we expect? If familiar size is important, size judge-\nments should be more accurate for objects of invariant size than those of\nvariable size, with size judgements least accurate for unfamiliar objects. If\ndistance perception is all-important (and known to be more accurate for\nnearby objects), size judgements should be better for all object categories\nat close viewing range.\nHaber and Levin (2001) found that size judgements were much better\nwith objects having an invariant size than those having a variable size (see\nFigure 2.23). In addition, the viewing distance had a minimal effect on size\njudgements. Both of these findings are contrary to predictions from the\nsize-distance invariance hypothesis.\nIf size judgements depend on perceived distance, size constancy should\nnot be found when an object’s perceived distance differs considerably from\nFigure 2.23\nAccuracy of size\njudgements as a function\nof object type (unfamiliar;\nfamiliar variable size;\nfamiliar invariant size) and\nviewing distance (0–50\nmetres vs 50–100 metres).\nBased on data in Haber and\nLevin (2001).\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n79\nits actual distance. The Ames room (Ames, 1952; see Figure 2.24) pro-\nvides a good example. It has a peculiar shape: the floor slopes and the\nrear wall is not at right angles to the adjoining walls. Nevertheless, the\nAmes room creates the same retinal image as a normal rectangular room\nwhen viewing monocularly through a peephole. The fact that one end of\nthe rear wall is much further away from the viewer is disguised by making\nit much higher.\nThe cues suggesting the rear wall is at right angles to observers are so\nstrong they mistakenly assume two adults standing in the corners by the\nFigure 2.24\n(a) A representation of the\nAmes room; (b) an actual\nAmes room showing the\neffect achieved with two\nadults.\nPhoto Peter Endig/dpa/Corbis.\nKEY TERM\nAmes room\nA very distorted room that\nnevertheless looks normal\nunder certain viewing\nconditions.\nCreated from usyd on 2022-02-13 13:25:58.",
    "80\nVisual perception and attention\nrear wall are at the same distance (see photograph). They thus estimate\nthe size of the nearer adult as much greater than that of the adult further\naway. See the Ames room on YouTube: “Ramachandran – Ames room\nillusion explained”.\nThe illusion effect with the Ames room is so great someone walking\nbackwards and forwards in front of the rear wall seems to grow and shrink\nas they move! Thus, perceived distance apparently determines perceived\nsize. However, this effect is reduced when the person walking along the\nrear wall is a man and the observer is a female having a close emotional\nrelationship with him. This is known as the Honi phenomenon because it\nwas first experienced by a woman (whose nickname was Honi) when she\nsaw her husband in the Ames room.\nSimilarly dramatic findings were reported by Glennerster et al. (2006).\nParticipants walked through a virtual-reality room as it expanded or con-\ntracted considerably. Even though they had detailed information from\nmotion parallax and motion to indicate the room’s size was changing, no\nparticipants noticed the changes! There were large errors in participants’\njudgements of the sizes of objects at longer distances because of their pow-\nerful expectation the size of the room would not alter.\nSome evidence discussed so far has been consistent with the assump-\ntion of the size-distance invariance hypothesis that perceived size depends\non perceived distance. However, many other findings are inconsistent\n(Kim, 2017b). For example, Kim et al. (2016) obtained size and distance\nestimates from observers for objects placed in various tunnels. Size and\ndistance were perceived independently (i.e., depended on different factors).\nIn contrast, the size-distance invariance hypothesis predicts that perceived\nsize and perceived distance should depend on each other and thus should\nnot be independent.\nKim (2018) obtained similar findings when observers viewed a virtual\nobject presented stereoscopically. Their size judgements were more accu-\nrate than their distance judgements, with each judgement depending on its\nown information source.\nMore evidence inconsistent with the size-distance invariance hypoth-\nesis was reported by Makovski (2017). Participants were presented with\nstimuli such as those shown in Figure 2.25 on a monitor. Even though per-\nceived distance was the same for all stimuli, “open” objects (having missing\nboundaries) were perceived as much larger than “closed” objects (with all\nboundaries intact). This is the open-object illusion in which observers\nextend the missing boundaries. This may resemble our common perception\nthat open windows make a room seem larger.\nVan der Hoort et al. (2011) found evidence for the body size\neffect,  in  which the size of a body mistakenly perceived to be one’s\nown influences the perceived sizes of objects. Participants equipped with\nhead-mounted displays connected to CCTV cameras saw the environment\nfrom the  perspective of a doll (see Figure 2.26). The doll was small or\nlarge.\nVan der Hoort et al. (2011) found objects were perceived as larger\nand further away when the doll was small than when it was large. These\neffects were greater when participants misperceived the body as their own\n(this was achieved by having the bodies of the participants and the doll\nKEY TERMS\nHoni phenomenon\nThe typical apparent\nsize changes when an\nindividual walks along\nthe rear wall of the Ames\nroom are reduced when\nfemale observers view a\nman to whom they are\nvery close emotionally.\nOpen-object illusion\nThe misperception that\nobjects with missing\nboundaries are larger\nthan objects the same\nsize without missing\nboundaries.\nBody size effect\nAn illusion in which\nmisperception of one’s\nown bodily size causes the\nperceived size of objects\nto be misjudged.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n81\ntouched at the same time). Thus, size\nand  distance perception depend partly\non our lifelong experience of seeing\neverything from the perspective of our\nown body.\nTajadura-Jiménez et al. (2018) ex-\ntended the above findings. Participants\nexperienced having the body of a 4-year-\nold child or an adult with the body\nscaled down to match the height of the\nchild’s body. Object size was overesti-\nmated more in the child-body condition,\nindicating that object size is influenced\nby higher-level cognitive processes (i.e.,\nage perception).\nEvaluation\nSize perception and size constancy\nsometimes depend on perceived dis-\ntance. Some of the strongest evidence\ncomes from research where misper-\nceptions of distance (e.g., in the\nAmes room; in virtual environments)\nproduce systematic distortions in perceived size. However, several other\nfactors also   influence size perception. These include familiar size, one’s\nperceived  body size and whether objects do (or do not) contain missing\nboundaries.\nWhat are the limitations of research and theory on size perception?\nFirst, psychologists have discovered fewer sources of information account-\ning for size perception than depth perception. In addition, as Kim (2017b,\np.  2) pointed out, “The efficacy of the few information sources that have\nbeen identified for size perception is questionable.” Second, while the\nsize-distance invariance hypothesis remains influential, there is a “vast lit-\nerature demonstrating independence of perceived size and distance” (Kim,\n2018, p. 17).\nPERCEPTION WITHOUT AWARENESS:\nSUBLIMINAL PERCEPTION\nCan we perceive aspects of the visual world without any conscious aware-\nness we are doing so? In other words, is there such a thing as subliminal\nperception (stimulus perception occurring even though the stimulus is\nbelow the threshold of conscious awareness)? Common sense suggests the\nanswer is “No”. However, much research evidence suggests the answer\nis “Yes”. However, we must use terms carefully. A thermostat responds\nappropriately to temperature changes and so could be said to exhibit\nunconscious perception!\nMuch important evidence has come from blindsight patients with\ndamage to early visual cortex (V1), an area of crucial importance to\nFigure 2.25\nTop: stimuli presented to participants; bottom: example of the\nstimulus display.\nFrom Makovski (2017).\nA\nB\nC\nD\nFigure 2.26\nWhat participants in the\ndoll experiment could see.\nFrom the viewpoint of a\nsmall doll, objects such as\na hand look much larger\nthan when seen from the\nviewpoint of a large doll.\nThis exemplifies the body\nsize effect.\nFrom Van der Hoort et al.\n(2011). Public Library of Science.\nWith kind permission from the\nauthor.\nKEY TERM\nSubliminal perception\nPerceptual processing\noccurring below the level\nof conscious awareness\nthat can nevertheless\ninfluence behaviour.\nCreated from usyd on 2022-02-13 13:25:58.",
    "82\nVisual perception and attention\nIN THE REAL WORLD: BLINDSIGHT PATIENT DB\nMuch early research on blindsight involved a patient, DB. He was blind in the lower part of his left\nvisual field as a result of surgery involving removal of part of his right primary visual cortex (BA17)\nto relieve his frequent severe migraine. DB was studied intensively by Larry Weiskrantz.\nDB is one of the most thoroughly studied blindsight patients (see Weiskrantz, 2010, for a his-\ntorical review). He underwent surgical removal of the right occipital cortex, including most of the\nprimary visual cortex, to relieve very severe migraine attacks. DB could detect the presence of an\nobject and could indicate its approximate location by pointing. He could also discriminate between\nmoving and stationary objects and could distinguish vertical from horizontal lines. However, DB’s\nabilities were limited – he could not distinguish between different-sized rectangles or between\ntriangles having straight and curved sides. Such findings suggest DB processed only low-level fea-\ntures of visual stimuli and could not discriminate form.\nWe have seen DB showed some ability to perform various visual tasks. However, he reported\nno conscious experience in his blind field. According to Weiskrantz et al. (1974, p. 721), “When\nhe was shown a video film of his reaching and judging orientation of lines [by presenting it to his\nintact visual field], he was openly astonished.”\nCampion et al. (1983) pointed out that DB and other blindsight patients are only partially blind.\nThey favoured the stray-light hypothesis, according to which patients respond to light reflected\nfrom the environment onto areas of the visual field still functioning. This hypothesis implies DB\nshould have shown reasonable visual performance when objects were presented to his blind spot\n(the area where the optic nerve passes through the retina). However, DB could not detect objects\npresented to his blind spot.\nvisual perception (discussed on pp. 45–46). Blindsight refers to patients’\nability  to  “detect, localise, and discriminate visual stimuli in their blind\nfield, despite denying being able to see the stimuli” Mazzi et al. (2016,\np. 1).\nIn what follows, we initially consider blindsight patients. After that,\nwe discuss evidence of subliminal perception in healthy individuals.\nBlindsight\nMany British soldiers in the First World War who had been blinded by\ngunshot wounds that destroyed their primary visual cortex (V1 or BA17)\nwere treated by George Riddoch, a captain in the Royal Army Medical\nCorps. These soldiers responded to motion in those parts of the visual field\nin which they claimed to be blind. The apparently paradoxical nature of\ntheir condition was neatly captured by Weiskrantz et al. (1974), who coined\nthe term “blindsight”.\nHow is blindsight assessed? Various approaches have been taken but\nthere are generally two measures. First, there is a forced-choice test in\nwhich patients guess (e.g., stimulus present or absent?) or point at stimuli\nthey cannot see. Second, there are patients’ subjective reports that they\ncannot see stimuli presented to their blind region. Blindsight is typically\ndefined by an absence of self-reported visual perception accompanied by\nabove-chance performance on the forced-choice test.\nKEY TERM\nBlindsight\nThe ability to respond\nappropriately to visual\nstimuli in the absence\nof conscious visual\nexperience in patients\nwith damage to the\nprimary visual cortex.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n83\nWe must not exaggerate patients’ preserved visual abilities. Indeed,\ntheir visual abilities in their blind field are so poor that a seeing person\nwith comparable impairment would be legally classified as blind.\nWhat do blindsight patients experience?\nIt is surprisingly hard to decide exactly what blindsight patients experi-\nence when presented with visual stimuli to their blind field. For example,\nthe blindsight patient GY described his experiences as “similar to that of a\nnormally sighted man who, with his eyes shut against sunlight, can perceive\nthe direction of motion of a hand waved in front of him” (Beckers & Zeki,\n1995, p. 56).\nOn another occasion GY was asked about his qualia (sensory expe-\nriences). He said, “That [experience of qualia] only happens on very easy\ntrials, when the stimulus is very bright. Actually, I’m not sure I really have\nqualia then” (Persaud & Lau, 2008, p. 1048).\nThere is an important distinction between type-1 and type-2 blind-\nsight. Type-1 blindsight occurs when patients have no conscious awareness\nof visual stimuli presented to the blind field. In contrast, type-2 blind-\nsight occurs when patients have some residual awareness (although very\ndifferent from that of healthy individuals). For example, a patient, EY,\n“sensed a definite pinpoint of light”, although “it looks like nothing at all”\n(Weiskrantz, 1980). Another patient, GY, said, “You don’t actually ever\nsense anything or see anything . . . it’s more an awareness but you don’t\nsee it” (Weiskrantz, 1997). Many patients exhibit type-1 blindsight on some\noccasions but type-2 blindsight on others.\nFindings: evidence for blindsight\nNumerous studies have assessed the perceptual abilities of blindsight\npatients. Here we briefly consider three illustrative studies. As indicated\nalready, blindsight patients often perform better when guessing an object’s\ndirection of motion than its perceptual qualities (e.g., form; colour). For\nexample, Chabanat et al. (2019) studied a blindsight patient, SA. He was\ncorrect 98% of the time when reporting an object’s direction of motion but\nperformed at chance level when reporting its colour.\nGY (discussed earlier) is a much-studied blindsight patient. He has\nextensive damage to the primary visual cortex in the left hemisphere. In\none study (Persaud & Cowey, 2008), GY was presented with a stimu-\nlus in the upper or lower part of his visual field. On inclusion trials, he\nwas instructed to report the part of the visual field to which the stimu-\nlus had been presented. On exclusion trials, GY was instructed to report\nthe opposite of its actual location (e.g., “up” when it was in the lower\npart).\nGY tended to respond with the real rather than the opposite loca-\ntion on exclusion and inclusion trials suggesting he had access to location\ninformation but lacked any conscious awareness of it (see Figure 2.27).\nIn contrast, healthy individuals showed a large difference in performance\non inclusion and exclusion trials indicating they had conscious access to\nlocation information.\nCreated from usyd on 2022-02-13 13:25:58.",
    "84\nVisual perception and attention\nPersaud et al. (2011) manipulated the stimuli presented to GY so his\nvisual performance was comparable in both fields. However, GY indicated\nconscious awareness of far more stimuli in the intact field than the blind\none (43% of trials vs 3%, respectively). GY had substantially more activa-\ntion in the prefrontal cortex and parietal areas to targets presented in the\nintact field suggesting those targets were processed much more thoroughly.\nBlindsight vs degraded conscious vision\nSome researchers argue blindsight patients exhibit degraded vision rather\nthan a total absence of conscious awareness of “blind” field stimuli. For\nexample, Overgaard et al. (2008) asked a blindsight patient, GR, to decide\nwhether a triangle, circle or square had been presented to her blind field.\nIn one experiment, GR simply responded “yes” or “no”. In another exper-\niment, Overgaard et al. used a 4-point Perceptual Awareness Scale: “clear\nimage”, “almost clear image”, “weak glimpse” and “not seen”.\nUsing the yes/no measure, GR indicated she had not seen the stimu-\nlus on 79% of trials. However, she identified it correctly 46% of the time.\nThese findings suggest the presence of type-1 blindsight. With the 4-point\nscale, in contrast, GR was correct 100% of the time when she had a clear\nimage, 72% of the time when her image was almost clear, 25% when she\nhad a weak glimpse and 0% when the stimulus was not seen. If the “clear\nimage” and “almost clear image” data are combined, GR claimed aware-\nness of the stimulus on 54% of trials, on 83% of which she was correct.\nThus, the use of a sensitive method (the 4-point scale) suggested much of\nGR’s apparent blindsight reflected degraded conscious vision.\nKo and Lau (2012) argued blindsight patients have more conscious\nvisual experience than usually assumed. Their key assumption was as\nfollows: “Blindsight patients may use an unusually conservative crite-\nrion for detection, which results in them saying ‘no’ nearly all the time\nto the question of ‘do you see something?’” (Ko & Lau, 2012, p. 1402).\nThis excessive caution may occur in part because damage to the prefrontal\ncortex impairs their ability to set the criterion for visual detection appro-\npriately. Their excessive conservatism or caution may explain why the\nreported visual experience of blindsight patients is so discrepant from their\nforced-choice perceptual performance.\nFigure 2.27\nEstimated contributions of\nconscious and subconscious\nprocessing to GY’s\nperformance in exclusion\nand inclusion conditions in\nhis normal and blind fields.\nReprinted from Persaud and\nCowey (2008). Reprinted with\npermission from Elsevier.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n85\nKo and Lau’s (2012) theoretical position is supported by Overgaard\net al.’s (2008) finding (discussed on p. 84) that blindsight patients were\nvery reluctant to admit to having seen stimuli presented to their blind\nfield. They also cited research supporting their assumption that blindsight\npatients often have prefrontal damage.\nMazzi et al. (2016) carried out a study resembling that of Overgaard\net al. (2008) on another blindsight patient, SL, showing no activity in the\nprimary visual cortex (V1). SL decided which of two features (e.g., red or\ngreen colour) was present in a stimulus. When she indicated whether she\nhad seen the stimulus or was merely guessing, her guessing performance\nwas significantly above chance suggestive of type-1 blindsight. However,\nwhen she indicated her awareness using the 4-point Perceptual Awareness\nScale, her visual performance was at chance level when she reported no\nawareness of the stimulus. These findings suggest an absence of blind-\nsight. The title of Mazzi et al.’s article provides the take-home message:\n“Different measures tell a different story” (p. 1).\nWhat can we conclude? Overgaard and Mogensen (2015, p. 37) argued\nthat “rudimentarily analysed visual information is available in blindsight”\nbut typically does not lead to conscious awareness. However, such infor-\nmation can produce conscious awareness if the patient uses much effort\nand top-down control.\nTwo findings support this approach. First, blindsight patients gen-\nerally do not regard their experiences as “visual” because they differ so\nmuch from normal visual perception. Second, there is much evidence\n(Overgaard  & Mogensen, 2015) that blindsight patients show enhanced\nvisual performance (and sometimes subjective awareness) after training.\nThis occurs because they make increasingly effective use of the rudimen-\ntary visual information available to them.\nBlindsight and the brain\nAs indicated above, the main brain damage in blindsight patients is to V1\n(the primary visual cortex). As we saw earlier on p. 47 in the chapter, visual\nprocessing typically proceeds from V1 (BA17) to other brain areas (e.g.,\nV2, V3, V4; see Figure 2.4). Of importance, stimuli presented to the “blind”\nfield often produce some activation in these other brain areas. However,\nthis activation is not associated with visual awareness in blindsight patients.\nOn p. 48 in the chapter we discussed research by Hurme et al. (2017)\ndesigned to clarify the role of V1 (the primary visual cortex) in the visual\nperception of healthy individuals. Transcranial magnetic stimulation\napplied to the primary visual cortex to reduce its efficiency disrupted\nunconscious and conscious vision. In a similar study, Hurme et al. (2019)\nfound TMS applied to V1 prevented conscious and unconscious motion\nperception in healthy individuals.\nIn view of the above findings, how is it that many blindsight patients\nprovide evidence of unconscious visual and motion processing? Part of the\nanswer lies within the lateral geniculate nucleus of the thalamus, an inter-\nmediate relay station between the eye and V1 (see Figure 2.28). Ajina et al.\n(2015) divided patients with V1 damage into those with or without blind-\nsight. All those with blindsight had intact connections between LGN and\nCreated from usyd on 2022-02-13 13:25:58.",
    "86\nVisual perception and attention\nMT/V5 (blue arrow in the figure) whereas those connections were impaired\nin patients without blindsight. This finding is important given the crucial\nimportance of MT/V5 for motion perception.\nCeleghin et al. (2019) reported a meta-analysis (see Glossary) providing\na fuller account of the brain areas associated with patients’ visual process-\ning. They identified 14 such areas. Some of these areas (e.g., the LGN; the\npulvinar) are critical for non-conscious motion perception, whereas others\n(e.g., superior temporal gyrus; amygdala) are involved in non- conscious\nemotion processing. Overall, the meta-analysis strongly suggested that\nblindsight typically consists of several non-conscious visual abilities rather\nthan one. Of interest, prefrontal areas (e.g., dorsolateral prefrontal cortex)\noften associated with conscious visual perception (see Chapter 16) were\nnot activated during visual processing by blindsight patients. These find-\nings support the view that visual processing in these patients is typically\nunaccompanied by conscious experience.\nFinally, Celeghin et al. (2019) discussed evidence that there is substan-\ntial reorganisation of brain connectivity in many blindsight patients fol-\nlowing damage to V1 (primary visual cortex). For example, consider the\nblindsight patient, GY, whose left V1 was destroyed. He has nerve fibre\nconnections between the undamaged right lateral geniculate nucleus and\nthe contralesional (opposite side of the body) visual motion area MT/V5\n(Bridge et al., 2008) – connections not present in healthy individuals. Such\nreorganisation helps to explain the visual abilities displayed by blindsight\npatients.\nEvaluation\nMuch has been learned about the nature of blindsight. First, two main\ntypes of blindsight have been identified. Second, evidence for the existence\nFigure 2.28\nThe areas of most relevance\nto blindsight are the lateral\ngeniculate nucleus (LGN)\nand middle temporal visual\narea (MT/V5). The structure\nclose to the LGN is the\npulvinar.\nFrom Tamietto and Morrone\n(2016).\nPulvinar\nPM\nPLdm\nMT/V5\nV3\nV2\nV1\nV2\nV3\nV4\nTEO\nTE\nLGN\nPLvl\nPlcl\nPl\ncm\nPlm\nSuperior\ncolliculus\nVentral stream\nDorsal stream\nPlp\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n87\nof blindsight often depends on the precise measure of visual awareness\nused. Third, brain connections important in blindsight (e.g., between the\nlateral geniculate nucleus and MT/V5) have been discovered. Fourth, the\nvisual abilities of many blindsight patients probably depend on the reor-\nganisation of connections within the brain following damage to the primary\nvisual cortex. Fifth, the assumption that visual processing is rudimentary in\nblindsight patients explains many findings. Sixth, research on blindsight has\nshed light on the many visual pathways that bypass V1 but whose function-\ning can be overshadowed by pathways involving V1 (Celeghin et al., 2019).\nWhat are the limitations of research in this area? First, there are con-\nsiderable differences among blindsight patients with several apparently\npossessing some conscious visual awareness in their allegedly blind field.\nSecond, many blindsight patients have more conscious visual experience\nin their “blind” field than appears from yes/no judgements about stimulus\nawareness. This probably happens because they are excessively cautious\nabout claiming to have seen a stimulus (Mazzi et al., 2016; Overgaard\net al., 2008).\nThird, the extent to which blindsight patients have degraded vision\nremains controversial. Fourth, the existence of reorganisation within the\nbrain in blindsight patients (e.g., Bridge et al., 2008) may limit the applica-\nbility of findings from such patients to healthy individuals.\nSubliminal perception\nIn research on subliminal perception in visually intact individuals, a perfor-\nmance measure of perception (e.g., enhanced speed or accuracy of respond-\ning) is typically compared with an awareness measure. We can distinguish\nbetween subjective and objective measures of awareness: subjective meas-\nures involve self-reports concerning observers’ awareness, whereas objective\nmeasures involve forced-choice responses (e.g., did the stimulus belong to\ncategory A or B?) (Hesselmann, 2013). As Shanks (2017, p. 752) argued,\n“Unconscious processing [subliminal perception] is inferred when above-\nchance performance is combined with null awareness.”\nFor example, Naccache et al. (2002) had observers decide rapidly\nwhether a visible target digit was smaller or larger than 5. Unknown to\nthem, an invisible masked digit on the same side of 5 as the target (congru-\nent) or the other side (incongruent) was presented immediately before the\ntarget. There were two main findings. First, responses to the target digits\nwere faster on congruent than incongruent trials (performance measure).\nSecond, no participants reported seeing any masked digits (subjective\nawareness measure) and their performance was at chance level when guess-\ning whether masked digits were below or above 5 (objective awareness\nmeasure). These findings suggested the existence of subliminal perception.\nFindings\nPersaud and McLeod (2008) tested the notion that only information per-\nceived with awareness can control our actions. They presented the letter “b”\nor “h” for 10 ms (short interval) or 15 ms (long interval). In the key condi-\ntion, participants were instructed to respond with the letter not presented.\nCreated from usyd on 2022-02-13 13:25:58.",
    "88\nVisual perception and attention\nFor example, if they were aware “b” had been presented, they would say\n“h”. The rationale was that only participants consciously aware of the letter\ncould inhibit saying it.\nPersaud and McLeod (2008) found participants responded correctly\nwith the non-presented letter on 83% of long-interval trials indicating rea-\nsonable conscious awareness. In contrast, participants responded correctly\non only 43% of short-interval trials (significantly below chance) suggesting\nsome stimulus processing but an absence of conscious awareness.\nAn important issue is whether perceptual awareness is all-or-none\n(i.e., present or absent) or graded (i.e., varying in extent). Evidence\nsuggesting it is graded was reported by Sandberg et al. (2010). One of four\nshapes was presented very briefly followed by masking. Observers made\na behavioural response (deciding which shape had been presented) fol-\nlowed by one of three subjective measures: (1) clarity of perceptual expe-\nrience (the Perceptual Awareness Scale); (2) confidence in their decision;\nand (3) wagering variable amounts of money on having made the correct\ndecision.\nWhat did Sandberg et al. (2010) find? First, above-chance task per-\nformance sometimes occurred without reported awareness with all three\nsubjective measures. Second, the Perceptual Awareness Scale predicted per-\nformance better than the other measures, probably because it was the most\nsensitive measure of conscious experience.\nThe partial awareness hypothesis (Kouider et al., 2010) potentially\nexplains graded perceptual experience. According to this hypothesis, per-\nceptual awareness can be limited to low-level features (e.g., colour) while\nexcluding high-level features (e.g., face identity). Supportive evidence was\nreported by Gelbard-Sagiv et al. (2016) with faces coloured blue or green.\nThey used continuous flash suppression (CFS): a stimulus presented to one\neye cannot be seen consciously when rapidly changing patterns are pre-\nsented to the other eye. Observers often had conscious awareness of the\ncolour of faces they could not identify.\nKoivisto and Grassini (2016) presented stimuli to one of four loca-\ntions. Observers then made a forced-choice responses concerning the stim-\nulus location and rated their subjective visual awareness of the stimulus\non a 3-point version of the Perceptual Awareness Scale (discussed above).\nOf central importance was the no-awareness category (i.e., “I did not see\nany stimulus”). The finding that observers were correct on 38% of trials\nassociated with no awareness (chance performance = 25%) was apparent\nevidence for subliminal perception.\nHowever, there is an alternative explanation. According to Koivisto and\nGrassini (2016, p. 241), the above finding occurred mainly when “observers\nwere very weakly aware of the stimulus, but behaved  conservatively and\nclaimed not having seen it”. This conservatism is known as response bias.\nTwo findings supported this explanation. First, nearly all the observers\nshowed response bias on no-awareness trials (see Figure 2.29).\nSecond, Koivisto and Grassini (2016) used event-related potentials.\nThe N200 (a negative wave 200 ms after stimulus presentation) is typi-\ncally substantially larger for stimuli associated with awareness. Of key\nimportance, the N200 was greater on no-awareness correct trials than\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n89\nno-awareness incorrect trials for observers with high-response bias but not\nthose with low-response bias (see Figure 2.29).\nIn sum, Koivisto and Grassini (2016) provided a coherent explana-\ntion for the finding that visual performance was well above chance on\nno-awareness trials. Observers often had weak conscious awareness on\ncorrect no-awareness trials (indicated by the N200 findings). Such weak\nconscious awareness occurred most frequently among those most biased\nagainst claiming to have seen the stimulus.\nNeuroimaging research has consistently shown that stimuli of which\nthe observers are unaware nevertheless produce activation in several brain\nareas. In one study (Rees, 2007), activation was assessed in brain areas\nassociated with face processing and with object processing while invisible\npictures of faces or houses were presented. The identity of the picture (face\nvs house) could be predicted with almost 90% accuracy from patterns of\nbrain activation. Thus, subliminal stimuli can be processed reasonably\nthoroughly by the visual system.\nResearch focusing on differences in brain activation between condi-\ntions where there is (or is not) conscious perceptual awareness is discussed\nthoroughly in Chapter 16. Here we will mention two major findings. First,\nthere is much less integrated or synchronised brain activation when there is\nno conscious perceptual awareness (e.g., Godwin et al., 2015; Melloni et al.,\n2007). Second, activation of areas within the prefrontal cortex (involved in\nintegrating brain activity) is much greater for consciously perceived visual\nstimuli than those not consciously perceived (e.g., Gaillard et al., 2009;\nGodwin et al., 2015).\nWhat do these findings mean? They strongly suggest processing is\npredominantly limited to low-level features (e.g., colour; motion) when\nstimuli are not consciously perceived, which is consistent with the partial\nawareness hypothesis (Kouider et al., 2010).\nFigure 2.29\nThe relationship between\nresponse bias in reporting\nconscious awareness (C)\nand enhanced N200 on\nno-awareness correct trials\ncompared to no-awareness\nincorrect trials (UC).\nFrom Koivisto and Grassini\n(2016). Reprinted with\npermission of Elsevier.\n–0.5\n0\nr = –0.53\n2\n0\n–2\n–4\n–6\nUC (µV)\n0.5\nC\n1\n1.5\nCreated from usyd on 2022-02-13 13:25:58.",
    "90\nVisual perception and attention\nEvaluation\nEvidence for unconscious or subliminal perception has been reported in\nnumerous studies using numerous tasks. Some evidence is behavioural (e.g.,\nNaccache et al., 2002; Persaud & McLeod, 2008) and some is based on pat-\nterns of brain activity (e.g., Melloni et al., 2007; Rees, 2007). The latter line\nof research suggests there can be considerable low-level processing of visual\nstimuli in the absence of conscious visual awareness. In spite of limitations\nof research in this area (see below), there is reasonably strong evidence for\nsubliminal perception.\nWhat are the limitations of research on subliminal perception? First,\nmeasures of conscious awareness vary in sensitivity. As a consequence, it\nis relatively easy for researches to apparently demonstrate the existence\nof subliminal perception by using an insensitive measure (Rothkirch &\nHesselmann, 2017).\nSecond, many researchers focus on observers whose verbal reports\nshow a lack of awareness. That would be appropriate if such reports were\ntotally reliable. However, such reports are somewhat unreliable meaning\nthat some of them would report awareness if they provided a second verbal\nreport (Shanks, 2017). In addition, limitations of attention and memory\nmay sometimes cause observers’ reports to omit some of their conscious\nexperience from verbal reports (Lamme, 2010).\nThird, many claimed demonstrations of subliminal perception are\nflawed because of the typical failure to consider and/or control response\nbias (Peters et al., 2016). In essence, observers with response bias may\nclaim to have no conscious awareness of visual stimuli when they actually\nhave partial awareness (Koivisto and Grassini, 2016).\nFourth, Breitmeyer (2015) identified 24 different methods used to make\nvisual stimuli inaccessible to visual awareness. Neuroimaging and other\ntechniques have been used to estimate the amount of unconscious process-\ning associated with each method. Some methods (e.g., object-substitution\nmasking: a visual stimulus is replaced by dots surrounding it) are associ-\nated with much more unconscious processing than others (e.g., binocular\nrivalry, see Glossary). Of key relevance here, the likelihood of obtaining\nevidence for subliminal perception depends substantially on the method\nused to suppress visual awareness.\nCHAPTER SUMMARY\n•\nVision and the brain. In the retina, there are cones (specialised\nfor colour vision) and rods (specialised for motion detection).\nThe retina-geniculate-striate pathway between the eye and\ncortex is divided into partially separate P and M pathways. The\ndorsal stream (associated with the M pathway) terminates in\nthe parietal cortex and the ventral stream (associated with the\nP pathway) terminates in the inferotemporal cortex. There are\nnumerous  interactions between the two pathways and the two\nstreams.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n91\nAccording to Zeki’s functional specialisation theory, different\ncortical areas are specialised for different visual functions (e.g.,\nform; colour; motion). This is supported by findings from patients\nwith selective visual deficits (e.g., achromatopsia; akinetopsia).\nHowever, much visual processing depends on large brain networks\nrather than specific areas and Zeki de-emphasised the importance\nof top-down (recurrent) processing. It remains unclear how we\nintegrate the outputs of different visual processes (the binding\nproblem). However, selective attention, synchronised neural activity\nand combining bottom-up (feedforward) processing and top-down\n(recurrent) processing all play a role.\n•\nTwo visual systems: perception-action model. Milner and\nGoodale identified a vision-for-perception system based on\nthe ventral stream and a vision-for-action system based on the\ndorsal stream. There is limited (and inconsistent) support for\nthe predicted double dissociation between patients with optic\nataxia (damage to the dorsal stream) and visual form agnosia\n(damage to the ventral stream). Illusory effects found when\nperceptual judgements are made (ventral stream) are often much\nreduced when grasping or pointing responses are used (dorsal\nstream).\nHowever, such findings are often hard to interpret, and\nvisually guided action often relies more on the ventral stream than\nacknowledged theoretically. More generally, the two visual systems\ninteract with each other much more than previously assumed and\nthere are probably more than two visual pathways.\n•\nColour vision. Colour vision helps us detect objects and make\nfine discriminations among them. According to dual-process\ntheory, there are three types of cone receptors and three types\nof opponent processes (green-red; blue-yellow; white-black). This\ntheory explains negative afterimages and colour deficiencies but is\noversimplified. Colour constancy occurs when a surface’s perceived\ncolour remains the same when the illuminant changes. Colour\nconstancy is influenced by our ability to assess the illuminant\naccurately; local colour contrast; familiarity of object colour;\nchromatic adaptation; and cone-excitation ratios. Most theories are\nmore applicable to colour vision with simple artificial stimuli than\ncomplex objects in the natural world.\n•\nDepth perception. There are numerous monocular cues to depth\n(e.g., linear perspective; texture; familiar size) plus oculomotor\nand binocular cues. Cues are sometimes combined additively in\ndepth perception. However, more weight is generally given to\nreliable cues than unreliable ones with weightings changing if a\ncue’s reliability alters. However, one cue often dominates all others\nwhen different cues conflict strongly. It is often assumed that\nobservers generally combine cues near-optimally, but it is hard to\nCreated from usyd on 2022-02-13 13:25:58.",
    "92\nVisual perception and attention\ndefine “optimality”. The assumption that observers process several\nindependent cues prior to integrating all the information is proba-\nbly wrong in natural environments providing rich information about\noverall environmental structure.\nSize perception is sometimes strongly influenced by perceived\ndistance as predicted by the size-distance invariance hypothesis.\nHowever, the impact of familiar size on depth perception cannot\nbe explained by that hypothesis. More generally, perceived size\nand perceived distance often depend on different factors.\n•\nPerception without awareness: subliminal perception. Patients\nwith extensive damage to V1 sometimes suffer from blindsight.\nThis is a condition involving some ability to respond to visual\nstimuli in the absence of normal conscious visual awareness\n(especially motion detection). There is no conscious awareness in\ntype-1 blindsight but some residual awareness in type-2 blindsight.\nBlindsight patients are sometimes excessively cautious when\nreporting their conscious experience. The visual abilities of some\nblindsight patients probably depend on reorganisation of brain\nconnections following brain damage.\nThere is much behavioural and neuroimaging evidence for\nsubliminal perception in visually intact individuals. However,\nthere are problems of interpretation caused by insensitive (and\nunreliable) measures of self-reported awareness. Some observers\nmay show apparent subliminal perception because they have a\nresponse bias leading them to claim no conscious awareness of\nvisual stimuli of which they actually have limited awareness.\nFURTHER READING\nBrenner, E. & Smeets, J.B.J. (2018). Depth perception. In J.T. Serences (ed.),\nStevens’ Handbook of Experimental Psychology and Cognitive Neuroscience, Vol.\n2: Sensation, Perception, and Attention (4th edn; 385–414). New York: Wiley.\nThe authors provide a comprehensive account of theory and research on depth\nperception.\nde Haan, E.H.F., Jackson, S.R. & Schenk, T. (2018). Where are we now with\n“what” and “how”? Cortex, 98, 1–7. Edward de Haan and his colleagues provide\nan evaluation of the perception-action model\nGoldstein, E.B. & Brockmole, J. (2017). Sensation and Perception (10th edn).\nBoston: Cengage. There is coverage of key areas within visual perception in this\nintroductory textbook.\nNaccache, L. (2016). Chapter 18: Visual consciousness: A “re-updated” neurolog-\nical tour. Neurology of Consciousness (2nd edn; pp. 281–295). Lionel Naccache\nprovides a theoretical framework within which to understand blindsight and\nother phenomena associated with visual consciousness.\nShanks, D.R. (2017). Regressive research: The pitfalls of post hoc data selection\nin the study of unconscious mental processes. Psychonomic Bulletin & Review,\n24, 752–775. David Shanks discusses some issues relating to research claiming to\nprovide evidence for subliminal perception.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Basic processes in visual perception\n93\nTang, F. (2018). Foundations of vision. In J.T. Serences (ed.), Stevens’ Handbook\nof Experimental Psychology and Cognitive Neuroscience, Vol. 2: Sensation,\nPerception, and Attention (4th edn; pp. 1–62). New York: Wiley. Frank Tong\nprovides a comprehensive account of the visual system and its workings.\nWitzel, C. & Gegenfurtner, K.R. (2018). Colour perception: Objects, constancy,\nand categories. Annual Review of Vision Science, 4, 475–499. Christoph Witzel\nand Karl Gegenfurtner discuss our current knowledge of colour perception.\nCreated from usyd on 2022-02-13 13:25:58.",
    "Object and face\nrecognition\nINTRODUCTION\nTens of thousands of times every day we identify or recognise objects in the\nworld around us. At this precise moment, you are looking at this book. If\nyou raise your eyes, perhaps you can see a wall and windows. Object rec-\nognition typically happens so effortlessly it is hard to believe it is actually\na complex achievement. Evidence of its complexity comes from numerous\nunsuccessful attempts to program computers to “perceive” the environ-\nment. However, computer programs that are reasonably effective at recog-\nnising complicated two-dimensional patterns have been developed.\nWhy is visual perception so complex? First, objects often overlap\nand so we must decide where one object ends and the next one starts.\nSecond, numerous objects (e.g., chairs; trees) vary enormously in their\nvisual  properties (e.g., colour; size; shape) and so it is hard to assign such\ndiverse stimuli to the same category. Third, we recognise objects almost\nregardless of orientation (e.g., we can easily identify a plate that appears\nelliptical).\nWe can go beyond simply identifying objects. For example, we can\ngenerally describe what an object would look like from different angles,\nand we also know its uses and functions. All in all, there is much more to\nobject recognition than might be supposed (than meets the eye?).\nWhat is discussed in this chapter? The overarching theme is to unravel\nthe mysteries associated with recognising three-dimensional objects.\nHowever, we initially discuss how two-dimensional patterns are recognised.\nThen the focus shifts to how we decide which parts of the visual world\nbelong together and thus form separate objects. This is a crucial early\nstage in object recognition. After that, general theories of object recog-\nnition are evaluated against the available neuroimaging and behavioural\nevidence.\nFace recognition (vitally important in our everyday lives) differs in\nimportant ways from object recognition. Accordingly, we discuss face rec-\nognition in a separate section. Finally, we consider whether the processes\ninvolved in visual imagery resemble those involved in visual perception.\nChapter\n3\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n95\nOther issues relating to object recognition (e.g., depth perception; size con-\nstancy) were discussed in Chapter 2.\nPATTERN RECOGNITION\nWe spend much of our time (e.g., when reading) engaged in pattern\nrecognition – the identification or categorisation of  two-dimensional\npatterns. Much research has considered how alphanumeric patterns (alpha-\nbetical and numerical symbols) are recognised. A key issue is the flexibility\nof the human perceptual system (e.g., we can recognise the letter “A” rapidly\nand across wide variations in orientation, typeface, size and writing style).\nPatterns can be regarded as consisting of a set of specific features or\nattributes (Jain & Duin, 2004). For example, the key features of the letter\n“A” are two straight lines and a connecting cross-bar. An advantage of this\nfeature-based approach is that visual stimuli varying greatly in size, orien-\ntation and minor details can be identified as instances of the same pattern.\nMany feature theories assume pattern recognition involves processing\nspecific features followed by more global or general processing to inte-\ngrate feature information. However, Navon (1977) argued global process-\ning often precedes more specific processing. He presented observers with\nstimuli such as the one shown in Figure 3.1. On some trials, they decided\nwhether the large letter was an “H” or an “S”; on others, they decided\nwhether the small letters were Hs or Ss.\nNavon (1977) found performance speed with the small letters was\ngreatly slowed when the large letter differed from the small letters. However,\ndecision speed with the large letters was uninfluenced by the nature of the\nsmall letters. Navon concluded we often see the forest (global structure)\nbefore the trees (features).\nThere are limitations with Navon’s (1977) research and conclusions.\nFirst, Dalrymple et al. (2009) found performance was faster at the level of\nthe small letters than the large letter when the small letters were relatively\nlarge and spread out. Thus, attentional pro-\ncesses influence performance.\nSecond, Navon failed to distinguish ade-\nquately between encoding (neuronal responses\ntriggered by visual stimuli) and decoding\n(conscious perception of those stimuli) (Ding\net al., 2017). Encoding typically progresses\nfrom lower-level representations of simple\nfeatures to higher-level representations of\nmore complex features (Felleman & Van\nEssen, 1991). In contrast, Ding et al. (2017,\np. E9115) found, “The brain prioritises de-\ncoding of higher-level features because they\nare . . . more invariant and categorical, and\nthus easier to . . . maintain in noisy working\nmemory.” Thus, Navon’s (1977) conclusions\nmay be more applicable to visual decoding\n(conscious perception) than the preceding\ninternal neuronal responses.\nKEY TERM\nPattern recognition\nThe ability to identify\nor categorise two-\ndimensional patterns (e.g.,\nletters; fingerprints).\nFigure 3.1\nThe kind of stimulus used by Navon (1977) to demonstrate the\nimportance of global features in perception.\nInteractive exercise:\nNavon\nCreated from usyd on 2022-02-13 13:26:14.",
    "96\nVisual perception and attention\nFeature detectors\nIf presentation of a visual stimulus leads to detailed processing of its basic\nfeatures, we should be able to identify cortical cells involved in such pro-\ncessing. Hubel and Wiesel (1962) studied cells in parts of the occipital cortex\ninvolved in visual processing. Some cells responded in two different ways to\na spot of light depending on which part of the cell was affected:\n(1) An “on” response with an increased rate of firing when the light\nwas on.\n(2) An “off” response with the light causing a decreased rate of firing.\nHubel and Wiesel (e.g., 1979) discovered two types of neuron in the primary\nvisual cortex: simple cells and complex cells. Simple cells have “on” and\n“off” rectangular regions. These cells respond most to dark bars in a light\nfield, light bars in a dark field, or straight edges between areas of light and\ndark. Any given cell responds strongly only to stimuli of a particular orien-\ntation and so its responses could be relevant to feature detection.\nComplex cells resemble simple cells in responding maximally to\nstraight-line stimuli in a particular orientation. However, complex cells\nhave large receptive fields and respond more to moving contours. Each\ncomplex cell is driven by several simple cells having the same orientation\npreference and closely overlapping receptive fields (Alonso & Martinez,\n1998). There are also end-stopped cells. Their responsiveness depends on\nstimulus length and orientation. In sum, Hubel and Wiesel envisaged, “A\nhierarchically organised visual system in which more complex visual fea-\ntures are built (bottom-up) from more simple ones” (Ward, 2015, p. 111).\nHubel and Wiesel’s account is limited in several ways:\n(1) The cells they identified provide ambiguous information because they\nrespond comparably to different stimuli (e.g., a horizontal line moving\nrapidly and a nearly horizontal line moving slowly). Observers must\ncombine information from numerous neurons to remove ambiguities.\n(2) Neurons differ in their responsiveness to different spatial frequencies\nand several phenomena in visual perception depend on this differen-\ntial responsiveness (discussed on pp. 104–105).\n(3) As Schulz et al. (2015, p. 1022) pointed out, “The responses of corti-\ncal neurons [in the primary visual cortex] to repeated presentations of\na stimulus are highly variable.” This variability complicates pattern\nrecognition.\n(4) Pattern recognition and object recognition depend on top-down\nprocesses triggered by expectations and context (e.g., Goolkasian\n& Woodberry, 2010; discussed on pp. 111–116) as well as on the\nbottom-up processes emphasised by Hubel and Wiesel.\nPERCEPTUAL ORGANISATION\nOur visual environment is typically complex and confusing with many\nobjects overlapping others, thus making it hard to achieve perceptual seg-\nregation of visual objects. How this is done was first studied systematically\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n97\nIN THE REAL WORLD: HOW CAN WE DISCOURAGE SPAMMERS?\nVirtually everyone has received a substantial amount of spam (unwanted\nemails). Spammers use bots (robots running automated tasks over\nthe internet) to send emails to thousands of individuals for various\nmoney-making purposes (e.g., fake sweepstake entries).\nA CAPTCHA (Completely Automated Turing test to tell Computers\nand Humans Apart) is commonly used to discourage spammers. The\nintention is to ensure a website user is human by providing a test\nhumans can solve but automated computer-based systems cannot. The\nCAPTCHA in Figure 3.2 is typical in consisting of distorted characters\nconnected together horizontally. In principle, the study of CAPTCHAs\ncan shed light on the strengths of human pattern recognition.\nComputer programs to solve CAPTCHAs\ngenerally involve a segmentation phase to\nlocate the characters followed by a rec-\nognition phase where each character is\nidentified. Many computer programs can\nrecognise individual characters even when\nvery distorted but their performance is\nmuch worse at segmenting connected char-\nacters. Overall, the performance of most\ncomputer programs at solving CAPTCHAs\nwas poor until fairly recently.\nNachar et al. (2015) devised a computer\nprogram focusing on edge corners (an\nedge corner is the intersection of two straight edges). Such corners are relatively unaffected by\nthe distortions and overlaps of characters found in CAPTCHAs. Nachar et al.’s approach proved\nsuccessful, allowing them to solve 57% of CAPTCHAs resembling the one shown in Figure 3.2.\nThere are two take-home messages. First, the difficulties encountered in devising computer pro-\ngrams to solve CAPTCHAs indicate humans have excellent pattern-recognition abilities. Second,\nedge corners provide an especially valuable source of information in pattern recognition. Of rel-\nevance, successful camouflage in many species depends heavily on markings that break up an\nanimal’s edges, making it less visible (Webster, 2015).\nKEY TERM\nCAPTCHA\nA Completely Automated\nTuring Test to tell\nComputers and Humans\nApart involving distorted\ncharacters connected\ntogether is often used\nto establish that the user\nof an internet website\nis human rather than an\nautomated system.\nFigure 3.2\nThe CAPTCHA used by Yahoo.\nFrom Gao et al. (2012).\nIN THE REAL WORLD: FINGERPRINTING\nAn important form of real-world pattern recognition involves experts matching a criminal’s finger-\nprints (latent print) against stored fingerprint records. Automatic fingerprint identification systems\n(AFISs) scan huge databases. This typically produces a small number of possible matches to the\nfingerprint obtained from the crime scene ranked by similarity to the criminal’s fingerprint. Experts\nthen decide which database fingerprint (if any) matches the criminal’s.\nWe might imagine experts are much better at fingerprint matching than novices because their\nanalytic (slow, deliberate) processing is superior. However, Thompson and Tangen (2014) found\nexperts greatly outperformed novices when pairs of fingerprints were presented for only 2 seconds,\nforcing them to rely heavily on non-analytic (fast and relatively “automatic”) processing. However,\nwhen fingerprint pairs were presented for 60 seconds, experts showed a greater performance\nCreated from usyd on 2022-02-13 13:26:14.",
    "98\nVisual perception and attention\nimprovement than novices (19% vs 7%, respectively). Thus, experts have superior analytic and\nnon-analytic processing.\nAccording to signal-detection theory, experts may surpass novices in their ability to discriminate\nbetween matching and non-matching prints. Alternatively, they may simply have a more lenient\nresponse bias than novices. If so, they would tend to respond “match” to every pair of prints.\nGood discrimination is associated with many “hits” (responding “match” on match trials) plus a\nlow false-alarm rate (not responding “match” on non-match trials). In contrast, a lenient response\ncriterion is associated with many false alarms.\nThompson et al. (2014) found novices made false alarms on 57% of trials on which two prints\nwere similar but did not match, whereas experts did so on only 1.65% of trials. Thus, experts have\na much more conservative response criterion as well as much better discrimination between match-\ning and non-matching prints.\nIt is often assumed expert fingerprint identification is very accurate. However, experts listing the\nminutiae (features) on fingerprints on two occasions showed total agreement between their assess-\nments only 16% of the time (Dror et al., 2012). Nevertheless, experts are much less likely than\nnon-experts to decide incorrectly that two fingerprints from the same person are from different\nindividuals (Champod, 2015).\nFingerprint identification is often complex. As an example, try to decide whether the fingerprints\nin Figure 3.3 come from the same person. Four fingerprinting experts said the fingerprint on the\nright was from the same person as the one on the left (Ouhane Daoud, the bomber involved in\nthe terrorist attack in Madrid on 11 March 2004). In fact, the one on the right came from Brandon\nMayfield, an American lawyer who was falsely arrested.\nExperts’ mistakes are often due to the incompleteness of the fingerprints found at crime scenes.\nHowever, top-down processes also contribute. Experts’ errors often involve forensic confirmation\nbias: “an individual’s pre-existing beliefs, expectations, motives, and situational context influence\nthe collection, perception, and interpretation of evidence” (Kassin et al., 2013, p. 45).\nDror et al. (2006) found evidence of forensic confirmation bias. Experts were asked to judge\nwhether two fingerprints matched having been told, incorrectly, that they were the ones mistakenly\nmatched by the FBI as the Madrid bomber. In fact, these experts had judged these fingerprints to\nbe a clear and definite match several years earlier. The misleading information provided led 60%\nof them to judge the prints to be definite non-matches! Thus, top-down processes triggered by\ncontextual information can distort fingerprint\nidentification.\nLangenburg et al. (2009) studied the effects\nof context (e.g., alleged conclusions of inter-\nnationally respected experts) on fingerprint\nidentification. Experts and non-experts were\nboth influenced by contextual information\n(and so showed confirmation bias). However,\nnon-experts were influenced more.\nThe above studies on confirmation bias\nmanipulated context very directly and explic-\nitly. Searston et al. (2016) found a more subtle\ncontext effect based on familiarity. Novice par-\nticipants were presented initially with a series\nof cases and fingerprint pairs and given feed-\nback as to whether the  fingerprints matched\nor not. Then they were presented with\ncases very similar to those seen previously\nFigure 3.3\nThe FBI’s mistaken identification of the Madrid bomber.\nThe fingerprint from the crime scene is on the left. The\nfingerprint of the innocent suspect (positively identified by\nvarious fingerprint experts) is on the right.\nFrom Dror et al. (2006). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n99\nand decided whether the fingerprint pairs matched. The participants exhibited response bias during\nthe second part of the experiment: their decisions (i.e., match or no-match) tended to correspond\nto the correct decisions associated with similar (but not identical) cases encountered earlier.\nIn sum, experts typically outperform novices at fingerprint matching because they have superior\ndiscrimination ability and a more conservative response criterion. However, even experts are influ-\nenced by irrelevant or misleading contextual information and often show evidence of confirmation\nbias. Worryingly, among forensic experts (including fingerprinting experts), only 52% regarded bias as\na matter for concern and even fewer (26%) believed their own judgements were influenced by bias.\nby the gestaltists, German psychologists (including Koffka, Köhler and\nWertheimer) who emigrated to the United States between the two World\nWars. Their fundamental principle was the law of Prägnanz – we typically\nperceive the simplest possible organisation of the visual field.\nMost of the gestaltists’ other laws can be subsumed under the law of\nPrägnanz. Figure 3.4(a) illustrates the law of proximity (visual elements\nclose in space tend to be grouped together). Figure 3.4b shows the law of\nsimilarity (similar elements tend to be grouped together).\nWe see two crossing lines in Figure 3.4(c) because, according to the\nlaw of law continuation, we group together those elements requiring the\nfewest changes or interruptions in straight or smoothly curving lines.\nFinally, Figure 3.4(d) illustrates the law of closure: the missing parts of a\nfigure are filled in to complete the figure (here a circle).\nWe might dismiss these principles as “mere textbook curiosities”\n(Wagemans et al., 2012a, p. 1180). However, the various grouping prin-\nciples “pervade virtually all perceptual experiences because they determine\nthe objects and parts that people perceive in their environment” (Wagemans\net al., 2012a, p. 1180).\nThe gestaltists emphasised figure-ground segmentation in percep-\ntion. The figure is perceived as having a distinct form or shape whereas\nthe ground lacks form. In addition, the figure is perceived as being in\nFigure 3.4\nExamples of the Gestalt\nlaws of perceptual\norganisation: (a) the law\nof proximity; (b) the law\nof similarity; (c) the law of\ngood continuation; and (d)\nthe law of closure.\nKEY TERMS\nLaw of Prägnanz\nThe notion that the\nsimplest possible\norganisation of the\nvisual environment is\nperceived; proposed by\nthe gestaltists.\nFigure-ground\nsegmentation\nThe perceptual\norganisation of the visual\nfield into a figure (object\nof central interest) and a\nground (less important\nbackground).\nCreated from usyd on 2022-02-13 13:26:14.",
    "100\nVisual perception and attention\nfront of the ground and the contour sep-\narating the figure from ground “belongs”\nto the figure. Check these claims with the\nfaces-goblet illusion (see Figure  3.5). When\nthe goblet is  perceived as the figure, it seems\nto be in front of a dark background. Faces\nare in front of a light background when\nforming the figure.\nWhat determines which region is identi-\nfied as the figure and which as the ground?\nRegions that are convex (curving outwards),\nsmall, surrounded and symmetrical are most\nlikely to be perceived as figures (Wagemans\net al., 2012a). For example, Fowlkes et al.\n(2007) found with images of natural scenes\nthat regions identified by observers as figures\nwere generally smaller and more convex than\nground regions.\nFinally, the gestaltists argued percep-\ntual grouping and organisation are innate or\nintrinsic to the brain. As a result, they de-\nemphasised the importance of past experience.\nFindings\nThe gestaltists’ approach was limited because they mostly used artificial\nfigures, making it important to see whether their findings apply to more\nrealistic stimuli. Geisler et al. (2001) used pictures to study the contours\nof flowers, rivers, trees and so on. They discovered object contours could\nbe calculated accurately using two principles that were different from those\nemphasised by the gestaltists:\n(1)  Adjacent segments of any contour typically have very similar\norientations.\n(2)  Segments of any contour that are further apart generally have some-\nwhat different orientations.\nGeisler et al. (2001) asked observers to decide which of two complex pat-\nterns presented together contained a winding contour. Task performance\nwas well predicted by the two key principles described above.\nElder and Goldberg (2002) analysed the statistics of natural contours\nand obtained findings largely consistent with Gestalt laws. Proximity was a\nvery  powerful cue when deciding which contours belonged to which objects.\nThere was also a small contribution from similarity and good continuation.\nNumerous cues influence figure-ground segmentation and the percep-\ntion of object boundaries with natural scenes. Mély et al. (2016) found\ncolour and luminance (see Glossary) strongly influenced the perception of\nobject boundaries. There was more accurate perception of object bound-\naries when several cues were combined than that found for any single cue\nin isolation.\nFigure 3.5\nAn ambiguous drawing that can be seen as either two faces\nor as a goblet.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n101\nIn sum, there is some support for Gestalt laws in natural scene\nperception. However, figure-ground segmentation is more complex in\nnatural scenes than most artificial figures, and so the Gestalt approach is\noversimplified.\nThe gestaltists failed to discover several principles of perceptual organ-\nisation. For example, Palmer and Rock (1994) proposed the principle of\nuniform connectedness. According to this principle, any connected region\nhaving uniform visual properties (e.g., colour; texture; lightness) tends to\nbe organised as a single perceptual unit. Palmer and Rock found grouping\nby uniform connectedness dominated proximity and similarity when there\nwas a conflict.\nPinna et al. (2016) argued that the gestaltists de-emphasised the role\nof dissimilarity in perceptual organisation. Consider Figure 3.6. The per-\nception of the empty circles as a rotated square or a diamond is strongly\ninfluenced by the location of the dissimilar element (i.e., the black circle).\nThis illustrates the principle of accentuation: “Elements group in the same\noriented direction of the dissimilar element placed . . . outside a whole set\nof continuous/homogeneous components” (Pinna et al., 2016, p. 21).\nMuch processing involved in perceptual organisation occurs very\nrapidly. Williford and von der Heydt (2016) discovered signals from\nneurons in V2 (see Chapter 2) relating to figure-ground organisation\nemerged within 70 ms of stimulus presentation for complex natural scenes\nas well as for simple figures. This extremely rapid processing is  consistent\nwith the gestaltists’ assumption that perceptual organisation is due to\ninnate factors but may also reflect massive experience in object recognition.\nThe role of learning was discussed by Bhatt and Quinn (2011). Infants\nas young as 3 or 4 months show grouping by continuation, proximity and\nconnectedness, which is apparently consistent with the Gestalt position.\nHowever, other grouping principles (e.g., closure) were used only later in\ninfancy, and infants typically made increased use of grouping principles\nover time. Thus, learning is important.\nFigure 3.6\nThe dissimilar element (black circle) accentuates the tendency to perceive the array of\nempty circles as (A) a rotated square or (B) a diamond.\nFrom Pinna et al., 2016.\nA\nB\nKEY TERM\nUniform connectedness\nThe notion that adjacent\nregions in the visual\nenvironment having\nuniform visual properties\n(e.g., colour) are\nperceived as a single\nperceptual unit.\nCreated from usyd on 2022-02-13 13:26:14.",
    "102\nVisual perception and attention\nAccording to the gestaltists, perceptual grouping occurs rapidly and\nshould be uninfluenced by attentional processes. The evidence is mixed.\nRashal et al. (2017) conducted several experiments. Attention was not\nrequired with grouping by proximity or similarity in colour. However,\nattention was required with grouping by similarity in shape. In general,\nattention was more likely to be required when the processes involved in per-\nceptual grouping were relatively complex. Overall, the processes involved\nin perceptual grouping are much more complicated and variable than the\ngestaltists had assumed.\nThe gestaltists also assumed figure-ground segmentation is innate and\nso not reliant on past experience or learning. Barense et al. (2012) reported\ncontrary evidence. Amnesic patients (having severe memory problems)\nand healthy controls were presented with various stimuli, some containing\nparts of well-known objects (see Figure 3.7). In other stimuli, the object\nparts were rearranged. The task was to decide which region of each stim-\nulus was the figure.\nThe healthy controls identified the regions containing familiar objects\nas figures more often than those containing rearranged parts. In contrast,\nthe amnesic patients showed no difference between the two types of stimuli\nbecause they experienced difficulty in identifying the objects presented.\nThus, figure-ground segmentation can depend\non past experience and memory (i.e., object\nfamiliarity).\nSeveral recent theories explain perceptual\ngrouping and figure-ground segmentation.\nFor example, consider Froyen et  al.’s (2015)\nBayesian hierarchical grouping model, accord-\ning to which observers initially form “beliefs”\nconcerning the objects to be expected in the\ncurrent context. In addition, their visual\nsystem assumes the visual image  consists of\na mixture of objects. The information avail-\nable in the image is then used to change the\nsubjective probabilities of different group-\ning hypotheses to make optimal use of that\ninformation. Of key importance, observers\nuse their learned knowledge of patterns and\nobjects (e.g., visual elements close  together\ngenerally belong to the same object).\nThe above approach exemplifies theories\nbased on Bayesian inference (see Glossary).\nTheir central assumption is that the initial\nsubjective probabilities associated with vari-\nous hypotheses as to the organisation of\nobjects within a visual  image change on the\nbasis of the information it provides. This\napproach is much  more realistic than the\ngestaltists’ relatively cut-and-dried approach.\nExperimental stimuli: Intact familiar confgurations\nControl stimuli: Part-rearranged novel confgurations\nFigure 3.7\nThe top row shows intact familiar shapes (from left to right:\na guitar, a standing woman, a table lamp). The bottom row\nshows the same objects but with the parts rearranged. The\ntask was to decide which region in each stimulus was the\nfigure.\nFrom Barense et al. (2012). Reprinted with permission of Oxford\nUniversity Press.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n103\nEvaluation\nWhat are the strengths of the Gestalt approach? First, the gestaltists\nfocused on key issues (e.g., figure-ground segmentation). Second, nearly all\ntheir grouping laws (and the notion of figure-ground segmentation) have\nstood the test of time and are applicable to natural scenes as well as arti-\nficial figures. Third, the notion that observers perceive the simplest possi-\nble organisation of the visual environment has proved very fruitful. Many\nrecent theories are based on the assumption that striving for simplicity is\ncentral to visual perception (Jäkel et al., 2016).\nWhat are the approach’s limitations? First, the gestaltists de-\nemphasised the importance of past experience and learning. As Wagemans\net al. (2012b, p. 1229) pointed out, the gestaltists “focused almost exclu-\nsively on processes intrinsic to the perceiving organism . . . The environ-\nment itself did not interest [them]”.\nSecond, the gestaltists produced descriptions of important perceptual\nphenomena but not adequate explanations. Recently, however, such expla-\nnations have been provided.\nThird, nearly all the evidence the gestaltists provided was based on\ntwo-dimensional drawings. The greater complexity of real-world scenes\n(e.g., important parts of objects hidden or occluded) means additional\nexplanatory assumptions are required.\nFourth, the gestaltists did not discover all the principles of percep-\ntual organisation. Among such undiscovered principles are uniform\nconnectedness, the principle of accentuation and generalised common\nfate (e.g., when elements of a visual scene become brighter or darker\ntogether, they are grouped together). More generally, the gestaltists did\nnot  appreciate the sheer complexity of the processes involved in percep-\ntual grouping.\nFifth, the gestaltists focused mostly on drawings involving only one\nGestalt law. With natural scenes, several laws often operate simultaneously\nand interact in complex ways not predicted by the gestaltists (Jäkel et al.,\n2016).\nSixth, the gestaltists’ approach was too inflexible. They did not realise\nperceptual grouping and figure-ground segregation depend on complex\ninteractions between basic (and possibly innate) processes and past experi-\nence (Rashal et al., 2017).\nAPPROACHES TO OBJECT RECOGNITION\nObject recognition (identifying objects in the visual field) is enormously\nimportant if we are to interact effectively with the environment. We start\nwith basic aspects of the human visual system followed by major theories of\nobject recognition.\nPerception-action model\nMilner and Goodale’s (1995, 2008) perception-action model (discussed in\nChapter 2) is relevant to understanding object perception. It is based on a\ndistinction between ventral (or “what”) and dorsal (or “how”) streams (see\nCreated from usyd on 2022-02-13 13:26:14.",
    "104\nVisual perception and attention\nFigure 2.9), with the latter providing visual guidance for action (e.g., grasp-\ning). They argued object recognition and perception depend primarily on\nthe ventral stream. This stream is hierarchically organised. Visual processing\nbasically proceeds from the retina through several areas including the lateral\ngeniculate nucleus, V1, V2 and V4, culminating in the inferotemporal cortex.\nThe importance of the ventral stream is indicated by research showing\nobject recognition can be reasonably intact after damage to the dorsal\nstream (Goodale & Milner, 2018). However, object recognition involves\nnumerous interactions between the ventral and dorsal streams (Freud et al.,\n2017b).\nSpatial frequency\nVisual perception develops over time even though it seems instantaneous\n(Hegdé, 2008). The visual processing involved in object recognition typ-\nically proceeds in a coarse-to-fine way with initial coarse or general pro-\ncessing followed by fine or detailed processing. As a result, we can perceive\nvisual scenes at a very general level and/or at a fine-grained level.\nHow does coarse-to-fine processing occur? Numerous cells in the\nprimary visual cortex respond to high spatial frequencies and capture fine\ndetail in the visual image. Numerous others respond to low spatial fre-\nquencies and capture coarse information in the visual image.\nLow spatial frequency information (often relating to motion and/\nor spatial location) is transmitted rapidly to higher-order brain areas via\nthe fast magnocellular system using the dorsal visual stream (discussed in\nChapter 2). Awasthi et al. (2016) used red light to produce magnocellular\nsuppression. As predicted, this interfered with the low spatial frequency\ncomponents of face perception.\nIn contrast, high spatial frequency information (often relating to\ncolour, shape and other aspects of object recognition) is transmitted rel-\natively slowly via the parvocellular system using the ventral visual stream\n(see Chapter 2). This speed difference explains why coarse processing typ-\nically precedes fine processing, although conscious perception is typically\nbased on integrated low and high spatial information.\nWe can observe the effects of varying\nspatial frequency by comparing images con-\nsisting only of low or high spatial frequency\n(see Figure 3.8). You probably agree it is con-\nsiderably easier to achieve object recognition\nwith the high spatial frequency image.\nFindings\nMusel et al. (2012) presented participants\nwith very brief (150 ms) scenes proceeding\nfrom coarse (low spatial frequency) to fine\n(high spatial  frequency) or vice versa (sample\nvideos can be viewed at DOI.10.1371/\njournal.pone.003893). Performance (deciding\nwhether each scene was an outdoor or indoor\nFigure 3.8\nHigh and low spatial frequency versions of a place (a building).\nFrom Awasthi et al. (2016).\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n105\none) was faster with the coarse-to-fine sequence, a finding subsequently\nreplicated by Kauffmann et al. (2015). These  findings  suggest the visual\nprocessing of natural scenes is predominantly coarse to fine. This sequence\nmay be more effective because low spatial frequency information is used to\ngenerate plausible interpretations of the visual input.\nThere is considerable evidence that global (general) processing often\nprecedes local (specific) processing (discussed on p. 95). Much research\nhas established an association between processing low spatial frequen-\ncies and global perception and between processing high spatial frequen-\ncies and local perception. However, use of low and high spatial frequency\ninformation in visual processing is often very flexible and is influenced by\ntask demands. Flevaris and Robertson (2016, p. 192) reviewed research\nshowing, “Attention to global and local aspects of a display biases the flex-\nible selection of relatively lower and relatively higher SFs [spatial frequen-\ncies] during image processing.”\nFinally, we can explain the notoriously elusive smile of Leonardo da\nVinci’s Mona Lisa with reference to spatial frequencies. Livingston (2000)\nproduced images of that painting with different spatial frequencies. Mona\nLisa’s smile is much more obvious in the two low spatial frequency images\n(see Figure 3.9). Livingston pointed out that our central or foveal vision\nis dominated by higher spatial frequencies compared with our peripheral\nvision. As a result, “You can’t catch her smile by looking at her mouth.\nShe smiles until you look at her mouth” (p. 1299).\nHistorical background: Marr’s computational approach\nDavid Marr (1982) proposed a very influential theory. He argued object\nrecognition involves various processing stages and is much more complex\nthan had previously been thought. More specifically, Marr claimed observ-\ners construct various representations (descriptions) providing increasingly\ndetailed information about the visual environment:\n●\nPrimal sketch: this provides a two-dimensional description of the main\nlight intensity changes in the visual input, including information about\nedges and contours.\nFigure 3.9\nImage of Mona Lisa\nrevealing very low spatial\nfrequencies (left), low\nspatial frequencies (centre)\nand high spatial frequencies\n(right).\nFrom Livingstone (2000). By\nkind permission of Margaret\nLivingstone.\nCreated from usyd on 2022-02-13 13:26:14.",
    "106\nVisual perception and attention\n●\n2½-D sketch: this incorporates a description of the depth and ori-\nentation of visible surfaces using information from shading, texture,\nmotion and binocular disparity. It resembles the primal sketch in being\nviewer-centred or viewpoint-dependent (i.e., it is influenced by the\nangle from which the observer sees objects or the environment).\n●\n3-D model representation: this describes objects’ shapes and their rel-\native positions three-dimensionally; it is independent of the observer’s\nviewpoint and so is viewpoint-invariant.\nWhy has Marr’s theoretical approach been so influential? First, he suc-\ncessfully combined ideas from neurophysiology, anatomy and computer\nvision (Mather, 2015). Second, he was among the first to realise the enor-\nmous complexity of object recognition. Third, his distinction between\nviewpoint-dependent and viewpoint-invariant representations triggered\nmuch subsequent research (discussed on pp. 109–111).\nWhat are the limitations of Marr’s approach? First, he focused exces-\nsively on bottom-up processes. Marr (1982, p. 101) admitted, “Top-down\nprocessing is sometimes used and necessary.” However, he de-emphasised\nthe major role expectations and knowledge play in object recognition\n(discussed in detail on pp. 111–116).\nSecond, Marr assumed that “Vision tells the truth about what is out\nthere” (Mather, 2015, p. 44). In fact, there are numerous exceptions. For\nexample, people observed from a tall building (e.g., the Eiffel Tower) seem\nvery small. Another example is the vertical-horizontal illusion –  observers\ntypically overestimate the length of a vertical line when it is compared\nagainst a horizontal line of the same length (e.g., Gavilán et al., 2017).\nThird, many processes proposed by Marr are incredibly complex com-\nputationally. As Mather (2015, p. 44) pointed out, “The computations\nrequired to produce view-independent 3-D object models are now thought\nby many researchers to be too complex.”\nBiederman’s recognition-by-components theory\nBiederman’s (1987) recognition-by-components theory developed Marr’s\ntheoretical approach. His central assumption was that objects consist of\nbasic shapes or components known as “geons” (geometric ions); examples\ninclude blocks, cylinders, spheres, arcs and wedges. Biederman claimed\nthere are approximately 36 different geons, which sounds suspiciously low\nto provide descriptions of all objects. However, geons can be combined in\nalmost endless ways. For example, a cup is an arc connected to the side of a\ncylinder. A pail involves the same two geons but with the arc connected to\nthe top of the cylinder.\nFigure 3.10 shows the key features of recognition-by-components\ntheory. We have already considered the stage where the components or\ngeons of an object are determined. When this information is available, it is\nmatched with stored object representations or structural models consisting\nof information about the nature of the relevant geons, their orientations,\nsizes and so on. Whichever stored representation fits best with the geon-\nbased information obtained from the visual object determines which object\nis identified by observers.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n107\nAs indicated in Figure 3.10, the first step\nin object recognition is edge extraction in\nwhich various aspects of the visual stimulus\n(e.g., luminance; texture; colour) are pro-\ncessed, leading to a description of the object\nresembling a line drawing. After that, deci-\nsions are made as to how the object should\nbe segmented to establish its geons.\nWhich edge information should observ-\ners focus on? According to Biederman (1987),\nnon-accidental image properties are crucial.\nThese are aspects of the visual image that\nare invariant across different viewing angles.\nExamples include whether an edge is straight\nor curved and whether a contour is concave\n(hollow) or convex (bulging) with the\nformer of particular importance. Biederman\nassumed objects’ geons of a visual object are\nconstructed from various non-accidental or\ninvariant properties.\nThis part of the theory leads to the key\nprediction that object recognition is typi-\ncally viewpoint-invariant (i.e., objects can\nbe recognised equally easily from nearly all\nviewing angles). The argument is that object\nrecognition depends crucially on the identifi-\ncation of geons, which can be identified from\nnumerous viewpoints. Thus, object recogni-\ntion is difficult only when one or more geons\nare hidden from view.\nHow do we recognise objects in subop-\ntimal viewing conditions (e.g., an intervening\nobject obscures part of the target object)?\nFirst, non-accidental properties can still be\ndetected even when only parts of edges are\nvisible. Second, if the concavities of a contour\nare visible, there are mechanisms for restoring\nthe missing parts of the contour. Third, we\ncan recognise many objects when some geons\nare missing because there is much redun-\ndant information under optimal viewing\nconditions.\nFindings\nNon-accidental properties play a vital role in\nobject recognition (Parker & Serre, 2015). For\nexample, it is easier to distinguish between\ntwo objects differing in non- accidental prop-\nerties. In addition, neuroimaging studies\nIrving Biederman. University of Southern California.\nFigure 3.10\nAn outline of Biederman’s recognition-by-components theory.\nAdapted from Biederman (1987).\nCreated from usyd on 2022-02-13 13:26:14.",
    "108\nVisual perception and attention\nreveal greater neural responses to changes in non-accidental properties than\nother visual changes. Rolls and Mills (2018) developed a model of object\nrecognition showing how non-accidental properties of objects can promote\nviewpoint-invariant object recognition.\nThere is general agreement that an object’s contour or outline is\nimportant in object recognition. For example, camouflage in many animal\nspecies is achieved by markings breaking up and distorting contour infor-\nmation (Webster, 2015). There is also general agreement that concavities\nand convexities are especially informative regions of an object’s contour.\nHowever, the evidence relating to Biederman’s (1987) assumption that\nconcavity is more important than convexity in object recognition is mixed\n(Schmidtmann et al., 2015).\nIn their own study, Schmidtmann et al. (2015) focused specifically on\nshape recognition using unfamiliar shapes. Shape recognition depended\nmore on information about convexities than concavities (although con-\ncavity information had some value). They argued convexity information\nis likely to be more important because convexities reveal an object’s outer\nboundary.\nAccording to the theory, object recognition depends on edge rather\nthan surface information (e.g., colour). However, Sanocki et al. (1998)\nargued that edge-extraction processes are less likely to produce accurate\nobject recognition when objects are presented in the context of other objects\nrather than on their own. This is because it can be hard to decide which\nedges belong to which objects when several objects are presented together.\nSanocki et al. presented observers briefly with objects, with line drawings,\nor full-colour photographs of objects. As predicted, object recognition was\nmuch worse with the line drawings than the full-colour photographs when\nobjects were presented in context.\nA key theoretical prediction is that object recognition is typically\nviewpoint-invariant. Biederman and Gerhardstein (1993) supported this\nprediction when familiar objects presented at different angles were named\nrapidly. However, numerous other studies have failed to obtain evidence\nfor viewpoint-invariance. This is especially the case with unfamiliar objects\ndiffering from familiar objects in not having previously been viewed from\nmultiple viewpoints (discussed in next section on pp. 109–111).\nEvaluation\nBiederman’s (1987) recognition-by-components theory has been very influ-\nential. It indicates how we can identify objects despite substantial differ-\nences among the members of most categories in shape, size and orientation.\nThe assumption that non-accidental properties of stimuli and geons play a\nrole in object recognition has received much support.\nWhat are the theory’s limitations? First, it focuses predominantly\non bottom-up processes triggered directly by the stimulus input. As a\nresult, it de-emphasises the impact on object recognition of top-down\nprocesses based on expectation (Trapp & Bar, 2015; discussed further on\npp.  111–116). Second, the theory accounts only for fairly unsubtle percep-\ntual discriminations. It cannot explain how we decide whether an animal\nis, for example, a particular breed of dog or cat. Third, the notion that\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n109\nobjects consist of invariant geons is too inflexible. As Hayward and Tarr\n(2005, p. 67) pointed out, “You can take almost any object, put a working\nlight-bulb on the top, and call it a lamp.”\nDoes viewpoint influence object recognition?\nForm a visual image of a bicycle. Your image probably involved a side view\nwith both wheels clearly visible. We can use this example to discuss a theo-\nretical controversy. Consider an experiment where some participants see a\nphotograph of a bicycle in the typical (or canonical) view as in your visual\nimage, whereas others see a photograph of the same bicycle viewed end-on\nor from above. Would those given the typical view identify the object as a\nbicycle fastest?\nWe will address the above question shortly. Before that, we must\ndiscuss two key terms mentioned earlier. If object recognition is equally\nrapid and easy regardless of viewing angle, it is viewpoint-invariant. In con-\ntrast, if object recognition is faster and easier when objects are seen from\ncertain angles, it is viewer-centred or viewpoint-dependent. Another impor-\ntant distinction is between categorisation (e.g., is the object a dog?) and\nidentification (e.g., is the object a poodle?), which requires within-category\ndiscriminations.\nFindings\nMilivojevic (2012) reviewed behavioural research in this area. Object rec-\nognition is typically uninfluenced by an object’s orientation when cate-\ngorisation is required (i.e., it is viewpoint-invariant). In contrast, object\nrecognition is significantly slower if an object’s orientation differs from\nits canonical or typical viewpoint when identification is required (i.e.,\nit is viewer-centred). Hamm and McMullen (1998) reported supporting\nfindings. Changes in viewpoint had no effect on speed of object recogni-\ntion when categorisation was required (e.g., deciding an object was a car).\nHowever, there were clear effects of changing viewpoint with identification\n(e.g., deciding whether an object was a taxi).\nSmall (or non-significant) effects of object orientation on categorisa-\ntion time do not necessarily indicate orientation has not affected internal\nprocessing. Milivojevic et al. (2011) found stimulus orientation had only\nsmall effects on speed and accuracy of categorisation. However, early com-\nponents of the event-related potentials (ERPs; see Glossary) were larger\nwhen stimuli were not in the upright position. Thus, stimulus orientation\nhad only modest effects on task performance but perceptual processing was\nless demanding with upright stimuli.\nNeuroimaging research has enhanced our understanding of object rec-\nognition (Milivojevic, 2012). With categorisation tasks, brain activation is\nmostly very similar regardless of object orientation. However, orientation\ninfluences brain activity early in processing suggesting initial processing is\nviewpoint-dependent.\nWith identification tasks, there is typically greater activation of areas\nwithin the inferior temporal cortex when objects are not in their typical\nor canonical orientation (Milivojevic, 2012). This finding is unsurprising\nCreated from usyd on 2022-02-13 13:26:14.",
    "110\nVisual perception and attention\nsince the inferotemporal cortex is heavily involved in object recognition\n(Gauthier & Tarr, 2016). Identification may require additional processing\n(e.g., more detailed processing of object features) for objects presented in\nunusual orientations.\nLearning influences the extent to which object recognition is\nviewpoint- dependent or viewpoint-invariant. Zimmermann and Eimer\n(2013) presented unfamiliar faces on 640 trials. Face recognition was\nviewpoint-dependent initially but became more viewpoint-invariant there-\nafter. Learning caused more information about each face to be stored in\nlong-term memory and this facilitated rapid access to visual face memory\nregardless of facial orientation.\nEtchells et al. (2017) also studied the effects of learning on face recog-\nnition. During learning, observers were repeatedly shown one or two views\nof unfamiliar faces. Subsequently they were shown a novel view of these\nfaces. There was evidence of viewpoint-invariant face recognition when\nlearning had been based on two different views but not when it had been\nbased on only a single view.\nRelated research was reported by Weibert et al. (2016). They found\nevidence of a viewpoint-invariant response in face-selective regions of\nthe medial temporal lobe with familiar (but not unfamiliar) faces. Thus,\nviewpoint-invariant responses during object recognition are more fre-\nquent  for faces for which observers have stored considerable relevant\ninformation.\nEvidence of viewpoint-dependent or viewpoint-invariant responses\nwithin the brain often depends on the precise brain areas studied. Erez\net al. (2016) found viewpoint-dependent responses in several visual areas\n(e.g., fusiform face area) but viewpoint-invariant responses in the perirhinal\ncortex. There is more evidence for viewpoint-invariant brain responses late\nrather than early in visual processing. Why is that? As Erez et al. (p. 2271)\nargued, “Representations of low-level features are transformed into more\ncomplex and invariant representations as information flows through suc-\ncessive stages of [processing].”\nMost research is limited because object recognition is typically\nassessed in only one context, which may prompt either viewpoint- invariant\nor  viewpoint-dependent recognition performance. Tarr and Hayward\n(2017) argued this approach can misleadingly suggest observers store only\nviewpoint-invariant or viewpoint-dependent information. Accordingly,\nthey used various contexts. Observers originally learned the identities of\nnovel objects that could be discriminated by viewpoint-invariant informa-\ntion. As predicted, they exhibited viewpoint-invariant object recognition\nwhen tested. When the testing context was changed to make it hard to\ncontinue to use that approach, observers shifted to exhibiting viewpoint-\ndependent behaviour.\nThe central conclusion from the above findings is that: “Object rep-\nresentations are neither viewpoint-dependent nor viewpoint-invariant,\nbut rather encode multiple kinds of information . . . deployed in a flex-\nible manner appropriate to context and task” (Tarr & Hayward, 2017,\np.  108). Thus, visual object representations contain richer and more var-\niegated information than typically assumed on the basis of limited testing\nconditions.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n111\nConclusions\nAs Gauthier and Tarr (2016, p. 179) concluded: “Depending on the exper-\nimental conditions and which parts of the brain we look at, one can\nobtain data supporting both the structural-description (i.e., the viewpoint-\ninvariant) and the view-based [viewpoint-dependent] approaches.” There\nhas been progress in identifying factors (e.g., is categorisation or identifi-\ncation required? is the object familiar or unfamiliar?) influencing whether\nobject recognition is viewpoint-invariant or viewpoint-dependent.\nGauthier and Tarr (2016, p. 379) argued researchers should address\nthe following question: “What is the nature of the features that com-\nprise high-level visual representations and lead to image-dependence or\nimage-invariance?” Thus, we should focus more on why object recognition\nis viewpoint-invariant or viewpoint-dependent. As yet, “The exact and\nfine-grained features of object representations are still unknown and are\nnot easily resolved” (Gauthier & Tarr, 2016, p. 379).\nOBJECT RECOGNITION: TOP-DOWN PROCESSES\nHistorically, most theorists (e.g., Marr, 1982; Biederman, 1987) studying\nobject recognition emphasised bottom-up processes. Apparent support can\nbe found in the hierarchical nature of visual processing. As Yardley et al.\n(2012, p. 4) pointed out,\nTraditionally, visual object recognition has been taken as mediated by a\nhierarchical, bottom-up stream that processes an image by  systematically\nanalysing its individual elements and relaying this information to the\nnext areas until the overall form and identity are determined.\nThe above account, assuming a feedforward hierarchy of processing stages\nfrom visual cortex through to inferotemporal cortex, is oversimplified.\nThere are as many backward projecting neurons (associated with top-down\nprocessing) as forward projecting ones throughout most of the visual system\n(Gilbert & Li, 2013). Up to 90% of the synapses from incoming neurons to\nprimary visual cortex (involved in early visual processing) originate in the\ncortex and thus reflect top-down processes. Recurrent processing (a form\nof top-down processing) from higher to lower brain areas is often necessary\nfor conscious visual perception (van Gaal & Lamme, 2012; see Chapter 16).\nTop-down processes should have their greatest impact on object rec-\nognition when bottom-up processes are relatively uninformative (e.g., when\nobservers are presented with degraded or briefly presented stimuli). Support\nfor this prediction is discussed on p. 112.\nFindings\nEvidence for the involvement of top-down processes in visual percep-\ntion was reported by Goolkasian and Woodberry (2010). They presented\nobservers with ambiguous figures immediately preceded by primes relevant\nto one interpretation (see Figure 3.11). The primes systematically biased the\ninterpretation of the ambiguous figures via top-down processes.\nCreated from usyd on 2022-02-13 13:26:14.",
    "112\nVisual perception and attention\nViggiano et al. (2008) obtained strong evidence that top-down pro-\ncesses within the prefrontal cortex influence object recognition. Observers\nviewed blurred or non-blurred photographs of living and non-living objects.\nOn some trials, repetitive transcranial magnetic stimulation (rTMS; see\nGlossary) was applied to the dorsolateral prefrontal cortex to disrupt top-\ndown processing. rTMS slowed object recognition time only with blurred\nphotographs. Thus, top-down processes were directly involved in object\nrecognition when the sensory information available to bottom-up processes\nwas limited.\nControversy\nFirestone and Scholl (2016) argued in a review, “There is . . . no evidence\nfor top-down effects of cognition on visual perception.” They claimed that\ntop-down processes often influence response bias, attention or memory\nrather than perception itself.\nFigure 3.11\nAmbiguous figures\n(e.g., Eskimo/Indian, Liar/\nFace) were preceded by\nprimes (e.g., Winter Scene,\nTomahawk) relevant to\none interpretation of the\nfollowing figure.\nFrom Goolkasian and\nWoodberry (2010). Reprinted\nwith permission from the\nPsychonomic Society 2010.\nYoung boy\nPeacock feathers\nWords on a page\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n113\nIN THE REAL WORLD: SHOOTER BIAS\nShooter bias is shown by “More shooting errors for unarmed black than white suspects” (Cox &\nDevine, 2016, p. 237). Black Americans are more than twice as likely as white Americans to be\nunarmed when killed by the police (Ross, 2015). For example, on 22 November 2014, a police\nofficer in Cleveland, Ohio, shot dead a 12-year-old black male (Tamir Rice) playing with a replica\npistol.\nShooter bias may reflect top-down influences on visual perception. Payne (2006) presented a\nwhite or black face followed by the very brief presentation of a gun or tool. When participants\nmade a rapid response, they indicated falsely they had seen a gun more often when the face was\nblack.\nShooter bias reflects top-down effects based on inaccurate racial stereotypes associating black\nindividuals with threat (e.g., Azevedo et al., 2017). This bias might be due to direct top-down\neffects on perception: objects are more likely to be misperceived as guns if held by black indi-\nviduals. Alternatively, shooter bias may reflect response bias (the expectation someone has a gun\nis greater if that person is black rather than white): there is no effect on perception but shooters\nrequire less perceptual evidence to shoot a black individual.\nAzevedo et al. (2017) found a briefly presented weapon (a gun) was more accurately perceived\nwhen preceded by a black face than a white one. However, the opposite was the case when a tool\nwas presented. These findings were due to response bias rather than perception.\nMoore-Berg et al. (2017) asked non-black participants to decide rapidly whether or not to shoot\nan armed or unarmed white or black person of high or low socio-economic status. There was shooter\nbias: participants were biased towards shooting if the individual was black, of low socio-economic\nstatus, or both. This shooter bias mostly reflected a response bias against shooting a white person\nof high socio-economic status (probably because of a low level of perceived danger).\nFirst, consider ambiguous or reversible figures (e.g., the faces-goblet\nillusion shown in Figure 3.5). Observers alternate between the two possible\ninterpretations (e.g., faces vs goblet). The dominant one at any moment\ndepends on their direction of attention but not necessarily on top-down\nprocesses (Long & Toppino, 2004).\nSecond, Auckland et al. (2007) presented observers briefly with a\ntarget object (e.g., playing cards) surrounded by four context objects. When\nthe context objects were semantically related to the target (e.g., dice; chess\npieces; plastic chips; dominoes), the target was recognised more often than\nwhen they were semantically unrelated. This finding depended in part on\nresponse bias (i.e., guesses based on context) rather than perceptual infor-\nmation about the target. (More evidence of response bias is discussed in\nthe Box).\nFirestone and Scholl’s (2016) article has provoked much controversy.\nLupyan (2016, p. 40) attacked their tendency to attribute apparent top-\ndown effects on perception to attention, memory and so on: “This ‘It’s\nnot perception, it’s just X’ reasoning assumes that attention, memory, and\nso forth be cleanly split from perception proper.” In fact, all these pro-\ncesses interact dynamically and so attention, perception and memory are\nnot clearly separate.\nKEY TERM\nShooter bias\nThe tendency for unarmed\nblack individuals to be\nmore likely than unarmed\nwhite individuals to be\nshot.\nCreated from usyd on 2022-02-13 13:26:14.",
    "114\nVisual perception and attention\nFurther findings\nHowe and Carter (2016) identified two\nperception-like phenomena driven by top-\ndown processes. First, there are visual hallu-\ncinations which are found in schizophrenic\npatients. Hallucinations are experienced as\nactual perceptions even though the relevant\nobject is not present and so they cannot\ndepend on bottom-up processes. Second, there\nis visual imagery (discussed on pp. 130–137).\nVisual imagery involves several processes\ninvolved in visual perception. Like halluci-\nnations, visual imagery occurs in the absence\nof bottom-up processes because the relevant\nobject is absent.\nLupyan (2017) discussed numerous top-\ndown effects on visual perception in studies\navoiding the problems identified by Firestone\nand Scholl (2016). Look at Figure 3.12, which\napparently shows an ordinary brick wall. If\nthat is what you see, have another look. This\ntime see whether you can spot the object\nmentioned at the end of the Conclusions\nsection. Once you have spotted the object, it\nbecomes impossible not to see it afterwards.\nHere we have powerful effects of top-down processing on perception based\non knowledge of what is in the photograph.\nConclusions\nAs Firestone and Scholl (2016) argued, it is hard to demonstrate top-down\nprocesses directly influence perception rather than attention, memory or\nresponse bias. However, many studies have shown such a direct influence.\nAs Yardley et al. (2012, p. 1) pointed out, “Perception relies on existing\nknowledge as much as it does on incoming information.” Note, however,\nthe influence of top-down processes is generally greater when visual stimuli\nare degraded. By the way, the hard-to-spot object in the photograph is a\ncigar!\nTheories emphasising top-down processes\nBar et al. (2006) found greater activation of the orbitofrontal cortex\n(part of the prefrontal cortex) when object recognition was hard than\nwhen it was easy. This activation occurred 50 ms before activation in\nrecognition-related regions of the temporal cortex, and so seemed impor-\ntant for object recognition. In Bar et al.’s model, object recognition\ndepends on  top-down processes involving the orbitofrontal cortex and\nbottom-up processes involving the ventral visual stream (see Figure 3.13;\nand Chapter 2).\nFigure 3.12\nA brick wall that can be seen as something else.\nFrom Plait (2016).\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n115\nTrapp and Bar (2015) developed this\nmodel claiming that visual input rapidly\nelicits various hypotheses concerning what\nhas been presented. Subsequent top-down\nprocesses  associated with the orbitofrontal\ncortex select  relevant hypotheses and sup-\npress irrelevant ones. More specifically, the\norbitofrontal cortex uses contextual infor-\nmation to generate hypotheses and resolve\ncompetition\namong\nhypotheses.\nPalmer\n(1975) showed the  importance of context.\nHe presented a picture of a scene (e.g., a\nkitchen) followed by the very brief presenta-\ntion of the picture of an object. The object\nwas recognised more often when relevant to\nthe context (e.g., a loaf) than when irrelevant\n(e.g., a drum).\nInteractive-iterative framework\nBaruch et al. (2018) argued that previous theo-\nrists had not appreciated the full complexities\nof interactions between bottom-up and top-\ndown processes in object recognition. They\nrectified this situation with their interactive-\niterative framework (see Figure 3.14).\nAccording to this framework, observers\ntypically form hypotheses concerning object\nidentity based on their goals, knowledge and\nthe environmental context. Of importance,\nthese hypotheses are often formed before the\nobject is presented. Observers discriminate\namong competing hypotheses by attend-\ning to a distinguishing feature of the object.\nFor example, if your tentative hypothesis\nwas elephant, you might allocate attention\nto the expected location of its trunk. If that\nfailed to provide the necessary information\nbecause that area was partially hidden (see\nFigure 3.15), you might then attend to other\nfeatures (e.g., size and shape of the leg; skin\ntexture).\nIn sum, Baruch et al. (2018) emphasised\ntwo related top-down processes strongly influ-\nencing object recognition. First, observers\nform hypotheses about the possible identity\nof an object prior to (or in interaction with)\nthe visual input. Second, observers direct\ntheir attention to object parts likely to be\nmaximally informative concerning its identity.\nFigure 3.13\nIn this modified version of Bar et al.’s (2006) theory, it is\nassumed that object recognition involves two different routes:\n(1) a top-down route in which information proceeds rapidly\nto the orbitofrontal cortex, which is involved in generating\npredictions about the object’s identity; (2) a bottom-up route\nusing the slower ventral visual stream.\nFrom Yardley et al. (2012). Reprinted with permission from Springer.\nFigure 3.14\nInteractive-iterative framework for object recognition with\ntop-down processes shown in dark green and bottom-up\nprocesses in brown.\nFrom Baruch et al. (2018). Reprinted with permission of Elsevier.\nPre-existing dynamically\nchanging context\nGoals, knowledge and\ncontext-based expectancies\nHypothesis/es regarding\nobject identity\nyes\nno\nResponse\nGuidance of attention to\ndistinguishing features\nCapture of attention by\nsalient features\nPotential\nconflict\nTop-down\nBottom-up\nVisual\ndata\nextraction\nVisual\ninput\nObject\nidentified?\nCreated from usyd on 2022-02-13 13:26:14.",
    "116\nVisual perception and attention\nFindings\nAccording\nto\nthe\ninteractive-iterative\nframework, expectations can exert top-\ndown influences on processing even before\na visual stimulus is presented. Kok et al.\n(2017) obtained support for this predic-\ntion. Observers expecting a given stimulus\nproduced a neural signal resembling that\ngenerated by the actual presentation of the\nstimulus shortly before it was presented.\nBaruch et al. (2018) tested various pre-\ndictions from their theoretical framework. In\none experiment, participants decided which\nof two types of artificial fish (tass or grout)\nhad been presented. The two fish types dif-\nfered with respect to distinguishing features\nassociated with the tail and the mouth, with\nthe tail being easier to discriminate. As pre-\ndicted, participants generally attended more to the tail than the mouth\nregion from stimulus onset. When much of the tail region was hidden from\nview, participants redirected their attention to the mouth region.\nSummary\nNumerous theorists have argued that object recognition depends on\ntop-down processes as well as bottom-up ones. Baruch et al.’s (2018)\ninteractive-iterative framework extends such ideas by identifying how these\ntwo types of processes interact. Of central importance, top-down processes\ninfluence the allocation of attention, and the allocation of attention influ-\nences subsequent bottom-up processing.\nFACE RECOGNITION\nThere are two main reasons for devoting a section to face recognition.\nFirst, recognising faces is of enormous importance to us, since we gener-\nally identify individuals from their faces. Form a visual image of someone\nimportant in your life – it probably contains detailed information about\ntheir face.\nSecond, face recognition differs importantly from other forms of object\nrecognition. As a result, we need theories specifically devoted to face recog-\nnition rather than simply relying on theories of object recognition.\nFace vs object recognition\nHow does face recognition differ from object recognition? There is more\nholistic processing in face recognition. Holistic processing involves “inte-\ngration across the area of the face, or processing of the relationships\nbetween features as well as, or instead of, the features themselves” (Watson\n& Robbins, 2014, p. 1). Holistic processing is faster because facial features\nFigure 3.15\nRecognising an elephant when a key feature (its trunk) is\npartially hidden.\nFrom Baruch et al. (2018). Reprinted with permission of Elsevier.\nKEY TERM\nHolistic processing\nProcessing that involves\nintegrating information\nfrom an entire object\n(especially faces).\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n117\nare processed in parallel rather than individually. Caharel et al. (2014)\nfound faces can be categorised as familiar or unfamiliar within approxi-\nmately 200 ms. Holistic processing is also more reliable than feature pro-\ncessing because individual facial features (e.g., mouth shape) are subject to\nchange.\nRelevant evidence comes from the face inversion effect: faces are\nmuch harder to identify when presented inverted or upside-down rather\nthan upright (Bruyer, 2011). This effect probably reflects difficulties in\nprocessing inverted faces holistically. There are surprisingly large effects\nof face inversion within the brain – Rosenthal et al. (2017, p. 4823) found\nface inversion “induces a dramatic functional reorganisation across related\nbrain networks”.\nIn contrast, adverse effects of inversion are often much smaller with\nnon-face objects. For example, Klargaard et al. (2018) found there was a\nlarger inversion effect for faces than for cars. However, it can be argued we\npossess expertise in face recognition and so we should consider individuals\npossessing expertise with non-face objects. The findings are mixed. Rossion\nand Curran (2010) found car experts had a much smaller inversion effect\nfor cars than faces. However, those with the greatest expertise showed a\ngreater inversion effect for cars. In contrast, Weiss et al. (2016) found horse\nexperts had no inversion effect for horses.\nMore evidence suggesting faces are special comes from the  part-whole\neffect – it is easier to recognise a face part when presented within a\nwhole face rather than in isolation. Farah (1994) studied this effect using\ndrawings of faces and houses. Participants’ ability to recognise face\nparts was much better when whole faces were presented rather than only\na single feature  (i.e., the part-whole effect). In contrast, recognition per-\nformance for house features was very similar in whole and single-feature\nconditions.\nRichler et al. (2011) explored the hypothesis that faces are processed\nholistically by using composite faces. Composite faces consist of a top half\nand a bottom half that may or may not be from the same face. The task\nwas to decide whether the top halves of two successive composite faces\nwere the same or different. Performance was worse when the bottom halves\nof the two composite faces were different. This composite face effect sug-\ngests people find it hard to ignore the bottom halves and thus that face\nprocessing is holistic.\nFinally, accurate face recognition is so important to humans we might\nexpect to find holistic processing of faces even in young children. As pre-\ndicted, children aged between 3 and 5 show holistic processing (McKone\net al., 2012).\nIn sum, face recognition (even in young children) involves holistic pro-\ncessing. However, it remains unclear whether the processing differences\nbetween faces and other objects occur because faces are special or because\nwe have dramatically more expertise with faces than most other object cat-\negories. Relevant evidence was reported by Ross et al. (2018). When par-\nticipants were presented with car pictures, car experts formed more holistic\nrepresentations within the brain than did car novices. The role played by\nexpertise is discussed further shortly.\nKEY TERM\nFace inversion effect\nThe finding that faces are\nmuch harder to recognise\nwhen presented upside\ndown; the effect of\ninversion is less marked\n(or absent) with other\nobjects.\nPart-whole effect\nThe finding that a face\npart is recognised more\neasily when presented in\nthe context of a whole\nface rather than on its\nown.\nCreated from usyd on 2022-02-13 13:26:14.",
    "118\nVisual perception and attention\nProsopagnosia\nMuch research has involved brain-damaged patients with severely impaired\nface processing. Such patients suffer from prosopagnosia (pros-uh-pag-\nNO-see-uh) coming from the Greek words for “face” and “without knowl-\nedge”. Prosopagnosia is also known as “face blindness”.\nProsopagnosia is a heterogeneous or diverse condition with the precise\nproblems of face and object recognition varying across patients. It can\nbe caused by brain damage (acquired prosopagnosia) or can occur in the\nabsence of any obvious brain damage (developmental prosopagnosia).\nAcquired prosopagnosics differ in terms of their specific face-processing\ndeficits and brain areas involved (discussed later).\nStudying prosopagnosics is of direct relevance to the issue of whether\nface recognition involves specific or specialised processes absent from\nobject recognition. If prosopagnosics invariably have great impairments\nin object recognition, it would suggest face and object recognition involve\nsimilar processes. In contrast, if some prosopagnosics have intact object\nrecognition, it would imply the processes underlying the two forms of rec-\nognition are different.\nFarah (1991) reviewed research on patients with acquired prosop-\nagnosia. All these patients also had more general problems with object\nrecognition. However, some exceptions have been reported. Moscovitch\nKEY TERM\nProsopagnosia\nA condition (also known\nas face blindness) in\nwhich there is a severe\nimpairment in face\nrecognition but much\nless impairment of\nobject recognition; it\nis often the result of\nbrain damage (acquired\nprosopagnosia) but can\nalso be due to impaired\ndevelopment of face-\nrecognition mechanisms\n(developmental\nprosopagnosia).\nIN REAL LIFE: HEATHER SELLERS\nWe can understand the profound problems\nprosopagnosics\nsuffer\nin\neveryday\nlife\nby\nconsidering Heather Sellers (see YouTube: “You\nDon’t Look  Like Anyone I Know”). She is an\nAmerican woman with severe prosopagnosia.\nWhen she was a child, she became separated\nfrom her mother at a grocery store. When reu-\nnited with her mother, she did not initially recog-\nnise her.\nHeather Sellers still has difficulty in recognising\nher own face. Heather: “A few times I have been\nin a crowded elevator with mirrors all found and a\nwoman will move, and I will go to get out the way\nand then realise ‘oh that woman is me’.” Such\nexperiences made her very anxious.\nSurprisingly, Heather Sellers was 36 before she\nrealised she had prosopagnosia. Why was this?\nAs a child, she became very skilled at identifying\npeople by their hair style, body type, clothing,\nvoice and gait. In spite of these skills, she has\noccasionally failed to recognise her own husband! According to Heather Sellers, “Not being able\nto reliably know who people are – it feels terrible like failing all the time.”\nHeather Sellers.\nPatricia Roehling.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n119\net al. (1997) studied CK, a man with object agnosia (impaired object rec-\nognition). He performed comparably to healthy controls on several face-\nrecognition tasks including photos, caricatures and cartoons.\nGeskin and Behrmann (2018) reviewed the literature on patients with\ndevelopmental prosopagnosia. Out of 238 cases, 80% had impaired object\nrecognition but 20% did not. Thus, several patients had impaired face\nrecognition but not object recognition. We would have a double dissocia-\ntion (see Glossary) if we could find individuals with developmental object\nagnosia but intact face recognition. Germine et al. (2011) found a female\n(AW), who had preserved face recognition but impaired object recognition\nfor many categories of objects.\nOverall, far more individuals have impaired face recognition (prosop-\nagnosia) but relatively intact object recognition than have impaired object\nrecognition but intact face recognition. These findings suggest that, “Face\nrecognition is an especially difficult instance of object recognition where\nboth systems [i.e., face and object recognition] rely on a common mecha-\nnism” (Geskin & Behrmann, 2018, p. 18). Face recognition is hard in part\nbecause it involves distinguishing among broadly similar category members\n(e.g., two eyes; nose; mouth). In contrast, object recognition often only\ninvolves identifying the relevant category (e.g., cat; car). According to this\nviewpoint, prosopagnosics would perform poorly if required to make fine-\ngrained perceptual judgments with objects.\nAn alternative interpretation emphasises expertise (Wang et al., 2016).\nNearly everyone has more experience (and expertise) at recognising faces\nthan the great majority of other objects. It is thus possible that brain\ndamage in prosopagnosics affects areas associated with expertise gener-\nally rather than specifically faces (the expertise hypothesis is discussed on\npp. 122–124).\nFindings\nIn spite of their poor conscious or explicit recognition of faces, many\nprosopagnosics show evidence of covert recognition (face processing\nwithout conscious awareness). For example, Eimer et al. (2012) found\ndevelopmental prosopagnosics were much worse than healthy controls at\nexplicit recognition of famous faces (27% vs 82% correct, respectively).\nHowever, famous faces produced brain activity in half the developmen-\ntal prosopagnosics indicating the relevant memory traces were activated\n(covert recognition). These prosopagnosics have very poor explicit recogni-\ntion performance because brain areas containing more detailed information\nabout the famous individuals were not activated.\nBusigny et al. (2010b) compared the first two interpretations discussed\nabove by using object-recognition tasks requiring complex within-category\ndistinctions for several categories: birds, boats, cars, chairs and faces. A\nmale patient (GG) with acquired prosopagnosia was as accurate as con-\ntrols with each non-face category (see Figure 3.16). However, he was sub-\nstantially less accurate than controls with faces (67% vs 94%, respectively).\nThus, GG apparently has a face-specific impairment rather than a general\ninability to recognise complex stimuli.\nCreated from usyd on 2022-02-13 13:26:14.",
    "120\nVisual perception and attention\nBusigny et al. (2010a) reviewed previous findings suggesting many\npatients with acquired prosopagnosia have essentially intact object rec-\nognition. However, this research was limited because the difficulty of the\nrecognition decisions required of the patients was not controlled systemat-\nically. Busigny et al. manipulated the similarity between target items and\ndistractors on an object-recognition task. Increasing similarity had com-\nparable effects on PS (a patient with acquired prosopagnosia) and healthy\ncontrols. In contrast, PS performed very poorly on a face-recognition task\nwhich was very easy for healthy controls.\nWhy is face recognition so poor in prosopagnosics? Busigny et al.\n(2010b) tested the hypothesis that they have great difficulty with holistic\nprocessing. A prosopagnosic patient (GG) did not show the face inversion\nor composite face effects suggesting he does not perceive individual faces\nholistically (an ability enhancing accurate face recognition). In contrast,\nGG’s object recognition was intact perhaps because holistic processing was\nnot required.\nVan Belle et al. (2011) also investigated the deficient holistic process-\ning hypothesis. GG’s face-recognition performance was poor when holistic\nprocessing was possible. However, it was intact when it was not possible to\nuse holistic processing (only one part of a face was visible at a time).\nFinally, we consider the expertise hypothesis. According to this\nhypothesis, faces differ from most other categories of objects in that we\nhave more expertise in identifying faces. As a result, apparent differences\nbetween faces and other objects in processes and brain mechanisms may\nmostly reflect differences in expertise. This hypothesis is discussed further\nbelow on pp. 122–124. Barton and Corrow (2016) reported evidence\nconsistent with this hypothesis in patients with acquired prosopagnosia\nwho had expertise in car recognition and reading prior to their brain\ndamage. These patients had impairments in car recognition and aspects\nof visual word reading suggesting they had problems with objects for\nwhich they had  possessed expertise (i.e., objects of expertise). Contrary\nevidence was reported by Weiss et al. (2016), who studied a patient\n(OH) with  developmental prosopagnosia. In spite of severely impaired\nface-recognition ability, she displayed superior recognition skills for\nhorses (she had spent 15 years working with them). Thus, visual expertise\ncan be acquired independently of the mechanisms responsible for expertise\nin face recognition.\nFigure 3.16\nAccuracy and speed of\nobject recognition for birds,\nboats, cars, chairs and faces\nby patient GG and healthy\ncontrols.\nFrom Busigny et al. (2012b).\nReprinted with permission from\nElsevier.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n121\nIn sum, the finding that many prosopagnosics have face-specific\nimpairments is consistent with the hypothesis that face recognition involves\nspecial processes. However, more general recognition impairments have\nalso often been reported and are apparently inconsistent with that hypoth-\nesis. There is also some support for the expertise hypothesis but again the\nfindings are mixed.\nFusiform face area\nIf faces are processed differently to other objects, we would expect to find\nbrain regions specialised for face processing. The fusiform face area (FFA)\nin the ventral temporal cortex has (as its name strongly implies!) been iden-\ntified as such a brain region.\nThe fusiform face area is indisputably involved in face process-\ning. Downing et al. (2006) found the fusiform face area responded more\nstrongly to faces than any of 18 object categories (e.g., tools; fruits; veg-\netables). However, other brain regions, including the occipital face area\n(OFA) and the superior temporal sulcus (STS) are also face-selective\n(Grill-Spector et al., 2017; see Figure 3.17). Such findings indicate that face\nprocessing depends on one or more brain networks rather than simply on\nthe fusiform face area.\nEven though several brain areas are face-selective, the fusiform\nface area has been regarded as having special importance. For example,\nAxelrod and Yovel (2015) considered brain activity in several face-\nselective  regions  when observers were shown photos of Leonardo\nDiCaprio and Brad Pitt. The fusiform face area was the only region in\nwhich the pattern of brain activity differed significantly between these\nactors. However, Kanwisher et al. (1997) found only 80% of their partic-\nipants had greater activation within the fusiform face area to faces than\nto other objects.\nIn sum, the fusiform face area plays a major role in face processing\nand recognition for most (but probably not all) individuals. However, face\nKEY TERM\nFusiform face area\nAn area that is associated\nwith face processing;\nthe term is somewhat\nmisleading given that the\narea is also associated\nwith processing other\ncategories of objects.\nFigure 3.17\nFace-selective areas in the right hemisphere. OFA = occipital face area; FFA = fusiform\nface area; pSTS-FA and aSTS-FA = posterior and anterior superior temporal sulcus face\nareas; IFG-FA = inferior frontal gyrus face area; ATL-FA = anterior temporal lobe face\narea.\nFrom Duchaine and Yovel (2015).\n(a) Dorsal\n(b) Ventral\nOFA\npSTS-FA\naSTS-FA\nIFG-FA\nOFA\nFFA\nATL-FA\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-13 13:26:14.",
    "122\nVisual perception and attention\nprocessing depends on a brain network, including several areas in addition\nto the fusiform face area (see Figure 3.17). Note also that the fusiform\nface area is activated when we process numerous types of non-face objects.\nFinally, face-processing deficits in prosopagnosics are not limited to the\nfusiform face area. For example, developmental prosopagnosics had less\nselectivity for faces than healthy controls in 12 different face areas (includ-\ning the fusiform face area) (Jiahui et al., 2018).\nExpertise hypothesis\nAccording to advocates of the expertise hypothesis (e.g., Wang et al., 2016;\ndiscussed on p. 119), major differences between face and object processing\nshould not be taken at face value (sorry!). According to this hypothesis,\nthe brain and processing mechanisms allegedly specific to faces are also\ninvolved in processing and recognising all object categories for which we\npossess expertise. Thus, we should perhaps relabel the fusiform face area as\nthe “fusiform expertise area”.\nWhy is expertise so important in determining face and object process-\ning? One reason is that expertise leads to greater holistic or integrated pro-\ncessing. For example, chess experts can very rapidly use holistic processing\nbased on their relevant stored knowledge to understand complex chess\npositions (see Chapter 12).\nThree main predictions follow from the expertise hypothesis:\n(1) Holistic or configural processing is not unique to faces but should be\nfound for any objects of expertise.\n(2) The fusiform face area should be highly activated when observ-\ners  recognise the members of any category for which they possess\nexpertise.\n(3) If the processing of faces and of objects of expertise involves similar\nprocesses, then processing objects of expertise should interfere with\nface processing.\nFindings\nThe first prediction is plausible. Wallis (2013) tested a model of object rec-\nognition to assess the effects of prolonged exposure to any given stimulus\ncategory. The model predicted that many phenomena associated with face\nprocessing (e.g., holistic processing; inversion effect) would be found for\nany stimulus category for which observers had expertise. Repeated simulta-\nneous presentation of the same features (e.g., nose; mouth; eyes) gradually\nincreases holistic processing. Wallis concluded a single model can explain\nobject and face recognition.\nThere is some support for the first prediction in research on detection\nof abnormalities in medical images (see Chapter 12). Kundel et al. (2007)\nfound experts generally fixated on an abnormality in under 1 second sug-\ngesting they used very fast, holistic processes. However, as we saw earlier,\nexperts with non-face objects often have a small inversion effect (assumed\nto reflect holistic processing). McKone et al. (2007) found such experts\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n123\nrarely show the composite effect (also assumed to reflect holistic process-\ning; discussed on p. 117).\nWe turn now to the second prediction. In a review, McKone et  al.\n(2007) found a modest tendency for the fusiform face area to be more\nactivated by objects of expertise than other objects. However, larger acti-\nvation effects for objects of expertise were found outside the  fusiform face\narea  than inside it. Support for the second prediction was reported by\nMcGugin et al. (2014): activation to car stimuli within the   fusiform face\narea was greater in participants having greater car expertise.\nMcGugin et al. (2018) argued that we can test the second prediction\nby comparing individuals varying in face-recognition ability (or exper-\ntise). As predicted, those with high face-recognition ability exhibited more\nface-selective activation within the fusiform face area than those having\nlow ability.\nBilalić (2016) found chess experts had more activation in the fusiform\nface area than non-experts when viewing chess positions but not single\nchess pieces. He concluded, “The more complex the stimuli, the more likely\nit is that the brain will require the help of the FFA in grasping its essence”\n(p. 1356).\nIt is important not to oversimplify the issues here. Even if face process-\ning and processing of other objects of expertise both involve the fusiform\nface area, the two forms of processing may use different neurons in differ-\nent combinations (Grill-Spector et al., 2017).\nWe turn now to the third prediction. McKeeff et al. (2010) found that\ncar experts were slower than novices when searching for face targets among\ncars but not among watches. Car and face expertise may have interfered\nwith each other because they depend on similar processes. Alternatively,\ncar experts may have been more likely than car novices to attend to dis-\ntracting cars because they find such stimuli more interesting.\nMcGugin et al. (2015) also tested the third prediction. Overall, car\nexperts had greater activation than car novices in face-selective areas (e.g.,\nfusiform face area) when processing cars. Of key importance, that differ-\nence was greatly reduced when faces were also presented. Thus, interfer-\nence was created when participants processed objects belonging to two\ndifferent categories of expertise (i.e., cars and faces).\nEvaluation\nThere is some support for the expertise hypothesis with respect to all three\npredictions. However, the extent of that support remains controversial. One\nreason is that it is hard to assess expertise level accurately or to control it. It\nis certainly possible that many (but not all) processing differences between\nfaces and other objects are due to greater expertise with faces. This would\nimply that faces are less special than often assumed.\nAccording to the expertise hypothesis, we are face experts. This may\nbe true of familiar faces, but it is certainly not true of unfamiliar faces\n(Young & Burton, 2018). Evidence of the problems we experience in recog-\nnising unfamiliar faces is contained in the Box on passport control.\nCreated from usyd on 2022-02-13 13:26:14.",
    "124\nVisual perception and attention\nIN REAL LIFE: PASSPORT CONTROL\nLook at the 40 faces displayed below (see Figure 3.18). How many different individuals are shown?\nProvide your answer before reading on.\nIn a study by Jenkins et al. (2011) using a similar stimulus array, participants on average decided\n7.5 different individuals were shown. However, the actual number for the array used by Jenkins et\nal. and the one shown in Figure 3.18 is only two! The two individuals (A and B) are arranged as\nshown below:\nA B A A A B A B A B\nA A A A A B B B A B\nB B B A A A B B A A\nB A B A A B B B B B\nPerhaps we are poor at matching unfamiliar faces because we rarely perform this task in every-\nday life. White et al. (2014) addressed this issue in a study on passport officers averaging 8 years of\nservice. These passport officers indicated on each trial whether a photograph was that of a physi-\ncally present person. Overall, 6% of valid photos were rejected and 14% of fraudulent photos were\nwrongly accepted. Thus, individuals with specialist training and experience are not exempt from\nproblems in matching unfamiliar faces. The main problem is that there is considerable variability in\nhow an individual looks in different photos (discussed further on p. 127).\nFigure 3.18\nAn array of 40 face photographs to be sorted into piles for each of the individuals shown in the photographs.\nFrom Jenkins et al. (2011). Reproduced with permission from the Royal Society.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n125\nIn another experiment, White et al. (2014) compared the performance of passport officers and\nstudents on a matching task with unfamiliar faces. The two groups were comparable with 71%\ncorrect performance on match trials and 89% on non-match trials. Thus, training and experience\nwere irrelevant.\nIn White et al.’s (2014) research, 50% of the photos were invalid (non-matching). This is (hope-\nfully!) a massively higher percentage of invalid photos than typically found at passport control.\nPapesh and Goldinger (2014) compared performance when actual mismatches occurred on 50% or\n10% of trials. In the 50% condition, mismatches were missed on 24% of trials, whereas they were\nmissed on 49% of trials in the 10% condition. Participants had a low expectation of mismatches in\nthe 10% condition and so were very cautious about deciding two photos were of different individ-\nuals (i.e., they had a very cautious response criterion indicating response bias).\nPapesh et al. (2018) replicated the above findings. They attempted to improve performance\nin the condition where mismatches occurred on only 10% of trials by introducing blocks where\nmismatches occurred on 90% of trials. However, this manipulation had little effect because partic-\nipants were reluctant to abandon their very cautious response criterion.\nHow can we provide better security at passport control? Increased practice at matching unfamil-\niar faces is not the answer – White et al. (2014) found performance was unrelated to the number\nof years passport officers had served. A promising approach is to find individuals having an excep-\ntional ability to recognise faces (super-recognisers). Robertson et al. (2016) asked participants to\ndecide whether face pairs depicted the same person. Mean accuracy was 96% for previously iden-\ntified police super-recognisers compared to only 81% for police trainees.\nWhy do some individuals have very superior face-recognition ability? Wilmer et al. (2010)\nfound the face-recognition performance of monozygotic (identical) twins was much closer than that\nof dizygotic (fraternal) twins, indicating face-recognition ability is strongly influenced by genetic\nfactors. Face-recognition ability correlated very modestly with other forms of  recognition  (e.g.,\nabstract art images), suggesting it is very specific. In similar fashion, Turano et  al. (2016) found\ngood and poor face recognisers did not differ with respect to car-recognition ability.\nKEY TERM\nSuper-recognisers\nIndividuals with an\noutstanding ability to\nrecognise faces.\nTheoretical approaches\nBruce and Young’s (1986) model has been the most influential theoretical\napproach to face processing and recognition and so we start with it. It is a\nserial stage model consisting of eight components (see Figure 3.19):\n(1) Structural encoding: this produces various descriptions or representa-\ntions of faces.\n(2) Expression analysis: people’s emotional states are inferred from their\nfacial expression.\n(3) Facial speech analysis: speech perception is assisted by lip reading (see\nChapter 9).\n(4) Direct visual processing: specific facial information is processed\nselectively.\n(5) Face recognition units: these contain structural information about\nknown faces; this structural information emphasises the less change-\nable aspects of the face and is fairly abstract.\n(6) Person identity nodes: these provide information about individuals\n(e.g., occupation; interests).\n(7) Name generation: a person’s name is stored separately.\nInteractive exercise:\nFace recognition\nCreated from usyd on 2022-02-13 13:26:14.",
    "126\nVisual perception and attention\n(8)  Cognitive system: this contains addi-\ntional information (e.g., most actors\nhave attractive faces); it influences which\ncomponents receive attention.\nWhat predictions follow? First, there should\nbe major differences in the processing of\nfamiliar and unfamiliar faces because various\ncomponents (face recognition units; person\nidentity nodes; name generation) are involved\nonly when processing familiar faces. Thus, it is\nmuch easier to recognise familiar faces, espe-\ncially when faces are seen from an unusual\nangle.\nSecond, separate processing routes are\ninvolved in working out facial identity (who\nis it?) and facial expression (what is he/she\nfeeling?). The former processing route (includ-\ning the occipital face area and the fusiform\nface area) focuses on relatively unchanging\naspects of faces, whereas the latter (involving\nthe superior temporal sulcus) deals with more\nchangeable aspects. This separation between\nprocesses responsible for recognising identity\nand expression makes sense – if there were\nno separation, we would have great prob-\nlems recognising familiar faces with unusual\nexpressions (Young, 2018).\nThird, when we see a familiar face, famil-\niarity information from the face recognition\nunit should be accessed first. This is followed\nby information about that person (e.g., occu-\npation) from the person identity node and\nthen that person’s name from the name gen-\neration component. As a result, we can find a\nface familiar while unable to recall anything else about that person, or we\ncan recall personal information about a person while being unable to recall\ntheir name. However, a face should never lead to recall of the person’s\nname in the absence of other information.\nFourth, the model assumes face processing involves several stages.\nThis implies the nature of face-processing impairments in brain-damaged\npatients depends on which stages of processing are impaired. Davies-\nThompson et al. (2014) developed the model to account for three forms of\nface impairment (see Figure 3.20).\nFindings\nAccording to the model, it is easier to recognise familiar faces than unfamil-\niar ones for various reasons. Of special importance, we possess much more\nstructural information about familiar faces. This structural information\nFigure 3.19\nThe model of face recognition put forward by Bruce and\nYoung (1986).\nAdapted from Bruce and Young (1986). Reprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n127\n(associated with face recognition units) relates to relatively unchanging\naspects of faces and gradually accumulates with increasing familiarity with\nany given face.\nHowever, the differences in ease of recognition between familiar and\nunfamiliar faces are greater than envisaged by Bruce and Young (1986).\nJenkins et al. (2011) found 40 face photographs showing only two different\nunfamiliar individuals were thought to show almost four times that number\n(discussed on p. 124). The two individuals were actually two Dutch celebri-\nties almost unknown in Britain. When Jenkins et al. (2011) repeated their\nexperiment with Dutch participants, nearly all performed the task perfectly\nbecause the faces were so familiar.\nWhy is unfamiliar face recognition so difficult? There is  considerable\nwithin-person variability in facial images, which is why different photo-\ngraphs of the same unfamiliar individual often look as if they come from\ndifferent individuals (Young & Burton, 2017, 2018). Jenkins and Burton\n(2011) argued we could improve identification of unfamiliar faces by aver-\naging  across several photographs of the same individual and so greatly\nreducing image variability. Their findings supported this prediction.\nBurton et al. (2016) shed additional light on the complexities of rec-\nognising unfamiliar faces. In essence, how one person’s face varies across\nimages differs from how someone else’s face varies. Thus, the characteris-\ntics that vary or remain constant across images differ from one individual\nto another.\nFigure 3.20\nDamage to regions of the inferior occipito-temporal cortex (including fusiform face area\n(FFA) and occipital face area (OFA)) is associated with apperceptive prosopagnosia\n(blue); damage to anterior inferior temporal cortex (aLT) is associated with associative\nprosopagnosia (red); and damage to the anterior temporal pole is associated with\nperson-specific amnesia (green). Davies-Thompson et al. (2014) discuss evidence\nconsistent with their model.\nFrom Davies-Thompson et al. (2014).\nEarly perceptual encoding\nPerceptual\nencoding of\ndynamic\nstructure\nFacial\nmemories\nExpression\nanalysis\nBiographic\ninformation\nVoice & gait\nanalysis\nSemantic data\nName input\nDamage results in:\nApperceptive prosopagnosia\nAssociative prosopagnosia\nPerson-specific amnesia\nPerceptual\nencoding of\nstatic\nstructure\nPole\nFFA\nOFA\naLT\nCreated from usyd on 2022-02-13 13:26:14.",
    "128\nVisual perception and attention\nThe second prediction is that different routes are involved in the pro-\ncessing of facial identity and facial expression. There is some support\nfor this prediction. Fox et al. (2011) found patients with damage to the\nface-recognition network had impaired identity perception but not expres-\nsion perception. In contrast, a patient with damage to the superior tem-\nporal sulcus had impaired expression perception but reasonably intact\nidentity perception. Sliwinska and Pitcher (2018) confirmed the role played\nby the superior temporal sulcus. Transcranial magnetic stimulation (TMS;\nsee Glossary) applied to this area impaired recognition of facial expression.\nHowever, the two routes are not entirely independent. Judgements of\nfacial expression are strongly influenced by irrelevant identity information\n(Schweinberger & Soukup, 1998). Redfern and Benton (2017) asked partic-\nipants to sort cards of faces into piles, one for each perceived identity. One\npack contained expressive faces and the other neutral faces. With expres-\nsive faces, faces belonging to different individuals were more likely to be\nplaced in the same pile. Thus, expressive facial information can influence\n(and impair) identity perception.\nFitousi and Wenger (2013) asked participants to respond positively to\na face that had a given identity and emotion (e.g., a happy face belonging\nto Kiera Knightley). Facial identity and facial expression were not pro-\ncessed independently although they should have been according to the\nmodel.\nAnother issue is that the facial expression route is more complex than\nassumed theoretically. For example, damage to the amygdala produces\ngreater deficits in recognising fear and anger than other emotions (Calder\n& Young, 2005). Young and Bruce (2011) admitted they had not expected\ndeficits in emotion recognition in faces to vary across emotions.\nThe third prediction is that we always retrieve personal information\n(e.g., occupation) about a person before recalling their name. Young et al.\n(1985) asked people to record problems they experienced in face recogni-\ntion. There were 1,008 such incidents but people never reported putting\na name to a face while knowing nothing else about that person. In con-\ntrast, there were 190 occasions on which someone remembered a reason-\nable amount of information about a person but not their name (also as\npredicted by the model).\nSeveral other findings support the third prediction (Hanley, 2011).\nHowever, the notion that names are always recalled after personal infor-\nmation is too rigid. Calderwood and Burton (2006) asked fans of the\ntelevision series Friends to recall the name or occupation of the main char-\nacters when shown their faces. Names were recalled faster than occupa-\ntions (against the model’s prediction).\nFourth, we relate face-processing impairments to Bruce and Young’s\n(1986) serial stage model. We consider three such impairments (discussed by\nDavies-Thompson et al., 2014; see Figure 3.20) with reference to Figure 3.19:\n(1) Patients with impaired early stages of face processing: such patients\n(categorised as having apperceptive prosopagnosia) have “an inability\nto form a sufficiently accurate representation of the face’s structure\nfrom visual data” (Davies-Thompson et al., 2014, p. 161). As a result,\nfaces are often not recognised as familiar.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n129\n(2) Patients with impaired ability to access facial memories in face rec-\nognition units although early processing of facial structure is relatively\nintact: such patients have associative prosopagnosia: they have greater\nproblems with memory than perception.\n(3) Patients with impaired access to biographical information stored in\nperson identity nodes: such patients have person-specific amnesia and\ndiffer from those with associative prosopagnosia because they often\ncannot recognise other people by any cues (including spoken names\nor voices).\nSo far we have applied Bruce and Young’s (1986) model to acquired prosop-\nagnosia. However, we can also apply the model to developmental prosop-\nagnosia (in which face-recognition mechanisms fail to develop normally).\nParketny et al. (2015) presented previously unfamiliar faces to develop-\nmental prosopagnosics and recorded event-related potentials (ERPs) while\nthey performed an easy face-recognition task. They focused on three ERP\ncomponents:\n(1) N170: this early component (about 170 ms) reflects processes involved\nin perceptual structural face processing.\n(2) N250: this component (about 250 ms) reflects a match between a pre-\nsented face and a stored face representation.\n(3) P600: this component (about 600 ms) reflects attentional processes\nassociated with face recognition.\nWhat did Parketny et al. (2015) find? Recognition times were 150 ms slower\nin the developmental prosopagnosics than healthy controls. N170 was\nbroadly similar in both groups with respect to timing and magnitude. N250\nwas 40 ms slower in the prosopagnosics than controls but of comparable\nmagnitude. Finally, P600 was significantly smaller in the prosopagnosics\nthan controls and was delayed by 80 ms. In sum, developmental prosop-\nagnosics show relatively intact early face processing but are slower and less\nefficient later in processing. ERPs provide an effective way of identifying\nthose aspects of face processing adversely affected in prosopagnosia.\nEvaluation\nBruce and Young (1986) provided a comprehensive framework emphasis-\ning the wide range of information that can be extracted from faces. It was\nremarkably innovative in identifying the major processes and structures\ninvolved in face processing and recognition and incorporating them within a\nplausible serial stage approach. Finally, the model enhanced our understand-\ning of why familiar faces are much easier to recognise than unfamiliar ones.\nWhat are the model’s limitations? First, the complexities involved in\nrecognising unfamiliar faces (e.g., coping with the great variability in a\ngiven individual’s facial images) were not fully acknowledged. As Young\nand Burton (2017, p. 213) pointed out, it was several years after 1986\nbefore researchers appreciated that “humans’ relatively poor performance\nat  unfamiliar-face recognition is as much a problem of perception as of\nmemory”.\nCase study:\nModel of face processing\nCreated from usyd on 2022-02-13 13:26:14.",
    "130\nVisual perception and attention\nSecond, the model’s account of the processing of facial expression\nis oversimplified. For example, the processing of facial expression is less\nindependent of the processing of facial identity than assumed theoretically.\nAccording to the model, damage to the expression analysis component\nshould produce impaired ability to recognise all facial expressions. In fact,\nmany brain-damaged patients have much greater impairment in facial rec-\nognition of some emotions than others (Young, 2018).\nThird, the model was somewhat vague about the precise information\nstored in the face recognition units and the person identity nodes. Fourth,\nit was wrong to exclude gaze perception from the model because it pro-\nvides useful information about what an observer is attending to (Young &\nBruce, 2011). Fifth, Bruce and Young (1986) focused on general factors\ninfluencing face recognition. However, as discussed earlier, there are sub-\nstantial individual differences in face-recognition ability with a few indi-\nviduals (super-recognisers) having outstanding ability. These individual\ndifferences depend mostly on genetic factors (Wilmer, 2017) not considered\nwithin the model.\nVISUAL IMAGERY\nClose your eyes and imagine the face of someone you know very well.\nWhat did you experience? Many people claim forming visual images is like\n“seeing with the mind’s eye”, suggesting there are important similarities\nbetween imagery and perception. Mental imagery is typically regarded as\ninvolving conscious experience. However, we could also regard imagery as\na form of mental representation (an internal cognitive symbol representing\naspects of external reality) (e.g., Pylyshyn, 2002). We would not necessarily\nbe consciously aware of images as mental representations.\nGalton (1883) supported the above viewpoint. He found many indi-\nviduals reported no conscious imagery when imagining a definite object\n(e.g., their breakfast table). Zeman et al. (2015) studied several individu-\nals lacking visual imagery and coined the term aphantasia to refer to this\ncondition.\nIf visual imagery and perception are similar, why do we very rarely\nconfuse them? One reason is that we are generally aware of deliberately\nconstructing images (unlike with visual perception). Another reason is\nthat images contain much less detail. For example, people rate their visual\nimages of faces as similar to photographs lacking sharp edges and borders\n(Harvey, 1986).\nHowever, many people sometimes confuse visual imagery and\nperception. Consider hallucinations in which perception-like experiences\noccur in the absence of the appropriate environmental stimulus. Visual\nhallucinations occur in approximately 27% of schizophrenic patients\nbut also in 7% of the general population. Waters et al. (2014) discussed\nresearch showing visual hallucinations in schizophrenics are often associ-\nated with activity in the primary visual cortex, suggesting hallucinations\ninvolve many processes associated with visual perception. One reason\nschizophrenics are susceptible to visual hallucinations is because of dis-\ntortions in top-down processing (e.g., forming strong expectations of what\nthey will see).\nKEY TERMS\nAphantasia\nThe inability to form\nmental images of objects\nwhen those objects are\nnot present.\nHallucinations\nPerceptual experiences\nthat appear real even\nthough the individuals or\nobjects perceived are not\npresent.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n131\nIn Anton’s syndrome (“blindness denial”), blind people are unaware\nthat they are blind and sometimes confuse imagery for actual perception.\nGoldenberg et al. (1995) described a patient whose primary visual cortex\nhad been nearly wholly destroyed. Nevertheless, she generated such vivid\nvisual images that she mistook them for genuine visual perception. The\nbrain damage in patients with Anton’s syndrome typically includes large\nparts of the visual cortex (Gandhi et al., 2016).\nThere is also Charles Bonnet syndrome, defined as “consistent or\nperiodic complex visual hallucinations that occur in visually impaired\nindividuals” (Yacoub & Ferrucci, 2011, p. 421). However, patients are\ngenerally aware the hallucinations are not real and so they are actually\npseudo-hallucinations. When patients hallucinate, they have increased\nactivity in brain areas specialised for visual processing (e.g., hallucinations\nin colour are associated with activity in colour-processing areas) (ffytche\net al., 1998).\nPainter et al. (2018) identified a major reason for this elevated activity.\nStimuli presented to intact regions of the retina cause extreme excitability\n(hyperexcitability) within early visual cortex. Visually impaired individuals\nwith hallucinations show greater hyperexcitability than those without.\nWhy is visual imagery useful?\nWhat functions are served by visual imagery? According to Moulton and\nKosslyn (2009, p. 1274), visual imagery “allows us to answer ‘what if’ ques-\ntions by making explicit and accessible the likely consequences of being in\na specific situation or performing a specific action”. For example, profes-\nsional golfers use mental imagery to predict what would happen if they hit\na certain shot.\nPearson and Kosslyn (2015) pointed out that many visual images\ncontain rich information that is accessible when required. For example,\nwhat is the shape of a cat’s ears? You may be able to answer the question\nby constructing a visual image.\nMore generally, visual imagery supports numerous cognitive functions.\nThese include creative insight, attentional search, guiding deliberate action,\nshort-term memory storage and long-term memory retrieval (Mitchell &\nCusack, 2016).\nImagery theories\nKosslyn (e.g., 1994; Pearson & Kosslyn, 2015) proposed an influential\ntheory based on the assumption that visual imagery resembles visual per-\nception. It was originally called perceptual anticipation theory because\nimage generation involves processes used to anticipate perceiving visual\nstimuli.\nAccording to the theory, visual images are depictive representations.\nWhat is a depictive representation? In such a depiction, “each part of the\nrepresentation corresponds to a part of the represented object such that the\ndistances among the parts in the representation correspond to the actual\ndistances among the parts” (Pearson & Kosslyn, 2015, p. 10089). Thus,\nfor example, a visual image of a desk with a computer on top and a cat\nKEY TERMS\nAnton’s syndrome\nA condition found in some\nblind people in which\nthey misinterpret their\nvisual imagery as visual\nperception.\nCharles Bonnet\nsyndrome\nA condition in which\nindividuals with eye\ndisease form vivid\nand detailed visual\nhallucinations sometimes\nmistaken for visual\nperception.\nDepictive representation\nA representation (e.g.,\nvisual image) resembling\na picture in that objects\nwithin it are organised\nspatially.\nResearch activity:\nMental imagery\nInteractive exercise:\nKosslyn – mental imagery\nCreated from usyd on 2022-02-13 13:26:14.",
    "132\nVisual perception and attention\nsleeping underneath would have the computer\nat the top and the cat at the bottom.\nWhere\nare\ndepictive\nrepresentations\nformed? Kosslyn argued they are created\nin early visual cortex (BA17 and BA18; see\nFigure 3.21) within a visual buffer. The visual\nbuffer is a short-term store for visual infor-\nmation only and is of major importance in\nvisual perception and imagery. There is also\nan “attention window” selecting some visual\ninformation in the visual buffer and passing\nit on to other brain areas for further process-\ning. This attention window is flexible – it can\nbe adjusted to include more, or less, visual\ninformation.\nProcessing in the visual buffer depends\nprimarily on external stimulation during per-\nception. However, such processing involves\nnon-pictorial information stored in long-term\nmemory during imagery. Shape information\nis stored in the inferior temporal lobe whereas spatial representations are\nstored in posterior parietal cortex (see Figure 3.21). In sum, visual percep-\ntion mostly involves bottom-up processing whereas visual imagery depends\non top-down processing.\nPylyshyn (e.g., 2002) argued visual imagery differs substantially from\nvisual perception. According to his propositional theory, performance on\nmental imagery tasks does not involve depictive or pictorial representa-\ntions. Instead, it involves tacit knowledge (knowledge inaccessible to con-\nscious awareness). Tacit knowledge is “Knowledge of what things would\nlook like to subjects in situations like the ones in which they are to imagine\nthemselves” (Pylyshyn, 2002, p. 161). Thus, performance on an imagery\ntask relies on relevant stored knowledge rather than visual images. Within\nthis theoretical framework, it is improbable that early visual cortex would\nbe involved on an imagery task.\nImagery resembles perception\nIf visual perception and imagery involve similar processes, they should\ninfluence each other. There should be facilitation if the contents of percep-\ntion and imagery are the same but interference if they differ. Pearson et al.\n(2008) reported a facilitation effect with binocular rivalry – when a different\nstimulus is presented to each eye, only one is consciously perceived at any\ngiven moment. The act of imagining a specific pattern strongly influenced\nwhich stimulus was subsequently perceived and this facilitation depended\non the similarity between the imagined and presented stimuli. The findings\nwere remarkably similar when the initial stimulus was perceived rather than\nimagined.\nBaddeley and Andrade (2000) reported an interference effect.\nParticipants rated the vividness of visual and auditory images while per-\nforming a second task involving visual/spatial processes. This task reduced\nKEY TERMS\nVisual buffer\nWithin Kosslyn’s theory, a\nshort-term visual memory\nstore involved in visual\nimagery and perception.\nBinocular rivalry\nWhen two different visual\nstimuli are presented one\nto each eye, only one\nstimulus is seen; the seen\nstimulus alternates over\ntime.\nFigure 3.21\nThe approximate locations of the visual buffer in BA17\nand BA18, of long-term memories of shapes in the inferior\ntemporal lobe, and of spatial representations in the posterior\nparietal cortex, according to Kosslyn and Thompson’s (2003)\nanticipation theory.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n133\nthe vividness of visual imagery more than that of auditory imagery because\nsimilar processes were involved on the visual/spatial and visual imagery\ntasks.\nLaeng et al. (2014) asked participants to view pictures of animals and\nto follow each one by forming a visual image of that animal. There was\na striking similarity in eye fixations devoted to the various areas of each\npicture in both conditions (see Fig. 3.22). Participants having the greatest\nsimilarity in dwell time between perception and imagery showed the best\nmemory for the size of each animal.\nAccording to Kosslyn’s theoretical position, much processing associ-\nated with visual imagery occurs in early visual cortex (BA17 and BA18)\nplus several other areas. In a review, Kosslyn and Thompson (2003) found\n50% of studies using visual-imagery tasks reported activation in early\nvisual cortex. Significant findings were most likely when the task involved\ninspecting the fine details of images or focusing on an object’s shape. In a\nmeta-analysis (see Glossary), Winlove et al. (2018) found the early visual\ncortex (V1) was typically activated during visual imagery. Consistent with\nKosslyn’s theory, activation in the early visual cortex is greater among\nindividuals reporting vivid visual imagery.\nThe neuroimaging evidence discussed above is limited – it is correla-\ntional and so the activation associated with visual imagery may not be\ndirectly relevant to the images that are formed. Naselaris et al. (2015)\nreported more convincing evidence. Participants formed images of five art-\nworks. It was possible to some extent to identify the imagined artworks\nfrom hundreds of other artworks through careful analysis of activity in the\nearly visual cortex. Some of this activity corresponded to the processing of\nlow-level visual features (e.g., space; orientation).\nFigure 3.22\nDwell time for the four\nquadrants of a picture\nduring perception and\nimagery.\nFrom Laeng et al. (2014).\nReprinted with permission of\nElsevier.\nTOP RIGHT\nDwell time\nPerception = 77%\nImagery = 64%\nBOTTOM RIGHT\nDwell time\nPerception = 10%\nImagery = 12%\nBOTTOM LEFT\nDwell time\nPerception = 1%\nImagery = 4%\nWhite space\nDwell time\nPerception = 2%\nImagery = 5%\nTOP LEFT\nDwell time\nPerception = 4%\nImagery = 8%\nCreated from usyd on 2022-02-13 13:26:14.",
    "134\nVisual perception and attention\nFurther neuroimaging support for the notion that imagery closely\nresembles perception was reported by Dijkstra et al. (2017a). They found\n“the overlap in neural representations between imagery and perception . . .\nextends beyond the visual cortex to include also parietal and premotor/\nfrontal areas” (p. 1372). Of most importance, the greater the neural overlap\nbetween imagery and perception throughout the entire visual system, the\nmore vivid was the imagery experience.\nImagery does not resemble perception\nLook at Figure 3.23. Start with the object on the left and form a clear image\nof it. Then close your eyes, mentally rotate the image by 90o clockwise\nand decide what you see. Then repeat the exercise with the other objects.\nFinally, rotate the book through 90o. You probably found it very easy to\nidentify the objects when perceiving them but impossible when only imagin-\ning rotating them. Slezak (1991, 1995) used stimuli closely resembling those\nin Figure 3.23 and found no observers reported seeing the objects. Thus,\nthe information within images is much less detailed and flexible than visual\ninformation.\nLee et al. (2012) identified important differences between imagery\nand perception. Observers viewed or imagined common objects (e.g., car;\numbrella) while activity in the early visual cortex and areas associated with\nlater visual processing (object-selective regions) was assessed. Attempts\nwere made by the researchers to identify the objects being imagined or\nperceived on the basis of activation in those areas.\nWhat did Lee et al. (2012) find? First, activation in all brain areas\nwas  considerably greater when participants perceived rather than\nimagined  objects. Second, objects being perceived or imagined were\nidentified with above-chance accuracy based on patterns of brain acti-\nvation except for imagined objects in the primary visual cortex (V1; see\nFigure 3.24).\nThird, the success rate in identifying per-\nceived objects was greater based on brain acti-\nvation in areas associated with early visual\nprocessing than those associated with later\nprocessing. However, the opposite was the case\nwith imagined objects (see Figure 3.24). Thus,\nobject processing in the early visual cortex is\nvery limited during imagery but is extremely\nimportant during perception. Imagery for\nobjects depends mostly on top-down pro-\ncesses based on object knowledge rather than\nprocessing in the early visual cortex.\nMost cognitive neuroscience research has\nfocused on the brain areas activated during\nvisual perception and imagery. It is also\nimportant to focus on connectivity between\nbrain areas. Dijkstra et al. (2017b) considered\nconnectivity among four brain areas of central\nimportance in perception and imagery: early\nFigure 3.23\nSlezak (1991, 1995) asked participants to memorise one of\nthe above images. They then imagined rotating the image 90\ndegrees clockwise and reported what they saw. None of them\nreported seeing the figures that can be seen clearly if you\nrotate the page by 90 degrees clockwise.\nLeft image from Slezak (1995), centre image from Slezak (1991), right\nimage reprinted from Pylyshyn (2002), with permission from Elsevier\nand the author.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n135\nvisual cortex (OCC), fusiform gyrus (FG; late visual cortex), IPS (intra-\nparietal sulcus) and IFG (inferior frontal gyrus). The first two are mostly\nassociated with bottom-up processing whereas the second two are mostly\nassociated with top-down processing.\nDijkstra et al.’s (2017b) key findings are shown in Figure 3.25. First,\nperception was associated with reasonably strong bottom-up brain connec-\ntivity and weak top-down brain connectivity. Second, imagery was associ-\nated with non-significant bottom-up connectivity but very strong top-down\nconnectivity. Thus, top-down connectivity from frontal to early visual areas\nFigure 3.24\nThe extent to which\nperceived (left side of\nfigure) or imagined (right\nside of figure) objects could\nbe classified accurately on\nthe basis of brain activity\nin the early visual cortex\nand object-selective cortex.\nES =extrastriate retinotopic\ncortex; LO = lateral\noccipital cortex; pFs =\nposterior fusiform sulcus.\nFrom S.H. Lee et al. (2012).\nReproduced with permission\nfrom Elsevier.\n##\n##\n##\n##\n0\nV1\nES\nRetinotopic\nClassifcation performance (%)\nLO\npFs\nObject-\nselective\n20\n40\n60\n**\n**\n**\n**\n0\nV1\nES\nRetinotopic\nClassifcation performance (%)\nLO\npFs\nObject-\nselective\n10\nChance\n20\n*\n**\n**\n(a)\n(b)\nIPS\nBottom-up\nFG\nIFG\nOCC\n–0.5\n0\n0\n1\n2\n3\n4\n5\n6\n7\n0.5\nPosterior estimate\nProbability density\n1\n1.5\n2\nPerception\nImagery\nTop-down\nIPS\nFG\nIFG\nOCC\n–0.5\n0\n0\n1\n2\n3\n4\n5\n6\n0.5\nPosterior estimate\nProbability density\n1\n1.5\n2\nFigure 3.25\nConnectivity during\nperception and imagery\ninvolving (a) bottom-up\nprocessing; and (b)\ntop-down processing.\nPosterior estimates indicate\nconnectivity strength (the\nfurther from 0 the stronger).\nThe meanings of OCC, FG,\nIPS and IFG are given in\nthe text.\nFrom Dijkstra et al. (2017b).\nCreated from usyd on 2022-02-13 13:26:14.",
    "136\nVisual perception and attention\nis a common mechanism during perception and imagery. However, there\nis much stronger top-down connectivity during imagery to compensate for\nthe absence of bottom-up connectivity. Individuals having the greatest top-\ndown connectivity during imagery reported the most vivid images.\nDijkstra et al. (2018) studied the time course for the development\nof visual representations in perception and in imagery using magneto-\nencephalography (MEG; see Glossary). With perception, they confirmed\nthat visual representations develop through a series of processing stages\n(see Chapter 2). With imagery, in contrast, the entire visual representation\nappeared to be activated simultaneously, presumably because all the rele-\nvant information was retrieved together from memory.\nBrain damage\nIf visual perception and visual imagery involve the same mechanisms, we\nmight expect brain damage to have comparable effects on perception and\nimagery. That is often the case. However, there are numerous exceptions\n(Bartolomeo, 2002, 2008). Moro et al. (2008) studied two brain-damaged\npatients with intact visual perception but impaired visual imagery. They\nwere both very poor at drawing objects from memory but could copy the\nsame objects when shown a drawing.\nThese patients (and others with impaired visual imagery but intact\nvisual perception) have damage to the left temporal lobe. Visual images are\nprobably generated from information about concepts (including objects)\nstored in the temporal lobes (Patterson et al., 2007). However, this genera-\ntion process is less important for visual perception.\nBridge et al. (2012) studied a young man, SBR, who had virtually no\nprimary visual cortex and nearly total blindness. However, he had vivid\nvisual imagery and his pattern of cortical activation when engaged in\nvisual imagery resembled that of healthy controls. Similar findings were\nreported with a 70-year-old woman, SH, who became blind at the age of\n27. She had intact visual imagery predominantly involving areas outside\nthe early visual cortex. Of relevance, she had greater connectivity between\nsome visual networks in the brain than most individuals.\nHow can we interpret the above findings? Visual perception mostly\ninvolves bottom-up processes triggered by the stimulus whereas visual\nimagery primarily involves top-down processes based on object knowledge.\nThus, it is unsurprising brain areas involved in early visual processing are\nmore important for perception than imagery whereas brain areas associ-\nated with storage of information about visual objects are more important\nfor imagery.\nEvaluation\nMuch progress has been made in understanding the relationship between\nvisual imagery and visual perception. Similar processes are involved in\nimagery and perception and they are both associated with somewhat\nsimilar patterns of brain activity. In addition, the predicted facilitatory and\ninterfering effects between imagery and perception tasks have been reported.\nThese findings are more consistent with Kosslyn’s theory than Pylyshyn’s.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n137\nOn the negative side, visual perception and visual imagery are less\nsimilar than assumed by Kosslyn. For example, there is the neuroimag-\ning evidence reported by Lee et al. (2012) and the frequent dissociations\nbetween perception and imagery found in brain-damaged patients. Of most\nimportance, visual perception involves strong bottom-up connectivity and\nweak top-down connectivity, whereas visual imagery involves very strong\ntop-down connectivity but negligible bottom-up connectivity (Dijkstra\net al., 2017b).\nCHAPTER SUMMARY\n•\nPattern recognition. Pattern recognition involves processing\nof specific features and global processing. Feature processing\ngenerally (but not always) precedes global processing. Several types\nof cells (e.g., simple cells; complex cells; end-stopped cells) are\ninvolved in feature processing. There are complexities in pattern\nrecognition due to interactions among cells and the  influence\nof top-down processes. Evidence from computer  programs to\nsolve CAPTCHAs suggests humans are very good at processing\nedge corners. Fingerprint identification is sometimes very\naccurate; however, even experts show confirmation bias (distorted\nperformance caused by contextual information). Fingerprint experts\nare much better than novices at discriminating between matches\nand non-matches and also adopt a more conservative response bias.\n•\nPerceptual organisation. The gestaltists proposed several\nprinciples of perceptual grouping and emphasised the importance\nof figure-ground segmentation. They argued that perceptual\ngrouping and figure-ground segregation depend on innate factors.\nThey also argued we perceive the simplest possible organisation\nof the visual field. The gestaltists provided descriptions rather\nthan explanations. Their approach underestimated the complex\ninteractions of factors underlying perceptual organisation. The\ngestaltists de-emphasised the role of experience and learning\nin perceptual organisation. However, recent theories based on\nBayesian inference (e.g., the Bayesian hierarchical grouping model)\nhave emphasised learning processes and fully acknowledge the\nimportance of learning.\n•\nApproaches to object recognition. Visual processing typically\ninvolves a coarse-to-fine processing sequence: low spatial frequen-\ncies in visual input (associated with coarse processing) are conveyed\nto higher visual areas faster than high spatial frequencies (associ-\nated with fine processing). Biederman assumed in his recognition-\nby-components theory that objects consist of geons (basic shapes).\nAn object’s geons are determined by edge-extraction processes\nand the resultant geon-based description is viewpoint-invariant.\nBiederman’s theory de-emphasises the role of top-down processes.\nCreated from usyd on 2022-02-13 13:26:14.",
    "138\nVisual perception and attention\nObject recognition is sometimes viewpoint-invariant (as\npredicted by Biederman) with easy categorical discriminations, but\nit is more typically viewer-centred when identification is required.\nObject representations often contain viewpoint-dependent and\nviewpoint-invariant information.\n•\nObject recognition: top-down processes. Top-down\nprocesses are more important in object recognition when\nobservers view degraded or briefly presented stimuli. Top-\ndown processes sometimes influence attention, memory or\nresponse bias rather than perception itself. However, there are\nalso direct effects of top-down processes on object recognition.\nAccording to the interactive-iterative framework (Baruch et al.,\n2018), top-down and bottom-up processes interact with top-down\nprocesses (e.g., attention) influencing subsequent bottom-up\nprocessing.\n•\nFace recognition. Face recognition involves more holistic\nprocessing than object recognition. Deficient holistic processing\npartly explains why prosopagnosic patients have much greater\nproblems with face recognition than object recognition. Face\nprocessing involves a brain network including the fusiform face and\noccipital face areas. However, much of this network is also used in\nprocessing other objects (especially when recognising objects for\nwhich we have expertise).\nBruce and Young’s model assumes several serial processing\nstages. Research on prosopagnosics supports this assumption\nbecause the precise nature of their face-recognition impairments\ndepends on which stage(s) are most affected. The model also\nassumes there are major differences in the processing of familiar\nand unfamiliar faces. This assumption has received substantial\nsupport. However, Bruce and Young did not fully appreciate\nthat unfamiliar faces are hard to recognise because of the\ngreat variability of any given individual’s facial images. The\nmodel assumes there are two independent processing routes\n(for facial expression and facial identity), but they are not entirely\nindependent. The model ignores the role played by genetic\nfactors in accounting for individual differences in face-recognition\nability.\n•\nVisual imagery. Visual imagery allows us to predict the visual\nconsequences of performing certain actions. According to\nKosslyn’s perceptual anticipation theory, visual imagery closely\nresembles visual perception. In contrast, Pylyshyn, in his\npropositional theory, argued visual imagery involves making use\nof tacit knowledge and does not resemble visual perception.\nVisual imagery and perception influence each other as predicted\nby Kosslyn’s theory. Neuroimaging studies and studies on brain-\ndamaged patients indicate similar areas are involved in imagery\nCreated from usyd on 2022-02-13 13:26:14.",
    "Object and face recognition\n139\nand perception. However, areas involved in top-down processing\n(e.g., left temporal lobe) are more important in imagery than\nperception, and areas involved in bottom-up processing (e.g., early\nvisual cortex) are more important in perception. More generally,\nbottom-up brain connectivity is far more important in perception\nthan imagery, whereas top-down brain connectivity is far more\nimportant in imagery than perception.\nFURTHER READING\nBaruch, O., Kimchi, R. & Goldsmith, M. (2018). Attention to distinguishing fea-\ntures in object recognition: An interactive-iterative framework. Cognition, 170,\n228–244. Orit Baruch and colleagues provide a theoretical framework for under-\nstanding how bottom-up and top-down processes interact in object recognition.\nDijkstra, N., Zeidman, P., Ondobaka, S., van Gerven, M.A.J. & Friston, K.\n(2017b). Distinct top-down and bottom-up brain connectivity during visual per-\nception and imagery. Scientific Reports, 7 (Article 5677). In this article, Nadine\nDijkstra and her colleagues clarify the roles of top-down and bottom-up pro-\ncesses in visual perception and imagery.\nFirestone, C. & Scholl, B.J. (2016). Cognition does not affect perception: Evaluating\nthe evidence for “top-down” effects. Behavioral and Brain Sciences, 39, 1–77. The\nauthors argue that top-down processes do not directly influence visual percep-\ntion. Read the open peer commentary following the article, however, and you\nwill see most experts disagree.\nGauthier, I. & Tarr, M.J. (2016). Visual object recognition: Do we (finally) know\nmore now than we did? Annual Review of Vision Science, 2, 377–396. Isabel\nGauthier and Michael Tarr provide a comprehensive overview of theory and\nresearch on object recognition.\nGrill-Spector, K., Weiner, K.S., Kay, K. & Gomez, J. (2017). The functional\nneuroanatomy of human face perception. Annual Review of Vision Science, 3,\n167–196. This article by Kalanit Grill-Sector and colleagues contains a compre-\nhensive account of brain mechanisms underlying face perception.\nWagemans, J. (2018). Perceptual organisation. In J.T. Serences (ed.), Stevens’\nHandbook of Experimental Psychology and Cognitive Neuroscience, Vol. 2:\nSensation, Perception, and Attention (4th edn; pp. 803–822). New York: Wiley.\nJohan Wagemans reviews various theoretical and empirical approaches to under-\nstanding perceptual organisation.\nYoung, A.W. (2018). Faces, people and the brain: The 45th Sir Frederic Bartlett\nlecture. Quarterly Journal of Experimental Psychology, 71, 569–594. Andy Young\nprovides a very interesting account of theory and research on face perception.\nCreated from usyd on 2022-02-13 13:26:14.",
    "Motion perception\nand action\nINTRODUCTION\nMost research on perception discussed in previous chapters involved pre-\nsenting a visual stimulus and assessing aspects of its meaning. What was\nmissing (but is an overarching theme of this chapter) is the time dimension.\nIn the real world, we move around and/or people or objects in the environ-\nment move. The resulting changes in the visual information available to us\nare very useful in ensuring we perceive the environment accurately and also\nrespond appropriately. This emphasis on change and movement necessarily\nleads to a consideration of the relationship between perception and action.\nIn sum, our focus in this chapter is on how we process (and respond to) a\nconstantly changing environment.\nThe first theme addressed in this chapter is the perception of move-\nment. This includes our ability to move successfully within the visual envi-\nronment and predict accurately when moving objects will reach us.\nThe second theme is concerned with more complex issues – how do\nwe act appropriately on the environment and the objects within it? Of rel-\nevance are theories (e.g., the perception-action theory; the dual- process\napproach) distinguishing between processes and systems involved in vision-\nfor- perception and those involved in vision-for-action (see Chapter  2).\nHere we consider theories providing more detailed accounts of vision-for-\naction and/or the workings of the dorsal pathways allegedly underlying\nvision-for-action.\nThe third theme focuses on the processes involved in making sense\nof moving objects (especially other people). It thus differs from the first\ntheme in which moving stimuli are considered mostly in terms of predicting\nwhen they will reach us. There is an emphasis on the perception of biolog-\nical movement when the available visual information is impoverished. We\nalso consider the role of the mirror neuron system in interpreting human\nmovement.\nFinally, we consider our ability (or failure!) to detect changes in\nobjects within the visual environment over time. Unsurprisingly, attention\nimportantly determines which aspects of the environment are consciously\nChapter\n4\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n141\ndetected. This issue provides a useful bridge between the areas of visual\nperception and attention (the subject of the next chapter).\nDIRECT PERCEPTION\nJames Gibson (1950, 1966, 1979) put forward a radical approach to visual\nperception that was largely ignored at the time. Until approximately 40\nyears ago, it was assumed the main purpose of visual perception is to allow\nus to identify or recognise objects. This typically involves relating infor-\nmation extracted from the visual environment to our stored knowledge\nof objects (see Chapter 3). Gibson argued that this approach is limited –\nin evolutionary terms, vision developed so our ancestors could respond\nrapidly to the environment (e.g., hunting animals; escaping from danger).\nGibson (1979, p. 239) argued that perception involves “keeping in\ntouch with the environment”. This is sufficient for most purposes because\nthe information provided by environmental stimuli is much richer than\npreviously believed. We can relate Gibson’s views to Milner and Goodale’s\n(1995, 2008) vision-for-action system (see Chapter 2). According to both\ntheoretical accounts, there is an intimate relationship between perception\nand action.\nGibson regarded his theoretical approach as ecological. He emphasised\nthat perception facilitates interactions between the individual and their\nenvironment. Here is the essence of his direct theory of perception:\nWhen I assert that perception of the environment is direct, I mean that\nit is not mediated by retinal pictures, neural pictures, or mental pic-\ntures. Direct perception is the activity of getting information from the\nambient array of light. I call this a process of information pickup that\ninvolves . . . looking around, getting around, and looking at things.\n(Gibson, 1979, p. 147)\nWe will briefly consider some of Gibson’s theoretical assumptions:\n●\nThe pattern of light reaching the eye is an optic array. It contains all\nthe visual information from the environment striking the eye.\n●\nThe optic array provides unambiguous or invariant information about\nthe layout of objects. This information comes in many forms including\noptic flow patterns and affordances (see below) and texture gradients\n(discussed in Chapter 2).\nGibson produced training films in the Second World War describing how\npilots handle taking off and landing. Of crucial importance is optic flow –\nthe changes in the pattern of light reaching observers when they move or\nparts of the visual environment move. When pilots approach a landing strip,\nthe point towards which they are moving (focus of expansion) appears\nmotionless with the rest of the visual environment apparently moving away\nfrom that point (see Figure 4.1). The further away any part of the landing\nstrip is from that point, the greater is its apparent speed of movement.\nWang et al. (2012) simulated the pattern of optic flow that would be\nexperienced if individuals moved forwards in a stationary environment.\nKEY TERMS\nOptic array\nThe structural pattern of\nlight falling on the retina.\nOptic flow\nThe changes in the\npattern of light reaching\nan observer when there is\nmovement of the observer\nand/or aspects of the\nenvironment.\nFocus of expansion\nThe point towards which\nsomeone in motion is\nmoving; it does not\nappear to move.\nCase study:\nGibson's theory of direct\nperception affordances\nCreated from usyd on 2022-02-13 13:26:41.",
    "142\nVisual perception and attention\nTheir attention was attracted towards the focus of expansion, thus showing\nits psychological importance. (More is said later about optic flow and the\nfocus of expansion.)\nGibson (1966, 1979) argued certain higher-order characteristics of\nthe visual array (invariants) remain unaltered as observers move around\ntheir environment. Invariants (e.g., the focus of expansion) are important\nbecause they remain the same over different viewing angles. The focus of\nexpansion is an invariant feature of the optic array.\nAffordances\nAccording to Gibson (1979), the potential uses of objects (their  affordances)\nare directly perceivable. For example, a ladder “affords” ascent or descent.\nGibson believed that “affordances are opportunities for action that exist\nin the environment and do not depend on the animal’s mind . . . they do\nnot cause behaviour but simply make it possible” (Withagen et al., 2012,\np. 251). In Gibson (1979, p. 127), affordances are what the environment\n“offers the animal, what it provides or furnishes”.\nEvidence for the affordance of “climbability” of steps varying in height\nwas reported by Di Stasi and Guardini (2007). The step height judged the\nmost “climbable” was the one that would have involved the minimum\nexpenditure of energy.\nGibson argued an object’s affordances are perceived directly or auto-\nmatically. In support, Pappas and Mack (2008) found images of objects\npresented below the level of conscious awareness nevertheless produced\nmotor priming. For example, the image of a hammer caused activation\nin brain areas involved in preparing to use a hammer. Wilf et al. (2013)\nfocused on the affordance of graspability with participants lifting their\narms to perform a reach-like movement with graspable and non-graspable\nobjects (see Figure 4.2). Muscle activity started faster for graspable than\nnon-graspable objects suggesting that the affordance of graspability trig-\ngers rapid activity in the motor system.\nFigure 4.1\nThe optic-flow field as a\npilot comes in to land, with\nthe focus of expansion in\nthe middle.\nFrom Gibson (1950).\nWadsworth, a part of Cengage\nLearning, Inc. 2014 American\nPsychological Association.\nReproduced with permission.\nKEY TERMS\nInvariants\nProperties of the optic\narray that remain constant\neven though other\naspects vary; part of\nGibson’s theory.\nAffordances\nThe potential uses of\nan object which Gibson\nclaimed are perceived\ndirectly.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n143\nGibson’s approach to affordances is substantially oversimplified. For\nexample, an apparently simple task such as cutting up a tomato involves\nselecting an appropriate tool, deciding on how to grasp and manipulate\nthe tool, and monitoring movement execution (Osiurak & Badets, 2016).\nIn other words, “People reason about physical object properties to solve\neveryday life activities” (Osiurak & Badets, 2016, p. 540). This is sharply\ndifferent to Gibson’s emphasis on the ease and immediacy of tool use.\nWhen individuals observe a tool, Gibson assumed this provided them\nwith direct access to knowledge about how to manipulate it and this\nmanipulation knowledge gave access to the tool’s functions. This assump-\ntion exaggerates the importance of manipulation knowledge. For example,\nFigure 4.2\nGraspable and non-\ngraspable objects having\nsimilar asymmetrical\nfeatures.\nFrom Wilf et al. (2013).\nReprinted with permission.\nNon-\ngraspable\nNon-\ngraspable\nGraspable\nGraspable\nCreated from usyd on 2022-02-13 13:26:41.",
    "144\nVisual perception and attention\nGarcea and Mahon (2012) found function judgements about tools were\nmade faster than manipulation judgements, whereas Gibson’s approach\nimplies that manipulation judgements should have been faster.\nFinally, Gibson argued stored knowledge is not required for\nindividuals to make appropriate movements with respect to objects\n(e.g., tools). In fact, individuals often make extensive use of motor and\nfunction  knowledge when dealing with objects (Osiurak & Badets, 2016).\nFor example, making tea involves filling the kettle with water, boiling the\nwater, finding some milk and so on. Foulsham (2015) discussed research\nshowing there are only small individual differences in the pattern of eye\nfixations when people make tea. Such findings strongly imply they use\nstored information about the sequence of motor actions involved in\ntea-making.\nEvaluation\nWhat are the strengths of Gibson’s ecological approach? First, “Gibson’s\nrealisation that natural scenes are the ecologically valid stimulus that should\nbe used for the study of vision was of fundamental importance” (Bruce &\nTadmor, 2015, p. 32).\nSecond, and related to the first point, Gibson disagreed with the previ-\nous emphasis on static observers looking at static visual displays. Foulsham\nand Kingstone (2017) compared the eye fixations of participants walking\naround a university campus with those of other participants viewing static\npictures of the same scene. The eye fixations were significantly different:\nthose engaged in walking focused more on features (e.g., the path) impor-\ntant for locomotion whereas those viewing static pictures focused centrally\nwithin each picture.\nThird, Gibson was far ahead of his time. There is support for two\nvisual systems (Milner & Goodale, 1995, 2008; see Chapter 2): a vision-\nfor- perception system and a vision-for-action system. Before Gibson, the\nmajor emphasis was on the former. In contrast, he argued our percep-\ntual system allows us to respond rapidly and accurately to environmental\nstimuli without using memory, which is a feature of the latter system.\nWhat are the limitations of Gibson’s approach? First, Gibson attempted\nto specify the visual information used to guide action but ignored many\nof the processes involved (see Chapters 2 and 3). For example, Gibson\nassumed the perception of invariants occurred almost “automatically”, but\nit actually requires several complex processes.\nSecond, Gibson’s argument that we do not need to assume the existence\nof internal representations (e.g., object knowledge) is flawed. The logic of\nGibson’s position is that: “There are invariants specifying a friend’s face, a\nperformance of Hamlet, or the sinking of the Titanic, and no knowledge of\nthe friend, of the play, or of maritime history is required to perceive these\nthings” (Bruce et al., 2003, p. 410). Evidence refuting Gibson’s argument\nwas reviewed by Foulsham (2015; discussed above).\nThird, and related to the second point, Gibson de-emphasised the role\nof top-down processes (based on our knowledge and expectations) in visual\nperception. Such processes are especially important when the visual input\nis impoverished (see Chapter 3).\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n145\nFourth, Gibson’s views on the effects of motion on perception were\noversimplified. For example, when moving towards a goal, we use more\ninformation sources than Gibson assumed (discussed below).\nVISUALLY GUIDED MOVEMENT\nFrom an ecological perspective, it is important to understand how we move\naround the environment. For example, what information do we use when\nwalking towards our current goal or target? We must ensure we are not\nhit by cars when crossing the road and when driving we must avoid hitting\nother cars. Playing tennis well involves predicting exactly when and where\nthe ball will strike our racquet. The ways visual perception plays a crucial\nrole in facilitating our locomotion and ensuring our safety are discussed in\nthe next section.\nHeading and steering\nWhen we want to reach some goal (e.g., a gate at the end of a field), we\nuse visual information to move directly towards it. Gibson (1950) empha-\nsised the importance of optic flow (see Glossary; discussed on pp. 141–142).\nWhen we move forwards in a straight line, the point towards which we are\nmoving (the focus of expansion) appears motionless. In contrast, the area\naround that point seems to expand.\nGibson (1950) proposed a hypothesis, according to which, if we are\nnot moving directly towards our goal, we use the focus of expansion and\noptic flow to bring our heading (point of expansion) into alignment with\nour goal. This is known as the global radial outflow hypothesis.\nGibson’s approach works well in principle when applied to an indi-\nvidual trying to move straight from A to B. However, matters are more\ncomplex when we cannot move directly to our goal (e.g., driving around a\nbend in the road; avoiding obstacles). Another complexity is that observers\noften make head and eye movements. In sum, the retinal flow field (changes\nin the pattern of light on the retina) is influenced by rotation in the retinal\nimage produced by following a curved path and/or eye and head movements.\nThe above complexities mean it is often hard to use information from\nretinal flow to determine our direction of heading. It has often been claimed\nthat a copy of motor commands (preprogramming) to move the eye and\nhead (efference copy) is used by observers to compensate for the effects of\neye and head movements on the retinal image. However, Feldman (2016)\nargued this approach is insufficient on its own because it de-emphasises the\nbrain’s active involvement in relating perception and action.\nFindings: heading\nGibson emphasised the role of optic flow in allowing individuals to move\ndirectly towards their goal. Relevant information includes the focus of\nexpansion (see Glossary) and the direction of radial motion (e.g., expan-\nsion within optic flow). Strong et al. (2017) obtained evidence indicating the\nimportance of both factors and also established they depend on separate\nbrain areas. More specifically, they used transcranial magnetic stimulation\nKEY TERMS\nRetinal flow field\nThe changing patterns\nof light on the retina\nproduced by movement\nof the observer relative\nto the environment as\nwell as by eye and head\nmovements.\nEfference copy\nAn internal copy of a\nmotor command (e.g., to\nthe eyes); it can be used\nto identify movement\nwithin the retinal image\nthat is not due to\nobject movement in the\nenvironment.\nCreated from usyd on 2022-02-13 13:26:41.",
    "146\nVisual perception and attention\n(TMS; see Glossary) to disrupt key brain areas. TMS applied to area V3A\nimpaired perception of the focus of expansion but not direction of radial\nmotion, with the opposite pattern being obtained when TMS was applied to\nthe motion area V5/MT+ (see Chapter 2).\nAs indicated above, eye and/or head movements make it harder to use\noptic flow effectively for heading. Bremmer et al. (2010) considered this\nissue in macaque monkeys presented with distorted visual flow fields sim-\nulating the combined effects of self-motion and an eye movement. Their\nkey finding was that numerous cells in the medial superior temporal area\nsuccessfully compensated for this distortion.\nAccording to Gibson, a walker tries to make the focus of expansion\ncoincide with the body moving straight ahead. If a walker wore prisms\nproducing a 9° error in their perceived visual direction, the focus of expan-\nsion should be misaligned compared to their expectation. As a result, there\nshould be a correction process, a prediction confirmed by Herlihey and\nRushton (2012). Also as predicted, walkers denied access to information\nabout retinal motion failed to show any correction.\nFactors additional to the optic flow information emphasised by Gibson\nare also used when making heading judgements. This is unsurprising given\nthe typical richness of the available environmental information. van den\nBerg and Brenner (1994) noted we only require one eye to use optic flow\ninformation. However, they discovered heading judgements were more\naccurate when observers used both eyes. Binocular disparity (see Glossary)\nin the two-eye condition provided useful additional information about the\nrelative depths of objects. Cormack et al. (2017) introduced the notion of\na binoptic flow field to describe the 3-D information available to observers\n(but de-emphasised by Gibson).\nGibson assumed optic-flow patterns generated by self-motion are of\nfundamental importance when we head towards a goal. However, motion is\nnot essential for accurate perception of heading. The judgements of heading\ndirection made by observers viewing two static photographs of a real-world\nscene in rapid succession were reasonably accurate in the absence of optic-\nflow information (Hahn et al., 2003). These findings can be explained in\nterms of retinal displacement – objects closer to the direction of heading\nshow less retinal displacement as we move closer to the target.\nSnyder and Bischof (2010) argued that information about the direction\nof heading is provided by two systems. One system uses movement infor-\nmation (e.g., optic flow) rapidly and fairly automatically (as proposed by\nGibson). The other system uses displacement information more slowly and\nrequires greater processing resources. It follows that performing a second\ntask at the same time as making judgements about direction of heading\nshould have little effect on those judgements if movement information is\navailable. In contrast, a second task should impair heading judgements\nwhen only displacement information is available. The evidence supported\nboth predictions.\nHeading: future path\nWilkie and Wann (2006) argued judgements of heading (the direction in\nwhich someone is moving) are of little relevance if they are moving along a\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n147\ncurved path. With curved paths, path judge-\nments (identifying future points along one’s\npath) were much more accurate than heading\njudgements.\nAccording to the above analysis, we\nmight expect individuals (e.g., drivers) to\nfixate some point along their future path\nwhen it is curved. This is the future path\nstrategy. In contrast, Land and Lee (1994)\nargued (with supportive evidence) that drivers\napproaching a bend focus on the tangent\npoint – the point on the inside edge of the\nroad at which its direction appears to reverse\n(see Figure 4.3).\nThe tangent point has two potential\nadvantages. First, it is easy to identify and\ntrack. Second, road curvature can easily be\nworked out by considering the angle between\nthe direction of heading and the tangent point.\nKandil et al. (2009) found most drivers nego-\ntiating 270° bends at a motorway junction\nfixated the tangent point much more often than\nthe future path (75% vs 14%, respectively).\nOther research suggests the tangent point\nis less important. For example, Itkonen et al.\n(2015) instructed drivers to “drive as they\nnormally would” or “look at the tangent\npoint”. Eye movements differed markedly in\nthe two conditions – drivers were much more\nlikely to fixate points along the future path in\nthe former condition.\nHow can we interpret the above appar-\nently inconsistent findings? Lappi et al. (2013)\nhypothesised drivers often fixate the tangent\npoint when approaching and entering a bend\nbut fixate the future path further into the\nbend. They argued the tangent point provides relatively precise informa-\ntion and so drivers use it when uncertainty about the precise nature of the\ncurve or bend is maximal (i.e., when approaching and entering it).\nLappi et al. (2013) obtained supporting evidence for the above hypoth-\nesis. Drivers’ fixations while driving along a lengthy curve formed by the\nslip road to a motorway were predominantly on the path ahead rather than\nthe tangent point after the first few seconds (see short clips of drivers’ eye\nmovements while performing this task at 10.1371/journal.pone.0068326).\nThe evidence discussed so far does not rule out optic flow as a factor\ninfluencing drivers’ steering. Mole et al. (2016) manipulated optic-flow\nspeed in a simulated driving situation. This produced steering errors\n(understeering or oversteering) when going around bends even when full\ninformation about road edges was available. Thus, optic flow influenced\ndriving performance.\nRoad position\nFigure 4.3\nThe visual features of a road viewed in perspective. The\ntangent point is marked by the filled circle on the inside edge\nof the road, and the desired future path is shown by the\ndotted line. According to the future-path theory, drivers should\ngaze along the line marked “active gaze”.\nFrom Wilkie et al. (2010). Reprinted with permission from\nSpringer-Verlag.\nKEY TERM\nTangent point\nFrom a driver’s\nperspective, the point\non a road at which the\ndirection of its inside\nedge appears to reverse.\nCreated from usyd on 2022-02-13 13:26:41.",
    "148\nVisual perception and attention\nEvaluation\nGibson’s views concerning the importance of optic-flow information have\ndeservedly been very influential. Such information is especially useful when\nindividuals can move directly towards their goal rather than following a\ncurved or indirect path. Indeed, the evidence suggests optic flow is often\nIN THE REAL WORLD: ON-ROAD DRIVING\nMuch research on drivers’ gaze patterns lacks ecological validity (see Glossary). Drivers are typ-\nically in a simulator and the environment through which they drive is somewhat oversimplified.\nAccordingly, Lappi et al. (2017) studied the gaze patterns of a 43-year-old male driving school\ninstructor driving on a rural road in Finland. His eye movements revealed a more complex picture\nthan most previous research.\nWhat did Lappi et al. (2017) discover? Here are four major findings:\n(1) The driver’s gaze shifted very frequently from one feature of the visual environment to another\nand he made many head movements.\n(2) The driver’s gaze was predominantly on the far road (see Figure 4.4). This preview of the road\nahead allowed him to make use of anticipatory control.\n(3) In bends, the driver’s gaze was mostly within the far road “triangle” formed by the tangent\npoint (TP), the lane edge opposite the TP and the occlusion point (OP; the point where the\nroad disappears from view). In general terms, the OP is used to anticipate the road ahead\nwhereas the TP is used for more immediate compensatory steering control.\n(4) The driver fixated specific targets (e.g., traffic signs; other road users) very rapidly, suggesting\nhis peripheral vision was very efficient.\nIn sum, drivers’ gaze patterns are more complex than implied by previous research. Drivers do not\nconstantly fixate any given feature (e.g., tangent point) passively. Instead, they “sample visual infor-\nmation as needed, leading to input that is intermittent, and determined by the active observer . . .\nrather than imposed by the environment” (Lappi et al., 2017, p. 11). Drivers’ eye movements are\ndetermined in part by control mechanisms (e.g., path planning) (Lappi & Mole, 2018). These mech-\nanisms are responsive to drivers’ goals. For example, professional racing drivers have the goal of\ndriving as fast as possible whereas many ordinary drivers have the goal of driving safely.\nFigure 4.4\nThe far road “triangle” in (A) a left turn and (B) a right turn.\nFrom Lappi et al. (2017).\n(A)\n(B)\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n149\nthe dominant source of information determining judgements of heading\ndirection. Drivers going around bends use optic-flow information. They\nalso make some use of the tangent point. This is a relatively simple feature\nof the visual environment and its use by drivers is in the spirit of Gibson’s\nperspective.\nWhat are the limitations of Gibson’s approach and other related\napproaches?\n(1) Individuals moving directly towards a target use several kinds of\ninformation (e.g., binocular disparity; retinal displacement) ignored\nby Gibson.\n(2) The tangent point is used infrequently when individuals move along a\ncurved path: they more often fixate points lying along the future path.\n(3) Drivers going around bends use a greater variety of information\nsources than implied by Gibson’s approach. Of most importance,\ndrivers’ eye movements are strongly influenced by active, top-down\nprocesses (e.g., motor control) not included within Gibson’s theoris-\ning. More specifically, drivers’ eye movements depend on their current\ndriving goals as well as the environmental conditions.\n(4) Research and theorising have de-emphasised meta-cognition (beliefs\nabout one’s own performance). Mole and Lappi (2018) found drivers\noften made inaccurate meta-cognitive judgements of their own driving\nperformance (e.g., they tended to exaggerate the importance of driving\nspeed in determining performance). Such inaccurate judgements prob-\nably often lead to impaired driving performance.\nTime to contact\nIn everyday life, we often need to predict the moment of contact between\nus and some object. These situations include ones where we are moving\ntowards an object (e.g., a wall) and those in which an object (e.g., a ball)\nis approaching us. We might work out the time to contact by dividing our\nestimate of the object’s distance by our estimate of its speed. However, this\nwould be complex and error-prone because information about speed and\ndistance is not directly available.\nLee (1976, 2009) argued that there is a simpler way to work out the time\nto contact or collision. If we approach it (or it approaches us) at constant\nvelocity, we can use tau. Tau is defined as the size of an object’s retinal\nimage divided by its rate of expansion. The faster the rate of  expansion,\nthe less time there is to contact.\nWhen driving, the rate of decline of tau over time (tau-dot) indicates\nwhether there is sufficient braking time to stop before contact or collision.\nLee (1976) argued drivers brake to hold constant the rate of change of\ntau. This tau-dot hypothesis is consistent with Gibson’s approach because\nit assumes tau-dot is an invariant available to observers from optic flow.\nLee’s theoretical approach has been highly influential. However, his\nemphasis on tau has limited applicability in various ways (Tresilian, 1999).\nFirst, tau ignores acceleration in object velocity. Second, tau only provides\ninformation about the time to contact or collision with the eyes. Thus,\ndrivers might find the front of their car smashed in if they relied solely on\nCreated from usyd on 2022-02-13 13:26:41.",
    "150\nVisual perception and attention\ntau! Third, tau is accurate only when applied to spherically symmetrical\nobjects: do not rely on it when catching a rugby ball!\nHarrison et al. (2016) argued that people’s behaviour is often influ-\nenced by factors other than their estimate of the time to contact. For\nexample, consider someone deciding whether to cross a road when there\nis an approaching car. Their decision is often influenced by judgements of\ntheir physical mobility and their personality (e.g., cautious or impetuous)\n(see p. 151).\nFindings\nAccording to Lee’s (1976) theory, observers can often judge time to contact\naccurately based on using tau relatively “automatically”. If so, observ-\ners’ time-to-contact judgements might not be impaired if they performed\na cognitively demanding task while observing an object’s movement.\nBaurès et al. (2018) obtained support for this prediction. Indeed, time-to-\ncontact judgements were more accurate when observers performed a sec-\nondary task, perhaps because this made it less likely they would attend to\npotentially  misleading information (e.g., expectations about an object’s\nmovements).\nAccording to Lee (1976), judgements of the time to contact when\ncatching a ball should depend crucially on the rate of expansion of the\nball’s retinal image. Savelsbergh et al. (1993) used a deflating ball having\na significantly slower rate of expansion than an ordinary ball. The pre-\ndiction was that peak grasp closure should occur later to the deflating\nball. This prediction was confirmed. However, the actual slowing was\nmuch less than predicted (30 ms vs 230 ms).\nParticipants minimised the distorting effects\nof  manipulating the rate of expansion by\nusing additional sources of information (e.g.,\ndepth cues).\nHosking and Crassini (2010) had par-\nticipants judge time to contact for familiar\nobjects (tennis ball and football) presented in\ntheir standard size or with their sizes reversed.\nThey also used unfamiliar black spheres.\nContrary to Lee’s hypothesis, time-to-contact\njudgments were influenced by familiar size\n(especially when the object was a very large\ntennis ball) leading participants to overesti-\nmate time to contact (see Figure 4.5).\nTau is available in monocular vision.\nHowever, observers often make use of infor-\nmation available in binocular vision, espe-\ncially binocular disparity (see Chapter 2).\nFath et al. (2018) discussed research showing\nbinocular information sometimes provides\nmore accurate judgements than tau of time to\ncontact (e.g., when viewing small objects or\nrotating non-spherical objects).\nFigure 4.5\nErrors in time-to-contact judgements for the smaller and\nthe larger object as a function of whether they were presented\nin their standard size, the reverse size (off-size) or lacking\ntexture (no-texture). Positive values indicate that responses\nwere made too late and negative values that they were made\ntoo early.\nFrom Hosking and Crassini (2010). With kind permission from Springer\nScience+Business Media.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n151\nIn their own research, Fath et al. (2018) assessed accuracy of time-to-\ncontact judgements when observers viewed fast- or slow-moving objects.\nThey used three conditions varying in the amount of information available\nto observers: (1) monocular flow information only (permitting assessment\nof tau); (2) binocular disparity information only; (3) all sources of infor-\nmation available. Fath et al. predicted that binocular disparity information\nwould be less likely to be used with fast-moving objects than slow-moving\nones because it is relatively time-consuming to calculate changes in binoc-\nular disparity over time.\nWhat did Fath et al. (2018) find? First, with fast objects, time-to-\ncontact judgements were more accurate with monocular flow information\nonly than with binocular disparity information only. Second, with slow\nobjects, the opposite findings were obtained. Third, accuracy of time-to-\ncontact judgements when all sources of information were available were\ncomparable to accuracy in the better of the single-source conditions with\nfast and with slow objects.\nDeLucia (2013) found observers mistakenly predicted a large approach-\ning object would reach them sooner than a closer small approaching object:\nthe size-arrival effect. This effect occurred because observers attached more\nimportance to relative size than tau.\nWe turn now to research on drivers’ braking decisions. Lee’s (1976)\nnotion that drivers brake to hold constant the rate of change of tau was\ntested by Yilmaz and Warren (1995). They told participants to stop at a\nstop sign in a simulated driving task. As predicted, there was generally a\nlinear reduction in tau during braking. However, some participants showed\nlarge rather than gradual changes in tau shortly before stopping.\nTijtgat et al. (2008) found individual differences in stereo vision influ-\nenced drivers’ braking behaviour to avoid a collision. Drivers with weak\nstereo vision started braking earlier than those with normal stereo vision\nand their peak deceleration also occurred earlier. Those with weak stereo\nvision found it harder to calculate distances causing them to underestimate\nthe time to contact. Thus, deciding when to brake does not depend only\non tau or tau-dot.\nHarrison et al. (2016) argued that Lee’s (1976) theoretical approach is\nlimited in two important ways when applied to drivers’ braking behaviour.\nFirst, it ignores physical limitations in the real world. For example, tau-dot\nspecifies to a driver the deceleration during braking required to avoid col-\nlision. However, this strategy will not work if the driver’s braking system\nmakes the required deceleration unachievable.\nSecond, individuals differ in the emphasis they place on minimisation\nof costs (e.g., preferred safety margin). According to Harrison et al., these\nlimitations suggest drivers’ braking behaviour is influenced by their sensi-\ntivity to relevant affordances (possibilities for action) such as their knowl-\nedge of the dynamics of the braking system in their car.\nEvaluation\nThe notion that tau is used to make time-to-contact judgements is simple\nand elegant. There is much evidence that such judgements are often strongly\ninfluenced by tau. Even when competing factors affect time-to-contact\nCreated from usyd on 2022-02-13 13:26:41.",
    "152\nVisual perception and attention\njudgements, tau often has the greatest influence on those judgements. Tau is\nalso often used when drivers make decisions about when to brake.\nWhat are the limitations of theory and research in this area? First,\ntime-to-contact judgements are typically more influenced by tau or tau-dot\nin relatively uncluttered laboratory environments than naturalistic condi-\ntions (Land, 2009). Second, tau is not the only factor determining time-\nto-contact judgements. As Land (2009, p. 853) pointed out, “The brain\nwill accept all valid cues in the performance of an action, and weight them\naccording to their current reliability.” These cues can include object famili-\narity, binocular disparity and relative size. It clearly makes sense to use all\nthe available information in this way.\nThird, the tau hypothesis ignores the emotional value of the approach-\ning object. Time-to-contact judgements are shorter for threatening pictures\nthan neutral ones (Brendel et al., 2012). This makes evolutionary sense – it\ncould be fatal to overestimate how long a very threatening object (e.g., a\nlion) will take to reach you!\nFourth, braking behaviour involves factors additional to tau and\ntau-dot. For example, there are individual differences in preferred safety\nmargin. Rock et al. (2006) identified an alternative braking strategy in a\nreal-world driving task in which drivers directly estimated the constant\nideal deceleration required to stop at a given point.\nVISUALLY GUIDED ACTION: CONTEMPORARY\nAPPROACHES\nThe previous section focused mainly on the issue of how we use visual\ninformation when moving through the environment. Here we consider\nsimilar issues but the emphasis shifts towards processes involved in success-\nful goal-directed action towards objects. For example, how do we reach for\na cup of coffee? This issue was addressed by Milner and Goodale (1995,\n2008) in their perception-action model (see Chapter 2). Contemporary\napproaches that have developed and extended the perception-action model\nare discussed below.\nRole of planning: planning-control model\nGlover (2004) proposed a planning-control model of goal-directed action\ntowards objects. According to this model, we initially use a planning system\nfollowed by a control system but the two systems often overlap in time.\nHere are the main features of the two systems:\n(1) Planning system\n●\nIt is used mostly before the initiation of movement.\n●\nIt selects an appropriate target (e.g., cup of coffee), decides how\nit should be grasped and works out the timing of the movement.\n●\nIt is influenced by factors such as the individual’s goals, the\nnature of the target object, the visual context and various cogni-\ntive processes.\n●\nIt is relatively slow because it uses much information and is influ-\nenced by conscious processes.\nInteractive exercise:\nPlanning control\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n153\n(2) Control system\n●\nIt is used during the carrying out of a movement.\n●\nIt ensures movements are accurate, making adjustments, if neces-\nsary, based on visual feedback. Efference copy (see Glossary) is\nused to compare actual with desired movement. Proprioception\nis also involved.\n●\nIt is influenced by the target object’s spatial characteristics (e.g.,\nsize; shape; orientation) but not by the surrounding context.\n●\nIt is fairly fast because it uses little information and is not suscep-\ntible to conscious influence.\nAccording to the planning-control model, most errors in human action\nstem from the planning system. In contrast, the control system typically\nensures actions are accurate and achieve their goal. Many visual illusions\noccur because of the influence of visual context. Since information about\nvisual context is used only by the planning system, responses to visual illu-\nsions should typically be inaccurate if they depend on the planning system\nbut accurate if they depend on the control system.\nThere are similarities between the planning-control model and\nMilner and Goodale’s perception-action model. However, Glover\n(2004) focused  more on the processing changes occurring during action\nperformance.\nFindings\nGlover et al. (2012) compared the brain areas involved in planning and\ncontrol using a planning condition (prepare to reach and grasp an object\nbut remain still) and a control condition (reach out immediately for the\nobject). There was practically no overlap in the brain areas associated with\nplanning and control. This finding supports the model’s assumption that\nplanning and control processes are separate.\nAccording to the planning-control model, various factors (e.g., seman-\ntic properties of the visual scene) influence the planning process associated\nwith goal-directed movements but not the subsequent control process. This\nprediction was tested by Namdar et al. (2014). Participants grasped an\nobject in front of them using their thumb and index finger. The object had\na task-irrelevant digit (1, 2, 8 or 9) on it. As predicted, numerically larger\ndigits led to larger grip apertures during the first half of the movement tra-\njectory but not the second half (involving the control process).\nAccording to Glover (2004), action planning involves conscious\nprocessing followed by rapid non-conscious processing during action\ncontrol. These theoretical assumptions can be tested by requiring partic-\nipants to carry out a second task while performing an action towards an\nobject. According to the model, this second task should disrupt planning\nbut not control. However, Hesse et al. (2012) found a second task dis-\nrupted  planning and control when participants made grasping movements\ntowards objects. Thus, planning and control can both require attentional\nresources.\nAccording to the model, visual illusions occur because misleading\nvisual context influences the initial planning system rather than the later\nKEY TERM\nProprioception\nAn individual’s awareness\nof the position and\norientation of parts of\ntheir body.\nCreated from usyd on 2022-02-13 13:26:41.",
    "154\nVisual perception and attention\ncontrol system. Roberts et al. (2013) required participants to make rapid\nreaching movements to a Müller-Lyer figure. Vision was available only\nduring the first 200 ms of movement or the last 200 ms. The findings were\nopposite to those predicted theoretically – performance was more accurate\nwith early vision than late vision.\nElliott et al. (2017) explained the above findings with their multiple\nprocess model. According to this model, performance was good when early\nvision was available because of a control system known as impulse control.\nImpulse control “entails an early, and continuing, comparison of expected\nsensory consequences to perceived sensory consequences to regulate limb\ndirection and velocity during the distance-covering phase of the move-\nment” (p. 108).\nEvaluation\nGlover’s (2004) planning-control model has proved successful in various\nways. First, it successfully developed the common assumption that motor\nmovements towards an object involve successive planning and control pro-\ncesses. Second, the assumption cognitive processes are important in action\nplanning is correct. Third, there is evidence (e.g., Glover et al., 2012) that\nseparate brain areas are involved in planning and control.\nWhat are the model’s limitations? First, the planning system involves\nseveral very different processes: “goal determination; target identification\nand selection; analysis of object affordances [potential object uses]; timing;\nand computation of the metrical properties of the target such as its size,\nshape, orientation and position relative to the body” (Glover et al., 2012,\np. 909). This diversity sheds doubt on the assumption there is a single plan-\nning system.\nSecond, the model argues control occurs late during object-directed\nmovements and is influenced by visual feedback. However, there appears\nto be a second control process (called impulse control by Elliott et al.,\n2017) operating throughout the movement trajectory and not influenced\nby visual feedback.\nThird, and related to the second point, the model presents an over-\nsimplified picture of the processes involved in goal-directed action. More\nspecifically, the processing involved in producing goal-directed movements\nis far more complex than implied by the notion of a planning process fol-\nlowed by a control process. For example, planning and control processes\nare often so intermixed that “the distinction between movement planning\nand movement control is blurred” (Gallivan et al., 2018, p. 519).\nFourth, complex decision-making processes are often involved when\nindividuals plan goal-directed actions in the real world. For example, when\nplanning, tennis players players must often decide between a simple shot\nminimising energy expenditure and risk or injury or a more ambitious shot\nthat might immediately win the current point (Gallivan et al., 2018).\nFifth, the model is designed to account for planning and control pro-\ncesses when only one object is present or of interest. In contrast, visual\nscenes in everyday life are often far more complex and contain several\nobjects of potential relevance (see below).\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n155\nRole of planning: changing action plans\nWe all have considerable experience of changing, modifying and abandon-\ning action plans with respect to objects in the environment. How do we\nresolve competition among action plans? According to Song (2017, p. 1),\n“Critical is the existence of parallel motor planning processes, which allow\nefficient and timely changes.”\nWhat evidence indicates we often process information about several\ndifferent potential actions simultaneously? Suppose participants are given\nthe task of reaching rapidly towards a target in the presence of distrac-\ntors (Song & Nakayama, 2008). On some trials, their reach is initially\ndirected towards the target. On other trials, their initial reach is directed\ntowards a distractor but this is corrected in mid-flight producing a strongly\ncurved trajectory. Song and Nakayama’s key finding was that corrective\nmovements occurred very rapidly following the onset of the initial move-\nment. This finding strongly implies that the corrective movement had been\nplanned prior to execution of the initial incorrect movement.\nSong (2017) discussed several other studies where similar findings were\nobtained. He concluded, “The sensori-motor system generates multiple\ncompeting plans in parallel before actions are initiated . . . this concur-\nrent processing enables us to efficiently resolve competition and select one\nappropriate action rapidly” (p. 6).\nBrain pathways\nIn their perception-action model, Milner and Goodale (1995, 2008) dis-\ntinguished between a ventral stream or pathway and a dorsal stream\nor pathway (see Chapter 2). In approximate terms, the ventral stream is\ninvolved in object perception whereas the dorsal stream “is generally con-\nsidered to mediate the visual guidance of action, primarily in real time”\n(Milner, 2017, p. 1297).\nMuch recent research has indicated that the above theoretical account\nis oversimplified (see Chapter 2). Of central importance is the accumulat-\ning evidence that there are actually two somewhat separate dorsal streams\n(Osiurak et al., 2017; Sakreida et al., 2016):\n(1) The dorso-dorsal stream: processing in this stream relates to the\nonline control of action and is hand-centred; it has been described as\nthe “grasp” system (Binkofski & Buxbaum, 2013).\n(2) The ventro-dorsal stream: processing in this stream is offline and relies\non memorised knowledge of objects and tools and is object-centred;\nit has been described as the “use” system (Binkofski & Buxbaum,\n2013).\nSakreida et al. (2016) identified several other differences between these two\nstreams (see Figure 4.6). In essence, object processing within the dorso-\ndorsal stream is variable because it is determined by the immediately acces-\nsible properties of an object (e.g., its size and shape). Such processing is\nfast and “automatic”. In contrast, processing within the ventro-dorsal\nstream is stable because it is determined by memorised object knowledge.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-13 13:26:41.",
    "156\nVisual perception and attention\nSuch processing is slow and more cognitively demanding than processing\nwithin the dorso-dorsal stream.\nFindings\nConsiderable neuroimaging evidence supports the proposed distinction\nbetween two dorsal streams. Martin et al. (2018, p. 3755) reviewed research\nindicating the dorso-dorsal stream “traverses from visual area V3a through\nV6 toward the superior parietal lobule, and . . . reaches the dorsal premotor\ncortex”. In contrast, the ventro-dorsal stream “encompasses higher- order\nvisual areas like MT/V5+, the inferior parietal lobule . . . as well as the\nventral premotor cortex and inferior frontal gyru” (p. 3755). Sakreida et al.\n(2016) conducted a meta-analytic review based on 71 neuroimaging studies\nand obtained similar findings.\nEvidence from brain-damaged patients is also supportive of the dis-\ntinction between two dorsal streams. First, we consider patients with\ndamage to the ventro-dorsal stream. Much research has focused on limb\napraxia, a disorder where patients often fail to make precise goal-directed\nactions in spite of possessing the physical ability to perform those actions\n(Pellicano et al., 2017). More specifically, “Reaching and grasping actions\nin LA [limb apraxia] are normal when vision of the limb and target is\navailable, but typically degrade when they must be performed ‘off-line’, as\nwhen subjects are blindfolded prior to movement execution” (Binkovski\n& Buxbaum, 2013, p. 5). This pattern of findings is expected if the dorso-\ndorsal stream is intact in patients with limb apraxia.\nSecond, we consider patients with damage to the dorso-dorsal stream.\nMuch research here has focused on optic ataxia (see Glossary). As pre-\ndicted, patients with optic ataxia have impaired online motor control and\nso exhibit inaccurate reaching towards (and grasping of) objects.\nEvaluation\nNeuroimaging research has provided convincing evidence for the existence\nof two dorsal processing streams. The distinction between dorso-dorsal and\nventro-dorsal streams has also been supported by studies on brain-damaged\nFigure 4.6\nThe dorso-dorsal and\nventro-dorsal streams\nshowing their brain\nlocations and forms of\nprocessing.\nFrom Sakreida et al. (2016).\nReprinted with permission of\nElsevier.\nDorso-dorsal\nVARIABLE\nSTABLE\nVentro-dorsal\nCentral sulcus\nContinuum\nRelated concepts\n• Fast and “automatic” online\nprocessing during actual\nobject interaction\n• Variation of object properties\n(e.g., size, shape, weight, or\norientation) during task\nperformance\n• Low working memory load\n• Structure-\nbased\nactions/\n“Grasp”\nsystem by\nBuxbaum and\nKalénine\n• Function-\nbased\nactions/\n“Use”\nsystem by\nBuxbaum and\nKalénine\n• Grasping\ncircuit by\nJeannerod\n• Reaching\ncircuit by\nJeannerod\n• Slow and “non-automatic”\n“ofine”  processing of memo-\nrised object knowledge\n• Constant object properties\nduring active or observed\nobject-related reaching,\ngrasping or pointing\n• High working memory load\nKEY TERM\nLimb apraxia\nA condition caused by\nbrain damage in which\nindividuals have impaired\nability to make skilled\ngoal-directed movements\ntowards objects even\nthough they possess the\nphysical ability to perform\nthem.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n157\npatients. More specifically, there is some evidence for a double dissociation\n(see Glossary) between the impairments exhibited by patients with limb\napraxia and optic ataxia.\nWhat are the limitations of research in this area? First, the ventral\nstream (strongly involved in object recognition) is also important in vis-\nually guided action (Osiurak et al., 2017). However, precisely how this\nstream interacts with the dorso-dorsal and ventro-dorsal streams is unclear.\nSecond, there is some overlap in the brain between the dorso-dorsal and\nventro-dorsal streams and so it is important not to exaggerate their inde-\npendence. Third, there is a lack of consensus concerning the precise func-\ntions of the two dorsal streams (see Osiurak et al., 2017, and Sakreida\net al., 2016).\nPERCEPTION OF HUMAN MOTION\nWe are very good at interpreting other people’s movements. We can decide\nvery rapidly whether someone is walking, running or limping. Our initial\nfocus is on two key issues. First, how successfully can we interpret human\nmotion with very limited visual information?\nSecond, do the processes involved in per-\nception of human motion differ from those\ninvolved in perception of motion in general? If\nthe answer to this question is positive, we also\nneed to consider why the perception of human\nmotion is special.\nAs indicated already, our focus is\nmostly on the perception of human motion.\nHowever, there are many similarities between\nthe perception of human and animal motion,\nand we will sometimes use the term “biolog-\nical motion” to refer generally to the percep-\ntion of animal motion.\nFinally, we discuss an important theoret-\nical approach based on the notion that the\nsame brain system or network is involved in\nperceiving and understanding human actions\nand in performing those same actions.\nPerceiving human motion\nSuppose you were presented with point-light\ndisplays, as was done initially by Johansson\n(1973). Actors were dressed entirely in black\nwith lights attached to their joints (e.g., wrists;\nknees; ankles). They were filmed moving\naround a darkened room so only the lights\nwere visible to observers watching the film (see\nFigure 4.7 and “Johansson Motion Perception\nPart 1” on YouTube).What do you think\nyou would perceive in those circumstances?\nFigure 4.7\nPoint-light sequences (a) with the walker visible and (b) with\nthe walker not visible.\nShiffrar and Thomas (2013). With permission of the authors.\nCreated from usyd on 2022-02-13 13:26:41.",
    "158\nVisual perception and attention\nIn fact, Johansson found observers perceived the moving person accurately\nwith only six lights and a short segment of film.\nIn subsequent research, Johansson et al. (1980) found observers per-\nceived human motion with no apparent difficulty when viewing a point-\nlight display for only one-fifth of a second! Ruffieux et al. (2016) studied a\npatient, BC, who was cortically blind but had a residual ability to process\nmotion. When presented with two point-light displays (one of a human\nand one of an animal) at the same time, he generally correctly identified\nthe human.\nThe above findings imply we are very efficient at processing impov-\nerished point-light displays. However, Lu et al. (2017) reported some\ncontrary evidence. Observers were given two tasks: (1) detecting the\npresence of a human walker; (2) discriminating whether a human walker\nwas walking leftward or rightward. The walker was presented in point\nlights,  contour, silhouette or as a skeleton. Detection performance was\nrelatively good for the point-light display but discrimination performance\nwas not (see Figure 4.8). Performance was high with the skeleton display\nbecause it provided detailed information about the connections between\njoints.\nTop-down or bottom-up processes?\nJohansson (1975) argued the ability to perceive biological motion is innate,\ndescribing the processes involved as “spontaneous” and “automatic”.\nSupport was reported by Simion et al. (2008) in a study on newborns (1–3\ndays). These newborns preferred to look at a display showing biological\nmotion more than one that did not. Remarkably, Simion et al. used point-\nlight displays of chickens of which the newborns had no previous experi-\nence. These findings suggest the perception of biological motion involves\nbasic bottom-up processes.\nEvidence that learning plays a role was reported by Pinto (2006).\nThree-month-olds were equally sensitive to motion in point-light humans,\ncats and spiders. In contrast, 5-month-olds were more sensitive to displays\nof human motion. Thus, the infant visual system becomes increasingly spe-\ncialised for perceiving human motion.\nFigure 4.8\nHuman detection and\ndiscrimination efficiency for\nhuman walkers presented\nin contour, point lights,\nsilhouette and skeleton.\nFrom Lu et al. (2017).\n0\nContour\nHuman efficiency (%)\n0.6\n1.2\nPoint light\nSilhouette\nSkeleton\nDetection\nDiscrimination\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n159\nIf the detection of biological motion were “automatic”, it would be\nrelatively unaffected by attention. However, in a review Thompson and\nParasuraman (2012) concluded attention is required, especially when the\navailable visual information is ambiguous or competing information is\npresent.\nMayer et al. (2015) presented circular arrays of between two and\neight video clips. In one condition, observers decided rapidly whether\nany clip  showed human motion; in another condition, they decided\nwhether any clips showed machine motion. There were two key find-\nings. First,  detection times increased with array size for both human and\nmachine motion,  suggesting attention is required to detect both types of\nmotion.  Second, the effects of array size on detection times were much\ngreater for machine motion. Thus, searching is more efficient for human\nthan machine motion suggesting human motion perception may be special\n(see below).\nIs human motion perception special?\nMuch evidence indicates we are better at detecting human motion than\nmotion in other species (Shiffrar & Thomas, 2013). Cohen (2002) assessed\nobservers’ sensitivity to human, dog and seal motion using point-light\ndisplays. Performance was best with human motion and worst with seal\nmotion. Of importance, the same pattern of performance was found in seal\ntrainers and dog trainers. Thus, the key factor is not simply visual experi-\nence; instead, we are more sensitive to observed motions resembling our\nown repertoire of actions.\nWe can also consider whether human motion perception is special by\nconsidering the brain. There has been an increasing recognition that many\nbrain areas are involved in biological motion pro-\ncessing (see Figure 4.9). The pathway from the fusi-\nform gyrus (FFG) to the superior temporal sulcus\n(STS) is of particular importance, as are top-down\nprocesses from the insula (INS), the STS and the\ninferior frontal gyrus (IFG).\nMuch research indicates the central importance\nof the superior temporal sulcus. Grossman et al.\n(2005) applied repetitive transcranial magnetic stim-\nulation (rTMS; see Glossary) to that area to disrupt\nprocessing. This caused a substantial reduction in\nobservers’ sensitivity to biological motion. Gilaie-\nDotan et al. (2013) found grey matter volume in the\nsuperior temporal sulcus correlated positively with\nthe detection of biological (but not non-biological)\nmotion.\nEvidence from brain-damaged patients indi-\ncates that perceiving biological motion involves dif-\nferent processes from those involved in perceiving\nobject motion generally. Vaina et al. (1990) studied\na patient, AF, with damage to the posterior visual\npathways. He performed poorly on basic motion\nFigure 4.9\nBrain areas involved in biological motion processing\n(STS = superior temporal sulcus; IFG = inferior frontal\ngyrus; INS = insula; Crus 1 = left lateral cerebellar\nlobule; MTC = middle temporal cortex; OCC = early\nvisual cortex; FFG = fusiform gyrus).\nFrom Sokolov et al. (2018).\nCrus I\nMTC\nFFG\n4\n6\n10\n8\n11\n9\nOCC\nINS\nSTS\nIFG\n*\n*\nCreated from usyd on 2022-02-13 13:26:41.",
    "160\nVisual perception and attention\ntasks but was reasonably good at detecting biological motion from\npoint-light displays. In contrast, Saygin (2007) found in stroke patients\nwith damage in the temporal and premotor frontal areas that their\nperception of biological motion was more impaired than non-biological\nmotion.\nWhy is biological motion perception special?\nWe could explain the special nature of biological motion perception in three\nways (Shiffrar & Thomas, 2013). First, biological motion is the only type of\nmotion humans can produce as well as perceive. Second, most people spend\nmore time perceiving and trying to understand other people’s motion than\nany other form of visual motion. Third, other people’s movements provide\na rich source of social and emotional information.\nWe start with the first reason (discussed further on pp. 161–162). The\nrelevance of motor skills to the perception of biological motion was shown\nby Kloeters et al. (2017). Patients with Parkinson’s disease (which impairs\nmovement execution) had significantly inferior perception of human\nmovement with point-light displays compared to healthy controls. More\ndramatically, paraplegics with severe spinal injury were almost three times\nless sensitive than healthy controls to human movement in point-light\ndisplays.\nWe must not exaggerate the importance of motor involvement in bio-\nlogical motion perception. A man, DC, born without upper limbs, identi-\nfied manual actions shown in videos and photographs as well as healthy\ncontrols (Vannuscorps et al., 2013). Motor skills may be most important\nin biological motion perception when the visual information presented is\nsparse or ambiguous (e.g., as with point-light displays).\nJacobs et al. (2004) obtained support for the second reason listed\nabove. Observers’ ability to identify walkers from point-light displays was\nmuch better when the walker was observed for 20 hours a week rather than\n5 hours. In our everyday lives, we often recognise individuals in motion by\nintegrating information from biological motion with information from the\nface and the voice within the superior temporal sulcus (Yovel & O’Toole,\n2016). Successful integration of these different information sources clearly\ndepends on learning and experience.\nWe turn now to the third reason mentioned earlier. Charlie Chaplin\nshowed convincingly that bodily movements can convey social and emo-\ntional information. Atkinson et al. (2004) found observers performed\nwell at identifying emotions from point-light displays (especially for fear,\nsadness and happiness). Part of the explanation for these findings is that\nangry individuals walk especially fast whereas fearful or sad ones walk\nvery slowly (Barliya et al., 2013).\nWe can explore the role of social factors in biological motion detec-\ntion by studying adults with autism spectrum disorder who have severely\nimpaired social interaction skills. The findings are somewhat inconsist-\nent However, adults with autism spectrum disorder generally have a rea-\nsonably intact ability to detect human motion in point-light displays but\nexhibit impaired emotion processing in such displays (see Bakroon &\nLakshminarayanan, 2018 for a review).\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n161\nMirror neuron system\nResearch on monkeys in the 1990s transformed our\nunderstanding of biological motion. Gallese et al. (1996)\nassessed monkeys’ brain activity while they performed\na given action and while they observed another monkey\nperform the same action. They found 17% of neurons in\narea F5 of the premotor cortex were activated in both\nconditions. Such findings led theorists to propose a mirror\nneuron system consisting of neurons activated during\nboth observation and performance of actions (see Keysers\net al., 2018, for a review).\nThere have been numerous attempts to identify a\nmirror neuron system in humans. Our current under-\nstanding of brain areas associated with the mirror neuron\nsystem is shown in Figure 4.10. Note that the mirror\nneuron system consists of an integrated network rather\nthan separate brain areas (Keysers et al., 2018).\nMost research is limited because it shows only that\nthe same brain areas are involved in action perception\nand production. Perry et al. (2018) used more precise\nmethods to reveal a more complex picture within areas\nassumed to form part of the mirror neuron system. Some\nsmall areas were activated during both observing actions\nand imitating them, thus providing evidence for a human\nneuron system. However, other adjacent areas were acti-\nvated only during observing or action imitation.\nMore convincing evidence for a human mirror\nneuron system was reported by de la Rosa et al. (2016).\nThey focused on activation in parts of the inferior frontal gyrus (BA44/45)\ncorresponding to area F5 in monkeys. Their key finding was that 52 voxels\n(see Glossary) within BA44/45 responded to both action perception and\naction production.\nBefore proceeding, we should note the term “mirror neuron system”\nis somewhat misleading because mirror neurons do not provide us with\nan exact motoric coding of observed actions. As Williams (2013, p. 2962)\nwittily remarked, “If only this was the case! I could become a Olympic ice-\nskater or a concert pianist!”\nFindings\nWe have seen that neuroimaging studies have indicated that the mirror\nneuron system is activated during motor perception and action. Such evi-\ndence is correlational, and so does not demonstrate that the mirror neuron\nsystem is necessary for motor perception and action understanding.\nMore direct evidence comes from research on brain-damaged patients.\nBinder et al. (2017) studied left-hemisphere stroke patients with apraxia\n(impaired ability to perform planned actions) having damage within the\nmirror neuron system (e.g., inferior frontal gyrus). These patients had\ncomparable deficits in action imitation, action recognition and action\nPMv\nMirror network\nVisual input\nMotor output\npMT G/STS\nPF\nPMd\nAIP SIM1\nFigure 4.10\nThe main brain areas associated with the\nmirror neuron system (MNS) plus their\ninterconnections (red). Areas involved in visual\ninput (blue; pMTG = posterior mid-temporal\ngyrus; STS = superior temporal gyrus) and motor\noutput (green; M1 = primary motor cortex) are\nalso shown. AIP = anterior intraparietal areas;\nPF = area within the parietal lobe; PMv and\nPMd = ventral and dorsal premotor cortex;\nSI = primary somato-sensory cortices.\nFrom Keysers et al. (2018). Reprinted with permission\nof Elsevier.\nKEY TERM\nMirror neuron system\nNeurons that respond\nto actions whether\nperformed by oneself\nor someone else; it is\nclaimed these neurons\nassist in imitating (and\nunderstanding) the\nactions of others.\nCreated from usyd on 2022-02-13 13:26:41.",
    "162\nVisual perception and attention\ncomprehension. The co-existence of these deficits was precisely as pre-\ndicted. Another predicted finding was that left-hemisphere stroke patients\nwithout apraxia had less brain damage in core regions of the mirror neuron\nsystem than those with apraxia.\nAnother approach to demonstrating the causal role of the mirror\nneuron system is to use experimental techniques such as transcranial direct\ncurrent stimulation (tDCS; see Glossary). Avenanti et al. (2018) assessed\nobservers’ ability to predict which object would be grasped after seeing\nthe start of a reaching movement. Task performance was enhanced when\nanodal tDCS was used to facilitate neural activity within the mirror neuron\nsystem, whereas it was impaired when cathodal tDCS was used to inhibit\nsuch neural activity.\nFindings: functions of the mirror neuron system\nWhat are the functions of the mirror neuron system? It has often been\nassumed mirror neurons play a role in working out why someone else is\nperforming certain actions as well as deciding what those actions are. For\nexample, Eagle et al. (2007, p. 131) claimed the mirror neuron system is\ninvolved in “the automatic, unconscious, and non-inferential simulation\nin the observer of the actions, emotions, and sensations carried out and\nexpressed by the observed”.\nRizzolatti and Sinigaglia (2016) argued that full understanding of\nanother person’s actions requires a multi-level process. The first level\ninvolves identifying the outcome of the observed action and the emotion\nbeing displayed by the other person. This is followed by the observer rep-\nresenting the other person’s desires, beliefs and intentions. The mirror\nneuron system is primarily involved at the first level but may provide an\ninput to subsequent processes.\nLingnau and Petris (2013) argued that understanding another person’s\nactions often requires complex cognitive processes as well as simpler pro-\ncesses within the mirror neuron system. Observers saw point-light displays\nof human actions and some were asked to identify the goal of each action.\nAreas within the prefrontal cortex (associated with high-level cognitive pro-\ncesses) were more activated when goal identification was required. These\nfindings can be explained within the context of Rizzolatti and Sinigaglia’s\n(2016) approach discussed above.\nWurm et al. (2016) distinguished between two forms of motion per-\nception and understanding. They used the example of observers under-\nstanding that someone is opening a box. If they have a general or abstract\nunderstanding of this action, their understanding should generalise to\nother boxes and other ways of opening a box. In contrast, if they only\nhave a specific or concrete understanding of the action, their understand-\ning will not generalise. Wurm et al. (2016) found specific or concrete action\nunderstanding could occur within the mirror neuron system. However,\nmore general or abstract understanding involved high-level perceptual\nregions (e.g., the lateral parieto-temporal cortex) outside the mirror neuron\nsystem.\nIn sum, the mirror neuron system is of central importance with respect\nto some (but not all) aspects of action understanding. More specifically,\nKEY TERM\nApraxia\nA condition caused by\nbrain damage in which\nthere is greatly reduced\nability to perform\npurposeful or planned\nbodily movements in\nspite of the absence of\nmuscular damage.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n163\nadditional (more “cognitive”) brain areas are required if action under-\nstanding is complex (Lingnau & Petris, 2013) or involves generalising from\npast experience (Wurm et al., 2016). It is also likely that imitating someone\nelse’s actions often involves processes (e.g., person-perception processes)\nadditional to those directly involving the mirror neuron system (Ramsey,\n2018).\nOverall evaluation\nSeveral important research findings have been obtained. First, we have an\nimpressive ability to perceive human or biological motion even with very\nlimited visual input. Second, the brain areas involved in human motion\nperception differ somewhat from those involved in perceiving motion in\ngeneral. Third, perception of human motion is special because it is the only\ntype of motion we can both perceive and produce. Fourth, a mirror neuron\nsystem allows us to imitate and understand other people’s movements.\nFifth, the core brain network of the mirror neuron system has been identi-\nfied. Its causal role has been established through studies on brain-damaged\npatients and research using techniques such as transcranial direct current\nstimulation.\nWhat are the limitations of research in this area? First, much remains\nunclear about interactions of bottom-up and top-down processes in the\nperception of biological motion.\nSecond, the mirror neuron system does not account for all aspects of\naction understanding. As Gallese and Sinigaglia (2014, p. 200) pointed out,\naction understanding “involves representing to which . . . goals the action\nis directed; identifying which beliefs, desires, and intentions specify reasons\nexplaining why the action happened; and realising how those reasons are\nlinked to the agent and to her action”.\nThird, nearly all studies on the mirror neuron system have investigated\nits properties with respect only to hand actions. However, somewhat differ-\nent mirror neuron networks are probably associated with hand-and-mouth\nactions (Ferrari et al., 2017a).\nFourth, it follows from theoretical approaches to the mirror neuron\nsystem that an observer’s ability to understand another person’s actions\nshould be greater if they both execute any given action in a similar fashion.\nThis prediction has been confirmed (Macerollo et al., 2015). Such research\nindicates the importance of studying individual differences in motor\nactions, which have so far been relatively neglected.\nCHANGE BLINDNESS\nWe have seen that a changing visual environment allows us to move in the\nappropriate direction and to make coherent sense of our surroundings.\nHowever, as we will see, our perceptual system does not always respond\nappropriately to changes in the visual environment.\nHave a look around you (go on!). You probably have a strong impres-\nsion of seeing a vivid and detailed picture of the visual scene. As a result,\nyou are probably confident you could immediately detect any reasonably\nlarge change in the visual environment. In fact, that is often not the case.\nCreated from usyd on 2022-02-13 13:26:41.",
    "164\nVisual perception and attention\nChange blindness, which is “the failure to detect changes in visual\nscenes” (Ball et al., 2015, p. 2253) is the main phenomenon we will discuss.\nWe also consider inattentional blindness, “the failure to consciously per-\nceive otherwise salient events when they are not attended” (Ward & Scholl,\n2015, p. 722). Research on change blindness focuses on dynamic processes\nover time. It has produced striking and counterintuitive findings leading to\nnew theoretical thinking about the processes underlying conscious visual\nawareness.\nChange blindness and inattentional blindness both depend on a mixture\nof perceptual and attentional processes. It is thus appropriate to discuss\nthese phenomena at the end of our coverage of perception and immediately\nprior to the start of our coverage of attention.\nYou have undoubtedly experienced change blindness at the movies\ncaused by unintended continuity mistakes when a scene has been reshot.\nFor example, in the film Skyfall, James Bond is followed by a white\ncar. Mysteriously, this car suddenly becomes black and then returns to\nbeing white! For more examples, type “Movie continuity mistakes” into\nYouTube.\nWe greatly exaggerate our ability to detect visual changes. Levin\net  al. (2002) asked observers to watch videos involving two people in\na  restaurant. In one video, the plates change from red to white and in\nanother a scarf worn by one person disappeared. Levin et al. found 46%\nof observers claimed they would have noticed the change in the colour\nof the plates without being forewarned and the figure was 78% for the\ndisappearing scarf. In a previous study, 0% of observers detected either\nchange! Levin et  al. introduced the term change blindness blindness to\ndescribe our wildly optimistic beliefs about our ability to detect visual\nchanges.\nIn the real world, we are often aware of visual changes because we\ndetect motion signals accompanying the change. Laboratory researchers\nhave used various ways to prevent observers from detecting motion signals.\nOne way is to make the change during a saccade\n(rapid movement of the eyes). Another way is\nto have a short gap between the original and\nchanged displays (the flicker paradigm).\nSuppose you walked across a large square\nclose to a unicycling clown wearing a vivid\npurple and yellow outfit, large shoes and a bright\nred nose (see Figure 4.11). Would you spot\nhim? I imagine your answer is “Yes”. However,\nHyman et al. (2009) found only 51% of people\nwalking on their own spotted the clown. Those\nfailing to spot the clown exhibited inattentional\nblindness.\nChange blindness vs inattentional\nblindness\nChange blindness and inattentional blindness\nboth involve a failure to detect some visual event\nKEY TERMS\nChange blindness\nFailure to detect various\nchanges (e.g. in objects)\nin the visual environment.\nInattentional blindness\nFailure to detect an\nunexpected object\nappearing in the visual\nenvironment.\nChange blindness\nblindness\nThe tendency of observers\nto overestimate greatly\nthe extent to which they\ncan detect visual changes\nand so avoid change\nblindness.\nFigure 4.11\nThe unicycling clown who cycled close to students walking\nacross a large square.\nFrom Hyman et al. (2009).\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n165\noccurring in plain sight. Unsurprisingly, failures of attention often play an\nimportant role in causing both forms of blindness.\nHowever, there are major differences between the two phenomena\n(Jensen et al., 2011). First, consider the effects of instructing observers to\nlook for unexpected objects or visual changes. Target detection in change\nblindness paradigms is often hard even with such instructions. In contrast,\ntarget detection in inattentional blindness paradigms becomes trivially\neasy. Second, change blindness involves the use of memory to compare pre-\nchange and post-change stimuli, whereas inattentional blindness does not.\nThird, inattentional blindness mostly occurs when the observer’s attention\nis engaged in a demanding task (e.g., chatting on a mobile phone) unlike\nchange blindness.\nIn sum, more complex processing is typically required for successful\nperformance in change blindness tasks. More specifically, observers must\nengage successfully in five separate processes for change detection to occur\n(Jensen et al., 2011):\n(1) Attention must be paid to the change location.\n(2) The pre-change visual stimulus at the change location must be\nencoded into memory.\n(3) The post-change visual stimulus at the change location must be\nencoded into memory.\n(4) The pre- and post-change representations must be compared.\n(5) The discrepancy between the pre- and post-change representations\nmust be recognised at the conscious level.\nIN THE REAL WORLD: IT’S MAGIC!\nMagicians benefit from the phenomena of inattentional blindness and change blindness (Kuhn &\nMartinez, 2012). Most magic tricks involve misdirection which is designed “to disguise the method\nand thus prevent the audience from detecting it” (Kuhn & Martinez, 2012, p. 2). Many people\nbelieve misdirection involves the magician manipulating the audience’s attention away from some\naction crucial to the trick’s success. That is often (but not always) the case.\nInattentional blindness\nKuhn and Findlay (2010) studied inattentional blindness using a disappearing lighter (see\nFigure 4.12 for details). There were three main findings. First, of the observers who detected the\ndrop, 31% were fixating close to the magician’s left hand when the lighter was dropped from that\nhand. However, 69% were fixating some distance away and so detected the drop in peripheral\nvision (see Figure 4.13). Second, the average distance between fixation and the drop was the same\nin those who detected the drop in peripheral vision and those who did not. Third, the time taken\nafter the drop to fixate the left hand was much less in observers using peripheral vision to detect\nthe drop than those failing to detect it (650 ms vs 1,712 ms).\nWhat do the above findings mean? The lighter drop can be detected by overt attention (atten-\ntion directed to the fixation point) or covert attention (attention directed away from the fixation\npoint). Covert attention was surprisingly effective because the human visual system can readily\ndetect movement in peripheral vision (see Chapter 2).\nCreated from usyd on 2022-02-13 13:26:41.",
    "166\nVisual perception and attention\nMost people underestimate the importance of peripheral vision to trick detection. Across several\nmagic tricks (including the lighter trick and other tricks involving change blindness), Ortega et\nal. (2018) found under 30% of individuals\nthought they were likely to detect how a\ntrick worked using peripheral vision. In fact,\nhowever, over 60% of the tricks where they\ndetected the method involved peripheral\nvision! Thus, most people exaggerate the\nrole of central vision in understanding magic\ntricks.\nChange blindness\nSmith et al. (2012) used a magic trick in\nwhich a coin was passed from one hand\nto the other and then dropped. Observers\nguessed whether the coin landed heads or\ntails. On one trial, the coin was switched\n(e.g., from a £1 coin to a 2p coin). All\nobservers fixated the coin throughout the\ntime it was visible but about 90% failed\nto detect the coin had changed! Thus, an\nobject can be attended to without some\nof the features irrelevant to the current\ntask being processed sufficiently to prevent\nchange blindness.\nFigure 4.12\nThe sequence of events in the disappearing lighter trick: (a) the magician picks up a lighter with his left hand and (b)\nlights it; (c) and (d) he pretends to take the flame with his right hand and (e) gradually moves it away from the hand\nholding the lighter; (f) he reveals his right hand is empty while the lighter is dropped into his lap; (g) the magician\ndirects his gaze to his left hand and (h) reveals that his left hand is also empty and the lighter has disappeared.\nF igure 4.13\nParticipants’ fixation points at the time of dropping the\nlighter for those detecting the drop (triangles) and those\nmissing the drop (circles).\nFrom Kuhn and Findlay (2010). Reprinted with permission of Taylor\n& Francis.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n167\nKuhn et al. (2016) used a trick in which a magician made the colour of playing cards change.\nExplicit instructions to observers to keep their eyes on the  cards influenced overt attention but\nfailed to reduce change blindness.\nConclusions\nThe success of many magic tricks depends less on where observers are fixating (overt attention)\nthan we might think. Observers can be deceived even when their overt attention is directed to\nthe crucial location. In addition, they often avoid change blindness or inattentional blindness even\nwhen their overt attention is directed some distance away from the crucial location. Such findings\nare typically explained by assuming the focus of covert attention often differs from that of overt\nattention. More generally, peripheral vision is often of more importance to the detection of magic\ntricks than most people believe.\nChange blindness underestimates visual processing\nBall and Busch (2015) distinguished between two types of change detec-\ntion: (1) seeing the object that changed; (2) sensing there has been a change\nwithout conscious awareness of which object has changed. Several coloured\nobjects were presented in pre- and post-change displays. If the post-change\ndisplay contained a colour not present in the pre-change display, observ-\ners often sensed change had occurred without being aware of what had\nchanged.\nWhen observers show change blindness, it does not necessarily mean\nthere was no processing of the change. Ball et al. (2015) used object changes\nwhere the two objects were semantically related (e.g., rail car changed to\nrail) or unrelated (e.g., rail car changed to sausage). Use of event-related\npotentials (ERPs; see Glossary) revealed a larger negative wave when the\nobjects were semantically unrelated even when observers exhibited change\nblindness. Thus, there was much unconscious processing of the pre- and\npost-change objects.\nWhat causes change blindness?\nThere is no single (or simple) answer to the question “What causes change\nblindness?”. However, two major competing theories both provide partial\nanswers. First, there is the attentional approach (e.g., Rensink et al., 1997).\nAccording to this approach, change detection requires selective attention\nto be focused on the object that changes. Attention is typically directed to\nonly a limited part of visual space, and changes in unattended objects are\nunlikely to be detected.\nSecond, there is a theoretical approach emphasising the importance of\nperipheral vision (Rosenholtz, 2017a,b; Sharan et al., 2016 unpublished).\nIt is based on the assumption that visual processing occurs in parallel\nacross the entire visual field (including peripheral vision). According to\nthis approach, “Peripheral vision is a limiting factor underlying standard\ndemonstrations of change blindness” (Sharan et al., 2016, p. 1).\nCreated from usyd on 2022-02-13 13:26:41.",
    "168\nVisual perception and attention\nAttentional approach\nChange blindness often depends on attentional processes. We typically\nattend to regions of a visual scene likely to contain salient or important\ninformation. Spot the differences between the pictures in Figure 4.14.\nObservers took an average of 10.4 seconds with the first pair of pictures\nbut only 2.6 with the second pair (Rensink et al., 1997). The height of the\nrailing is less important than the helicopter’s position.\nHollingworth and Henderson (2002) recorded eye movements while\nobservers viewed visual scenes (e.g., kitchen; living room). It was assumed\nthe object fixated at any moment was the being attended. There were two\npotential changes in each scene:\n●\nType change: an object was replaced by one from a different category\n(e.g., a plate replaced by a bowl).\n●\nToken change: an object was replaced by an object from the same cat-\negory (e.g., a plate replaced by a different plate).\nFigure 4.14\n(a) The object that is\nchanged (the railing)\nundergoes a shift in\nlocation comparable to\nthat of the object that is\nchanged (the helicopter) in\n(b). However, the change\nis much easier to see in\n(b) because the changed\nobject is more important.\nFrom Rensink et al. (1997).\nReprinted by permission of\nSAGE Publications.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n169\nWhat did Hollingworth and Henderson (2002) find? First, there was much\ngreater change detection when the changed object was fixated prior to\nthe change than when it was not fixated (see Figure 4.15a). Second, there\nwas change blindness for 60% of objects fixated prior to changing. Thus,\nattention to the to-be-changed object was necessary (but not sufficient)\nfor change detection. Third, change detection was much greater when the\nobject type changed rather than simply token change because type changes\nare more dramatic and obvious.\nEvaluation\nThe attentional approach has various successes to its credit. First, change\ndetection is greater when target stimuli are salient or important and so\nattract attention. Second, change detection is generally greater when the\nto-be-changed object has been fixated (attended to) prior to the change.\nWhat are the limitations with the attentional approach? First, the\nnotion that narrow-focused attention determines our visual experience is\nFigure 4.15\n(a) Percentage of correct\nchange detection as a\nfunction of form of change\n(type vs token) and time\nof fixation (before vs\nafter change); also false\nalarm rate when there\nwas no change. (b) Mean\npercentage correct change\ndetection as a function of\nthe number of fixations\nbetween target fixation and\nchange of target and form\nof change (type vs token).\nBoth from Hollingworth and\n2002 American Psychological\nAssociation. Reproduced with\npermission.\nCreated from usyd on 2022-02-13 13:26:41.",
    "170\nVisual perception and attention\nhard to reconcile with our strong belief that experience spans the entire\nfield of view (Cohen et al., 2016). Second, “A selective attention account is\nhard to prove or disprove, as it relies on largely unknown attentional loci\nas well as poorly understood effects of attention” (Sharan et al., 2016).\nThird, change blindness is sometimes poorly predicted by the focus of\novert attention (indexed by eye fixations) (e.g., Smith et al., 2012; Kuhn\net al., 2016). Such findings are often explained by covert attention, but this\nis typically not measured directly. Fourth, the attentional approach implies\nincorrectly that very little useful information is extracted from visual areas\noutside the focus of attention (see below).\nPeripheral vision approach\nVisual acuity is greatest in the centre of the visual field (the fovea; see\nGlossary). However, peripheral vision (all vision outside the fovea) typically\ncovers the great majority of the visual field (see Chapter 2). As Rosenholtz\n(2016, p. 438) pointed out, it is often assumed “Peripheral vision is impov-\nerished and all but useless”. This is a great exaggeration even though acuity\nand colour perception are much worse in the periphery than the fovea. In\nfact, peripheral vision is often most impaired by visual crowding: “iden-\ntification of a peripheral object is impaired by nearby objects” (Pirkner &\nKimchi, 2017, p. 1) (see Chapter 5).\nAccording to Sharan et al. (2016, p. 3), “The hypothesis that change\nblindness may arise in part from limitations of peripheral vision is quite\ndifferent from usual explanations of the phenomenon [which attribute it to]\na mix of inattention and lack of details stored in memory.”\nSharan et al. (2016) tested the above hypothesis. Initially, they catego-\nrised change-detection tasks as easy, medium and hard on the basis of how\nrapidly observers detected the change. Then they presented these tasks to\ndifferent observers who fixated at various degrees of visual angle (eccentric-\nities) from the area that changed. There were two key findings:\n(1) Change-detection performance was surprisingly good even when the\nchange occurred well into peripheral vision.\n(2) Peripheral vision plays a major role in determining change-detection\nperformance – hard-to-detect changes require closer fixations than\nthose that are easy to detect.\nKEY TERM\nVisual crowding\nThe inability to recognise\nobjects in peripheral\nvision due to the presence\nof neighbouring objects.\nFigure 4.16\n(a) Change-detection\naccuracy as a function\nof task difficulty and\nvisual eccentricity. (b)\nThe eccentricity at which\nchange-detection accuracy\nwas 85% correct as a\nfunction of task difficulty.\nFrom Sharan et al. (2016).\n+\n+\n0\n0.4\n0.5\n0.6\n0.7\n0.8\nAccuracy\n0.9\n1\n(a)\nEasy\nMedium\nHard\np = 0.013\n0\n1\n2\n3\n4\n5\n6\n7\n8\nEccentricity (deg)\n(b)\n5\n10\nEccentricity (deg)\n15\n20\nEasy\nMedium\nHard\n++ +\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+ + ++\n+\n+\n+\n+\n+\n+ +\n+++ + +\n+\n+++ +\n+\n+\n+ +\n+\n+\n+\n++\n++\n+\n+\n+\n+\n+\n+\n+++\n+ +\n+\n+\n+ +\n+\n+\n+\n+ +\n+\n+\n+\n++\np = 0.019\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n171\nFurther evidence that much information is extracted from peripheral as well\nas foveal vision was reported by Clarke and Mack (2015). On each trial,\ntwo real-world scenes were presented with an interval of 1,500 ms between\nthem. When this interval was unfilled, only 11% of changes were detected.\nHowever, when a cue indicating the location of a possible change was pre-\nsented 0, 300 or 1,000 ms after the offset of the first scene, change-detection\nrates were much higher. They were greatest in the 0 ms condition (29%) and\nlowest in the 1,000 ms condition (18%). Thus, much information about the\nfirst scene (including information from peripheral vision) was stored briefly\nin iconic memory (see Glossary and Chapter 6).\nIf peripheral vision provides observers with general or gist information,\nthey might detect global scene changes without detecting precisely what\nhad changed. Howe and Webb (2014) obtained support for this prediction.\nObservers were presented with an array of 30 discs (15 red, 15 green). On\n24% of trials when three discs changed colour, observers detected the array\nhad changed but could not identify the discs involved.\nEvaluation\nThe peripheral vision approach has proved successful in various ways.\nFirst, visual information is often extracted from across the entire visual\nfield as predicted by this approach (but not the attentional approach). This\nsupports our strong belief that we perceive most of the immediate visual\nenvironment. Second, this approach capitalises on established knowledge\nconcerning peripheral vision. Third, this approach has been applied suc-\ncessfully to explain visual-search performance (see Chapter 5).\nWhat are the limitations of this approach? First, it de-emphasises atten-\ntion’s role in determining change blindness, and does not provide a detailed\naccount of how attentional and perceptual processes are integrated. Second,\nSharan et al. (2016) discovered change detection was sometimes difficult\neven though the change could be perceived easily in peripheral vision. This\nindicates that other factors (as yet unidentified) are also involved. Third,\nthe approach does not consider failure to compare pre- and post-change\nrepresentations as a reason for change blindness (see below).\nComparison of pre- and post-change representations\nChange blindness can occur because observers fail to compare their pre-\nand post-change representations. Angelone et al. (2003) presented a video\nin which the identity of the central actor changed. On a subsequent line-up\ntask to identify the pre-change actor, observers showing change blindness\nperformed comparably to those showing change detection (53% vs 46%,\nrespectively).\nVarakin et al. (2007) extended the above research in a real-world study\nin which a coloured binder was switched for one of a different colour while\nobservers’ eyes were closed. Some observers exhibited change blindness even\nthough they remembered the colours of the pre- and post-change binders\nand so had failed to compare the two colours. Other observers showing\nchange blindness had poor memory for the pre- and post-change colours\nand so failed to represent these two pieces of information in memory.\nCreated from usyd on 2022-02-13 13:26:41.",
    "172\nVisual perception and attention\nIs change blindness a defect?\nIs change blindness an unfortunate defect? Fischer and Whitney (2014)\nargued the answer is “No”. The visual world is typically relatively stable\nover short time periods. As a result, it is worthwhile for us to sacrifice\nperceptual accuracy occasionally to ensure we have a continuous, stable\nperception of our visual environment.\nFischer and Whitney (2014) supported their argument by finding the\nperceived orientation of a grating was biased in the direction of a previ-\nously presented grating, an effect known as serial dependence. Manassi\net  al. (2018) found serial dependence for an object’s location – when an\nobject that had been presented previously was re-presented, it was per-\nceived as being closer to its original location than was actually the case.\nSerial dependence probably involves several stages of visual perception and\nmay also involve memory processes (Bliss et al., 2017). In sum, the visual\nsystem’s emphasis on perceptual stability inhibits our ability to detect\nchanges within the visual scene.\nInattentional blindness and its causes\nThe most famous study on inattentional blindness was reported by Simons\nand Chabris (1999). In one condition, observers watched a video where stu-\ndents dressed in white (the white team) passed a ball to each other and the\nobservers counted the number of passes (see the video at www.simonslab.\ncom/videos.html). At some point, a woman in a black gorilla suit walks into\ncamera shot, looks at the camera, thumps her chest and then walks off (see\nFigure 4.17). Altogether she is on screen for 9 seconds. Very surprisingly,\nonly 42% of observers noticed the gorilla! This is a striking example of\ninattentional blindness.\nWhy was performance so poor in the\nabove experiment? Simons and Chabris\n(1999) obtained additional relevant evi-\ndence. In a second condition, observers\ncounted the number of passes made by stu-\ndents dressed in black. Here 83% of observ-\ners detected the gorilla’s presence. Thus,\nobservers were more likely to attend to\nthe gorilla when it resembled task-relevant\nstimuli (i.e., in colour).\nIt is generally assumed detection perfor-\nmance is good when observers count black\nteam passes because of selective attention\nto black objects. Indeed, Rosenholtz et  al.\n(2016) found that observers counting black\nteam passes had eye fixations closer to the\ngorilla than those counting white team\npasses. However, Rosenholtz et al. also\nfound that observers counting black team\npasses (but whose fixation patterns resem-\nbled those of observers counting white\nKEY TERM\nSerial dependence\nSystematic bias of current\nvisual perception towards\nrecent visual input.\nFigure 4.17\nFrame showing a woman in a gorilla suit in the middle of a game\nof passing the ball.\nFrom Simons & Chabris (1999). Figure provided by Daniel Simons, www.\ndansimons.com/www.theinvisiblegorilla.com.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n173\nteam passes) had unusually poor detection performance (54% compared to\na typical 80%). Thus, detection performance may depend on the strengths\nand limitations of peripheral vision as well as failures of selective attention.\nThe presence of inattentional blindness can lead us to underestimate\nthe amount of processing of the undetected stimulus. Schnuerch et al.\n(2016) found categorising attended stimuli was slower when the meaning\nof an undetected stimulus conflicted with that of the attended stimulus.\nThus, the meaning of undetected stimuli was processed despite inatten-\ntional blindness. Other research using event-related potentials (reviewed by\nPitts, 2018) has shown that undetected stimuli typically receive moderate\nprocessing.\nHow can we explain inattentional blindness? As we have seen, expla-\nnations often emphasise the role of selective attention or attentional set.\nSimons and Chabris’ (1999) findings indicate the importance of similarity\nin stimulus features (e.g., colour) between task stimuli and the unexpected\nobject. However, Most (2013) argued that similarity in semantic category\nis also important. Participants tracked numbers or letters. On the critical\ntrial, an unexpected stimulus (the letter E or number 3) was visible for\n7 seconds. The letter and number were visually identical except they were\nmirror images of each other.\nWhat did Most (2013) find? There was much less inattentional blind-\nness when the unexpected stimulus belonged to the same category as the\ntracked objects. Thus, inattentional blindness can depend on attentional\nsets based on semantic categories (e.g., letters; numbers).\nLégal et al. (2017) investigated the role of demanding top-down atten-\ntional processes in producing inattentional blindness using Simons and\nChabris’ (1999) gorilla video. Some observers counted the passes made by\nthe white team (standard task) whereas others had the more attentionally\ndemanding task of counting the number of aerial passes as well as total\npasses. As predicted, there was much more evidence of inattentional blind-\nness (i.e., failing to detect the gorilla) when the task was more demanding.\nLégal et al. (2017) reduced inattentional blindness in other conditions\nby presenting detection-relevant words subliminally (e.g., identify; notice)\nto observers prior to watching the video. This increased detection rates for\nthe gorilla in the standard task condition from 50% to 83%. Overall, the\nfindings indicate that manipulating attentional processes can have powerful\neffects on inattentional blindness.\nCompelling evidence that inattentional blindness depends on top-down\nprocesses that strongly influence what we expect to see was reported by\nPersuh and Melara (2016). Observers fixated a central dot followed by the\npresentation of two coloured squares and decided whether the colours were\nthe same. On the critical trial, the dot was replaced by Barack Obama’s\nface (see Figure 4.18). Amazingly, 60% of observers failed to detect this\nunexpected stimulus presented in foveal vision: Barack Obama blindness.\nOf these observers, a below-chance 8% identified Barack Obama when\ndeciding whether the unexpected stimulus was Angelina Jolie, a lion’s\nhead, an alarm clock or Barack Obama (see Figure 4.18).\nPersuh and Melara’s (2016) findings are dramatic because they indi-\ncate inattentional blindness can occur even when the novel stimulus is pre-\nsented on its own with no competing stimuli. These findings suggest there\nCreated from usyd on 2022-02-13 13:26:41.",
    "174\nVisual perception and attention\nare important differences in the processes underlying inattentional blind-\nness and change blindness: the latter often depends on visual crowding (see\nGlossary), which is totally absent in Persuh and Melara’s study.\nEvaluation\nSeveral factors influencing inattentional blindness have been identified.\nThese factors include the similarity (in terms of stimulus features and\nsemantic category) between task stimuli and the unexpected object; the\nattentional demands of the task; and observers’ expectations concerning\nwhat they will see. If there were no task requiring attentional resources and\ncreating expectations, there would undoubtedly be very little inattentional\nblindness (Jensen et al., 2011).\nWhat are the limitations of research in this area? First, it is typically\nunclear whether inattentional blindness is due to perceptual failure or to\nmemory failure (i.e., the unexpected object is perceived but rapidly for-\ngotten). However, Ward and Scholl (2015) found that observers showed\ninattentional blindness even when observers were instructed to report\nimmediately seeing anything unexpected. This finding strongly sug-\ngests that inattentional blindness reflects deficient perception rather than\nmemory failure.\nSecond, observers typically engage in some processing of undetected\nstimuli even when they fail to report the presence of such stimuli (Pitts,\n2018). More research is required to clarify the extent of non-conscious pro-\ncessing of undetected stimuli.\nThird, it is likely that the various factors influencing inattentional\nblindness interact in complex ways. However, most research has consid-\nered only a single factor and so the nature of such interactions has not\nbeen established.\nFigure 4.18\nThe sequence of events on\nthe initial baseline trials and\nthe critical trial.\nFrom Persuh and Melara (2016).\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n175\nCHAPTER SUMMARY\n•\nIntroduction. The time dimension is very important in visual\nperception. The changes in visual perception produced as we\nmove around the environment and/or environmental objects move\npromote accurate perception and facilitate appropriate actions.\n•\nDirect perception. Gibson argued perception and action are\nclosely intertwined and so research should not focus exclusively on\nstatic observers perceiving static visual displays. According to his\ndirect theory, an observer’s movement creates optic flow providing\nuseful information about the direction of heading. Invariants,\nwhich are unchanged as people move around their environment,\nhave particular importance. Gibson claimed the uses of objects\n(their affordances) are perceived directly. He underestimated the\ncomplexity of visual processing, minimising the role of object\nknowledge in visual perception, with the effects of motion on\nperception being more complex than he realised.\n•\nVisually guided movement. The perception of heading depends\nin part on optic-flow information. However, there are complexities\nbecause the retinal flow field is determined by eye and head\nmovements as well as by optic flow. Heading judgements are also\ninfluenced by binocular disparity and the retinal displacement of\nobjects as we approach them.\nAccurate steering on curved paths (e.g., driving around a\nbend) sometimes involves focusing on the tangent point (e.g.,\npoint on the inside edge of the road at which its direction seems\nto reverse). However, drivers sometimes fixate a point along the\nfuture path. More generally, drivers’ gaze patterns are flexibly\ndetermined by control mechanisms that are responsive to their\ngoals.\nCalculating time to contact with an object often involves\ncalculating tau (the size of the retinal image divided by the\nobject’s rate of expansion). Drivers often use tau-dot (rate of\ndecline of tau over time) to decide whether there is sufficient\nbraking time to stop before contact. Observers often make use of\nadditional sources of information (e.g., binocular disparity; familiar\nsize; relative size) when working out time to contact. Drivers’\nbraking decisions also depend on their preferred margin of safety\nand the effectiveness of the car’s braking system.\n•\nVisually guided action: contemporary approaches. The planning-\ncontrol model distinguishes between a slow planning system used\nmostly before the initiation of movement and a fast control system\nused during movement execution. As predicted, separate brain\nareas are involved in planning and control. However, the definition\nof “planning” is very broad, and the notion that planning always\nprecedes control is oversimplified. Recent evidence indicates\nCreated from usyd on 2022-02-13 13:26:41.",
    "176\nVisual perception and attention\nthat visually guided action depends on three processing streams\n(dorso-dorsal; the ventro-dorsal; and ventral, which is discussed\nmore fully in Chapter 2) each making a separate contribution. This\ntheoretical approach is supported by studies on brain-damaged\npatients and by neuroimaging research.\n•\nPerception of human motion. Human motion is perceived even\nwhen only impoverished visual information is available. Perception\nof human and biological motion involves bottom-up and top-down\nprocesses with the latter most likely to be used with degraded\nvisual input. The perception of human motion is special because\nwe can produce as well as perceive human actions and because\nwe devote considerable time to making sense of it.\nIt has often been assumed that our ability to imitate and\nunderstand human motion depends on a mirror neuron system\n(an extensive brain network). This system’s causal involvement in\naction perception and understanding has been shown in research\non brain-damaged patients and studies using techniques to alter\nits neural activity. The mirror neuron system is especially important\nin the understanding of relatively simple actions. However,\nadditional high-level cognitive processes are often required if\naction understanding is complex or involves generalising from past\nexperience.\n•\nChange blindness. There is convincing evidence for change\nblindness and inattentional blindness. Change blindness depends\non attentional processes: it occurs more often when the changed\nobject does not receive attention. However, change blindness\ncan occur for objects that are fixated and it also depends on the\nlimitations of peripheral vision. The visual system’s emphasis on\ncontinuous, stable perception probably plays a part in making us\nsusceptible to change blindness. Inattentional blindness depends\nvery strongly on top-down processes (e.g., selective attention) and\ncan be found even when only the novel stimulus is present in the\nvisual field.\nFURTHER READING\nBinder, E., Dovern, A., Hesse, M.D., Ebke, M., Karbe, H., Salinger, J. et al.\n(2017). Lesion evidence for a human mirror neuron system. Cortex, 90, 125–137.\nEllen Binder and colleagues discuss the nature of the mirror neuron system based\non evidence from brain-damaged patients.\nKeysers, C., Paracampo, R. & Gazzola, V. (2018). What neuromodulation and\nlesion studies tell us about the function of the mirror neuron system and embod-\nied cognition. Current Opinion in Psychology, 24, 35–40. This article provides a\nsuccinct account of our current understanding of the mirror neuron system.\nLappi, O. & Mole, C. (2018). Visuo-motor control, eye movements, and steering: A\nunified approach for incorporating feedback, feedforward, and internal models.\nPsychological Bulletin, 144, 981–1001. Otto Lappi and Callum Mole provide\nCreated from usyd on 2022-02-13 13:26:41.",
    "Motion perception and action\n177\na comprehensive theoretical account of driving behaviour that emphasises the\nimportance of top-down control mechanisms in influencing drivers’ eye fixations.\nOsiurak, F., Rossetti, Y. & Badets, A. (2017). What is an affordance? 40 years\nlater. Neuroscience and Biobehavioral Reviews, 77, 403–417. François Osiurak\nand colleagues discuss Gibson’s notion of affordances in the contest of contem-\nporary research and theory.\nRosenholtz, R. (2017a). What modern vision science reveals about the awareness\npuzzle: Summary-statistic encoding plus decision limits underlie the richness of\nvisual perception and its quirky failures. Vision Sciences Society Symposium on\nSummary Statistics and Awareness, preprint arXiv:1706.02764. Ruth Rosenholtz\nprovides an excellent account of the role played by peripheral vision in change\nblindness and other phenomena.\nSakreida, K., Effnert, I., Thill, S., Menz, M.M., Jirak, D., Eickhoff, C.R. et al.\n(2016). Affordance processing in segregated parieto-frontal dorsal stream\nsub-pathways. Neuroscience and Biobehavioral Reviews, 69, 80–112. The path-\nways within the brain involved in goal-directed interactions with objects are dis-\ncussed in the context of a meta-analytic review.\nCreated from usyd on 2022-02-13 13:26:41.",
    "Attention and\nperformance\nINTRODUCTION\nAttention is invaluable in everyday life. We use attention to avoid being\nhit by cars when crossing the road, to search for missing objects and to\nperform two tasks together. The word “attention” has various meanings\nbut typically refers to selectivity of processing as emphasised by William\nJames (1890, pp. 403–404):\nAttention is . . . the taking into possession of the mind, in clear and\nvivid form, of one out of what seem several simultaneously possible\nobjects or trains of thought. Focalisation, concentration, of conscious-\nness are of its essence.\nWilliam James distinguished between “active” and “passive” modes of\nattention. Attention is active when controlled in a top-down way by the\nindividual’s goals or expectations. In contrast, attention is passive when\ncontrolled in a bottom-up way by external stimuli (e.g., a loud noise). This\ndistinction remains theoretically important (e.g., Corbetta & Shulman,\n2002; see discussion, pp. 192–196).\nAnother important distinction is between focused and divided atten-\ntion. Focused attention (or selective attention) is studied by present-\ning individuals with two or more stimulus inputs at the same time and\ninstructing them to respond to only one. Research on focused or selective\nattention tells us how effectively we can select certain inputs and avoid\nbeing distracted by non-task inputs. It also allows us to study the selection\nprocess and the fate of unattended stimuli.\nDivided attention is also studied by presenting at least two stimulus\ninputs at the same time. However, individuals are instructed they must\nattend (and respond) to all stimulus inputs. Divided attention is also\nknown as multi-tasking (see Glossary). Studies of divided attention provide\nuseful information about our processing limitations and the capacity of\nour attentional mechanisms.\nChapter\n5\nKEY TERMS\nFocused attention\nA situation in which\nindividuals try to attend\nto only one source of\ninformation while ignoring\nother stimuli; also known\nas selective attention.\nDivided attention\nA situation in which two\ntasks are performed at the\nsame time; also known as\nmulti-tasking.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n179\nThere is a final important distinction (the last one, I promise you!)\nbetween external and internal attention. External attention is “the selec-\ntion and modulation of sensory information” (Chun et al., 2011). In con-\ntrast, internal attention is “the selection, modulation, and maintenance of\ninternally generated information, such as task rules, responses, long-term\nmemory, or working memory” (Chun et al., 2011, p. 73). The connec-\ntion to Baddeley’s working memory model is especially important (e.g.,\nBaddeley (2012); see Chapter 6). The central executive component of\nworking memory is involved in attentional control and is crucially involved\nin internal and external attention.\nMuch attentional research has two limitations. First, the emphasis is\non attention to externally presented task stimuli rather than internally gen-\nerated stimuli (e.g., worries; self-reflection). One reason is that it is easier to\nassess and to control external attention. Second, what participants attend\nto is determined by the experimenter’s instructions. In contrast, what we\nattend to in the real world is mostly determined by our current goals and\nemotional states.\nTwo important topics related to attention are discussed elsewhere.\nChange blindness (see Glossary), which shows the close links between atten-\ntion and perception, is considered in Chapter 4. Consciousness (including\nits relationship to attention) is discussed in Chapter 16.\nFOCUSED AUDITORY ATTENTION\nMany years ago, British scientist Colin Cherry (1953) became fascinated\nby the cocktail party problem – how can we follow just one conversation\nwhen several people are talking at once? As we will see, there is no simple\nanswer.\nMcDermott (2009) identified two problems listeners face when attend-\ning to one voice among many. First, there is sound segregation: the listener\nmust decide which sounds belong together. This is complex: machine-based\nspeech recognition programs often perform poorly when attempting to\nachieve sound segregation with several sound sources present together\n(Shen et al., 2008). Second, after segregation has been achieved, the listener\nmust direct attention to the sound source of interest and ignore the others.\nMcDermott (2009) pointed out that auditory segmentation is often\nharder than visual segmentation (deciding which visual features belong\nto which objects; see Chapter 3). There is considerable overlap of signals\nfrom different sound sources in the cochlea whereas visual objects typically\noccupy different retinal regions.\nThere is another important issue – when listeners attend to one audi-\ntory input, how much processing is there of the unattended input(s)? As we\nwill see, various answers have been proposed.\nCherry (1953) addressed the issues discussed so far (see Eysenck, 2015,\nfor an evaluation of his research). He studied the cocktail party problem\nusing a dichotic listening task in which a different auditory message was\npresented to each ear and the listener attended to only one. Listeners\nengaged in shadowing (repeating the attended message aloud as it was pre-\nsented) to ensure their attention was directed to that message. However,\nthe shadowing task has two potential disadvantages: (1) listeners do not\nKEY TERMS\nCocktail party problem\nThe difficulties involved\nin attending to one voice\nwhen two or more people\nare speaking at the same\ntime.\nDichotic listening task\nA different auditory\nmessage is presented to\neach ear and attention\nhas to be directed to one\nmessage.\nShadowing\nRepeating one auditory\nmessage word for word\nas it is presented while a\nsecond auditory message\nis also presented; it is\nused on the dichotic\nlistening task.\nCreated from usyd on 2022-02-14 13:21:43.",
    "180\nVisual perception and attention\nnormally engage in shadowing and so the task is artificial; and (2) it\nincreases listeners’ processing demands.\nListeners solved the cocktail party problem by using differences between\nthe auditory inputs in physical features (e.g., sex of speaker; voice intensity;\nspeaker location). When these physical differences were eliminated by pre-\nsenting two messages in the same voice to both ears at once, listeners found\nit very hard to separate out the messages based on differences in meaning.\nCherry (1953) found very little information seemed to be extracted\nfrom the unattended message. Listeners seldom noticed when it was spoken\nbackwards or in a foreign language. However, physical changes (e.g., a\npure tone) were nearly always detected. The conclusion that unattended\ninformation receives minimal processing was supported by Moray (1959),\nwho found listeners remembered very few words presented 35 times each.\nWhere is the bottleneck? Early vs late selection\nMany psychologists have argued we have a processing bottleneck (discussed\nbelow). A bottleneck in the road (e.g., where it is especially narrow) can\ncause traffic congestion, and a bottleneck in the processing system seriously\nlimits our ability to process two (or more) simultaneous inputs. However,\nit would sometimes solve the cocktail problem by permitting listeners to\nprocess only the desired voice.\nWhere is the bottleneck? Broadbent (1958) argued a filter (bottleneck)\nearly in processing allows information from one input or message through\nit based on the message’s physical characteristics. The other input remains\nbriefly in a sensory buffer and is rejected unless attended to rapidly (see\nFigure 5.1). Thus, Broadbent argued there is early selection.\nTreisman (1964) argued the bottleneck’s location is more flexible than\nBroadbent suggested (see Figure 5.1). She claimed listeners start with pro-\ncessing based on physical cues, syllable pattern and specific words and then\nprocess grammatical structure and meaning. Later processes are omitted or\nattenuated if there is insufficient processing capacity to permit full stimulus\nanalysis.\nTreisman (1964) also argued top-down processes (e.g., expectations)\nare important. Listeners performing the shadowing task sometimes say a\nword from the unattended input. Such breakthroughs mostly occur when\nthe word on the unattended channel is highly probable in the context of\nthe attended message.\nDeutsch and Deutsch (1963) argued all stimuli are fully analysed, with\nthe most important or relevant stimulus determining the response. Thus,\nthey placed the bottleneck much later in processing than did Broadbent\n(see Figure 5.1).\nFindings: unattended input\nBroadbent’s approach predicts little or no processing of unattended audi-\ntory messages. In contrast, Treisman’s approach suggests flexibility in\nthe processing of unattended messages, whereas Deutsch and Deutsch’s\napproach implies reasonably thorough processing of such messages.\nRelevant findings are discussed below.\nInteractive exercise:\nTreisman\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n181\nFigure 5.1\nA comparison of\nBroadbent’s theory (top),\nTreisman’s theory (middle),\nand Deutsch and Deutsch’s\ntheory (bottom).\nTreisman and Riley (1969) asked listeners to shadow one of two audi-\ntory messages. They stopped shadowing and tapped when they detected\na target in either message. Many more target words were detected on the\nshadowed message.\nAydelott et al. (2015) asked listeners to perform a task on attended\ntarget words. When unattended words related in meaning were presented\nshortly before the target words themselves, performance on the target\nwords was enhanced when unattended words were presented as loudly as\nattended ones. Thus, the meaning of unattended words was processed.\nThere is often more processing of unattended words that have a special\nsignificance for the listener. For example, Li et al. (2011) obtained evidence\nthat unattended weight-related words (e.g., fat; chunky) were processed\nmore thoroughly by women dissatisfied with their weight. Conway et al.\n(2001) found listeners often detected their own name on the unattended\nmessage. This was especially the case if they had low working memory\ncapacity (see Glossary) indicative of poor attentional control.\nCoch et al. (2005) asked listeners to attend to one of two auditory\ninputs and to detect targets presented on either input. Event-related poten-\ntials (ERPs; see Glossary) provided a measure of processing activity. ERPs\n100 ms after target presentation were greater when the target was presented\non the attended rather than the unattended message. This suggests there\nwas more processing of the attended than unattended targets.\nGreater brain activation for attended than unattended auditory stimuli\nmay reflect enhanced processing for attended stimuli and/or suppressed\nprocessing for unattended stimuli. Horton et al. (2013) addressed this\nCreated from usyd on 2022-02-14 13:21:43.",
    "182\nVisual perception and attention\nissue. Listeners heard separate speech messages presented to each ear with\ninstructions to attend to the left or right ear. There was greater brain acti-\nvation associated with the attended message (especially around 90 ms after\nstimulus presentation). This difference depended on enhancement of the\nattended message combined with suppression of the unattended message.\nClassic theories of selective auditory attention (those of Broadbent,\nTreisman, and Deutsch and Deutsch) de-emphasised the importance of\nsuppression or inhibition of the unattended message shown by Horton\net al. (2013). For example, Schwartz and David (2018) reported suppres-\nsion of neuronal responses in the primary auditory cortex to distractor\nsounds. More generally, all the classic theories de-emphasise the flexibility\nof selective auditory attention and the role of top-down processes in selec-\ntion (see below).\nFindings: cocktail party problem\nHumans are generally very good at separating out and understanding one\nvoice from several speaking at the same time (i.e., solving the cocktail party\nproblem). The extent of this achievement is indicated by the finding that\nautomatic speech recognition systems are considerably inferior to human\nspeech recognition (Spille & Meyer, 2014).\nMesgarani and Chang (2012) studied listeners with implanted multi-\nelectrode arrays permitting the direct recording of activity within the audi-\ntory cortex. They heard two different messages (one in a male voice; one\nin a female voice) presented to the same ear with instructions to attend to\nonly one. The responses within the auditory cortex revealed “The salient\nspectral [based on sound frequencies] and temporal features of the attended\nspeaker, as if subjects were listening to that speaker alone” (Mesgarani &\nChang, 2012, p. 233).\nListeners found it easy to distinguish between the two messages in the\nstudy by Mesgarani and Chang (2012) because they differed in physical\ncharacteristics (i.e., male vs female voice). Olguin et al. (2018) presented\nnative English speakers with two messages in different female voices. The\nattended message was always in English whereas the unattended message\nwas in English or an unknown language. Comprehension of the attended\nmessage was comparable in both conditions. However, there was stronger\nneural encoding of both messages in the former condition. As Olguin et al.\nconcluded, “The results offer strong support to flexible accounts of selec-\ntive [auditory] attention” (p. 1618).\nIn everyday life, we are often confronted by several different speech\nstreams. Accordingly, Puvvada and Simon (2017) presented three speech\nstreams and assessed brain activity as listeners attended to only one. Early\nin processing, “the auditory cortex maintains an acoustic representation of\nthe auditory scene with no significant preference to attended over ignored\nsources” (p. 9195). Later in processing, “Higher-order auditory cortical\nareas represent an attended speech stream separately from, and with signifi-\ncantly higher fidelity [accuracy] than, unattended speech streams” (p. 9189).\nThis latter finding results from top-down processes (e.g., attention).\nHow do we solve the cocktail party problem? The importance of\ntop-down processes is suggested by the existence of extensive descending\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n183\npathways from the auditory cortex to brain areas involved in early auditory\nprocessing (Robinson & McAlpine, 2009). Various top-down factors based\non listeners’ knowledge and/or expectations are involved. For example, lis-\nteners are more accurate at identifying what one speaker is saying in the\ncontext of several other voices if they have previously heard that speaker’s\nvoice in isolation (McDermott, 2009).\nWoods and McDermott (2018) investigated top-down processes in\nselective auditory attention in more detail. They argued, “Sounds pro-\nduced by a given source often exhibit consistencies in structure that might\nbe useful in separating sources” (p. E3313). They used the term “schemas”\nto refer to such structural consistencies.\nListeners showed clear evidence of schema learning leading to rapid\nimprovements in their listening performance. An important aspect of such\nlearning is temporal coherence – a given source’s sound features are typ-\nically all present when it is active and absent when it is silent. Shamma\net al. (2011) discussed research showing that if listeners can identify one\ndistinctive feature of the target voice, they can then distinguish its other\nsound features via temporal coherence.\nEvans et al. (2016) compared patterns of brain activity when attended\nspeech was presented on its own or together with competing unattended\nspeech. Brain areas associated with attentional and control processes (e.g.,\nfrontal and parietal regions) were more activated in the latter condition.\nThus, top-down processes relating to attention and control are important\nin selective auditory processing.\nFinally, Golumbic et al. (2013) suggested individuals at actual cocktail\nparties can potentially use visual information to assist them in understand-\ning what a given speaker is saying. Listeners heard two simultaneous mes-\nsages (one in a male voice and the other in a female voice). Processing of\nthe attended message was enhanced when they saw a video of the speaker\ntalking.\nIn sum, listeners generally achieve the complex task of selecting one\nspeech message from among several such messages. There has been pro-\ngress in identifying the top-down processes involved. For example, if lis-\nteners can identify at least one consistently distinctive feature of the target\nvoice, this makes it easier for them to attend only to that voice. Top-down\nprocesses often produce a “winner-takes-all” situation where the processing\nof one auditory input (the winner) suppresses the brain activity  associated\nwith all other inputs (Kurt et al., 2008).\nFOCUSED VISUAL ATTENTION\nThere has been much more research on visual attention than auditory atten-\ntion. The main reason is that vision is our most important sense modality\nwith more of the cortex devoted to it than any other sense. Here we con-\nsider four key issues. First, what is focused visual attention like? Second,\nwhat is selected in focused visual attention? Third, what happens to unat-\ntended visual stimuli? Fourth, what are the major systems involved in visual\nattention? In the next section (see pp. 196–200), we discuss what the study\nof visual disorders has taught us about visual attention.\nCreated from usyd on 2022-02-14 13:21:43.",
    "184\nVisual perception and attention\nSpotlight, zoom lens or multiple spotlights?\nLook around you and attend to any interesting objects. Was your visual\nattention like a spotlight? A spotlight illuminates a fairly small area, little\ncan be seen outside its beam and it can be redirected to focus on any given\nobject. Posner (1980) argued the same is true of visual attention.\nOther psychologists (e.g., Eriksen & St. James, 1986) claim visual\nattention is more flexible than suggested by the spotlight analogy and\nargue visual attention resembles a zoom lens. We can increase or decrease\nthe area of focal attention just as a zoom lens can be adjusted to alter the\nvisual area it covers. This makes sense. For example, car drivers often need\nto narrow their attention after spotting a potential hazard.\nA third theoretical approach is even more flexible. According to the\nmultiple spotlights theory (Awh & Pashler, 2000), we sometimes exhibit\nsplit attention (attention directed to two or more non-adjacent regions\nin space). The notion of split attention is controversial. Jans et al. (2010)\nargued attention is often strongly linked to motor action and so attending\nto two separate objects might disrupt effective action. However, there is no\nstrong evidence for such disruption.\nFindings\nSupport for the zoom-lens model was reported by Müller et al. (2003). On\neach trial, observers saw four squares in a semi-circle and were cued to\nattend to one, two or all four. Four objects were then presented (one in\neach square) and observers decided whether a target (e.g., a white circle)\nwas among them. Brain activation in early visual areas was most wide-\nspread when the attended region was large (i.e., attend to all four squares)\nand was most limited when it was small (i.e., attend to one square). As pre-\ndicted by the zoom-lens theory, performance (reaction times and errors)\nwas best with the smallest attended region and worst with the largest one.\nChen and Cave (2016, p. 1822) argued the optimal attentional zoom\nsetting “includes all possible target locations and excludes possible distrac-\ntor locations”. Most findings indicated people’s attentional zoom setting\nis close to optimal. However, Collegio et al. (2019) obtained contrary\nfindings. Drawings of large objects (e.g., jukebox) and small objects (e.g.,\nwatch) were presented so their retinal size was the same. The observer’s\narea of focal attention was greater with large objects because they made\ntop-down inferences concerning their real-world sizes. As a result, the area\nof focal attention was larger than optimal for large objects.\nGoodhew et al. (2016) pointed out that nearly all research has focused\nonly on spatial perception (e.g., identification of a specific object). They\nfocused on temporal perception (was a disc presented continuously or\nwere there two presentations separated by a brief interval?). Spotlight size\nhad no effect on temporal acuity, which is inconsistent with the theory.\nHow can we explain these findings? Spatial resolution is poor in peripheral\nvision but temporal resolution is good. As a consequence, a small atten-\ntional spotlight is more beneficial for spatial than temporal acuity.\nWe turn now to split attention. Suppose you had to identify two digits\nthat would probably be presented to two cued locations a little way apart\nKEY TERM\nSplit attention\nAllocation of attention\nto two (or more) non-\nadjacent regions of visual\nspace.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n185\nFigure 5.2\n(a) Shaded areas indicate\nthe cued locations; the\nnear and far locations are\nnot cued. (b) Probability of\ntarget detection at valid\n(left or right) and invalid\n(near or far) locations.\nBased on information in Awh\nand Pashler (2000).\n(see Figure 5.2a). Suppose also that on some trials a digit was presented\nbetween the two cued locations. According to zoom-lens theory, the area\nof maximal attention should include the two cued locations and the space\nin between. As a result, the detection of digits presented in the middle\nshould have been very good. In fact, Awh and Pashler (2000) found it was\npoor (see Figure 5.2b). Thus, attention can resemble multiple spotlights, as\npredicted by the split-attention approach.\nMorawetz et al. (2007) presented letters and digits at five locations\nsimultaneously (one in each quadrant of the visual field and one in the\ncentre). In one condition, observers attended to the visual stimuli at the\nupper left and bottom right locations and ignored the other stimuli. There\nwere two peaks of brain activation corresponding to the attended areas but\nless activation corresponding to the region in between. Overall, the pattern\nof activation strongly suggested split attention.\nNiebergall et al. (2011) recorded the neuronal responses of monkeys\nattending to two moving stimuli while ignoring a distractor. In the key\ncondition, there was a distractor between (and close to) the two attended\nstimuli. In this condition, neuronal responses to the distractor decreased\ncompared to other conditions. Thus, split attention involves a mecha-\nnism reducing attention to (and processing of) distractors located between\nattended stimuli.\nCreated from usyd on 2022-02-14 13:21:43.",
    "186\nVisual perception and attention\nIn most research demonstrating split attention, the two non-adjacent\nstimuli being attended simultaneously were each presented to a different\nhemifield (one half of the visual field). Note that the right hemisphere\nreceives visual signals from the left hemifield and the left hemisphere\nreceives signals from the right hemifield. Walter et al. (2016) found per-\nformance was better when non-adjacent stimuli were presented to different\nhemifields rather than the same hemifield. Of most importance, the assess-\nment of brain activity indicated effective filtering or inhibition of stimuli\npresented between the two attended stimuli only when presented to differ-\nent hemifields.\nIn sum, we can use visual attention very flexibly. Visual selective atten-\ntion can resemble a spotlight, a zoom lens or multiple spotlights, depending\non the current situation and the observer’s goals. However, split attention\nmay require that two stimuli are presented to different hemifields rather\nthan the same one. A limitation with all these theories is that metaphors\n(e.g., attention is a zoom lens) are used to describe experimental findings but\nthese metaphors fail to specify the underlying mechanisms (Di Lollo, 2018).\nWhat is selected?\nWhy might selective attention resemble a spotlight or zoom lens? Perhaps\nwe selectively attend to an area or region of space: space-based attention.\nAlternatively, we may attend to a given object or objects: object-based\nattention. Object-based attention is prevalent in everyday life because visual\nattention is mainly concerned with objects of interest to us (see Chapters 2\nand 3). As expected, observers’ eye movements as they view natural scenes\nare directed almost exclusively to objects (Henderson & Hollingworth,\n1999). However, even though we typically focus on objects of potential\nimportance, our attentional system is so flexible we can attend to an area of\nspace or a given object.\nThere is also feature-based attention. For example, suppose you are\nlooking for a friend in a crowd. Since she nearly always wears red clothes,\nyou might attend to the feature of colour rather than specific objects or\nlocations. Leonard et al. (2015) asked observers to identify a red letter\nwithin a series of rapidly presented letters. Performance was impaired when\na # symbol also coloured red was presented very shortly before the target.\nThus, there was evidence for feature-based attention (e.g., colour; motion).\nFindings\nVisual attention is often object-based. For example, O’Craven et al. (1999)\npresented observers with two stimuli (a face and a house), transparently\noverlapping at the same location, with instructions to attend to one of\nthem. Brain areas associated with face processing were more activated\nwhen the face was attended to than when the house was. Similarly, brain\nareas associated with house processing were activated when the house was\nthe focus of attention.\nEgly et al. (1994) devised a much-used method for comparing object-\nbased and space-based attention (see Figure 5.3). The task was to select\na target stimulus as rapidly as possible. A cue presented before the target\nKEY TERM\nHemifield\nOne half of the visual\nfield. Information from\nthe left hemifield of each\neye proceeds to the\nright hemisphere and\ninformation from the right\nhemifield proceeds to the\nleft hemisphere.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n187\nwas valid (same location as the target) or\ninvalid (different location from the target).\nOf key importance, invalid cues were in the\nsame object as the target (within-object cues)\nor in a different object (between-object cues).\nThe key finding was that target detection was\nfaster on invalid trials when the cue was in the\nsame object rather than a different one. Thus,\nattention was at least partly object-based.\nDoes object-based attention in the Egly\net al. (1994) task occur fairly “automatically”\nor does it involve strategic processes? Object-\nbased attention should always be found if it is\nautomatic. Drummond and Shomstein (2010)\nfound no evidence for object-based attention\nwhen the cue indicated with 100% certainty\nwhere the target would appear. Thus, any\npreference for object-based attention can be\noverridden when appropriate.\nHollingworth et al. (2012) found evidence object-based and space-based\nattention can occur at the same time using a task resembling that of Egly\net al. (1994). There were three types of within-object cues varying in the\ndistance between the cue and subsequent target (see Figure 5.4). There was\nevidence for object-based attention: when the target was far from the cue,\nperformance was worse when the cue was in a different object rather than\nthe same one. There was also evidence for space-based attention: when the\ntarget was in the same object as the cue, performance declined the greater\nthe distance between target and cue. Thus, object-based and space-based\nattention are not mutually exclusive.\nSimilar findings were reported by Kimchi et al. (2016). Observers\nresponded faster to a target presented within rather than outside an object.\nThis indicates object-based attention. There was also evidence for space-\nbased attention: when targets were presented outside the object, observ-\ners responded faster when they were close to it. Kimchi et al. concluded\nthat “object-related and space-related attentional processing can operate\nsimultaneously” (p. 48).\nPilz et al. (2012) compared object-based and space-based attention\nusing various tasks. Overall, there was much more evidence of space-based\nthan object-based attention, with only a small fraction of participants\nshowing clear-cut evidence of object-based attention.\nDonovan et al. (2017) noted that most studies indicating visual atten-\ntion is object-based have used spatial cues, which may bias the allocation\nof attention. Donovan et al. avoided the use of spatial cues and found\n“Object-based representations do not guide attentional selection in the\nabsence of spatial cues” (p. 762). This finding suggests previous research\nhas exaggerated the extent of object-based visual attention.\nWhen we search the visual environment, it would be inefficient if we\nrepeatedly attended to any given location. In fact, we exhibit inhibition of\nreturn (a reduced probability of returning to a region recently the focus of\nattention). Of theoretical importance is whether inhibition of return applies\nFigure 5.3\nStimuli adapted from Egly et al. (1994). Participants saw two\nrectangles and a cue indicated the most likely location of a\nsubsequent target. The target appeared at the cued location\n(V), at the uncued end of the cued rectangle (IS) or at the\nuncued, equidistant end of the uncued rectangle (ID).\nFrom Chen (2012). © Psychonomic Society, Inc. Reprinted with\npermission from Springer.\nKEY TERM\nInhibition of return\nA reduced probability of\nvisual attention returning\nto a recently attended\nlocation or object.\nCreated from usyd on 2022-02-14 13:21:43.",
    "188\nVisual perception and attention\nmore to locations or objects. The evidence is mixed (see Chen, 2012). List\nand Robertson (2007) used Egly et al.’s (1994) task shown in Figure 5.4\nand found location- or space-based inhibition of return was much stronger\nthan object-based inhibition of return.\nTheeuwes et al. (2014) found location- and object-based inhibition of\nreturn were both present at the same time. According to Theeuwes et al.\n(p. 2254), “If you direct your attention to a location in space, you will\nautomatically direct attention to any object . . . present at that location,\nand vice versa.”\nThere is considerable evidence of feature-based attention (see Bartsch\net al., 2018, for a review). In their own research, Bartsch et al. addressed\nFigure 5.4\n(a) Possible target locations\n(same object far, same\nobject near, valid, different\nobject far) for a given cue.\n(b) Performance accuracy at\nthe various target locations.\nFrom Hollingworth et al. (2012).\n© 2011 American Psychological\nAssociation.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n189\nthe issue of whether feature-based attention to colour-defined targets is\nconfined to the spatially attended region or whether it occurs across the\nentire visual field. They discovered the latter was the case.\nFinally, Chen and Zelinsky (2019) argued it is important to study the\nallocation of attention under more naturalistic conditions than those typ-\nically used in research. In their study, observers engaged in free (uncon-\nstrained) viewing of natural scenes. Eye-fixation data suggested that\nattention initially selects regions of space. These regions may provide “the\nperceptual fragments from which objects are built” (p. 148).\nEvaluation\nResearch on whether visual attention is object- or location-based have\nproduced variable findings and so few definitive conclusions are pos-\nsible. However, the relative importance of object-based and space- or\nlocation-based attention is flexible. For example, individual differences are\nimportant (Pilz et al., 2012). Note that visual attention can be both object-\nbased and space-based at the same time.\nWhat are the limitations of research in this area? First, most research\napparently demonstrating that object-based attention is more important\nthan space- or location-based attention has involved the use of spatial\ncues. Recent evidence (Donovan et al., 2017) suggests such cues may bias\nvisual attention and that visual attention is not initially object-based in\ntheir absence.\nSecond, space-, object- and feature-based forms of attention often inter-\nact with each other to enhance object processing (Kravitz & Behrmann,\n2011). However, we have as yet limited theoretical understanding of the\nmechanisms involved in such interactions.\nThird, there is a need for more research assessing patterns of attention\nunder naturalistic conditions. In recent research where observers view artifi-\ncial stimuli while performing a specific task, it is unclear whether attentional\nprocesses resemble those when they engage in free viewing of natural scenes.\nWhat happens to unattended or distracting stimuli?\nUnsurprisingly, unattended visual stimuli receive less processing than\nattended ones. Martinez et al. (1999) compared event-related potentials\n(ERPs) to attended and unattended visual stimuli. The ERPs to unattended\nvisual stimuli were comparable to those to attended ones 50–55 ms after\nstimulus onset. After that, however, the ERPs to attended stimuli were\ngreater than those to unattended stimuli. Thus, selective attention influ-\nences all but the very early stages of processing.\nAs we have all discovered to our cost, it is often hard (or impossible)\nto ignore task-irrelevant stimuli. Below we consider factors determining\nwhether task performance is adversely affected by distracting stimuli.\nLoad theory\nLavie’s (2005, 2010) load theory has been an influential approach to\nunderstanding distraction effects. It distinguishes between perceptual\nCreated from usyd on 2022-02-14 13:21:43.",
    "190\nVisual perception and attention\nand cognitive load. Perceptual load refers to the perceptual demands of a\ncurrent task. Cognitive load refers to the burden placed on the cognitive\nsystem by a current task (e.g., demands on working memory).\nTasks involving high perceptual load require nearly all our perceptual\ncapacity whereas low-load tasks do not. With low-load tasks there are\nspare attentional resources, and so task-irrelevant stimuli are more likely\nto be processed. In contrast, tasks involving high cognitive load reduce our\nability to use cognitive control to discriminate between target and distrac-\ntor stimuli. Thus, high perceptual load is associated with low distractibility,\nwhereas high cognitive load is associated with high distractibility.\nFindings\nThere is much support for the hypothesis that high perceptual load reduces\ndistraction effects. Forster and Lavie (2008) presented six letters in a circle\nand participants decided which target letter (X or N) was present. The five\nnon-target letters resembled the target letter more closely in the high-load\ncondition. On some trials a picture of a cartoon character (e.g., Spongebob\nSquarepants) was presented as a distractor outside the circle. Distractors\ninterfered with task performance only under low-load conditions.\nAccording to the theory, brain activation associated with distractors\nshould be less when individuals are performing a task involving high per-\nceptual load. This finding has been obtained with visual tasks and distrac-\ntors (e.g., Schwartz et al., 2005) and also with auditory tasks and distractors\n(e.g., Sabri et al., 2013).\nWhy is low perceptual load associated with high distractibility? Biggs\nand Gibson (2018) argued this happens because observers generally adopt\na broad attentional focus when perceptual load is low. They tested this\nhypothesis using three low-load conditions in which participants decided\nwhether a target X or N was presented and a distractor letter was some-\ntimes presented (see Figure 5.5). They argued that observers would adopt\nthe smallest attentional focus in the circle condition and the largest atten-\ntional focus in the solo condition. As predicted, distractor interference was\ngreatest in the solo condition and least in the circle condition. Thus, dis-\ntraction effects depend strongly on size of attentional focus as well as per-\nceptual load.\nThe hypothesis that distraction effects should be greater when cognitive\nor working memory load is high rather than low was tested by Burnham\net al. (2014). As predicted, distraction effects on a visual search task were\nFigure 5.5\nSample displays for three\nlow perceptual load\nconditions in which the\ntask required deciding\nwhether a target X or N\nwas presented. See text for\nfurther details.\nFrom Biggs and Gibson (2018).\nX\nStandard condition\nT\n*\n*\n*\n*\n*\nX\nSolo condition\nT\nX\nCircle condition\nT\n*\n*\n*\n*\n*\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n191\ngreater when participants performed another task placing high demands\non the cognitive system.\nSörqvist et al. (2016) argued high cognitive load can reduce rather than\nincrease distraction. They pointed out that cognitive load is typically asso-\nciated with high levels of concentration and our everyday experience indi-\ncates high concentration generally reduces distractibility. As predicted, they\nfound neural activation associated with auditory distractors was reduced\nwhen cognitive load on a visual task was high rather than low.\nThe effects of cognitive load on distraction are very variable. How can\nwe explain this variability? Sörqvist et al. (2016) argued that an impor-\ntant factor is how easily distracting stimuli can be distinguished from task\nstimuli. When it is easy (e.g., task and distracting stimuli are in differ-\nent modalities as in the Sörqvist et al., 2016, study), high cognitive load\nreduces distraction. In contrast, when it is hard to distinguish between task\nand distracting stimuli (e.g., they are similar and/or in the same modality),\nthen high cognitive load increases distraction.\nLoad theory assumes the effects of perceptual and cognitive load are\nindependent. However, Linnell and Caparos (2011) found perceptual and\ncognitive processes interacted: perceptual load only influenced attention as\npredicted when cognitive load was low. Thus, the effects of perceptual load\nare not “automatic” as assumed theoretically but instead depend on cogni-\ntive resources being available.\nEvaluation\nThe distinction between perceptual and cognitive load has proved useful\nin predicting when distraction effects will be small or large. More specifi-\ncally, the prediction that high perceptual load is associated with reduced\ndistraction effects has received much empirical support. In applied research,\nload theory successfully predicts several aspects of drivers’ attention and\nbehaviour (Murphy & Greene, 2017). For example, drivers exposed to high\nperceptual load responded more slowly to hazards and drove less safely.\nWhat are the theory’s limitations? First, the terms “perceptual load”\nand “cognitive load” are vague, making it hard to test the theory (Murphy\net al., 2016). Second, the assumption that perceptual and cognitive load\nhave separate effects on attention is incorrect (Linnell & Caparos, 2011).\nThird, perceptual load and attentional breadth are often confounded.\nFourth, the prediction that high cognitive load is associated with high\ndistractibility has been disproved when task and distracting stimuli are\neasily distinguishable. Fifth, the theory de-emphasises several relevant\nfactors including the salience or conspicuousness of distracting stimuli and\nthe  spatial distance between distracting and task stimuli (Murphy et al.,\n2016).\nMajor attention networks\nAs we saw in Chapter 1, many cognitive processes are associated with net-\nworks spread across relatively large areas of cortex rather than small, spe-\ncific regions. With respect to attention, several theorists (e.g., Posner, 1980;\nCorbetta & Shulman, 2002) have argued there are two major networks.\nCreated from usyd on 2022-02-14 13:21:43.",
    "192\nVisual perception and attention\nOne attention network is goal-directed or endogenous whereas the other is\nstimulus-driven or exogenous.\nPosner’s (1980) approach\nPosner (1980) studied covert attention in which attention shifts to a given\nspatial location without an accompanying eye movement. In his research,\npeople responded rapidly to a light. The light was preceded by a central\ncue (arrow pointing to the left or right) or a peripheral cue (brief illumina-\ntion of a box outline). Most cues were valid (i.e., indicating where the target\nlight would appear) but some were invalid (i.e., providing inaccurate infor-\nmation about the light’s location).\nResponses to the light were fastest to valid cues, intermediate to neutral\ncues (a central cross) and slowest to invalid cues. The findings were com-\nparable for central and peripheral cues. When the cues were valid on only\na small fraction of trials, they were ignored when they were central cues.\nHowever, they influenced performance when they were peripheral cues.\nThe above findings led Posner (1980) to distinguish between two atten-\ntion systems:\n(1) An endogenous system: it is controlled by the individual’s intentions\nand is used when central cues are presented.\n(2) An exogenous system: it automatically shifts attention and is involved\nwhen uninformative peripheral cues are presented. Stimuli that are\nsalient or different from other stimuli (e.g., in colour) are most likely\nto be attended to using this system.\nCorbetta and Shulman’s (2002) approach\nCorbetta and Shulman (2002) identified two attention systems that are\ninvolved in basic aspects of visual processing. First, there is a goal-directed\nor top-down system resembling Posner’s endogenous system. This dorsal\nattention network consists of a fronto-parietal network including the intra-\nparietal sulcus. It is influenced by expectations, knowledge and current\ngoals. It is used when a cue predicts the location or other feature of a forth-\ncoming visual stimulus.\nSecond, Corbetta and Shulman (2002) identified a stimulus-driven or\nbottom-up attention system resembling Posner’s exogenous system. This is\nthe ventral attention network and consists primarily of a right- hemisphere\nventral fronto-parietal network. This system is used when an unexpected\nand potentially important stimulus (e.g., flames appearing under the door)\noccurs. Thus, it has a “circuit-breaking” function, meaning visual atten-\ntion is redirected from its current focus. What stimuli trigger this circuit-\nbreaking? According to Corbetta et al. (2008), non-task stimuli (i.e.,\ndistractors) closely resembling task stimuli are especially likely to activate\nthe ventral attention network although salient or conspicuous stimuli also\nactivate the same network.\nCorbetta and Shulman (2011; see Figure 5.6) identified the brain\nareas associated with each network. Key areas within the dorsal attention\nnetwork are as follows: superior parietal lobule (SPL), intraparietal sulcus\nKEY TERM\nCovert attention\nAttention to an object\nin the absence of an eye\nmovement towards it.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n193\n(IPS), inferior frontal junction (IFJ), frontal eye field (FEF), middle tem-\nporal area (MT) and V3A (a visual area). Key areas within the ventral\nattention network are as follows: inferior frontal junction (IFJ), inferior\nfrontal gyrus (IFG), supramarginal gyrus (SMG), superior temporal gyrus\n(STG) and insula (Ins). The temporo-parietal junction also forms part of\nthe ventral attention network.\nThe existence of two attention networks makes much sense. The\ngoal-directed system (dorsal attention network) allows us to attend to\nstimuli directly relevant to our current goals. If we only had this system,\nhowever, our attentional processes would be dangerously inflexible. It is\nalso important to have a stimulus-driven attentional system (ventral atten-\ntion network) leading us to switch attention away from goal-relevant stimuli\nto unexpected threatening stimuli (e.g., a ferocious animal). More generally,\nthe two attention networks typically interact effectively with each other.\nFindings\nCorbetta and Shulman (2002) supported their two-network model by car-\nrying out meta-analyses of brain-imaging studies. In essence, they argued,\nbrain areas most often activated when participants expect a stimulus that\nhas not yet been presented form the dorsal attention network. In contrast,\nbrain areas most often activated when individuals detect low-frequency\ntargets form the ventral attention network.\nHahn et al. (2006) tested Corbetta and Shulman’s (2002) theory by\ncomparing patterns of brain activation when top-down and bottom-up\nprocesses were required. As predicted, there was little overlap between the\nbrain areas associated with top-down and bottom-up processing. In addi-\ntion, the brain areas involved in each type of processing corresponded rea-\nsonably well to those identified by Corbetta and Shulman.\nChica et al. (2013) reviewed research on the two attention systems and\nidentified 15 differences between them. For example, stimulus-driven atten-\ntion is faster than top-down attention and is more object-based. In addi-\ntion, it is more resistant to interference from other peripheral cues once\nactivated. The existence of so many differences strengthens the argument\nthe two attentional systems are separate.\nConsiderable research evidence (mostly involving neuroimaging) indi-\ncates the dorsal and ventral attention systems are associated with distinct\nFigure 5.6\nThe brain areas associated\nwith the dorsal or goal-\ndirected attention network\nand the ventral or stimulus-\ndriven network. The full\nnames of the areas involved\nare indicated in the text.\nFrom Corbetta and Shulman\n(2011). © Annual Reviews. With\npermission of Annual Reviews.\nCreated from usyd on 2022-02-14 13:21:43.",
    "194\nVisual perception and attention\nneural circuits even during the resting state (Vossel et al., 2014). However,\nneuroimaging studies cannot establish that any given brain area is necessar-\nily involved in stimulus-driven or goal-directed attention processes. Chica\net al. (2011) provided relevant evidence by using transcranial magnetic\nstimulation (TMS; see Glossary) to interfere with processing in a given\nbrain area. TMS applied to the right temporo-parietal junction impaired\nthe functioning of the stimulus-driven system but not the top-down one.\nIn the same study, Chica et al. (2011) found TMS applied to the right\nintraparietal sulcus impaired the functioning of both attention systems.\nThis provides evidence of the two attention systems working together.\nEvidence from brain-damaged patients (discussed below, see pp. 196–200)\nis also relevant to establishing the brain areas necessarily involved in goal-\ndirected or stimulus-driven attentional processes. Shomstein et  al. (2010)\nhad brain-damaged patients complete two tasks, one requiring stimulus-\ndriven attentional processes whereas the other required top-down processes.\nPatients having greater problems with top-down attentional processing typ-\nically had brain damage to the superior parietal lobule (part of the dorsal\nattention network). In contrast, patients having greater problems with\nstimulus-driven attentional processing typically had brain damage to the\ntemporo- parietal junction (part of the ventral attention network).\nWen et al. (2012) investigated interactions between the two visual atten-\ntion systems. They assessed brain activation while participants responded to\ntarget stimuli in one visual field while ignoring all stimuli in the unattended\nvisual field. There were two main findings. First, stronger causal influences\nof the top-down system on the stimulus-driven system led to superior per-\nformance on the task. This finding suggests the appearance of an object\nat the attended location caused the top-down attention system to suppress\nactivity within the stimulus-driven system.\nSecond, stronger causal influences of the stimulus-driven system\non the top-down system were associated with impaired task performance.\nThis finding suggests activation within the stimulus-driven system pro-\nduced  by  stimuli not in attentional focus disrupted the attentional set\nmaintained by the top-down system.\nRecent developments\nCorbetta and Shulman’s (2002) theoretical approach has been developed\nin recent years. Here we briefly consider three such developments. First, we\nnow have a greater understanding of interactions between their two atten-\ntion networks. Meyer et al. (2018) found stimulus-driven and goal-directed\nattention both activated frontal and parietal regions within the dorsal\nattention network, suggesting it has a pivotal role in integrating bottom-up\nand top-down processing.\nSecond, previous research reviewed by Corbetta and Shulman (2002)\nindicated the dorsal attention network is active immediately prior to the\npresentation of an anticipated visual stimulus. However, this research did\nnot indicate how long this attention network remained active. Meehan\net al. (2017) addressed this issue and discovered that top-down influences\nassociated within the dorsal attention network persisted over a relatively\nlong time period.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n195\nThird, brain networks relevant to attention additional to those within\nCorbetta and Shulman’s (2002) theory have been identified (Sylvester\net al., 2012). One such network is the cingulo-opercular network including\nthe anterior insula/operculum and dorsal anterior cingulate cortex (dACC;\nsee Figure 5.7). This network is associated with non-selective attention or\nalertness (Coste & Kleinschmidt, 2016).\nAnother additional network is the default mode network including\nthe posterior cingulate cortex (PCC), the lateral parietal cortex (LP), the\ninferior temporal cortex (IT), the medial prefrontal cortex (MPF) and the\nsubgenual anterior cingulate cortex (sgACC). The default mode network\nis activated during internally focused cognitive processes (e.g., mind-\nwandering; imagining the future). What is the relevance of this network\nto attention? In essence, performance on tasks requiring externally focused\nattention is often enhanced if the default mode network is deactivated\n(Amer et al., 2016a).\nFinally, there is the fronto-parietal network (Dosenbach et al., 2008),\nwhich includes the anterior dorsolateral prefrontal cortex (aDLPFC), the\nKEY TERM\nDefault mode network\nA network of brain\nregions that is active\n“by default” when an\nindividual is not involved\nin a current task; it is\nassociated with internal\nprocesses including mind-\nwandering, remembering\nthe past and imagining\nthe future.\nFigure 5.7\nThis is part of a theoretical\napproach based on several\nfunctional networks of\nrelevance to attention:\nthe four networks shown\n(fronto-parietal; default\nmode; cingulo-opercular;\nand ventral attention) are all\ndiscussed fully in the text.\nSylvester et al., 2012, p. 528.\nReprinted with permission of\nElsevier.\nMPF\nsgACC\ndACC\nMCC\nIPS\naDLPFC\n(a)\n(b)\nKey:\nFronto-parietal\nCingulo-opercular\nDefault mode\nVentral attention\nNetworks\nTPJ\nVLPFC\nLP\nIT\nanterior insula\nPCC\nCreated from usyd on 2022-02-14 13:21:43.",
    "196\nVisual perception and attention\nmiddle cingulate cortex (MCC) and the intraparietal sulcus (IPS). It is\nassociated with top-down attentional and cognitive control.\nEvaluation\nThe theoretical approach proposed by Corbetta and Shulman (2002) has\nseveral successes to its credit. First, there is convincing evidence for some-\nwhat separate stimulus-driven and top-down attention systems, each with\nits own brain network. Second, research using transcranial magnetic stimu-\nlation suggests major brain areas within each attention system play a causal\nrole in attentional processes. Third, some interactions between the two net-\nworks have been identified. Fourth, research on brain-damaged patients\nsupports the theoretical approach (see next section, pp. 196–200).\nWhat are the limitations of this theoretical approach? First, the precise\nbrain areas associated with each attentional system have not been clearly\nidentified. Second, there is more commonality (especially within the pari-\netal lobe) in the brain areas associated with the two attention networks\nthan assumed theoretically by Corbetta and Shulman (2002). Third, there\nare additional attention-related brain networks not included within the\noriginal theory. Fourth, much remains to be discovered about how differ-\nent attention systems interact.\nDISORDERS OF VISUAL ATTENTION\nHere we consider two important attentional disorders in brain-damaged\nindividuals: neglect and extinction. Neglect (or spatial neglect) involves a\nlack of awareness of stimuli presented to the side of space on the oppo-\nsite side to the brain damage (the contralesional side). This occurs because\ninformation from the left side of the visual field proceeds to the right\nhemisphere.\nMost neglect patients have damage in the right hemisphere and so\nlack awareness of stimuli on the left side of the visual field: space-based or\negocentric neglect. For example, patients crossing out targets presented to\ntheir left or right side (cancellation task) cross out more of those presented\nto the right. When instructed to mark the centre of a horizontal line (line\nbisection task), patients put it to the right of the centre. Note that the right\nhemisphere is dominant in spatial attention in healthy individuals – they\nexhibit pseudo-neglect, in which the left side of visual space is favoured\n(Friedrich et al., 2018).\nThere is also object-centred or allocentric neglect involving a lack\nof awareness of the left side of objects (see Figure 5.8). Patients with\nright-hemisphere damage typically draw the right side of all figures in a\nmulti-object scene but neglect their left side in the left and right visual\nfields (Gainotti & Ciaraffa, 2013).\nDo allocentric and egocentric neglect reflect a single disorder or sepa-\nrate disorders? Rorden et al. (2012) obtained two findings supporting the\nsingle disorder explanation. First, the correlation between the extent of\neach form of neglect across 33 patients was +.80. Second, similar brain\nregions were associated with each type of neglect. However, Pedrazzini\net al. (2017) found damage to the intraparietal sulcus was more associated\nKEY TERMS\nNeglect\nA disorder involving\nright-hemisphere damage\n(typically) in which the\nleft side of objects and/\nor objects presented to\nthe left visual field are\nundetected; the condition\nresembles extinction but\nis more severe.\nPseudo-neglect\nA slight tendency in\nhealthy individuals to\nfavour the left side of\nvisual space.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n197\nwith allocentric than egocentric neglect, whereas the opposite was the case\nwith damage to the temporo-parietal junction.\nExtinction is often found in neglect patients. Extinction involves a\nfailure to detect a stimulus presented to the side opposite the brain damage\nwhen a second stimulus is presented to the same side as the brain damage.\nExtinction and neglect are closely related but separate deficits (de Haan\net al., 2012). We will focus mostly on neglect because it has attracted much\nmore research.\nWhich brain areas are damaged in neglect patients? Neglect is a het-\nerogeneous condition and the brain areas damaged vary considerably\nacross patients. In a meta-analysis, Molenberghs et al. (2012) found the\nmain areas damaged in neglect patients are in the right hemisphere and\ninclude the superior temporal gyrus, the inferior frontal gyrus, the insula,\nthe supramarginal gyrus and the angular gyrus (gyrus means ridge). Nearly\nall these areas are within the stimulus-driven or ventral attention network\n(see Figure 5.6) suggesting brain networks are damaged rather than simply\nspecific brain areas (Corbetta & Shulman, 2011).\nWe also need to consider functional connectivity (correlated brain\nactivity between brain regions). Baldassarre et al. (2014, 2016) discovered\nwidespread disruption of functional connectivity between the hemispheres\nin neglect patients. This disruption did not involve the bottom-up and top-\ndown attention networks. Of importance, recovery from attention deficits\nin neglect patients was associated with improvements in functional con-\nnectivity in bottom-up and top-down attention networks (Ramsey et al.,\n2016).\nThe right-hemisphere temporo-parietal junction and intraparietal sulcus\nare typically damaged in extinction patients (de Haan et al., 2012). When\ntranscranial magnetic stimulation is applied to these areas to interfere with\nprocessing, extinction-like behaviour results (de Haan et al., 2012). Dugué\net al. (2018) confirmed the importance of the temporo-parietal junction\nFigure 5.8\nOn the left is a copying\ntask in which a patient with\nunilateral neglect distorted\nor ignored the left side of\nthe figures to be copied\n(shown on the left). On the\nright is a clock drawing\ntask in which the patient\nwas given a clock face and\ntold to insert the numbers\ninto it.\nReprinted from Danckert and\nFerber (2006). Reprinted with\npermission from Elsevier.\nKEY TERM\nExtinction\nA disorder of visual\nattention in which a\nstimulus presented to the\nside opposite the brain\ndamage is not detected\nwhen another stimulus is\npresented at the same\ntime to the side of the\nbrain damage.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-14 13:21:43.",
    "198\nVisual perception and attention\n(part of the ventral attention network) in control of spatial attention in a\nneuroimaging study on healthy individuals. However, its subregions varied\nin terms of their involvement in voluntary and involuntary attention shifts.\nConscious awareness and processing\nNeglect patients generally report no conscious awareness of stimuli pre-\nsented to the left visual field. However, that does not necessarily mean those\nstimuli are not processed. Vuilleumier et al. (2002b) presented extinction\npatients with two pictures at the same time, one to each visual field. The\npatients showed very little memory for left-field stimuli. Then the patients\nidentified degraded pictures. There was a facilitation effect for left-field pic-\ntures indicating they had been processed.\nVuilleumier et al. (2002a) presented GK, a male patient with neglect\nand extinction, with fearful faces. He showed increased activation in the\namygdala (associated with emotional responses) whether or not these faces\nwere consciously perceived. This is explicable given there is a processing\nroute from the retina to the amygdala bypassing the cortex (Diano et al.,\n2017).\nSarri et al. (2010) found extinction patients had no awareness of left-\nfield stimuli. However, these stimuli were associated with activation in\nearly visual processing areas, indicating they received some processing.\nProcessing in neglect and extinction has been investigated using\nevent-related potentials. Di Russo et al. (2008) focused on the processing\nof left-field stimuli not consciously perceived by neglect patients. Early\nprocessing of these stimuli was comparable to that of healthy controls with\nonly later processing being disrupted. Lasaponara et al. (2018) obtained\nsimilar findings in neglect patients. In healthy individuals, the presentation\nof left-field targets inhibits processing of right-field space. This was less\nthe case in neglect patients, which helps to explain their lack of conscious\nperception of left-field stimuli.\nTheoretical considerations\nCorbetta and Shulman (2011) discussed neglect in the context of their\ntwo-system theory (discussed earlier, see pp. 192–196). In essence, the\nbottom-up ventral attention network is damaged. Strong support for this\nassumption was reported by Toba et al. (2018a) who found in 25 neglect\npatients that impaired performance on tests of neglect was associated with\ndamage to parts of the ventral attention network (e.g., angular gyrus;\nsupramarginal gyrus). Since the right hemisphere is dominant in the ventral\nattention network, neglect patients typically have damage in that hem-\nisphere. Of importance, Corbetta and Shulman (2011) also assumed that\ndamage to the ventral network impairs the functioning of the goal-directed\ndorsal attention network (even though not itself damaged).\nHow does the damaged ventral attention network impair the dorsal\nattention network’s functioning? The two attention networks interact and\nso damage to the ventral network inevitably affects the functioning of the\ndorsal network. More specifically, damage to the ventral attention network\n“impairs non-spatial [across the entire visual field] functions, hypoactivates\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n199\n[reduces activation in] the right hemisphere, and unbalances the activity of\nthe dorsal attention network” (Corbetta & Shulman, 2011, p. 592).\nde Haan et al. (2012) proposed a theory of extinction based on two\nmajor assumptions:\n(1) “Extinction is a consequence of biased competition for attention\nbetween the ipsilesional [right-field] and contralesional [left-field]\ntarget stimuli” (p. 1048);\n(2) Extinction patients have much reduced attentional capacity so often\nonly one target [the right-field one] can be detected.\nFindings\nAccording to Corbetta and Shulman (2011), the dorsal attention network in\nneglect patients functions poorly because of reduced activation in the right\nhemisphere and associated reduced alertness and attentional resources.\nThus, increasing patients’ general alertness should enhance their detection\nof left-field visual targets. Robertson et al. (1998) found the slower detec-\ntion of left visual field stimuli compared to those in the right visual field was\nno longer present when warning sounds were used to increase alertness.\nBonato and Cutini (2016) compared neglect patients’ ability to detect\nvisual targets with (or without) a second, attentionally demanding task.\nDetection rates were high for targets presented to the right visual field in\nboth conditions. In contrast, patients detected only approximately 50% as\nmany targets in the left visual field as the right when performing another\ntask. Thus, neglect patients have limited attentional resources.\nCorbetta and Shulman (2011) assumed neglect patients have an essen-\ntially intact dorsal attention network. Accordingly, neglect patients might\nuse that network effectively if steps were taken to facilitate its use. Duncan\net al. (1999) presented arrays of letters and neglect patients recalled only\nthose in a pre-specified colour (the dorsal attention network could be used\nto select the appropriate letters). Neglect patients resembled healthy con-\ntrols in showing equal recall of letters presented to each side of visual space.\nThe two attention networks typically work closely together. Bays et al.\n(2010) studied neglect patients. They used eye movements during a visual\nsearch to assess patients’ problems with top-down and stimulus-driven\nattentional processes. Both types of attentional processes were equally\nimpaired (as predicted by Corbetta and Shulman, 2011). Of most impor-\ntance, there was a remarkably high correlation of +.98 between these two\ntypes of attentional deficit.\nToba et al. (2018b) identified two reasons for the failure of neglect\npatients to detect left-field stimuli:\n(1) a “magnetic” attraction of attention (i.e., right-field stimuli immedi-\nately capture attention).\n(2) impaired spatial working memory making it hard for patients to keep\ntrack of the locations of stimuli.\nBoth reasons were equally applicable to most patients. However, the\nfirst reason was dominant in 12% of patients and the second reason in\nCreated from usyd on 2022-02-14 13:21:43.",
    "200\nVisual perception and attention\n24% of patients. Accordingly, Toba et al. argued we should develop\nmulti-component models of visual neglect to account for such individual\ndifferences.\nWe turn now to extinction patients. According to de Haan et al.\n(2012), extinction occurs because of biased competition between stimuli.\nIf two stimuli could be integrated, that might minimise competition and so\nreduce extinction. Riddoch et al. (2006) tested this prediction by present-\ning objects used together often (e.g., wine bottle and wine glass) or never\nused together (e.g., wine bottle and ball). Extinction patients identified both\nobjects more often in the former condition than the latter (65% vs 40%,\nrespectively).\nThe biased competition hypothesis has been tested in other ways. We\ncan impair attentional processes in the intact left hemisphere by applying\ntranscranial magnetic stimulation to it. This should reduce competition\nfrom the left hemisphere in extinction patients and thus reduce extinction.\nSome findings are consistent with this prediction (Oliveri & Caltagirone,\n2006).\nde Haan et al. (2012) also identified reduced attentional capacity as a\nfactor causing extinction. Bonato et al. (2010) studied extinction with or\nwithout the addition of a second, attentionally demanding task. As pre-\ndicted, extinction patients showed a substantial increase in the extinction\nrate (from 18% to over 80%) with this additional task.\nOverall evaluation\nResearch has produced several important findings. First, neglect and\nextinction patients can process unattended visual stimuli in the absence of\nconscious awareness of those stimuli. Second, most neglect patients have\ndamage to the ventral attention network leading to impaired functioning of\nthe undamaged dorsal attention network. Third, extinction occurs because\nof biased competition for attention and reduced attentional capacity.\nWhat are the limitations of research in this area? First, it is hard\nto produce theoretical accounts applicable to all neglect or extinction\npatients because the precise symptoms and regions of brain damage\nvary considerably across patients. Second, neglect patients vary in their\nprecise processing deficits (e.g., Toba et al., 2018b), but this has been\nde-emphasised in most theories. Third, the precise relationship between\nneglect and  extinction remains unclear. Fourth, the dorsal and ventral\nnetworks generally interact but the extent of their interactions remains to\nbe determined.\nVISUAL SEARCH\nWe spend much time searching for various objects (e.g., a friend in a\ncrowd). The processes involved have been studied in research on visual\nsearch where a specified target is detected as rapidly as possible. Initially,\nwe consider an important real-world situation where visual search can be\nliterally a matter of life-or-death: airport security checks. After that, we\nconsider an early very influential theory of visual search before discussing\nmore recent theoretical and empirical developments.\nKEY TERM\nVisual search\nA task involving the rapid\ndetection of a specified\ntarget stimulus within a\nvisual display.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n201\nIN THE REAL WORLD: AIRPORT SECURITY CHECKS\nAirport security checks have become more thorough since 9/11. When your luggage is x-rayed, an\nairport security screener searches for illegal and dangerous items (see Figure 5.9). Screeners are\nwell trained but mistakes sometimes occur.\nThere are two major reasons it is often hard for airport security screeners to detect dangerous\nitems. First, illegal and dangerous items are (thankfully!) present in only a minute fraction of pas-\nsengers’ luggage. This rarity of targets makes it hard for airport security screeners to detect them.\nMitroff and Biggs (2014) asked observers to detect illegal items in bags (see Figure 5.9). The\ndetection rate was only 27% when targets appeared under 0.15% of the time: they termed this\nthe “ultra rare item effect”. In contrast, the detection rate was 92% when targets appeared more\nthan 1% of the time.\nPeltier and Becker (2016) tested two explanations for the reduced detection rate with rare targets:\n(1) a reduced probability that the target is fixated (selection error); and (2) increased caution about\nreporting targets because they are so unexpected (identification error). There was evidence for\nboth explanations. However, most detection failures were selection errors (see Figure 5.10).\nFigure 5.9\nEach bag contains one illegal item. From left to right: a large bottle; a dynamite stick; and a gun part.\nFrom Mitroff & Biggs (2014).\n10\n50\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nAccuracy\nPrevalence\nAccuracy\n90\nTarget present\nTarget absent\nFigure 5.10\nFrequency of selection and identification errors when targets were present on 10%, 50% or 90% of trials.\nFrom Peltier and Becker (2016).\nCreated from usyd on 2022-02-14 13:21:43.",
    "202\nVisual perception and attention\nFeature integration theory\nFeature integration theory was proposed by Treisman and Gelade (1980)\nand subsequently updated and modified (e.g., Treisman, 1998). According\nto the theory, we need to distinguish between object features (e.g., colour;\nsize; line orientation) and the objects themselves. There are two processing\nstages:\n(1) Basic visual features are processed rapidly and pre-attentively in par-\nallel across the visual scene.\n(2) Stage (1) is followed by a slower serial process with focused atten-\ntion providing the “glue” to form objects from the available features\n(e.g., an object that is round and has an orange colour is perceived\nas an orange). In the absence of focused attention, features from\ndifferent objects may be combined randomly producing an illusory\nconjunction.\nIt follows from the above assumptions that targets defined by a single feature\n(e.g., a blue letter or an S) should be detected rapidly and in parallel. In\ncontrast, targets defined by a conjunction or combination of features (e.g., a\ngreen letter T) should require focused attention and so should be slower to\ndetect. Treisman and Gelade (1980) tested these predictions using both types\nof targets; the display size was 1–30 items and a target was present or absent.\nAs predicted, response was rapid and there was very little effect of\ndisplay size when the target was defined by a single feature: these findings\nsuggest parallel processing (see Figure 5.11). Response was slower and was\nstrongly influenced by display size when the target was defined by a con-\njunction of features: these findings suggest there was serial processing.\nAccording to the theory, lack of focused attention can produce illusory\nconjunctions based on random combinations of features. Friedman-Hill\nSecond, security screeners search for numerous different objects. This increases search difficulty.\nMenneer et al. (2009) found target detection was worse when screeners searched for two catego-\nries of objects (metal threats and improvised explosive devices) rather than one.\nHow can we increase the efficiency of security screening? First, we can exploit individual dif-\nferences in the ability to detect targets. Rusconi et al. (2015) found individuals scoring high on a\nquestionnaire measure of attention to detail had superior target-detection performance than low\nscorers.\nSecond, airport security screeners can find it hard to distinguish between targets (i.e., danger-\nous items) and similar-looking non-targets. Geng et al. (2017) found that observers whose training\nincluded non-targets resembling targets learned to develop increasingly precise internal target\nrepresentations. Such representations can improve the speed and accuracy of security screening.\nThird, the low detection rate when targets are very rare can be addressed. Threat image pro-\njection (TIP) can be used to project fictional threat items into x-ray images of luggage to increase\nthe apparent frequency of targets. When screeners are presented with TIPs plus feedback when\nthey miss them, screening performance improves considerably (Hofer & Schwaninger, 2005). In\nsimilar fashion, Schwark et al. (2012) found providing false feedback to screeners to indicate they\nhad missed rare targets reduced their cautiousness about reporting targets and improved their\nperformance.\nKEY TERM\nIllusory conjunction\nMistakenly combining\nfeatures from two\ndifferent stimuli to\nperceive an object that is\nnot present.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n203\net al. (1995) studied a brain-damaged patient (RM) having problems with\nthe accurate location of visual stimuli. This patient produced many illu-\nsory conjunctions combining the shape of one stimulus with the colour of\nanother.\nLimitations\nWhat are the theory’s limitations? First, Duncan and Humphreys (1989,\n1992) identified two factors not included within feature integration theory:\n(1) When distractors are very similar to each other, visual search is faster\nbecause it is easier to identify them as distractors.\n(2) The number of distractors has a strong effect on search time to\ndetect even targets defined by a single feature when targets resemble\ndistractors.\nSecond, Treisman and Gelade (1980) estimated the search time with con-\njunctive targets was approximately 60 ms per item and argued this repre-\nsented the time taken for focal attention to process each item. However,\nresearch with other paradigms indicates it takes approximately 250 ms for\nattention indexed by eye movements to move from one location to another.\nThus, it is improbable focal attention plays the key role assumed within the\ntheory.\nThird, the theory assumes visual search is often item-by-item. However,\nthe information contained within most visual scenes cannot be divided up\ninto “items” and so the theory is of limited applicability. Such considera-\ntions led Hulleman and Olivers (2017) to produce an article entitled “The\nimpending demise of the item in visual search”.\nFourth, visual search involves parallel processing much more than\nimplied by the theory. For example, Thornton and Gilden (2007) used\n29 different visual tasks and found 72% apparently involved parallel\nFigure 5.11\nPerformance speed on\na detection task as a\nfunction of target deﬁnition\n(conjunctive vs single\nfeature) and display size.\nAdapted from Treisman and\nGelade (1980).\nCreated from usyd on 2022-02-14 13:21:43.",
    "204\nVisual perception and attention\nprocessing. We can explain such findings by assuming that each eye fixa-\ntion permits considerable parallel processing using information available in\nperipheral vision (discussed below, see pp. 206–208).\nFifth, the theory assumes that the early stages of visual search are\nentirely feature-based. However, recent research using event-related poten-\ntials indicates that object-based processing can occur much faster than pre-\ndicted by feature integration theory (e.g., Berggren & Eimer, 2018).\nSixth, the theory assumes visual search is essentially random. This\nassumption is wrong with respect to the real world – we typically use our\nknowledge of where a target object is likely to be located when searching\nfor it (see below).\nDual-path model\nIn most of the research discussed so far, the target appeared at a random\nlocation within the visual display. This is radically different from the real\nworld. Suppose you are outside looking for your missing cat. Your visual\nsearch would be very selective – you would ignore the sky and focus mostly\non the ground (and perhaps the trees). Thus, your search would involve\ntop-down processes based on your knowledge of where cats are most likely\nto be found.\nEhinger et al. (2009) studied top-down processes in visual search by\nrecording eye fixations of observers searching for a person in 900 real-\nworld outdoor scenes. Observers typically fixated plausible locations (e.g.,\npavements) and ignored implausible ones (e.g., sky; trees; see Figure 5.12).\nObservers also fixated locations differing considerably from neighbouring\nlocations and areas containing visual features resembling those of a human\nfigure.\nHow can we reconcile Ehinger et al.’s (2009) findings with those\ndiscussed earlier? Wolfe et al. (2011) proposed a dual-path model (see\nFigure  5.13). There is a selective pathway of limited capacity (indicated\nby the bottleneck) with objects being selected individually for recognition.\nFigure 5.12\nThe first three eye fixations made by observers searching for pedestrians. As can be\nseen, the great majority of their fixations were on regions in which pedestrians would\nmost likely be found. Observers’ fixations were much more like each other in the left-\nhand photo than in the right-hand one, because there were fewer likely regions in the\nleft-hand one.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n205\nThis pathway has been the focus of most research until recently. There is\nalso a non-selective pathway in which the “gist” of a scene is processed.\nSuch processing can then guide processing within the selective pathway\n(represented by the arrow labelled “guidance”). This pathway allows us to\nutilise our stored environmental knowledge and so is of great value in the\nreal world.\nFindings\nWolfe et al. (2011) compared visual searches for objects presented within a\nscene setting or at random locations. As predicted, search rate per item was\nmuch faster in the scene setting (10 ms vs 40 ms, respectively). Võ and Wolfe\n(2012) explained that finding in terms of “functional set size” – searching in\nscenes is efficient because most regions can be ignored. As predicted, Võ\nand Wolfe found 80% of each scene was rarely fixated.\nKaiser and Cichy (2018) presented observers with objects typically\nlocated in the upper (e.g., aeroplane; hat) or lower (e.g., carpet; shoe) visual\nfield. These objects were presented in their typical or atypical location\n(e.g., hat in the lower visual field). Observers had to indicate whether an\nobject presented very briefly was located in the upper or lower visual field.\nObservers’ performance was better when objects appeared in their typical\nlocation because of their extensive knowledge of where objects are gener-\nally located.\nChukoskie et al. (2013) found observers can easily learn where\ntargets are located. An invisible target was presented at random loca-\ntions on a blank screen and observers were provided with feedback. There\nwas a strong learning effect – fixations rapidly shifted from being fairly\nFigure 5.13\nA two-pathway model of\nvisual search. The selective\npathway is capacity limited\nand can bind stimulus\nfeatures and recognise\nobjects. The non-selective\npathway processes the gist\nof scenes. Selective and\nnon-selective processing\noccur in parallel to produce\neffective visual search.\nFrom Wolfe et al. (2011).\nReprinted with permission from\nElsevier.\nEarly vision\nNonselective pathway\nSelective pathway\nBinding and\nrecognition\nColor\nFeatures\nOrientation\nSize\nDepth\nMotion\nEtc.\nCreated from usyd on 2022-02-14 13:21:43.",
    "206\nVisual perception and attention\nrandom  to being focused on the area within which the target might be\npresent.\nEhinger et al.’s (2009) findings (discussed earlier, see p. 204) suggested\nthat scene gist or context can be used to enhance the efficiency of visual\nsearch. Katti et al. (2017) presented scenes very briefly (83 ms) followed by\na mask. Observers were given the task of detecting a person or a car and\nperformed very accurately (over 90%) and rapidly. Katti et al. confirmed\nthat scene gist or context influenced performance. However, performance\nwas influenced more strongly by features of the target object  – the more\nkey features of an object were visible, the faster it was detected.\nWhat is the take-home message from the above study? The efficiency\nof visual search with real-world scenes is more complex than implied by\nEhinger et al. (2009). More specifically, observers may rapidly fixate on the\narea close to a target person because they are using scene gist or because\nthey rapidly process features of the person (e.g., wearing clothes).\nEvaluation\nOur knowledge of likely (and unlikely) locations for any given object in a\nscene influences visual search in the real world. This is fully acknowledged\nin the dual-path model. There is also support for the notion that scene\nknowledge facilitates visual search by reducing functional set size.\nWhat are the model’s limitations? First, how we use gist knowledge\nof a scene very rapidly to reduce the search area remains unclear. Second,\nthere is insufficient focus on the learning processes that can greatly facil-\nitate visual search – the effects of such processes can be seen in the very\nrapid and accurate detection of target information by experts in several\ndomains (see Chapter 11).\nThird, it is important not to exaggerate the importance of scene gist or\ncontext in influencing the efficiency of visual search. Features of the target\nobject can influence visual search more than scene gist (Katti et al., 2017).\nFourth, the assumption that items are processed individually within\nthe selective pathway is typically mistaken. As we will see shortly, visual\nsearch often depends on parallel processes within peripheral vision and\nsuch processes are not considered within the model.\nAttention vs perception: texture tiling model\nSeveral theories (e.g., Treisman & Gelade, 1980) have assumed that indi-\nvidual items are the crucial units in visual search. Such theories have also\noften assumed that slow visual search depends mostly on the limitations of\nfocused attention. A plausible implication of these assumptions is that slow\nvisual search depends mostly on foveal vision (the fovea is a small area of\nmaximal visual acuity in the retina).\nBoth the above assumptions have been challenged recently. At the\nrisk of oversimplification, full understanding of visual search requires less\nemphasis on attention and more on perception. According to Rosenholtz\n(2016), peripheral (non-foveal) vision is of crucial importance. Acuity\ndecreases as we move away from the fovea to the periphery of vision, but\nmuch less than often assumed. You can demonstrate this by holding out\nKEY TERM\nFovea\nA small area within the\nretina in the centre in the\nfield of vision where visual\nacuity is greatest.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n207\nyour thumb and fixating the nail. Foveal vision only covers the nail so the\ngreat majority of what you can see is in peripheral vision.\nWe can also compare the value of foveal and peripheral vision by con-\nsidering individuals with impaired eyesight. Those with severely impaired\nperipheral vision (e.g., due to glaucoma) had greater problems with mobil-\nity (e.g., number of falls; ability to drive) than those who lack foveal vision\n(due to macular degeneration) (Rosenholtz, 2016). Individuals with severely\nimpaired central or foveal vision performed almost as well as healthy con-\ntrols at detecting target objects in coloured scenes (75% vs 79%, respec-\ntively) (Thibaut et al., 2018).\nIf visual search depends heavily on peripheral vision, what predictions\ncan we make? First, if each fixation provides observers with a considerable\namount of information about several objects, visual search will typically\ninvolve parallel rather than serial processing. Second, we need to consider\nlimitations of peripheral vision (e.g., visual acuity is less in peripheral\nthan foveal vision). However, a more important limitation concerns visual\ncrowding – a reduced ability to recognise objects or other stimuli because\nof irrelevant neighbouring objects or stimuli (clutter). Visual crowding\nimpairs peripheral vision to a much greater extent than foveal vision.\nRosenholtz et al. (2012) proposed the texture tiling model based on\nthe assumption peripheral vision is of crucial importance in visual search.\nMore specifically, processing in peripheral vision can cause adjacent stimuli\nto tile (join together) to form an apparent target, thus increasing the diffi-\nculty of visual search. Below we consider findings relevant to this model.\nFindings\nAs mentioned earlier (p. 203), Thornton and Gilden (2007) found almost\nthree-quarters of the visual tasks they studied involved parallel processing.\nThis is entirely consistent with the emphasis on parallel processing in the\nmodel.\nDirect evidence for the importance of peripheral vision to visual search\nwas reported by Young and Hulleman (2013). They manipulated the visible\narea around the fixation point making it small, medium or large. As pre-\ndicted by the model, visual search performance was worst when the visible\narea was small (so only one item could be processed per fixation). Overall,\nvisual search was almost parallel when the visible area was large but serial\nwhen it was small.\nChang and Rosenholtz (2016) used various search tasks. According to\nfeature integration theory, both tasks shown in Figure 5.14 should be com-\nparably hard because the target and distractors share features. In contrast,\nthe texture tiling model predicts the task on the right should be harder\nbecause adjacent distractors seen in peripheral vision can more easily tile\n(join together) to form an apparent T. The findings from these tasks (and\nseveral others) supported the texture tiling model but were inconsistent\nwith feature integration theory.\nFinally, Hulleman and Olivers (2017) produced a model of visual\nsearch consistent with the texture tiling model. According to this model,\neach eye fixation lasts 250 ms, during which information from foveal and\nperipheral vision is extracted in parallel. They also assumed that the area\nKEY TERM\nVisual crowding\nThe inability to recognise\nobjects in peripheral\nvision due to the presence\nof neighbouring objects.\nCreated from usyd on 2022-02-14 13:21:43.",
    "208\nVisual perception and attention\naround the fixation point within which a target can generally be detected\nis smaller when the visual search task is difficult (e.g., because target dis-\ncriminability is low).\nA key prediction from Hulleman and Olivers’ (2017) model is that the\nmain reason why search times are longer with more difficult search tasks is\nbecause more eye fixations are required than with easier tasks. A computer\nsimulation based on these assumptions produced search times very similar\nto those obtained in experimental studies.\nEvaluation\nWhat are the strengths of the texture tiling model? First, the information\navailable in peripheral vision is much more important in visual search than\nassumed previously. The model explains how observers make use of the\ninformation available in peripheral vision.\nSecond, the model explains why parallel processing is so prevalent\nin visual search – it reflects directly parallel processing within peripheral\nvision. Third, there is accumulating evidence that search times are gener-\nally directly related to the number of eye fixations.\nFourth, an approach based on eye fixations and peripheral vision can\npotentially explain findings from all visual search paradigms, including\ncomplex visual scenes and item displays. Such an approach thus has more\ngeneral applicability than feature integration theory.\nWhat are the model’s limitations? First, as Chang and Rosenholtz\n(2016) admitted, it needs further development to account fully for visual\nsearch performance. For example, it does not predict search times with\nprecision. In addition, it does not specify the criteria used by observers to\ndecide no target is present.\nSecond, visual search is typically much faster for experts than non-\nexperts in their domain of expertise (e.g., medical experts examining mam-\nmograms) (see Chapter 11). The texture tiling model does not identify\nclearly the processes allowing experts to make very efficient use of periph-\neral information.\nCROSS-MODAL EFFECTS\nNearly all the research discussed so far is limited in that the visual (or audi-\ntory) modality was studied on its own. We might try to justify this approach\nby assuming attentional processes in each sensory modality operate\nFigure 5.14\nThe target (T) is easier to\nfind in the display on the\nleft than the one on the\nright.\nFrom Chang and Rosenholtz\n(2016).\nEasier search\n(a)\nFind the T\nHarder search\n(b)\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n209\nindependently from those in other modalities. However, that assumption is\nincorrect. In the real world, we often coordinate information from two or\nmore sense modalities at the same time (cross-modal attention). An example\nis lip reading, where we use visual information about a speaker’s lip move-\nments to facilitate our understanding of what they are saying (see Chapter 9).\nSuppose we present participants with two streams of lights (as was\ndone by Eimer and Schröger, 1998), with one stream being presented to the\nleft and the other to the right. At the same time, we present participants\nwith two streams of sounds (one to each side). In one condition, partici-\npants detect deviant visual events (e.g., longer than usual stimuli) presented\nto one side only. In the other condition, participants detect deviant audi-\ntory events in only one stream.\nEvent-related potentials were recorded to assess the allocation of atten-\ntion. Unsurprisingly, Eimer and Schröger (1998) found ERPs to deviant\nstimuli in the relevant modality were greater to stimuli presented on the\nto-be-attended side than the to-be-ignored side. Thus, participants allo-\ncated attention as instructed.\nOf more interest is what happened to the allocation of attention in\nthe irrelevant modality. Suppose participants detected visual targets on the\nleft side. In that case, ERPs to deviant auditory stimuli were greater on\nthe left side than the right. This is a cross-modal effect: the voluntary or\nendogenous allocation of visual attention also affected the allocation of\nauditory attention. Similarly, when participants detected auditory targets\non one side, ERPs to deviant visual stimuli on the same side were greater\nthan ERPs to those on the opposite side. Thus, the allocation of auditory\nattention also influenced the allocation of visual attention.\nVentriloquism effect\nWhat happens when there is a conflict between simultaneous visual and\nauditory stimuli? We will focus on the ventriloquism effect in which\nsounds are misperceived as coming from their apparent visual source.\nVentriloquists (at least good ones!) speak without moving their lips while\nmanipulating a dummy’s mouth movements. It seems as if the dummy is\nspeaking. Something similar happens at the movies. The actors’ lips move\non the screen but their voices come from loudspeakers beside the screen.\nNevertheless, we hear those voices coming from their mouths.\nCertain conditions must be satisfied for the ventriloquism effect to\noccur (Recanzone & Sutter, 2008). First, the visual and auditory stimuli\nmust occur close together in time. Second, the sound must match expecta-\ntions created by the visual stimulus (e.g., high-pitched sound coming from\na small object). Third, the sources of the visual and auditory stimuli should\nbe close together spatially. More generally, the ventriloquism effect reflects\nthe unity assumption (the assumption that two or more sensory cues come\nfrom the same object: Chen & Spence, 2017).\nThe ventriloquism effect exemplifies visual dominance (visual informa-\ntion dominating perception). Further evidence comes from the Colavita\neffect (Colavita, 1974): participants instructed to respond to all stimuli\nrespond more often to visual than simultaneous auditory stimuli (Spence\net al., 2011).\nKEY TERMS\nCross-modal attention\nThe coordination of\nattention across two or\nmore modalities (e.g.,\nvision and audition).\nVentriloquism effect\nThe mistaken perception\nthat sounds are\ncoming from their\napparent source (as in\nventriloquism).\nCreated from usyd on 2022-02-14 13:21:43.",
    "210\nVisual perception and attention\nWhen during processing is visual spatial information integrated with\nauditory information? Shrem et al. (2017) found that misleading visual\ninformation about the location of an auditory stimulus influenced the pro-\ncessing of the auditory stimulus approximately 200 ms after stimulus onset.\nThe finding that this effect is still present even when participants are aware\nof the spatial discrepancy between the visual and auditory input suggests it\noccurs relatively “automatically”.\nHowever, the ventriloquism effect is smaller when participants had\npreviously heard syllables spoken in a fearful voice (Maiworm et al., 2012).\nThis suggests the effect is not entirely “automatic” but is reduced when the\nrelevance of the auditory channel is increased.\nWhy does vision capture sound in the ventriloquism effect? The visual\nmodality typically provides more precise information about spatial loca-\ntion. However, when visual stimuli are severely blurred and poorly local-\nised, sound captures vision (Alais & Burr, 2004). Thus, we combine visual\nand auditory information effectively by attaching more weight to the more\ninformative sense modality.\nTemporal ventriloquism\nThe above explanation for the ventriloquist illusion is a development of\nthe modality appropriateness and precision hypothesis (Welch & Warren,\n1980). According to this hypothesis, when conflicting information is pre-\nsented in two or more modalities, the modality having the greatest acuity\ngenerally dominates. This hypothesis predicts the existence of another illu-\nsion. The auditory modality is typically more precise than the visual modal-\nity at discriminating temporal relations. As a result, judgements about\nthe temporal onset of visual stimuli might be biased by auditory stimuli\npresented very shortly beforehand or afterwards. This is the temporal\nventriloquism effect.\nResearch on temporal ventriloquism\nwas reviewed by Chen and Spence (2017).\nA simple example is when the apparent\nonset of a flash is shifted towards an abrupt\nsound presented slightly asynchronously (see\nFigure  5.15). Other research has found that\nthe apparent duration of visual stimuli can be\ndistorted by asynchronous auditory stimuli.\nWe need to consider the temporal ven-\ntriloquism effect in the context of the unity\nassumption. This is the assumption that “two\nor more uni-sensory cues belong together\n(i.e., that they come from the same object or\nevent)” (Chen & Spence, 2017, p. 1). Chen\nand Spence discussed findings showing that\nthe unity assumption generally (but not\nalways) enhances the temporal ventriloquism\neffect.\nOrchard-Mills et al. (2016) extended\nresearch by using two visual stimuli (one\nKEY TERM\nTemporal ventriloquism\neffect\nMisperception of the\ntiming of a visual stimulus\nwhen an auditory stimulus\nis presented close to it in\ntime.\nFigure 5.15\nAn example of temporal ventriloquism in which the apparent\ntime of onset of a flash is shifted towards that of a sound\npresented at a slightly different timing from the flash.\nFrom Chen and Vroomen (2013). Reprinted with permission from\nSpringer.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n211\nIN THE REAL WORLD: WARNING SIGNALS PROMOTE SAFE DRIVING\nFront-to-rear-end collisions cause 25% of road accidents with driver inattention the most common\ncause (Spence, 2012). Thus, it is important to devise effective warning signals to enhance driver\nattention and reduce collisions. Warning signals might be especially useful if they were informative\n(i.e., indicating the nature of the danger). However, informative warning signals requiring time-con-\nsuming cognitive processing might be counterproductive.\nHo and Spence (2005) considered drivers’ reaction times when braking to avoid a car in front or\naccelerating to avoid a speeding car behind. An auditory warning signal (car horn) came from the\nsame direction as the critical visual event on 80% or 50% of trials. Braking times were faster when\nthe sound and critical visual event were from the same direction. The greater beneficial effects of\nauditory signals when predictive rather than non-predictive suggests the involvement of endoge-\nnous spatial attention (controlled by the individual’s intentions). Auditory stimuli also influenced\nvisual attention even when non-predictive: this probably involved exogenous spatial attention\n(“automatic” allocation of attention).\nGray (2011) studied braking times to avoid a collision with the car in front when drivers heard\nauditory warning signals increasing in intensity as the time to collision reduced. These signals are\nknown as looming sounds. The most effective condition was the one where the rate of increase\nin the intensity of the auditory signal was the fastest because it implied the time to collision was\nthe least. Lahmer et al. (2018) found evidence that looming sounds are effective because they are\nconsistent with the visual experience of an approaching collision.\nVibrotactile signals produce the perception of vibration through touch. Gray et al. (2014) studied\nthe effects of such signals on speed of braking to avoid a collision. Signals were presented at three\nsites on the abdomen arranged vertically. In the most effective condition, successive signals moved\ntowards the driver’s head at an increasing rate reflecting the speed they were approaching the\ncar in front. Braking time was 250 ms faster in this condition than a no-warning control condition,\nprobably because it was highly informative.\nAhtamad et al. (2016) compared the effectiveness of three vibrotactile warning signals delivered\nto the back on braking times to avoid a collision with the car in front: (1) expanding (centre of back\nfollowed by areas to left and right); (2) contracting (areas to left and right followed by the centre\nof the back); (3) static (centre of the back + areas to left and right at the same time). The dynamic\nvibrotactile conditions (1 and 2) produced comparable braking reaction times that were faster than\nthose in the static condition (3).\nIn a second experiment, Ahtamad et al. (2016) compared the expanding vibrotactile condition\nagainst a linear motion condition (vibrotactile stimulation to the hands followed by the shoulders).\nEmergency braking reaction times were faster in the linear motion condition (approximately 585 ms\nvs 640 ms) because drivers found it easier to interpret the warning signals in that condition.\nIn sum, the various auditory and vibrotactile warning signals discussed above typically reduce\nbraking reaction times by approximately 40 ms. That sounds modest. However, it can easily be the\ndifference between colliding with the car in front or avoiding it and so could potentially save many\nlives. At present, however, we lack a theoretical framework within which to understand precisely\nwhy some warning signals are more effective than others.\nabove and the other below fixation) and two auditory stimuli (low- and\nhigh-pitch). When the visual and auditory stimuli were congruent (e.g.,\nvisual stimulus above fixation and auditory stimulus high-pitch), the tem-\nporal ventriloquism effect was found. However, this effect was eliminated\nwhen the visual and auditory stimuli were incongruent, which prevented\nbinding of information across the two senses.\nCreated from usyd on 2022-02-14 13:21:43.",
    "212\nVisual perception and attention\nOverall evaluation\nWhat are the limitations of research on cross-modal effects? First, as just\nmentioned, our theoretical understanding lags behind the accumulation of\nempirical findings. Second, much research has involved complex artificial\ntasks far removed from naturalistic conditions. Third, individual differ-\nences have generally been ignored. However, individual differences (e.g.,\npreference for auditory or visual stimuli) influence cross-modal effects (van\nAtteveldt et al., 2014).\nDIVIDED ATTENTION: DUAL-TASK PERFORMANCE\nIn this section, we consider factors influencing how well we can perform\ntwo tasks at the same time. In our hectic 24/7 lives, we increasingly try to\ndo two things at once (multi-tasking) (e.g., sending text messages while\nwalking down the street). More specifically, multi-tasking “refers to the\nability to co-ordinate the completion of several tasks to achieve an overall\ngoal” (MacPherson, 2018, p. 314). It can involve performing two tasks at\nthe same time or switching between two tasks. There is controversy as to\nwhether massive amounts of multi-tasking have beneficial or detrimental\neffects on attention and cognitive control (see Box).\nWhat determines how well we can perform two tasks at once?\nSimilarity (e.g., in terms of modality) is one important factor. Treisman\nand Davies (1973) found two monitoring tasks interfered with each other\nmuch more when the stimuli on both tasks were in the same modality\n(visual or auditory).\nTwo tasks can also be similar in response modality. McLeod (1977)\nhad participants perform a continuous tracking task with manual respond-\ning together with a tone-identification task. Some participants responded\nvocally to the tones whereas others responded with the hand not involved\nin tracking. Tracking performance was worse with high response similarity\n(manual responses on both tasks) than with low response similarity.\nPractice is the most important factor determining how well two tasks\ncan be performed together. The saying “Practice makes perfect” was\napparently supported by Spelke et al. (1976). Two students (Diane and\nJohn) received 5 hours of training a week for 4 months on various tasks.\nTheir first task involved reading short stories for comprehension while\nwriting down words from dictation, which they initially found very hard.\nAfter 6 weeks of training, however, they could read as rapidly and with\nas much comprehension when writing to dictation as when only reading.\nWith further training, Diane and John learned to write down the names\nof the categories to which the dictated words belonged while maintaining\nnormal reading speed and comprehension.\nSpelke et al.’s (1976) findings are hard to interpret for various reasons.\nFirst, Spelke et al. focused on accuracy measures, which are typically less\nsensitive to dual-task interference than speed measures. Second, Diane and\nJohn’s attentional focus was relatively uncontrolled, and so they may have\nalternated attention between tasks rather than attending to both at the\nsame time. More controlled research on the effects of practice on dual-task\nperformance is discussed later.\nKEY TERMS\nEndogenous spatial\nattention\nAttention to a stimulus\ncontrolled by intentions\nor goal-directed\nmechanisms.\nExogenous spatial\nattention\nAttention to a given\nspatial location\ndetermined by\n“automatic” processes.\nMulti-tasking\nPerforming two or more\ntasks at the same time by\nswitching rapidly between\nthem.\nCase study:\nMulti-tasking efficiency\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n213\nSerial vs parallel processing\nWhen individuals perform two tasks together, they might use serial or par-\nallel processing. Serial processing involves switching attention backwards\nand forwards between two tasks with only one task being processed at any\ngiven moment. In contrast, parallel processing involves processing both\ntasks at the same time.\nThere has been much theoretical controversy on the issue of serial vs\nparallel processing in dual-task conditions (Koch et al., 2018). Of impor-\ntance, processing can be mostly parallel or mostly serial. Lehle et al. (2009)\ntrained participants to use serial or parallel processing when perform-\ning two tasks together. Those using serial processing performed better.\nHowever, they found the tasks more effortful because they had to inhibit\nprocessing of one task while performing the other one.\nLehle and Hübner (2009) also instructed participants to perform two\ntasks together in a serial or parallel fashion. Those using parallel processing\nIN THE REAL WORLD: MULTI-TASKING\nWhat are the effects of frequent multi-tasking in our everyday lives? Two main answers have been\nproposed. First, heavy multi-tasking may impair cognitive control because it leads individuals to\nallocate their attentional resources too widely. This is the scattered attention hypothesis (van der\nSchuur et al., 2015).\nSecond, heavy multi-tasking may enhance some control processes (e.g., task switching) because\nof prolonged practice in processing multiple streams of information. This is the trained attention\nhypothesis (van der Schuur et al., 2015). The relevant evidence is very inconsistent – “positive,\nnegative, and null effects have all been reported” (Uncapher & Wagner, 2018, p. 9894).\nOphir et al. (2009) used a questionnaire (the Media Multitasking Index) to identify levels of\nmulti-tasking. Heavy multi-taskers were more distractible. In a review, van der Schuur et al. (2015)\nfound findings supported the scattered attention hypothesis (e.g., heavy multi-taskers had impaired\nsustained attention).\nMoisala et al. (2016) found heavy multi-taskers were more adversely affected than light\nmulti-taskers by distracting stimuli while performing speech–listening and reading tasks. During\ndistraction, the heavy multi-taskers had greater activity than the light multi-taskers in the right pre-\nfrontal cortex (associated with attentional control). This suggests heavy multi-taskers have greater\nproblems than previously believed – their performance is impaired even though they try harder to\nexert top-down attentional control.\nUncapher and Wagner (2018) found in a review that most research indicated negative effects\nof heavy multi-tasking on tasks involving working memory, long-term memory, sustained atten-\ntion and relational reasoning. These negative effects are likely to be due to attentional lapses.\nOf relevance, there are several studies where media multi-tasking was positively associated with\nself-reported everyday attentional failures. In addition, heavy multi-taskers often report high impul-\nsivity – such individuals often make rapid decisions based on very limited evidence.\nMost studies have only found an association between media multi-tasking and measures of\nattention and performance. This makes it hard to establish causality – it is possible individuals with\ncertain patterns of attention choose to engage in extensive multi-tasking. Evidence suggesting\nthat media multi-tasking can cause attention problems was reported by Baumgartner et al. (2018).\nThey found that high media multi-tasking at one point in time predicted attention problems several\nmonths later.\nCreated from usyd on 2022-02-14 13:21:43.",
    "214\nVisual perception and attention\nperformed much worse. Fischer and Plessow (2015) reviewed dual-task\nresearch and concluded: “While serial task processing appears to be the\nmost efficient [dual-task] processing strategy, participants are able to adopt\nparallel processing. Moreover, parallel processing can even outperform\nserial processing under certain conditions” (p. 8).\nBrüning and Manzey (2018) confirmed serial processing is not always\nmore efficient than parallel processing. Participants performed many alter-\nnate trials on two different tasks but could see the stimulus for the next\ntrial ahead of time. Participants engaging in parallel processing (process-\ning the stimulus for trial n+1 during trial n) performed better than those\nusing only serial processing (not processing the trial n+1 stimulus ahead of\ntime). Parallel processing reduced the costs incurred when task switching.\nIndividuals high in working memory capacity (see Glossary) were more\nlikely to use parallel processing, perhaps because of their superior atten-\ntional control.\nIN THE REAL WORLD: CAN WE THINK AND DRIVE?\nCar driving is the riskiest activity engaged in by tens of millions of adults. Over 50 countries have\nlaws restricting the use of mobile or cell phones by drivers to increase car safety. Are such restric-\ntions necessary? The short answer is “Yes” – drivers using a mobile phone are several times more\nlikely to be involved in a car accident (Nurullah, 2015). This is so even though drivers try to reduce\nthe risks by driving slightly more slowly (reducing speed by 5–6 mph) than usual shortly after initi-\nating a mobile-phone call (Farmer et al., 2015).\nCaird et al. (2008) in a review of studies using simulated driving tasks reported that reaction\ntimes to events (e.g., onset of brake lights on the car in front) increased by 250 ms with mobile-\nphone use and were greater when drivers were talking rather than listening. This 250 ms increase\nin reaction time translates into travelling an extra 18 feet (5.5 metres) before stopping for a motor-\nist doing 50 mph (80 kph). This could be the difference between stopping just short of a child or\nkilling that child.\nStrayer and Drews (2007) studied the above slowing effect using event-related potentials while\ndrivers responded rapidly to the onset of brake lights on the car in front. The magnitude of the\nP300 (a positive wave associated with attention) was reduced by 50% in mobile-phone users.\nStrayer et al. (2011) considered a real-life driving situation. Drivers were observed to see whether\nthey obeyed a law requiring them to stop at a road junction. Of drivers not using a mobile phone,\n79% obeyed the law compared to only 25% of mobile-phone users.\nTheoretical considerations\nWhy do so many drivers endanger people’s lives by using mobile phones? Most believe they\ncan drive safely while using a mobile phone whereas other drivers cannot (Sanbonmatsu et al.,\n2016b). Their misplaced confidence depends on limited monitoring of their driving performance:\ndrivers using a mobile phone make more driving errors but do not remember making more errors\n(Sanbonmatsu et al., 2016a).\nWhy does mobile-phone use impair driving performance? Strayer and Fisher (2016) in their\nSPIDER model identified five cognitive processes that are adversely affected when drivers’  attention\nis diverted from driving (e.g., by mobile-phone use):\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n215\n(1) There is less effective visual scanning of the environment for potential threats. Distracted drivers\nare more inclined to focus attention on the centre of the road and less inclined to scan objects\nin the periphery and their side mirrors (Strayer & Fisher, 2016).\n(2) The ability to predict where threats might occur is impaired. Distracted drivers are much less\nlikely to make anticipatory glances towards the location of a potential hazard (e.g., obstructed\nview of a pedestrian crossing) (Taylor et al., 2015).\n(3) There is reduced ability to identify visible threats, a phenomenon known as inattentional blind-\nness (see Glossary; and Chapter 4). In a study by Strayer and Drews (2007), 30 objects (e.g.,\npedestrians; advertising hoardings) were clearly visible to drivers. However, those using a\nmobile phone subsequently recognised far fewer objects they had fixated than those not using\na mobile phone (under 25% vs 50%, respectively).\n(4) It is harder to decide what action is necessary in a threatening situation. Cooper et al. (2009)\nfound drivers were 11% more likely to make unsafe lane changes when using a mobile\nphone.\n(5) It becomes harder to execute the appropriate action. Reaction times are slowed (Caird et al.,\n2008, discussed above, p. 214).\nThe SPIDER model is oversimplified in several ways. First, various different activities are associated\nwith mobile-phone use. Simmons et al. (2016) found in a meta-analytic review that the risk of safety-\ncritical events was increased by activities requiring drivers to take their eyes off the road (e.g., locat-\ning a phone; dialling; texting). However, talking on a mobile phone did not increase risk.\nSecond, driving-irrelevant cognitive activities do not always impair all aspects of driving per-\nformance. Engstrom et al. (2017, p. 734) proposed their cognitive control hypothesis: “Cognitive\nload selectively impairs driving sub-tasks that rely on cognitive control but leaves automatic perfor-\nmance unaffected.” For example, driving-irrelevant activities involving cognitive load (e.g., mobile-\nphone use) typically have no adverse effect on well-practised driving skills, such as lane keeping\nand braking when getting close to the vehicle in front (Engstrom et al., 2017).\nThird, individuals using mobile phones while driving are unrepresentative of drivers in general\n(e.g., they tend to be relatively young and to engage in more risk-taking activities: Precht et al.,\n2017). Thus, we must consider individual differences in personality and risk taking when interpret-\ning accidents associated with mobile-phone use.\nFourth, the SPIDER model implies that performance cannot be improved by adding a secondary\ntask. However, driving performance in monotonous conditions is sometimes better when drivers\nlisten to the radio at the same time (see Engstrom et al., 2017). Listening to the radio can reduce\nthe mind-wandering that occurs when someone drives in monotonous conditions. Drivers indicat-\ning their immediate thoughts during their daily commute reported mind-wandering 63% of the\ntime and active focus on driving only 15%–20% of the time (Burdett et al., 2018).\nMultiple resource theory\nWickens (1984, 2008) argued in his multiple resource model that the pro-\ncessing system consists of several independent processing resources or\nmechanisms. The model includes four major dimensions (see Figure 5.16):\n(1) Processing stages: there are successive stages of perception, cognition\n(e.g., working memory) and responding.\n(2) Processing codes: perception, cognition and responding can use\nspatial and/or verbal codes; action can involve speech (vocal verbal)\nor manual/spatial responses.\nCreated from usyd on 2022-02-14 13:21:43.",
    "216\nVisual perception and attention\n(3) Modalities: perception can involve visual and/or auditory resources.\n(4) Visual channels: visual processing can be focal (high acuity) or ambient\n(peripheral).\nHere is the model’s crucial prediction: “To the extent that two tasks use dif-\nferent levels along each of the three dimensions [excluding (4) above], time-\nsharing [dual-task performance] will be better” (Wickens, 2008, p. 450). Thus,\ntasks requiring different resources can be performed together more success-\nfully than those requiring the same resources. Wickens’s approach bears\nsome resemblance to Baddeley’s (e.g., 2012) working memory model (see\nChapter 6). According to that model, two tasks can be performed together\nsuccessfully provided they use different components or processing resources.\nFindings\nResearch discussed earlier (Treisman & Davies, 1973; McLeod, 1977)\nshowing the negative effects of stimulus and response similarity on per-\nformance are entirely consistent with the theory. Lu et al. (2013) reviewed\nresearch where an ongoing visual-motor task (e.g., car driving) was\nperformed together with an interrupting task in the visual, auditory or\ntactile (touch) modality. As predicted, non-visual interrupting tasks (espe-\ncially those in the tactile modality) were processed more effectively than\nvisual ones and there were no adverse effects on the visual-motor task.\nAccording to the model, there should be only limited dual-task inter-\nference between two visual tasks if one requires focal or foveal vision,\nwhereas the other requires ambient or peripheral vision. Tsang and Chan\n(2018) obtained support for this prediction in a study in which participants\ntracked a moving target in focal vision while responding to a spatial task\nin ambient or peripheral vision.\nDual-task performance is often more impaired than predicted by\nthe theory. For example, consider a study by Robbins et al. (1996; see\nFigure 5.16\nWickens’s four-dimensional\nmultiple resource model.\nThe details are described in\nthe text.\nFrom Wickens (2008). © 2008.\nReprinted by permission of\nSAGE Publications.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n217\nChapter 6). The main task was selecting chess moves and we will focus on\nthe condition where the task performed at the same time was generating\nrandom letters. These two tasks involve different processing codes (spatial\nvs verbal, respectively) and they also involve different response types\n(manual vs vocal, respectively). Nevertheless, generating random letters\ncaused substantial interference on the chess task.\nEvaluation\nThe main assumptions of the theory have largely been supported by the\nexperimental evidence. In other words, dual-task performance is generally\nless impaired when two tasks differ with respect to modalities, processing\ncodes or visual channels than when they do not.\nWhat are the model’s limitations?\n(1) Successful dual-task performance often requires higher-level processes\nof coordinating and organising the demands of the two tasks (see\nlater section on cognitive neuroscience, pp. 220–222). However, these\nprocesses are de-emphasised within the theory.\n(2) The theory’s assumption there is a sequence of processing stages (per-\nception; cognition; responding) is too rigid given the flexible nature of\nmuch dual-task processing (Koch et al., 2018). The numerous forms\nof cognitive processing intervening between perception and respond-\ning are not discussed in detail.\n(3) It is implied within the theory that negative or interfering effects of\nperforming two tasks together would be constantly present. However,\nSteinborn and Huestegge (2017) found dual-task conditions led only\nto occasional performance breakdown due to attention failures.\nThreaded cognition\nSalvucci and Taatgen (2008, 2011) proposed a model of threaded cogni-\ntion in which streams of thought are represented as threads of processing.\nFor example, processing two tasks might involve two separate threads. The\ncentral theoretical assumptions are as follows:\nMultiple threads or goals can be active at the same time, and as long as\nthere is no overlap in the cognitive resources needed by these threads,\nthere is no multi-tasking interference. When threads require the same\nresource at the same time, one thread must wait and its performance\nwill be adversely affected.\n(Salvucci & Taatgen, 2011, p. 228)\nThis is because all resources have limited capacity.\nTaatgen (2011) discussed the threaded cognition model (see\nFigure 5.17). Several cognitive resources can be the source of competition\nbetween two tasks. These include visual perception, declarative memory,\ntask control and focal working memory or problem state. Nijboer et al.\n(2016a) discussed similarities between this model and Baddeley’s working\nmemory model (see Chapter 6). Three components of the model relate to\nCreated from usyd on 2022-02-14 13:21:43.",
    "218\nVisual perception and attention\nworking memory: (1) problem state (atten-\ntional focus); (2) declarative memory (acti-\nvated short-term memory); and (3) subvocal\nrehearsal (resembling the phonological loop;\nsee Chapter 6).\nEach thread or task controls resources\nin a greedy, polite way – threads claim\nresources greedily when required but release\nthem politely when no longer needed. These\naspects of the model lead to one of its most\noriginal assumptions – several goals (each\nassociated with a given thread) can be active\nsimultaneously.\nThe model resembles Wickens’s multiple\nresource model: both models assume there\nare several independent processing resources.\nHowever, only the threaded cognition model\nled to a computational model making spe-\ncific predictions. In addition, the threaded\ncognition model identifies the brain areas\nassociated with each processing resource (see\nFigure 5.17).\nFindings\nAccording to the model, any given cogni-\ntive resource (e.g., visual perception; focal\nworking memory) can be used by only one\nprocess at any given time. Nijboer et al. (2013)\ntested this assumption using multi-column subtraction as the primary task\nwith participants responding using a keypad. Easy and hard conditions dif-\nfered in whether digits were carried over (“borrowed”) from one column to\nthe next:\n(1: easy)\n(2: hard)\n336789495\n3649772514\n–224578381\n–1852983463\nThe model predicts focal working memory is required only in the hard con-\ndition. Subtraction was combined with a secondary task: a tracking task\ninvolving visual and manual resources or a tone-counting task involving\nworking memory.\nNijboer et al. (2013) predicted performance on the easy subtraction\ntask should be worse when combined with the tracking task because both\ncompete for visual and manual resources. In contrast, performance on\nthe hard subtraction task should be worse when combined with the tone-\ncounting task because there are large disruptive effects when two tasks\ncompete for working memory resources. The findings were as predicted.\nBorst et al. (2013) found there was far less impairment of hard sub-\ntraction performance by a secondary task requiring working memory when\nFigure 5.17\nThreaded cognition theory. We possess several cognitive\nresources (e.g., declarative memory, task control, visual\nperception). These resources can be used in parallel but each\nresource can only work on one task at a time. Our ability to\nperform two tasks at the same time (e.g., driving and dialling,\nsubtraction and typing) depends on the precise ways in which\ncognitive resources need to be used. The theory also identifies\nsome of the brain areas associated with cognitive resources.\nFrom Taatgen (2011). With permission of the author.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n219\nparticipants saw a visual sign explicitly indicating that “borrowing” was\nneeded. This supports the model’s assumption that dual-task performance\ncan be enhanced by appropriate environmental support.\nAccording to the threaded cognition model, we often cope with the\ndemands of combining two tasks by switching flexibly between them to\nmaximise performance. Support was reported by Farmer et al. (2018).\nParticipants performed a typing task and a tracking task at the same time.\nThe relative value of the two tasks was varied by manipulating the number\nof points lost for poor tracking performance. Participants rapidly learned\nto adjust their strategies over time to increase the overall number of points\nthey gained.\nKatidioti and Taatgen (2014) found task switching is not always\noptimal. Participants performed two tasks together: (1) an email task in\nwhich information needed to be looked up; (2) chat messages containing\nquestions to be answered. When there was a delay on the email task, most\nparticipants switched to the chat task. This happened even when this was\nsuboptimal because it caused participants to forget information in the\nemail task.\nHow can we explain the above findings? According to Katidioti and\nTaatgen (2014, p. 734), “The results . . . agree with threaded cognition’s\n‘greedy’ theory . . . which states that people will switch to a task that is\nwaiting as soon as the resources for it are available.” Huijser et al. (2018)\nobtained further evidence of “greediness”. When there were brief blank\nperiods during the performance of a cognitively demanding task, partic-\nipants often had task-irrelevant thoughts (e.g., mind-wandering) even\nthough these thoughts impaired task performance.\nKatidioti and Taatgen (2014) also discovered substantial individual\ndifferences in task switching – some participants never switched to the chat\ntask when delays occurred on the email task. Such individual differences\ncannot be explained by the theory.\nAs mentioned earlier, a recent version of threaded cognition theory\ndiscussed by Nijboer et al. (2016a) identifies three components of working\n(i.e., problem state or focus of attention; declarative memory or activated\nshort-term memory; and subvocal rehearsal). Nijboer et al. had partici-\npants perform two working memory tasks at the same time; these tasks\nvaried in the extent to which they required the same working memory com-\nponents. They obtained measures of performance and also used neuroim-\naging under dual-task and single-task conditions.\nWhat did Nijboer et al. (2016a) find? First, dual-task interference\ncould be predicted from the extent to which the two tasks involved the\nsame working memory components. Second, dual-task interference could\nalso be predicted from the extent of overlap in brain activation of the two\ntasks in single-task conditions. In sum, dual-task interference depended\non competition for specific resources (i.e., working memory components)\nrather than general resources (e.g., central executive).\nEvaluation\nThe model has proved successful in various ways. First, several important\ncognitive resources have been identified. Second, the model identifies brain\nCreated from usyd on 2022-02-14 13:21:43.",
    "220\nVisual perception and attention\nareas associated with various cognitive resources. This has led to compu-\ntational modelling testing the model’s predictions using neuroimaging and\nbehavioural findings. Thus, the model accounts for dual-task performance\nwithout assuming the existence of a central executive or other executive\nprocess (often vaguely defined in other theories). Fourth, the theory predicts\nfactors determining switching between two tasks being performed together.\nFifth, individuals often have fewer problems performing two simultaneous\ntasks than generally assumed.\nWhat are the model’s limitations? First, it predicts that “Practising two\ntasks concurrently [together] results in the same performance as perform-\ning the two tasks independently” (Salvucci & Taatgen, 2008, p. 127). This\nde-emphasises the importance of processes coordinating and managing two\ntasks performed together (see next section). Second, excluding processes\nresembling Baddeley’s central executive is controversial and may well\nprove inadvisable. Third, most tests of the model have involved the simul-\ntaneous performance of two relatively simple tasks and its applicability to\nmore complex tasks remains unclear. Fourth, the theory does not provide\na full explanation for individual differences in the extent of task switching\n(e.g., Katidioti & Taatgen, 2014).\nCognitive neuroscience\nThe cognitive neuroscience approach is increasingly used to test theoretical\nmodels and enhance our understanding of processes underlying dual-task\nperformance. Its value is that neuroimaging provides “an additional data\nsource for contrasting between alternative models” (Palmeri et al., 2017,\np.  61). More generally, behavioural findings indicate the extent to which\ndual-task conditions impair task performance but are often relatively unin-\nformative about the precise reasons for such impairment.\nSuppose we compare patterns of brain activation while participants\nperform tasks x and y singly or together. Three basic patterns are shown\nin Figure 5.18:\n(1) Underadditive activation: reduced activation in one or more brain\nareas in the dual-task condition occurs because of resource competi-\ntion between the tasks.\nFigure 5.18\n(a) Underadditive activation;\n(b) additive activation;\n(c) overadditive activation.\nWhite indicates task 1\nactivation; grey indicates\ntask 2 activation; and\nblack indicates activation\nonly present in dual-task\nconditions.\nFrom Nijboer et al., 2014.\nReprinted with permission of\nElsevier.\n(a) Underadditive activation\nComponent task 1\nComponent task 2\nDual-task\nAdditive activation\nOveradditive activation\n(b)\n(c)\nTime\nTime\nTime\nComponent task 1\nComponent task 2\nDual-task\nTime\nTime\nTime\nComponent task 1\nComponent task 2\nDual-task\nTime\nTime\nTime\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n221\n(2) Additive activation: brain activation in the dual-task condition is\nsimply the sum of the two single-task activations because access to\nresources is integrated efficiently between the two tasks.\n(3) Overadditive activation: brain activation in one or more brain areas is\npresent in the dual-task condition but not the single-task conditions.\nThis occurs when dual-task conditions require executive processes that\nare absent (or less important) with single tasks. These executive pro-\ncesses include the coordination of task demands, attentional control\nand dual-task management generally. We would expect such executive\nprocesses to be associated mostly with activation in prefrontal cortex.\nFindings\nWe start with an example of underadditive activation. Just et al. (2001)\nused two very different tasks (auditory sentence comprehension and mental\nrotation of 3-D figures) performed together or singly. Performance on both\ntasks was impaired under dual-task conditions compared to single-task\nconditions. Under dual-task conditions, brain activation in language pro-\ncessing areas decreased by 53% and reduced by 29% in areas associated\nwith mental rotation. These findings suggest fewer task-relevant processing\nresources were available when both tasks were performed together.\nSchweizer et al. (2013) also reported underadditivity. Participants\nperformed a driving task on its own or with a distracting secondary task\n(answering spoken questions). Driving performance was unaffected by\nthe secondary task. However, driving with distraction reduced activa-\ntion in posterior brain areas associated with spatial and visual processing\n(underadditivity). It also produced increased activation in the prefrontal\ncortex (overadditivity; see Figure 5.19) probably because driving with dis-\ntraction requires increased attentional or cognitive control within the pre-\nfrontal cortex.\nDual-task performance is often associated with overadditivity due to\nincreased activity within the prefrontal cortex (especially the lateral pre-\nfrontal cortex) during dual-task performance (see Strobach et al., 2018, for\na review). However, most such findings do not show that this increased\nprefrontal activation is actually required for dual-task performance.\nMore direct evidence that prefrontal areas associated with attentional\nor cognitive control are causally involved in enhancing dual-task perfor-\nmance was reported by Filmer et al. (2017) and Strobach et al. (2018).\nFilmer et al. (2017) studied the effects of transcranial direct current stim-\nulation (tDCS; see Glossary) applied to areas of the prefrontal cortex\nassociated with cognitive control. Anodal tDCS during training enhanced\ncognitive control and subsequent dual-task performance.\nFigure 5.19\nEffects of an audio\ndistraction task on brain\nactivity associated with a\nstraight driving task. There\nwere significant increases\nin activation within the\nventrolateral prefrontal\ncortex and the auditory\ncortex (in orange). There\nwas decreased activation\nin occipital-visual areas (in\nblue).\nFrom Schweizer et al. (2013).\nKEY TERM\nUnderadditivity\nThe finding that brain\nactivation when tasks\nA and B are performed\nat the same time is less\nthan the sum of the brain\nactivation when tasks\nA and B are performed\nseparately.\nCreated from usyd on 2022-02-14 13:21:43.",
    "222\nVisual perception and attention\nStrobach et al. (2018) reported similar findings. Anodal tDCS applied\nto the lateral prefrontal cortex led to enhanced dual-task performance.\nIn another condition, cathodal tDCS to the same area of the prefrontal\ncortex impaired dual-task performance. These findings were as predicted\ngiven that anodal and cathodal tDCS often have opposite effects on per-\nformance. These findings indicate that the lateral prefrontal cortex causally\ninfluences dual-task performance.\nAdditional evidence of the importance of the lateral prefrontal cortex\nwas reported by Wen et al. (2018). Individuals with high connectivity (con-\nnectedness) within that brain area showed superior dual-task performance\nto those with low connectivity.\nFinally, patterns of brain activation can help to explain practice effects\non dual-task performance. Garner and Dux (2015) found much fronto-\nparietal activation (associated with cognitive control) when two tasks were\nperformed singly or together. Extensive training greatly reduced dual-task\ninterference and also produced increasing differentiation in the pattern of\nfronto-parietal activation associated with the two tasks. Participants showing\nthe greatest reduction in dual-task interference tended to have the greatest\nincrease in differentiation. Thus, using practice to increase differences in pro-\ncessing and associated brain processing between tasks can be very effective.\nEvaluation\nBrain activity in dual-task conditions often differs from the sum of brain\nactivity of the same two tasks performed singly. Dual-task activity can\nexhibit underadditivity or overadditivity. The findings are theoretically\nimportant because they indicate performance of dual tasks can involve\nmuch more cognitive control and other processes than single tasks. Garner\nand Dux’s (2015) findings demonstrate that enhanced dual-task perfor-\nmance with practice can depend on increased differentiation between the\ntwo tasks with respect to processing and brain activation.\nWhat are the limitations of the cognitive neuroscience approach?\nFirst, increased (or decreased) activity in a given brain area in dual-task\nconditions is not necessarily very informative. For example, Dux et al.\n(2009) found dual-task performance improved over time because prac-\ntice increased the speed of information processing in the prefrontal cortex\nrather than because it changed activation within that region. Second, it is\noften unclear whether patterns of brain activation are directly relevant to\ntask processing rather than reflecting non-task processing.\nThird, findings in this area are rather inconsistent (Strobach et al., 2018)\nand we lack a comprehensive theory to account for these inconsistencies.\nPlausible reasons for these apparent inconsistencies are the great variety of\ntask combinations used in dual-task studies and individual differences in\ntask proficiency among participants (Watanabe & Funahashi, 2018).\nPsychological refractory period: cognitive bottleneck?\nMuch of the research discussed so far was limited because the task combi-\nnations used made it hard to assess in detail the processes used by partic-\nipants. For example, the data collected were often insufficient to indicate\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n223\nthe frequency with which participants switched their attentional focus from\none task to the other. This led researchers to use much simpler tasks so that\nthey had “better experimental control over the timing of the component\ntask processes” (Koch et al., 2018, p. 575).\nThe dominant paradigm in recent research is as follows. There are two\nstimuli (e.g., two lights) and two responses (e.g., button presses), one asso-\nciated with each stimulus. Participants respond to each stimulus as rapidly\nas possible. When the two stimuli are presented at the same time (dual-task\ncondition), performance is typically worse on both tasks than when each\ntask is presented separately (single-task conditions).\nWhen the second stimulus is presented shortly after the first, there\nis typically a marked slowing of the response to the second stimulus:\nthe  psychological refractory period (PRP) effect. This effect is robust –\nRuthruff et al. (2009) obtained a large PRP effect even when participants\nwere given strong incentives to eliminate it.\nThe PRP effect has direct real-world relevance. Hibberd et al. (2013)\nstudied the effects of a simple in-vehicle task on braking performance when\nthe vehicle in front braked and slowed down. There was a classic PRP\neffect – braking time was slowest when the in-vehicle task was presented\nimmediately before the vehicle in front braked.\nHow can we explain the PRP effect? It is often argued task perfor-\nmance involves three successive stages: (1) perceptual; (2) central response\nselection; and (3) response execution. According to the bottleneck model\n(e.g., Pashler, 1994),\nThe response selection stage of the second task cannot begin until the\nresponse selection stage of the first task has finished, although the\nother stages . . . can proceed in parallel . . . according to this model,\nthe PRP effect is a consequence of the waiting time of the second task\nbecause of a bottleneck at the response selection stage.\n(Mittelstädt & Miller, 2017, p. 89)\nThe bottleneck model explains several findings. For example, consider the\neffects of varying the time between the start of the first and second stimuli\n(stimulus onset asynchrony (SOA)). According to the model, processing on\nthe first task should slow down second-task processing much more when\nthe SOA is small than when it is larger. The predicted finding is generally\nobtained (Mittelstädt & Miller, 2017).\nThe bottleneck model remains the most influential explanation of the\nPRP effect (and other dual-task costs). However, resource models (e.g.,\nNavon & Miller, 2002) are also influential. According to these models,\nlimited processing capacity can be shared between two tasks so both are\nprocessed simultaneously. Of crucial importance, sharing is possible even\nduring the response selection process. A consequence of sharing processing\ncapacity across task is that each task is processed more slowly than if per-\nformed on its own.\nMany findings can be explained by both models. However, resource\nmodels are more flexible than bottleneck models. Why is this? Resource\nmodels assume the division of processing resources between two tasks\nvaries freely to promote efficient performance.\nKEY TERMS\nPsychological refractory\nperiod (PRP) effect\nThe slowing of the\nresponse to the second\nof two stimuli when\npresented close together\nin time.\nStimulus onset\nasynchrony (SOA)\nTime interval between the\nstart of two stimuli.\nCreated from usyd on 2022-02-14 13:21:43.",
    "224\nVisual perception and attention\nAnother factor influencing the PRP effect is crosstalk (the two tasks\ninterfere directly with each other). This mostly occurs when the stimuli\nand/or responses on the two tasks are similar. A classic example of cross-\ntalk is when you try to rub your stomach in circles with one hand while\npatting your head with the other hand (try it!).\nFinally, note that participants in most studies receive only modest\namounts of practice in performing two tasks at the same time. As a con-\nsequence, the PRP effect may occur at least in part because participants\nreceive insufficient practice to eliminate it.\nFindings\nAccording to the bottleneck model, we would expect to find a PRP effect\neven when easy tasks are used and/or participants receive prolonged prac-\ntice. Contrary evidence was reported by Schumacher et al. (2001). They\nused two tasks: (1) say “one”, “two” or “three” to low-, medium- and\nhigh-pitched tones, respectively; (2) press response keys corresponding to\nthe position of a disc on a computer screen. These tasks were performed\ntogether for over 2,000 trials, by which time some participants performed\nthem as well together as singly.\nStrobach et al. (2013) conducted a study very similar to that of\nSchumacher et al. (2001). Participants took part in over 5,000 trials involv-\ning single-task or dual-task conditions. However, dual-task costs were not\neliminated after extensive practice: dual-task costs on the auditory task\nreduced from 185 to 60 ms and those on the visual task from 83 to 20 ms\n(see Figure 5.20). How did dual-task practice benefit performance? Practice\nspeeded up the central response selection stage in both tasks.\nWhy did the findings differ in the two studies discussed above? In both\nstudies, participants were rewarded for fast responding on single-task and\ndual-task trials. However, the way the reward system was set up in the\nSchumacher et al. study may have led participants to exert more effort in\ndual-task than single-task trials. This potential bias was absent from the\nKEY TERM\nCrosstalk\nIn dual-task conditions,\nthe direct interference\nbetween the tasks that is\nsometimes found.\nFigure 5.20\nReaction times for correct\nresponses only over eight\nexperimental sessions\nunder dual-task (auditory\nand visual tasks) and single-\ntask (auditory or visual task)\nconditions.\nFrom Strobach et al. (2013).\nReprinted with permission of\nSpringer.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n225\nStrobach et al. study. This difference in reward structure could explain the\ngreater dual-task costs in the Strobach et al. study.\nHesselmann et al. (2011) studied the PRP effect using event-related\npotentials. The slowing of responses on the second task was closely\nmatched by slowing in the onset of the P300 (an ERP component reflecting\nresponse selection). However, there was no slowing of earlier ERP compo-\nnents reflecting perceptual processing. Thus, as predicted by the bottleneck\nmodel, the PRP effect depended on response selection rather than percep-\ntual processes.\nAccording to the resource model approach, individuals choose whether\nto use serial or parallel processing on PRP tasks. Miller et al. (2009) argued\nthat serial processing generally leads to superior performance compared\nwith parallel processing. However, parallel processing should theoretically\nbe superior when the stimuli associated with the two tasks are mostly pre-\nsented close in time. As predicted, there was a shift from predominantly\nserial processing towards parallel processing when that was the case.\nMiller et al. (2009) used very simple tasks and it is likely parallel pro-\ncessing is most likely to be used with such tasks. Han and Marois (2013)\nused two tasks, one of which was relatively difficult. Participants used\nserial processing even when parallel processing was encouraged by finan-\ncial rewards.\nFinally, we consider the theoretically important backward crosstalk\neffect: “characteristics of Task 2 of 2 subsequently performed tasks influ-\nence Task 1 performance” (Janczyk et al., 2018, p. 261). Hommel (1998)\nobtained this effect. Participants responded to Task 1 by making a left or\nright key-press and to Task 2 by saying “left” or “right”. Task 1 responses\nwere faster when the two responses were compatible (e.g., press right key\n+ say “right”) than when they were incompatible (e.g., press right key +\nsay “left”). Evidence for the backward crosstalk effect was also reported by\nJanczyk et al. (2018).\nWhy is the backward crosstalk effect theoretically important? It indi-\ncates that aspects of response selection processing on Task 2 occur before\nresponse selection processing on Task 1 has finished. This effect is incom-\npatible with the bottleneck model, which assumes response selection on\nTask 1 is completed prior to any response selection on Task 2. In other\nwords, this model assumes there is serial processing at the response selec-\ntion stage. In contrast, the backward crosstalk effect is compatible with the\nresource model approach.\nSummary and conclusions\nThe findings from most research on the psychological refractory period\neffect are consistent with the bottleneck model. As predicted, this effect is\ntypically larger when the second task follows very soon after the first task.\nIn addition, even prolonged practice rarely eliminates the psychological\nrefractory period effect suggesting that central response selection processes\ntypically occur serially.\nThe bottleneck model assumes processing is less flexible than is often\nthe case. For example, the existence of the backward crosstalk effect is\ninconsistent with the bottleneck model but consistent with the resource\nKEY TERM\nBackward crosstalk\neffect\nAspects of Task 2\ninfluence response\nselection and\nperformance speed on\nTask 1 in studies on the\npsychological refractory\nperiod (PRP) effect.\nCreated from usyd on 2022-02-14 13:21:43.",
    "226\nVisual perception and attention\nmodel approach. Fischer et al. (2018) also found evidence for much flex-\nibility. There was less interference between the two tasks when finan-\ncial rewards were offered because participants devoted more processing\nresources to protecting the first task from interference. However, the\nresource model approach has the disadvantage compared to the bottleneck\nmodel that its predictions are less precise, making it harder to submit to\ndetailed empirical testing.\nFinally, as Koch et al. (2017, p. 575) pointed out, the bottleneck\nmodel “can be applied (with huge success) mainly for conditions in which\ntwo tasks are performed strictly sequentially”. This is often the case with\nresearch on the psychological refractory period effect but is much less\napplicable to more complex dual-task situations.\n“AUTOMATIC” PROCESSING\nWe have seen in studies of divided attention that practice often causes a dra-\nmatic improvement in performance. This improvement has been explained\nby assuming some processes become automatic through prolonged prac-\ntice. For example, the huge amount of practice we have had with reading\nwords has led to the assumption that familiar words are read “automati-\ncally”. Below we consider various definitions of “automaticity”. We also\nconsider different approaches to explaining the development of automatic\nprocessing.\nTraditional approach: Shiffrin and Schneider (1977)\nShiffrin and Schneider (1977) and Schneider and Shiffrin (1977) distin-\nguished between controlled and automatic processes:\n●\nControlled processes are of limited capacity, require attention and can\nbe used flexibly in changing circumstances.\n●\nAutomatic processes suffer no capacity limitations, do not require\nattention and are very hard to modify once learned.\nIn Schneider and Shiffrin’s (1977) research, participants memorised letters\n(the memory set) followed by a visual display containing letters. They\nthen decided rapidly whether any item in the visual display was the same\nas any item in the memory set. The crucial manipulation was the type of\nmapping. With consistent mapping, only consonants were used as members\nof the memory set and only numbers were used as distractors in the visual\ndisplay (or vice versa). Thus, a participant given only consonants to mem-\norise would know any consonant detected in the visual display was in the\nmemory set. With varied mapping, numbers and consonants were both used\nto form the memory set and to provide distractors in the visual display.\nThe mapping manipulation had dramatic effects (see Figure 5.21). The\nnumbers of items in the memory set and visual display greatly affected\ndecision speed only with varied mapping. According to Schneider and\nShiffrin (1977), varied mapping involved serial comparisons between each\nitem in the memory set and each item in the visual display until a match\nwas achieved or every comparison had been made. In contrast, consistent\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n227\nmapping involved automatic processes operating independently and in par-\nallel. These automatic processes have evolved through prolonged practice\nin distinguishing between letters and numbers.\nIn a second experiment, Shiffrin and Schneider (1977) used consistent\nmapping with the consonants B to L forming one set and Q to Z the other\nset. As before, items from only one set always formed the memory set\nwith all the distractors in the visual display being selected from the other\nset. Performance improved greatly over 2,100 trials, reflecting increased\nautomaticity. After that, there were 2,100 trials with the reverse consist-\nent mapping (swapping over the memory and visual display sets). With\nthis reversal, it took nearly 1,000 trials before performance recovered to its\nlevel at the start of the experiment!\nEvidence that there may be limited (or no conscious awareness in\nthe consistent mapping condition was reported by Jansma et al. (2001)).\nIncreasing automaticity (indexed by increased performance speed) was\naccompanied by reduced activation in areas associated with conscious\nawareness (e.g., dorsolateral prefrontal cortex).\nIn sum, automatic processes function rapidly and in parallel but are\ninflexible (second part of the second experiment). Controlled processes are\nflexible and versatile but operate relatively slowly and in a serial fashion.\nLimitations\nWhat are the limitations with this approach? First, the distinction between\nautomatic and controlled processes is oversimplified (discussed below).\nSecond, Shiffrin and Schneider (1977) argued automatic processes operate\nin parallel and place no demands on attentional capacity and so decision\nspeed should be unrelated to the number of items. However, decision\nFigure 5.21\nResponse times on a\ndecision task as a function\nof memory-set size, display-\nset size and consistent vs\nvaried mapping.\nResponse times on a\ndecision task as a function\nof memory-set size, display-\nset size and consistent\nvs varied mapping. Data\nfrom Shiffrin and Schneider\n(1977).\nAmerican Psychological\nAssociation.\nCreated from usyd on 2022-02-14 13:21:43.",
    "228\nVisual perception and attention\nspeed was slower when the memory set and visual display both contained\nseveral items (see Figure 5.21). Third, the theory is descriptive rather than\nexplanatory – it does not explain how serial controlled processing turns into\nparallel automatic processing.\nDefinitions of automaticity\nShiffrin and Schneider (1977) assumed there is a clear-cut distinction\nbetween automatic and controlled processes. More specifically, automatic\nprocesses possess several features (e.g., inflexibility; very efficient because\nthey have no capacity limitations; occurring in the absence of attention). In\nessence, it is assumed there is perfect coherence or consistency among the\nfeatures (i.e., they are all found together).\nMoors and De Houwer (2006) and Moors (2016) identified four key\nfeatures associated with automaticity:\n(1) unconscious: lack of conscious awareness of at least one of the fol-\nlowing: “the input, the output, and the transition from one to the\nother” (Moors, 2016, p. 265);\n(2) efficient: using very little attentional capacity;\n(3) fast;\n(4) goal-unrelated or goal-uncontrolled: at least one of the following is\nmissing: “the goal is absent, the desired state does not occur, or the\ncausal relation [between the goal and the occurrence of the desired\nstate] is absent” (Moors, 2016, p. 265).\nWhy might these four features (or the similar ones identified by Shiffrin\nand Schneider (1977)) often be found together? Instance theory (Logan,\n1988; Logan et al., 1999) provides an influential answer. It is assumed\ntask practice leads to storage of information in long-term memory which\nfacilitates subsequent performance on that task. In essence, “Automaticity\nis memory retrieval: performance is automatic when it is based on a\nsingle-step direct-access retrieval of past solutions from memory” (Logan,\n1988, p. 493). For example, if you were given the problem “24 × 7 = ???”\nnumerous times, you would retrieve the answer (168) “automatically”\nwithout performing any mathematical calculations.\nInstance theory makes coherent sense of several characteristics of\nautomaticity. Automatic processes are fast because they require only the\nretrieval of past solutions from long-term memory. They make few demands\non attentional resources because the retrieval of heavily  over-learned\ninformation is relatively effortless. Finally, there is no conscious awareness\nof automatic processes because no significant processes intervene between\nstimulus presentation and retrieval of the correct response.\nIn spite of its strengths, instance theory is limited (see Moors, 2016).\nFirst, the theory implies the key features of automaticity will typically all\nbe found together. However, this is not the case (see below). Second, it\nis assumed practice leads to automatic retrieval of solutions with learners\nhaving no control over such retrieval. However, Wilkins and Rawson (2011)\nfound evidence learners can exercise top-down control over retrieval: when\nthe instructions emphasised accuracy, there was less evidence of retrieval\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n229\nthan when they emphasised speed. Thus, the use of retrieval after practice\nis not fully automatic.\nMelnikoff and Bargh (2018) argued that the central problem with the\ntraditional approach is that no research has shown the four features asso-\nciated with “automaticity” occurring together. As they pointed out, “No\nattempt has been made to estimate the probability of a process being inten-\ntional given that is conscious versus unconscious, or the probability of a\nprocess being controllable given that it is efficient versus inefficient, and so\nforth” (p. 282).\nDecompositional approach: Moors (2016)\nMoors and De Houwer (2006) and Moors (2016) argued that previous\ntheoretical approaches are greatly oversimplified. Instead, they favoured\na decompositional approach. According to this approach, the features\nof automaticity are clearly separable and are by no means always found\ntogether: “It is dangerous to draw inferences about the presence or absence\nof one feature on the basis of the presence or absence of another” (Moors &\nde Houwer, 2006, p. 320).\nMoors and De Houwer (2006) also argued there is no firm dividing line\nbetween automaticity and non-automaticity. The features are continuous\nrather than all-or-none (e.g., a process can be fairly fast or slow; it can be\npartially conscious). As a result, most processes involve a blend of automa-\nticity and non-automaticity. This approach is rather imprecise because few\nprocesses are 100% automatic or non-automatic. However, we can make\nrelative statements (e.g., process X is more/less automatic than process Y).\nMoors (2016) claimed the relationships between factors such as goals,\nattention and consciousness are much more complex than claimed within\ntraditional approaches to “automaticity”. This led her to develop a new the-\noretical account (see Figure 5.22). A key assumption is that all information\nFigure 5.22\nFactors that are hypothesised to influence representational quality within Moors’ (2016) theoretical approach.\nFrom Moors (2016).\nCurrent stimulus factors\n• Stimulus quality: duration, intensity\n• Un/expectedness\n• Goal in/congruence\n• Novelty/familiarity\nPrior stimulus factors\n• Frequency\n• Recency\n• Stimulus quality: duration, intensity\nPrior stimulus × person factors\n• Selection history\n• Reward history\nPrior stimulus representation factors\n• Existence of stimulus representation in LTM\n• Strength of trace to stimulus representation in LTM\n~ Availability of stimulus representation in LTM\n• Quality of stimulus representation in WM\nCurrent stimulus representation factors\n• Quality of stimulus representation: duration,\nintensity, distinctiveness\n~ Accessibility of stimulus representation for\nprocessing\nAttention\nAttention\nConscious\nprocessing\nUnconscious\nprocessing\n1st threshold\n2nd threshold\nCreated from usyd on 2022-02-14 13:21:43.",
    "230\nVisual perception and attention\nprocesses require an input of sufficient representational quality (defined by\nthe “intensity, duration, and distinctiveness of a representation”, Moors,\n2016, p. 273).\nWhat factors determine representational quality?\n(1) current stimulus factors, including the extent to which a stimulus is\nexpected or unexpected, familiar or novel, and goal congruent or\nincongruent;\n(2) prior stimulus factors (e.g., the frequency and recency with which the\ncurrent stimulus has been encountered);\n(3) prior stimulus representation factors based on relevant information\nstored within long-term memory;\n(4) attention, which enhances or amplifies the impact of current stimulus\nfactors and prior stimulus representation factors on the current stim-\nulus representation.\nAccording to this theoretical account, the above factors influence repre-\nsentational quality additively so that a high level of one factor can compen-\nsate for a low level of another factor. For example, selective attention or\nrelevant information in long-term memory can compensate for brief stim-\nulus presentations. The main impact of consciousness occurs later than\nfor other factors (e.g., attention and goal congruence). More specifically,\nrepresentational quality must reach the first threshold to permit uncon-\nscious processing but a more stringent second threshold to permit conscious\nprocessing.\nFindings\nAccording to Moors’ (2016) theoretical framework, there is a flexible rela-\ntionship between controlled and conscious processing. This contrasts with\nSchneider and Shiffrin’s (1977) assumption that executive control is always\nassociated with conscious processing.\nDiao et al. (2016) reported findings consistent with Moors’ prediction.\nThey used a Go/No-Go task where participants made a simple response\n(Go trials) or withheld it (No-Go trials). High-value or low-value financial\nrewards were available for successful performance. Task stimuli were pre-\nsented above or below the level of conscious awareness.\nWhat did Diao et al. (2016) find? Performance was better on high-\nreward than low-reward trials even when task processing was uncon-\nscious. In addition, participants showed superior unconscious inhibitory\ncontrol (assessed by event-related potentials) on high-reward trials. Thus,\none feature of automaticity (unconscious processing) was present whereas\nanother feature (goal-uncontrolled) was not.\nHuber-Huber and Ansorge (2018) also reported problems for the tra-\nditional approach. Participants received target words indicating an upward\nor downward direction (e.g., above; below). Prior to the target word, a\nprime word also indicating an upward or downward direction was pre-\nsented below the level of conscious awareness. Response times to the target\nwords were slower when there was a conflict between the meanings of the\nprime and target words than when they were congruent in meaning. As in\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n231\nthe study by Diao et al. (2016), unconscious processing was combined with\ncontrol, a combination that is inconsistent with the traditional approach.\nEvaluation\nThe theoretical approach to automaticity proposed by Moors (2016) has\nseveral strengths. First, the assumption that various features associated with\nautomaticity often correlate poorly with each other is clearly superior to\nthe earlier notion that these features exhibit perfect coherence. Second, her\nassumption that processes vary in the extent to which they are “automatic”\nis much more realistic than the simplistic division of processes into auto-\nmatic and non-automatic. Third, the approach is more comprehensive than\nprevious ones because it considers more factors relevant to “automaticity”.\nWhat are the limitations with Moors’ (2016) approach? First, numer-\nous factors are assumed to influence representational quality (and thus the\nextent to which processes are automatic) (see Figure 5.22). It would thus\nrequire large-scale experimental research to assess the ways all these factors\ninteract. Second, the approach provides only a partial explanation of the\nunderlying mechanisms causing the various factors to influence representa-\ntional quality.\nCHAPTER SUMMARY\n•\nFocused auditory attention. When two auditory messages\nare presented at the same time, there is less processing of the\nunattended than the attended message. Nevertheless, unattended\nmessages often receive some semantic processing. The restricted\nprocessing of unattended messages may reflect a bottleneck at\nvarious stages of processing. However, theories assuming the\nexistence of a bottleneck de-emphasise the flexibility of selective\nauditory attention. Attending to one voice among several (the\ncocktail party problem) is a challenging task. Human listeners use\ntop-down and bottom-up processes to select one voice. Top-\ndown processes include the use of various control processes\n(e.g., focused attention; inhibitory processes) and learning about\nstructural consistencies present in the to-be-attended voice.\n•\nFocused visual attention. Visual attention can resemble a\nspotlight or zoom lens. In addition, the phenomenon of split\nattention suggests visual attention can also resemble multiple\nspotlights. However, accounts based on spotlights or a zoom\nlens typically fail to specify the underlying mechanisms. Visual\nattention can be object-based, space-based or feature-based, and\nit is often object-based and space-based at the same time. Visual\nattention is flexible and is influenced by factors such as individual\ndifferences.\nAccording to Lavie’s load theory, we are more susceptible\nto distraction when our current task involves low perceptual load\nand/or high cognitive load. There is much support for this theory.\nInteractive exercise:\nDefinitions of attention\nCreated from usyd on 2022-02-14 13:21:43.",
    "232\nVisual perception and attention\nHowever, the effects of perceptual and cognitive load are often\nnot independent as predicted. In addition, it is hard to test the\ntheory because the terms “perceptual load” and “cognitive load”\nare vague. There are stimulus-driven ventral attention and goal-\ndirected dorsal attention networks involving different (but partially\noverlapping) brain networks. More research is required to establish\nhow these two attentional systems interact. Additional brain\nnetworks (e.g., cingulo-opercular network; default mode network)\nrelevant to attention have also been identified.\n•\nDisorders of visual attention. Neglect occurs when damage\nto the ventral attention network in the right hemisphere impairs\nthe functioning of the undamaged dorsal attention network. This\nimpaired functioning of the dorsal attention network involves\nreduced activation and alertness within the left hemisphere.\nExtinction is due to biased competition for attention between the\ntwo hemispheres combined with reduced attentional capacity.\nMore research is required to clarify differences among neglect\npatients in their specific processing deficits (e.g., the extent to\nwhich failures to detect left-field stimuli are due to impaired spatial\nworking memory).\n•\nVisual search. One problem with airport security checks is that\nthere are numerous possible target objects. Another problem is\nthe rarity of targets, which leads to excessive caution in reporting\ntargets. According to feature integration theory, object features\nare processed in parallel and then combined by focused attention\nin visual search. This theory ignores our use of general scene\nknowledge in everyday life to focus visual search on areas of the\nscene most likely to contain the target object. It also exaggerates\nthe prevalence of serial processing. Contemporary approaches\nemphasise the role of perception in visual search. Parallel\nprocessing is very common because much information is typically\nextracted from the peripheral visual field as well as from central or\nfoveal vision. Problems in visual search occur when there is visual\ncrowding in peripheral vision.\n•\nCross-modal effects. In the real world, we often coordinate\ninformation across sense modalities. In the ventriloquist effect,\nvision dominates sound because an object’s location is typically\nindicated more precisely by vision. In the temporal ventriloquism\neffect, sound dominates vision because the auditory modality is\ntypically more precise at discriminating temporal relations. Both\neffects depend on the assumption that visual and auditory stimuli\ncome from the same object. Auditory or vibrotactile warning\nsignals that are informative about the direction of danger and/or\nimminence of collision speed up drivers’ braking times. We lack\na theoretical framework within which to understand why some\nwarning signals are more effective than others.\nCreated from usyd on 2022-02-14 13:21:43.",
    "Attention and performance\n233\n•\nDivided attention: dual-task performance. Individuals engaging\nin heavy multi-tasking show evidence of increased distractibility\nand impaired attentional control. A demanding secondary task\n(e.g., mobile-phone use) impairs aspects of driving performance\nrequiring cognitive control but not well-practised driving skills (e.g.,\nlane keeping). Multiple resource theory and threaded cognition\ntheory both assume dual-task performance depends on several\nlimited-capacity processing resources. This permits two tasks to\nbe performed together successfully provided they use different\nprocessing resources. This general approach de-emphasises high-\nlevel executive processes (e.g., monitoring and coordinating two\ntasks).\nSome neuroimaging studies have found underadditivity\nin dual-task conditions (less activation than for the two tasks\nperformed separately). This may indicate people have limited\ngeneral processing resources. Other neuroimaging studies\nhave found dual-task conditions can introduce new processing\ndemands of task coordination associated with activation within the\ndorsolateral prefrontal cortex and cerebellum. It is often unclear\nwhether patterns of brain activation are directly relevant to task\nprocessing.\nThe psychological refractory period (PRP) effect can be\nexplained by a processing bottleneck during response selection.\nThis remains the most influential explanation. However,\nsome evidence supports resource models claiming parallel\nprocessing of two tasks is often possible. Such models are more\nflexible than bottleneck models and they provide an explanation\nfor interference effects from the second of two tasks on the first\none.\n•\n“Automatic” processing. Shiffrin and Schneider distinguished\nbetween slow, flexible controlled processes and fast, automatic\nones. This distinction is greatly oversimplified. Other theorists have\nclaimed automatic processes are unconscious, efficient, fast and\ngoal-unrelated. However, these four processing features are not\nall-or-none and they often correlate poorly with each other. Thus,\nthere is no sharp distinction between automatic and non-automatic\nprocesses. Moors’ (2016) decompositional approach plausibly\nassumes that there is considerable flexibility in terms of the extent\nto which any given process is “automatic”.\nFURTHER READING\nChen, Y.-C. & Spence, C. (2017). Assessing the role of the “unity assumption”\non multi-sensory integration: A review. Frontiers in Psychology, 8 (Article 445).\nFactors determining the extent to which stimuli from different sensory modalities\nare integrated are discussed.\nEngstrom, J., Markkula, G., Victor, T. & Merat, N. (2017). Effects of cognitive\nload on driving performance: The cognitive control hypothesis. Human Factors,\nCreated from usyd on 2022-02-14 13:21:43.",
    "234\nVisual perception and attention\n59, 734–764. Johan Engstrom and his colleagues review research on factors influ-\nencing driving performance and provide a new theoretical approach.\nHulleman, J. & Olivers, C.N.L. (2017). The impending demise of the item in visual\nsearch. Behavioral and Brain Sciences, 40, 1–20. This review article indicates very\nclearly why theoretical accounts of visual search increasingly emphasise the role\nof fixations and visual perception. Several problems with previous  attention-based\ntheories of visual search are also discussed.\nKarnath, H.-O. (2015). Spatial attention systems in spatial neglect. Neuropsychologia,\n75, 61–73. Hans-Otto Karnath discusses theoretical accounts of neglect empha-\nsising the role of attentional systems.\nKoch, I., Poljac, E., Müller, H. & Kiesel, A. (2018). Cognitive structure, flexibil-\nity, and plasticity in human multitasking – An integrative review of dual-task\nand task-switching research. Psychological Bulletin, 144, 557–583. Iring Koch\nand colleagues review dual-task and task-switching research with an emphasis on\nmajor theoretical perspectives.\nMcDermott, J.H. (2018). Audition. In J.T. Serences (ed.), Stevens’ Handbook\nof Experimental Psychology and Cognitive Neuroscience, Vol. 2: Sensation,\nPerception, and Attention (4th edn; pp. 63–120). New York: Wiley. Josh\nMcDermott discusses theory and research focused on selective auditory attention\nin this comprehensive chapter.\nMelnikoff, D.E. & Bargh, J.A. (2018). The mythical number two. Trends in\nCognitive Sciences, 22, 280–293. Research revealing limitations with traditional\ntheoretical approaches to “automaticity” is discussed.\nMoors, A. (2016). Automaticity: Componential, causal, and mechanistic expla-\nnations. Annual Review of Psychology, 67, 263–287. Agnes Moors provides an\nexcellent critique of traditional views on “automaticity” and develops her own\ncomprehensive theoretical account.\nNobre, A.C. (2018). Attention. In J.T. Serences (ed.), Stevens’ Handbook of\nExperimental Psychology and Cognitive Neuroscience, Vol. 2: Sensation,\nPerception, and Attention (4th edn; pp. 241–316). New York: Wiley. Anna (Kia)\nNobre discusses the key role played by attention in numerous aspects of cogni-\ntive processing.\nCreated from usyd on 2022-02-14 13:21:43.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-14 13:21:43.",
    "Created from usyd on 2022-02-14 13:21:43.",
    "PART II\nMemory\nHow important is memory? Imagine if we were without it. We would not\nrecognise anyone or anything as familiar. We would be unable to talk, read\nor write because we would remember nothing about language. We would\nhave extremely limited personalities because we would have no recollection\nof the events of our own lives and therefore no sense of self. In sum, we\nwould have the same lack of knowledge as a newborn baby.\nNairne et al. (2007) argued there were close links between memory and sur-\nvival in our evolutionary history. Our ancestors prioritised information rele-\nvant to their survival (e.g., remembering the location of food or water; ways\nof securing a mate). Nairne et al. found memory for word lists was espe-\ncially high when participants rated the words for their relevance to survival\nin a dangerous environment: the survival-processing effect. This effect has\nbeen replicated several times (Kazanas & Altarriba, 2015) and is stronger\nwhen participants imagine themselves alone in a dangerous environment\nrather than with a group of friends (Leding & Toglia, 2018). In sum, human\nmemory may have evolved in part to promote survival.\nWe use memory for numerous purposes throughout every day of our lives. It\nallows us to keep track of conversations, to remember how to use a mobile\nphone, to write essays in examinations, to recognise other people’s faces, to\ntake part in conversations, to ride a bicycle, to carry out intentions and, perhaps,\nto play various sports. More generally, our interactions with others and with\nthe environment depend crucially on having an effective memory system.\nThe wonders of human memory are discussed at length in Chapters 6–8.\nChapter 6 deals mainly with key issues regarded as important from the early\ndays of memory research. For example, we consider the distinction between\nshort-term and long-term memory. The notion of short-term memory has\nbeen largely superseded by that of a working-memory system combining\nthe functions of processing and short-term information storage. There is\nextensive coverage of working memory in Chapter 6.\nAnother topic discussed at length in Chapter 6 is learning. Long-term\nmemory is generally enhanced when meaning is processed at the time of\nlearning. Long-term memory is also better if much of the learning period\nCreated from usyd on 2022-02-14 13:22:32.",
    "238\nMemory\nis spent practising retrieval. Evidence suggesting some learning is implicit\n(i.e., does not depend on conscious processes) is also discussed. Finally, we\ndiscuss forgetting. Why do we tend to forget information over time?\nChapter 7 is devoted to long-term memory. Our long-term memories\ninclude personal information, knowledge about language, much knowledge\nabout psychology (hopefully!), knowledge about thousands of objects in the\nworld around us, and information about how to perform various skills (e.g.,\nriding a bicycle; playing the piano). The central issue addressed in Chapter 7\nis how to account for this incredible richness. Several theorists have claimed\nthere are several long-term memory systems. Others argue that there are\nnumerous processes that are combined and recombined depending on the\nspecific demands of any given memory task.\nMemory is important in everyday life in ways de-emphasised historically.\nFor example, autobiographical memory (discussed in Chapter 8) is of great\nsignificance to us. It gives us a coherent sense of ourselves and our person-\nalities. The other topics considered in Chapter 8 are eyewitness testimony\nand prospective memory (memory for future intentions). Research into eye-\nwitness testimony has revealed that eyewitness testimony is often much less\naccurate than generally assumed. This has implications for the legal system\nbecause hundreds of innocent individuals have been imprisoned solely on\nthe basis of eyewitness testimony.\nWhen we think about memory, we naturally focus on memory of the past.\nHowever, we also need to remember numerous future commitments (e.g.,\nmeeting a friend as arranged), and such remembering involves prospective\nmemory. We will consider how we try to ensure we carry out our future\nintentions.\nThe study of human memory is fascinating, and substantial progress has\nbeen made. However, it is complex and depends on several factors. Four\nkinds of factors are especially important: events, participants, encoding and\nretrieval (Roediger, 2008). Events range from words and pictures to texts\nand life events. Participants vary in age, expertise, memory-specific dis-\norders and so on. What happens at encoding varies as a function of task\ninstructions, the immediate context and participants’ strategies. Finally,\nmemory performance at retrieval often varies considerably depending on\nthe nature of the memory task (e.g., free recall; cued recall; recognition).\nThe take-home message is that memory findings are context-sensitive –\nthey depend on interactions between the four factors. Thus, the effects of\nmanipulating, say, what happens at encoding depend on the participants\nused, the events to be remembered and the conditions of retrieval. That\nexplains why Roediger (2008) entitled his article, “Why the laws of memory\nvanished”. How, then, do we make progress? As Baddeley (1978, p. 150)\nargued, “The most fruitful way to extend our understanding of human\nmemory is not to search for broader generalisations and ‘principles’, but\nis rather to develop ways of separating out and analysing more deeply the\ncomplex underlying processes.”\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and\nforgetting\nINTRODUCTION\nThis chapter (and the next two) focus on human memory. All three chap-\nters deal with intact human memory, but Chapter 7 also considers amnesic\npatients in detail. Traditional laboratory-based research is the focus of this\nchapter and Chapter 7, with more naturalistic research being discussed\nin Chapter 8. There are important links among these different types of\nresearch. For example, many theoretical issues relevant to brain-damaged\nand healthy individuals can be tested in the laboratory or in the field.\nLearning and memory involve several stages of processing. Encoding\noccurs during learning: it involves transforming presented information\ninto a representation that can subsequently be stored. This is the first\nstage. As a result of encoding, information is stored within the memory\nsystem. Thus, storage is the second stage. The third stage is retrieval, which\ninvolves recovering information from the memory system. Forgetting (dis-\ncussed later, see pp. 278–293) occurs when our attempts at retrieval are\nunsuccessful.\nSeveral topics are discussed in this chapter. The basic structure of the\nchapter consists of three sections:\n(1) The first section focuses mostly on short-term memory (a form of\nmemory in which information is held for a brief period of time). This\nsection has three topics (short-term vs long-term memory; working\nmemory; and working memory: executive functions and individual\ndifferences). The emphasis here is on the early stages of processing\n(especially encoding).\n(2) The second section focuses on learning and the processes occurring\nduring the acquisition of information (i.e., encoding processes) leading to\nlong-term memory. Learning can be explicit (occurring with conscious\nawareness of what has been learned) or implicit (occurring without\nconscious awareness of what has been learned). The first two topics in\nthis section (levels of processing; learning through retrieval) focus on\nexplicit learning whereas the third topic focuses on implicit learning.\nChapter\n6\nKEY TERM\nEncoding\nThe process by which\ninformation contained\nin external stimuli is\ntransformed into a\nrepresentation that can be\nstored within the memory\nsystem.\nCreated from usyd on 2022-02-14 13:22:32.",
    "240\nMemory\n(3) The third section consists of a single topic: forgetting from long-term\nmemory. The emphasis differs from the other two sections in that the\nemphasis is on retrieval processes rather than encoding processes.\nMore specifically, the focus is on the reasons responsible for the fail-\nures of retrieval.\nSHORT-TERM VS LONG-TERM MEMORY\nMany theorists distinguish between short-term and long-term memory. For\nexample, there are enormous differences in capacity: only a few items can\nbe held in short-term memory compared with essentially unlimited capac-\nity in long-term memory. There are also massive differences in duration: a\nfew seconds for short-term memory compared with up to several decades\nfor long-term memory. The distinction between short-term and long-term\nmemory stores was central to multi-store models. More recently, however,\nsome theorists have proposed unitary-store models in which this distinction\nis much less clear-cut. Both types of models are discussed below.\nMulti-store model\nAtkinson and Shiffrin (1968) proposed an extremely influential multi-store\nmodel (see Figure 6.1):\n●\nsensory stores, each modality-specific (i.e., limited to one sensory\nmodality) and holding information very briefly;\n●\nshort-term store of very limited capacity;\n●\nlong-term store of essentially unlimited capacity holding information\nover very long periods of time.\nAccording to the multi-store model, environmental stimulation is  initially\nprocessed by the sensory stores. These stores are modality-specific (e.g.,\nvision; hearing). Information is held very briefly in the sensory stores, with\nsome being attended to and processed further within the short-term store.\nSensory stores\nThe visual store (iconic memory) holds visual information briefly.\nAccording to a recent estimate (Clarke & Mack, 2015), iconic memory for\na natural scene lasts for at least 1,000 ms after stimulus offset. If you twirl\nKEY TERM\nIconic memory\nA sensory store that\nholds visual information\nfor between 250–1,000\nmilliseconds following the\noffset of a visual stimulus.\nFigure 6.1\nThe multi-store model of\nmemory as proposed by\nAtkinson and Shiffrin (1968).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n241\na lighted object in a circle in the dark, you will see a circle of light because\nof the persistence of visual information in iconic memory. More generally,\niconic memory increases the time for which visual information is accessible\n(e.g., when reading).\nAtkinson and Shiffrin (1968) and many other theorists have assumed\niconic memory is pre-attentive (not dependent on attention). However,\nMack et  al. (2016) obtained findings strongly suggesting that iconic\nmemory does depend on attention. Participants had to report the letters\nin the centre of a visual array (iconic memory) or whether four circles pre-\nsented close to the fixation point were the same colour. Performance on\nthe iconic memory task was much worse when the probability of having\nto perform the iconic memory task was only 10% rather than 90%. This\nhappened because there was much less attention to the letters in the former\ncondition.\nEchoic memory, the auditory equivalent of iconic memory, holds audi-\ntory information for a few seconds. Suppose someone asked you a ques-\ntion while your mind was elsewhere. Perhaps you replied “What did you\nsay?”, just before realising you did know what had been said. This “play-\nback” facility depends on echoic memory. Ioannides et  al. (2003) found\nthe duration of echoic memory was longer in the left hemisphere than the\nright, probably because of the dominance of the left hemisphere in lan-\nguage processing.\nThere are sensory stores associated with all other senses (e.g., touch;\ntaste). However, they are less important than iconic and echoic memory\nand have attracted much less research.\nShort-term memory\nShort-term memory has very limited capacity. Consider digit span: par-\nticipants listen to a random digit series and then repeat back the digits\nimmediately in the correct order. There are also letter and word spans. The\nmaximum number of items recalled without error is typically about seven.\nThere are two reasons for rejecting seven items as the capacity of\nshort-term memory. First, we must distinguish between items and chunks –\n“groups of items . . . collected together and treated as a single unit” (Mathy\n& Feldman, 2012, p. 346). For example, most individuals presented with\nthe letter string IBMCIAFBI would treat it as three chunks rather than\nnine letters. Here is another example: you might find it hard to recall the\nfollowing five words: is thing many-splendoured a love but easier to recall\nthe same words presented as follows: love is a many-splendoured thing.\nSimon (1974) showed the importance of chunking. Immediate serial\nrecall was 22 words with 8-word sentences but only 7 with unrelated\nwords. In contrast, the number of chunks recalled varied less: it was 3 with\nthe sentences compared to 7 with the unrelated words. Second, estimates of\nshort-term memory capacity are often inflated because participants’ perfor-\nmance is influenced by rehearsal and long-term memory.\nWhat influences chunking? As we have seen, it is strongly determined by\ninformation stored in long-term memory (e.g., IBM stands for International\nBusiness Machines). However, chunking also depends on people’s abilities\nto identify patterns or regularities in the material presented for learning.\nKEY TERMS\nEchoic memory\nA sensory store that holds\nauditory information\nfor approximately 2–3\nseconds.\nChunks\nStored units formed from\nintegrating smaller pieces\nof information.\nInteractive exercise:\nCapacity of short-term\nmemory\nInteractive exercise:\nDuration of short-term\nmemory\nCreated from usyd on 2022-02-14 13:22:32.",
    "242\nMemory\nFor example, compare the digit sequences 2 3 4 5 6 and 2 4 6 3 5. It is\nmuch easier to chunk the former sequence as “all digits between 2 and 6”.\nChekaf et  al. (2016) found participants’ short-term memory was greatly\nenhanced by spontaneous detection of such patterns. When there were no\npatterns in the learning material, short-term memory was only three items.\nA similar capacity limit was reported by Chen and Cowan (2009).\nWhen rehearsal was prevented by articulatory suppression (saying “the”\nrepeatedly), only three chunks were recalled.\nWithin the multi-store model, it is assumed all items within short-term\nmemory have equal importance. However, this is an oversimplification.\nVergauwe and Langerock (2017) assessed speed of performance when par-\nticipants were presented with four letters followed by a probe letter and\ndecided whether the probe was the same as any of the original letters.\nResponse to the probe was fastest when it corresponded to the letter cur-\nrently being attended to (cues were used to manipulate which letter was the\nfocus of attention at any given moment).\nHow is information lost from short-term memory? Several answers\nhave been provided (Endress & Szabó, 2017). Atkinson and Shiffrin (1968)\nemphasised the importance of displacement – the capacity of short-term\nmemory is very limited, and so new items often displace items currently in\nshort-term memory. Another possibility is that information in short-term\nmemory decays over time in the absence of rehearsal. A further possibility\nis interference which could come from items on previous trials and/or from\ninformation presented during the retention interval.\nThe experimental findings are variable. Berman et  al. (2009) claimed\ninterference is more important than decay. Short-term memory perfor-\nmance on any given trial was disrupted by words presented on the previ-\nous trial. Suppose this disruption effect occurred because words from the\nprevious trial had not decayed sufficiently. If so, disruption would have\nbeen greatly reduced by increasing the inter-trial interval. In fact, increas-\ning that interval had no effect. However, the disruption effect was largely\neliminated when interference from previous trials was reduced.\nCampoy (2012) pointed out Berman et al.’s (2009) research was limited\nbecause their experimental design did not allow them to observe any decay\noccurring within 3.3 seconds of item presentation. Campoy obtained strong\ndecay effects at time intervals shorter than 3.3 seconds. Overall, the find-\nings suggest decay occurs mostly at short retention intervals and interfer-\nence at longer ones.\nStrong evidence interference is important was reported by Endress and\nPotter (2014). They rapidly presented 5, 11 or 21 pictures of familiar objects.\nIn their unique condition, no pictures were repeated over trials, whereas in\ntheir repeated condition, the same pictures were seen frequently over trials.\nShort-term memory was greater in the unique condition in which there was\nmuch less interference than in the repeated condition (see Figure 6.2).\nIn sum, most of the evidence indicates that interference is the most\nimportant factor causing forgetting from short-term memory, although\ndecay may also play a part. There is little direct evidence that displace-\nment (emphasised by Atkinson & Shiffrin, 1968) is the main factor causing\nforgetting. However, it is possible that interference causes items to be dis-\nplaced from short-term memory (Endress & Szabó, 2017).\nKEY TERM\nArticulatory suppression\nRapid repetition of a\nsimple sound (e.g.,\n“the the the”), which\nuses the articulatory\ncontrol process of the\nphonological loop.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n243\nShort-term vs long-term memory\nIs short-term memory distinct from long-term memory, as assumed\nby Atkinson and Shiffrin (1968)? If they are separate, we would expect\nsome patients to have impaired long-term memory but intact short-term\nmemory with others showing the opposite pattern. This would produce\na double dissociation (see Glossary). The findings are generally support-\nive. Patients with amnesia (discussed in Chapter 7) have severe long-term\nmemory  impairments but nearly all have intact short-term memory (Spiers\net al., 2001).\nA few brain-damaged patients have severely impaired short-term\nmemory but intact long-term memory. For example, KF had no prob-\nlems with long-term learning and recall but had a very small digit span\n(Shallice & Warrington, 1970). Subsequent research indicated his short-\nterm memory problems focused mainly on recall of verbal material (letters;\nwords; digits) rather than meaningful sounds or visual stimuli (Shallice &\nWarrington, 1974).\nEvaluation\nThe multi-store model has been enormously influential. It is widely accepted\n(but see below) that there are three separate kinds of memory stores. Several\nsources of experimental evidence support the crucial distinction between\nshort-term and long-term memory. However, the strongest evidence proba-\nbly comes from brain-damaged patients having impairments only to short-\nterm or long-term memory.\nWhat are the model’s limitations? First, it is very oversimplified (e.g.,\nthe assumptions that the short-term and long-term stores are both unitary:\noperating in a single, uniform way). Below we discuss an approach where\nthe single short-term store is replaced by a working memory system having\nfour components. In similar fashion, there are several long-term memory\nsystems (see Chapter 7).\nFigure 6.2\nShort-term memory\nperformance in conditions\ndesigned to create\ninterference (repeated\ncondition) or minimise\ninterference (unique\ncondition) for set sizes 5, 11\nand 21 pictures.\nFrom Endress and Potter, 2014.\n5\n3.2\n4.9\n3.7\n4.8\n9.1\n2.3\n0\n2\n4\n6\n8\n10\nUnique condition\nRepeated condition\nCapacity estimate\n11\nSet size\n21\nCreated from usyd on 2022-02-14 13:22:32.",
    "244\nMemory\nSecond, the assumption that the short-term store is a gateway between\nthe sensory stores and long-term memory (see Figure 6.1) is incorrect.\nThe  information processed in short-term memory has typically already\nmade contact with information in long-term memory (Logie, 1999). For\nexample, you can only process IBM as a single chunk in short-term\nmemory after you have accessed long-term memory to obtain the meaning\nof IBM.\nThird, Atkinson and Shiffrin (1968) assumed information in short-\nterm memory represents the “contents of consciousness”. This implies\nonly information processed consciously is stored in long-term memory.\nHowever, there is much evidence for implicit learning (learning without\nconscious awareness of what has been learned) (discussed later, see\npp. 269–278).\nFourth, the assumption all items within short-term memory have\nequal status is incorrect. The item currently being attended to is accessed\nmore rapidly than other items within short-term memory (Vergauwe &\nLangerock, 2017).\nFifth, the notion that most information is transferred to long-term\nmemory via rehearsal greatly exaggerates its role in learning. In fact,\nonly a small fraction of the information stored in long-term memory was\nrehearsed during learning.\nSixth, the notion that forgetting from short-term memory is caused by\ndisplacement minimises the role of interference.\nUnitary-store model\nSeveral theorists have argued the multi-store approach should be replaced\nby a unitary-store model. According to such a model, “STM [short-term\nmemory] consists of temporary activations of LTM [long-term memory]\nrepresentations or of representations of items that were recently per-\nceived” (Jonides et  al., 2008, p. 198). In essence, Atkinson and Shiffrin\n(1968) emphasised the differences between short-term and long-term\nmemory whereas advocates of the unitary-store approach focus on the\nsimilarities.\nHow can unitary-store models explain amnesic patients having essen-\ntially intact short-term memory but severely impaired long-term memory?\nJonides et  al. (2008) argued they have special problems in forming novel\nrelations (e.g., between items and their context) in both short-term and\nlong-term memory. Amnesic patients perform well on short-term memory\ntasks because such tasks typically do not require storing relational infor-\nmation. Thus, amnesic patients should have impaired short-term memory\nperformance on tasks requiring relational memory.\nAccording to Jonides et  al. (2008), the hippocampus and surround-\ning medial temporal lobes (damaged in amnesic patients) are crucial for\nforming novel relations. Multi-store theorists assume these structures are\nmuch more involved in long-term than short-term memory. However,\nunitary-store models predict the hippocampus and medial temporal lobes\nwould be involved if a short-term memory task required forming novel\nrelations.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n245\nFindings\nSeveral studies have assessed the performance of amnesic patients on\nshort-term memory tasks. In some studies (e.g., Hannula et al., 2006) the\nperformance of amnesic patients was impaired. However, Jeneson and\nSquire (2012) in a review found these allegedly short-term memory studies\nalso involved long-term memory. More specifically, the information to be\nlearned exceeded the capacity of short-term memory and so necessarily\ninvolved long-term memory as well as short-term memory (Norris, 2017).\nAs a result, such studies do not demonstrate deficient short-term memory\nin amnesic patients.\nSeveral neuroimaging studies have reported hippocampal involvement\n(thought to be crucial for long-term memory) during short-term memory\ntasks. However, it has generally been unclear whether hippocampal activa-\ntion was due in part to encoding for long-term memory. An exception was\na study by Bergmann et al. (2012). They assessed short-term memory for\nface–house pairs followed by an unexpected test of long-term memory for\nthe pairs.\nWhat did Bergmann et al. (2012) find? Encoding of pairs remembered\nin both short- and long-term memory involved the hippocampus. However,\nthere was no hippocampal activation at encoding when short-term memory\nfor word pairs was successful but subsequent long-term memory was not.\nThus, the hippocampus was only involved on a short-term memory task\nwhen long-term memories were being formed.\nEvaluation\nAs predicted by the unitary-store approach, activation of part of long-term\nmemory often plays an important role in short-term memory. More specif-\nically, relevant information from long-term memory frequently influences\nthe contents of short-term memory.\nWhat are the limitations of the unitary-store approach? First, the\nclaim that short-term memory consists only of activated long-term memory\nis oversimplified. As Norris (2017, p. 992) pointed out, “The central\nproblem . . . is that STM has to be able to store arbitrary configurations\nof novel information. For example, we can remember novel sequences of\nwords or dots in random positions on a screen. These cannot possibly have\npre-existing representations in LTM that could be activated.” Short-term\nmemory is also more flexible than expected on the unitary-store approach\n(e.g., backward digit recall: recalling digits in the opposite order to the one\npresented).\nSecond, we must distinguish between the assumption that short-term\nmemory is only activated long-term memory and the assumption that\nshort-term and long-term memory are separate but often interact. Most\nevidence supports the latter assumption rather than the former.\nThird, the theory fails to provide a precise definition of the crucial\nexplanatory concept of “activation”. It is thus unclear how activation\nmight maintain representations in short-term memory (Norris, 2017).\nFourth, the medial temporal lobes (including the hippocampus) are\nof crucial importance for many forms of long-term memory (especially\nCreated from usyd on 2022-02-14 13:22:32.",
    "246\nMemory\ndeclarative memory – see Glossary). Amnesic patients\nwith damage to these brain areas have severely\nimpaired declarative memory. In contrast, amnesic\npatients typically have intact short-term memory\n(Spiers et al., 2001).\nWORKING MEMORY: BADDELEY\nAND HITCH\nIs short-term memory useful in everyday life?\nTextbook writers used to argue it allows us to remember a telephone\nnumber for the few seconds required to dial it. Of course, that is now\nirrelevant  –  our mobile phones store all the phone numbers we need\nregularly.\nBaddeley and Hitch (1974) provided a convincing answer to the above\nquestion. They argued we typically use short-term memory when performing\ncomplex tasks. Such tasks involve storing information about the outcome\nof early processes in short-term memory while moving on to later processes.\nBaddeley and Hitch’s key insight was that short-term memory is essen-\ntial to the performance of numerous tasks that are not explicitly memory\ntasks.\nThe above line of thinking led Baddeley and Hitch (1974) to replace\nthe concept of short-term memory with that of working memory. Working\nmemory “refers to a system, or a set of processes, holding mental rep-\nresentations temporarily available for use in thought and action” (Oberauer\net al., 2018, p. 886). Since 1974, there have been several developments of\nthe working memory system (Baddeley, 2012, 2017; see Figure 6.3):\nAlan Baddeley and Graham\nHitch.\nPhotos courtesy of Alan\nBaddeley and Graham Hitch.\nFigure 6.3\nThe working memory model showing the connections between its four components and\ntheir relationship to long-term memory. Artic = articulatory rehearsal.\nFrom Darling et al., 2017.\nCentral\nexecutive\nVisuo-spatial\nsketch pad\nShape\nObject\nVisual\nSpatial\nHaptic\nKinaesthetic\nTactile\nSmell\nTaste\nSpeech\nLip-reading\nMusic\nand\nsound\nPhonological loop\nArtic\nEpisodic bufer\nEpisodic long-term\nmemory\nLanguage\nVisual\nsemantics\nResearch activity:\nPhonemic similarity\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n247\n●\na modality-free central executive, which “is an attentional system”\n(Baddeley, 2012, p. 22);\n●\na phonological loop processing and storing information briefly in a\nphonological (speech-based) form;\n●\na visuo-spatial sketchpad specialised for spatial and visual processing\nand temporary storage;\n●\nan episodic buffer providing temporary storage for integrated infor-\nmation coming from the visuo-spatial sketchpad and phonological\nloop; this component (added by Baddeley, 2000) is discussed later (see\npp. 252–253).\nThe most important component is the central executive. The phonological\nloop and the visuo-spatial sketchpad are slave systems used by the central\nexecutive for specific purposes. The phonological loop preserves word\norder, whereas the visuo-spatial sketchpad stores and manipulates spatial\nand visual information.\nAll three components discussed above have limited capacity and can\nfunction fairly independently of the others. Two key assumptions follow:\n(1) If two tasks use the same component, they cannot be performed suc-\ncessfully together.\n(2) If two tasks use different components, they can be performed as well\ntogether as separately.\nRobbins et  al. (1996) investigated these assumptions in a study on the\nselection of chess moves. Chess players selected continuation moves\nfrom various chess positions while also performing one of the following\ntasks:\n●\nrepetitive tapping: the control condition;\n●\nrandom letter generation: this involves the central executive;\n●\npressing keys on a keypad in a clockwise fashion: this uses the\nvisuo-spatial sketchpad;\n●\nrapid repetition of the word “see-saw”: this is articulatory suppression\nand uses the phonological loop.\nThe quality of chess moves was impaired when the additional task involved\nthe central executive or visuo-spatial sketchpad but not when it involved\nthe articulatory loop. Thus, calculating successful chess moves requires use\nof the central executive and the visuo-spatial sketchpad but not the articu-\nlatory loop.\nPhonological loop\nAccording to the working memory model, the phonological loop has two\ncomponents (see Figure 6.4):\n●\na passive phonological store directly concerned with speech perception;\n●\nan articulatory process linked to speech production (i.e., rehearsal)\ngiving access to the phonological store.\nKEY TERMS\nWorking memory\nA limited-capacity system\nused in the processing\nand brief holding of\ninformation.\nCentral executive\nA modality-free, limited-\ncapacity, component of\nworking memory.\nPhonological loop\nA component of working\nmemory in which speech-\nbased information is\nprocessed and stored\nbriefly and subvocal\narticulation occurs.\nVisuo-spatial sketchpad\nA component of working\nmemory used to process\nvisual and spatial\ninformation and to store\nthis information briefly.\nEpisodic buffer\nA component of working\nmemory; it is essentially\npassive and stores\nintegrated information\nbriefly.\nCreated from usyd on 2022-02-14 13:22:32.",
    "248\nMemory\nSuppose we test individuals’ memory span by presenting a word list vis-\nually and requiring immediate recall in the correct order. Would they use\nthe phonological loop to engage in verbal rehearsal (i.e., saying the words\nrepeatedly to themselves)? Two kinds of evidence (discussed below) indicate\nthe answer is “Yes”.\nFirst, there is the phonological similarity effect – reduced immediate\nserial recall when words are phonologically similar (i.e., have similar sounds).\nFor example, Baddeley et  al. (2018) found that short-term memory was\nmuch worse with phonologically similar words (e.g., pan, cat, bat, ban, pad, man)\nthan phonologically dissimilar words (e.g., man, pen, rim, cod, bud, peel).\nThe working memory model does not make it clear whether the phono-\nlogical similarity effect depends more on acoustic similarity (similar sounds)\nor articulatory similarity (similar articulatory movements). Schweppe et al.\n(2011) found the effect depends more on acoustic than articulatory similar-\nity. However, there was an influence of articulatory similarity when recall\nwas spoken.\nSecond, there is the word-length effect: word span (words recalled\nimmediately in the correct order) is greater for short than long words.\nBaddeley et al. (1975) obtained this effect with visually presented words. As\npredicted, the effect disappeared when participants engaged in articulatory\nsuppression (repeating the digits 1 to 8) to prevent rehearsal within the\nphonological loop during list presentation. In similar fashion, Jacquemot\net al. (2011) found a brain-damaged patient with greatly impaired ability to\nengage in verbal rehearsal had no word-length effect.\nJalbert et  al. (2011) pointed out a short word generally has more\northographic neighbours (words of the same length differing from it in\nonly one letter) than a long word. When short (one-syllable) and long\n(three-syllable) words were equated for neighbourhood size, the word-\nlength effect disappeared. Thus, the word-length effect may be misnamed.\nWhich brain areas are associated with the phonological loop? Areas in\nthe parietal lobe, especially the supramarginal gyrus (BA40) and angular\ngyrus (BA39), are associated with the phonological store, whereas Broca’s\narea (approximately BA44 and BA45) within the frontal lobe is associated\nwith the articulatory control process.\nEvidence indicating these areas differ in their functioning was reported\nby Papagno et al. (2017). Patients undergoing brain surgery received direct\nKEY TERMS\nPhonological similarity\neffect\nThe finding that\nimmediate serial recall of\nverbal material is reduced\nwhen the items sound\nsimilar.\nWord-length effect\nThe finding that verbal\nmemory span decreases\nwhen longer words are\npresented.\nOrthographic\nneighbours\nWith reference to a target\nword, the number of\nwords that can be formed\nby changing one of its\nletters.\nFigure 6.4\nPhonological loop system\nas envisaged by Baddeley\n(1990).\nInteractive exercise:\nEncoding in STM\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n249\nelectrical stimulation while performing a digit-span\ntask. Stimulation within the parietal lobe increased\nitem errors in the task because it disrupted the\nstorage of information. In contrast, stimulation\nwithin Broca’s area increased order errors because\nit disrupted rehearsal of items in the correct order\n(see Figure 6.5).\nHow is the phonological loop useful in every-\nday life? The answer is not immediately obvious.\nBaddeley et  al. (1988) found a female patient,\nPV, with a very small digit span (only two items)\ncoped very well (e.g., running a shop and raising a\nfamily). In subsequent research, however, Baddeley\net al. (1998) argued the phonological loop is useful\nwhen learning a language. PV (a native Italian\nspeaker) had generally good learning ability but\nwas totally unable to associate Russian words with\ntheir Italian translations. Indeed, she showed no\nlearning at all over ten trials!\nThe phonological loop (“inner voice”) is also\nused to resist temptation. Tullett and Inzlicht\n(2010) found articulatory suppression (saying computer repeatedly) reduced\nparticipants’ ability to control their actions (they were more likely to\nrespond on trials where they should have inhibited a response).\nVisuo-spatial sketchpad\nThe visuo-spatial sketchpad is used for the temporary storage and manipu-\nlation of visual patterns and spatial movement. In essence, visual processing\ninvolves remembering what and spatial processing involves remembering\nwhere. In everyday life, we use the sketchpad to find the route when moving\nfrom one place to another or when watching television. The distinction\nbetween visual and spatial processing is very clear with respect to blind\nindividuals. Schmidt et al. (2013) found blind individuals could construct\nspatial representations of the environment almost as accurately as those of\nsighted individuals despite their lack of visual processing.\nIs there a single system containing combining visual and spatial pro-\ncessing or are there partially separate systems? Logie (1995) identified two\nseparate components:\n(1)\nvisual cache: this stores information about visual form and colour;\n(2)\ninner scribe: this processes spatial and movement information; it is\ninvolved in the rehearsal of information in the visual cache and trans-\nfers information from the visual cache to the central executive.\nSmith and Jonides (1997) obtained findings supporting the notion of sepa-\nrate visual and spatial systems. Two visual stimuli presented together were\nfollowed by a probe stimulus. Participants decided whether the probe was\nin the same location as one of the initial stimuli (spatial task) or had the\nsame form (visual task). Even though the stimuli presented were identical in\nFigure 6.5\nSites where direct electrical stimulation disrupted digit-\nspan performance. Item-error sites are in blue, order-\nerror sites are in yellow and sites where both types of\nerrors occurred are in green.\nKEY TERMS\nVisual cache\nAccording to Logie, the\npart of the visuo-spatial\nsketchpad that stores\ninformation about visual\nform and colour.\nInner scribe\nAccording to Logie, the\npart of the visuo-spatial\nsketchpad dealing with\nspatial and movement\ninformation.\nCreated from usyd on 2022-02-14 13:22:32.",
    "250\nMemory\nthe two tasks, there was more activity in the\nright hemisphere during the spatial task than\nthe visual task, but the opposite was the case\nfor activity in the left hemisphere.\nZimmer (2008) found in a research review\nthat areas within the occipital and temporal\nlobes were activated during visual processing.\nIn contrast, areas within the parietal cortex\n(especially the intraparietal sulcus) were acti-\nvated during spatial processing.\nKlauer and Zhao (2004) used two main\ntasks: (1) a spatial task (memory for dot loca-\ntions); (2) a visual task (memory for Chinese\ncharacters). The main task was performed at\nthe same time as a visual (colour discrimina-\ntion) or spatial (movement discrimination)\ninterference task. If the visuo-spatial sketch-\npad has separate spatial and visual compo-\nnents, the spatial interference task should disrupt performance more on the\nspatial main task. Second, the visual interference task should disrupt per-\nformance more on the visual main task. Both predictions were supported\n(see Figure 6.6).\nVergauwe et  al. (2009) argued that visual and spatial tasks often\nrequire the central executive’s attentional resources. They used more\ndemanding versions of Klauer and Zhao’s (2004) main tasks and obtained\ndifferent findings: each type of interference (visual and spatial) had compa-\nrable effects on the spatial and visual main tasks. Thus, there are general,\nattentionally demanding interference effects when tasks are demanding but\nalso interference effects specific to the type of interference when tasks are\nrelatively undemanding.\nMorey (2018) discussed the theoretical assumption that the visuo-\nspatial sketchpad is a specialised system separate from other cognitive\nsystems and components of working memory. She identified two predic-\ntions following from that assumption:\n(1) Some brain-damaged patients should have selective impairments of\nvisual and/or spatial short-term memory with other cognitive pro-\ncesses and systems essentially intact.\n(2) Short-term visual or spatial memory in healthy individuals should be\nlargely or wholly unaffected by the requirement to perform a second-\nary task at the same time (especially when that task does not require\nvisual or spatial processing).\nMorey (2018) reviewed evidence inconsistent with both the above predic-\ntions. First, the great majority of brain-damaged patients with impaired\nvisual and/or spatial short-term memory also have various more general\ncognitive impairments. Second, Morey carried out a meta-analytic review\nand found that short-term visual and spatial memory was strongly impaired\nby cognitively demanding secondary tasks. This was the case even when the\nsecondary task did not require visual or spatial processing.\nFigure 6.6\nAmount of interference on\na spatial task (dots) and a\nvisual task (ideographs) as\na function of a secondary\ntask (spatial: movement\nvs visual: colour\ndiscrimination).\nFrom Klauer and Zhao (2004).\n© 2000 American Psychological\nAssociation. Reproduced with\npermission.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n251\nIn sum, there is some support for the notion that the visuo-spatial\nsketchpad has somewhat separate visual and spatial components. However,\nthe visuo-spatial sketchpad seems to interact extensively with other cogni-\ntive and memory systems, which casts doubt on the theoretical assumption\nthat it often operates independently from other systems.\nCentral executive\nThe central executive (which resembles an attentional system) is the most\nimportant and versatile component of the working memory system. It is\nheavily involved in almost all complex cognitive activities (e.g., solving\na problem; carrying out two tasks at the same time) but does not store\ninformation.\nThere is much controversy concerning the brain regions most asso-\nciated with the central executive and its various functions (see below,\npp.  257–262). However, it is generally assumed the prefrontal cortex is\nheavily involved. Mottaghy (2006) reviewed studies using repetitive tran-\nscranial magnetic stimulation (rTMS; see Glossary) to disrupt the dorsolat-\neral prefrontal cortex (BA9/46). Performance on many complex cognitive\ntasks was impaired by this manipulation. However, executive processes\ndo not depend solely on the prefrontal cortex. Many brain-damaged\npatients (e.g., those with diffuse trauma) have poor executive functioning\ndespite having little or no frontal damage (Stuss, 2011).\nBaddeley has always recognised that the central executive is associated\nwith several executive functions (see Glossary). For example, Baddeley\n(1996) speculatively identified four such processes: (1) focusing attention\nor concentration; (2) dividing attention between two stimulus streams;\n(3) switching attention between tasks; and (4) interfacing with long-\nterm memory. It has proved difficult to obtain consensus on the number\nand nature of executive processes. However, two influential theoretical\napproaches are discussed below.\nBrain-damaged individuals whose central executive functioning is\nimpaired suffer from dysexecutive syndrome. Symptoms include impaired\nresponse inhibition, rule deduction and generation, maintenance and shifting\nof sets, and information generation (Godefroy et al., 2010). Unsurprisingly,\npatients with this syndrome have great problems in holding a job and\nfunctioning adequately in everyday life (Chamberlain, 2003).\nEvaluation\nThe notion of a unitary central executive is greatly oversimplified (see\nbelow). As Logie (2016, p. 2093) argued, “Executive control [may] arise\nfrom the interaction among multiple differing functions in cognition that\nuse different, but overlapping, brain networks . . . the central executive\nmight now be offered a dignified retirement.”\nSimilar criticisms can be directed against the notion of a dysexecutive\nsyndrome. Patients with widespread damage to the frontal lobes may have\na global dysexecutive syndrome. However, as discussed below, patients\nwith limited frontal damage display various patterns of impairment to\nexecutive processes (Stuss & Alexander, 2007).\nKEY TERMS\nExecutive processes\nProcesses that organise\nand coordinate the\nfunctioning of the\ncognitive system to\nachieve current goals.\nDysexecutive syndrome\nA condition in which\ndamage to the frontal\nlobes causes impairments\nto the central executive\ncomponent of working\nmemory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "252\nMemory\nEpisodic buffer\nWhy was the episodic buffer added to the model? There are various reasons.\nFirst, the original version of the model was limited because its components\nwere too separate in their functioning. For example, it was unclear how\nverbal information from the phonological loop and visual and spatial infor-\nmation from the visuo-spatial sketchpad was integrated to form multidi-\nmensional representations.\nSecond, it was hard to explain within the original model the finding\nthat people can provide immediate recall of up to 16 words presented in\nsentences (Baddeley et  al., 1987). This high level of immediate sentence\nrecall is substantially beyond the capacity of the phonological loop.\nThe function of the episodic buffer is suggested by its name. It is\nepisodic because it holds integrated information (or chunks) about epi-\nsodes or event in a multidimensional code combining visual, auditory and\nother information sources. It acts as a buffer between the other working\nmemory components and also links to perception and long-term memory.\nBaddeley (2012) suggested the capacity of the episodic buffer is approx-\nimately four chunks (integrated units of information). This potentially\nexplains why people can recall up to 16 words in immediate recall from\nsentences.\nBaddeley (2000) argued the episodic buffer could be accessed only via\nthe central executive. However, it is now assumed the episodic buffer can\nbe accessed by the visuo-spatial sketchpad and the phonological loop as\nwell as by the central executive (see Figure 6.3).\nIn sum, the episodic buffer\ndiffered from the existing subsystems representations [i.e., phonolog-\nical loop and visuo-spatial sketchpad] in being able to hold a limited\nnumber of multi-dimensional representations or episodes, and it dif-\nfered from the central executive in having storage capacity . . . The\nepisodic buffer is a passive storage system, the screen on which bound\ninformation from other sources could be made available to conscious\nawareness and used for planning future action.\n(Baddeley, 2017, pp. 305–306)\nFindings\nWhy did Baddeley abandon his original assumption that the central exec-\nutive controls access to and from the episodic buffer? Consider a study by\nAllen et al. (2012). Participants were presented with visual stimuli and had\nto remember briefly a single feature (colour; shape) or colour–shape combi-\nnations. It was assumed combining visual features would require the central\nexecutive prior to storage in the episodic buffer. On that assumption, the\nrequirement to perform a task requiring the central executive (counting\nbackwards) at the same time should have reduced memory to a greater\nextent for colour–shape combinations than single features.\nAllen et  al. (2012) found that counting backwards had comparable\neffects on memory performance regardless of whether or not feature com-\nbinations needed to be remembered. These findings suggest combining\nCase study:\nThe episodic buffer\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n253\nvisual features does not require the central executive but instead occurs\n“automatically” prior to information entering the episodic buffer.\nGrot et al. (2018) clarified the relationship between the central execu-\ntive and the episodic buffer. Participants learned to link or bind together\nwords and spatial locations within the episodic buffer for a memory\ntest. It was either relatively easy to bind words and spatial locations\ntogether (passive binding) or relatively difficult (active binding). The\ncentral executive was involved only in the more difficult active binding\ncondition.\nDarling et  al. (2017) discussed several studies showing how memory\ncan be enhanced by the episodic buffer. Much of this research focused on\nvisuo-spatial bootstrapping (verbal memory being bootstrapped (supported)\nby visuo-spatial memory). Consider a study by Darling and Havelka (2010).\nImmediate serial recall of random digits was best when they were presented\non a keypad display rather on a single item or linear display (see Figure 6.7).\nWhy was memory performance best with the keypad display? This was the\nonly condition which allowed visual information, spatial information and\nknowledge about keyboard displays accessed from long-term memory to be\nintegrated within the episodic buffer using bootstrapping.\nEvaluation\nThe episodic buffer provides a brief storage facility for information from\nthe phonological loop, the visuo-spatial sketchpad and long-term memory.\nBootstrapping data (e.g., Darling & Havelka, 2010) suggest that processing\nin the episodic buffer “interacts with long-term knowledge to enable inte-\ngration across multiple independent stimulus modalities” (Darling et  al.,\n2017, p. 7). The central executive is most involved when it is hard to bind\ntogether different kinds of information within the episodic buffer.\nWhat are the limitations of research on the episodic buffer? First, it\nremains unclear precisely how information from the phonological loop and\nthe visuo-spatial sketchpad is combined to form unified representations\nwithin the episodic buffer. Second, as shown in Figure 6.3, it is assumed\ninformation from sensory modalities other than vision and hearing can be\nstored in the episodic buffer. However, relevant research on smell and taste\nis lacking.\nFigure 6.7\nScreen displays for the digit\n6. Clockwise from top left:\n(1) single item display; (2)\nkeypad display; and (3)\nlinear display.\nFrom Darling and Havelka\n(2010).\n1\n0\n2\n3\n4\n5\n5\n6\n6\n7\n8\n0\n9\n1\n2\n3\n4\n6\n7\n8\n9\nCreated from usyd on 2022-02-14 13:22:32.",
    "254\nMemory\nOverall evaluation\nThe working memory model remains highly influential over 45 years since\nit was first proposed. There is convincing empirical evidence for all com-\nponents of the model. As Logie (2015, p. 100) noted, it explains findings\n“from a very wide range of research topics, for example, aspects of chil-\ndren’s language development, aspects of counting and mental arithmetic,\nreasoning and problem solving, dividing and switching attention, navigat-\ning unfamiliar environments”.\nWhat are the model’s limitations? First, it is oversimplified. Several\nkinds of information are not considered within the model (e.g., those\nrelating to smell, touch and taste). In addition, we can subdivide spatial\nworking memory into somewhat separate eye-centred, hand-centred and\nfoot-centred spatial working memory (Postle, 2006). This could lead to an\nunwieldy model with numerous components each responsible for a differ-\nent kind of information.\nSecond, the notion of a central executive should be replaced with a\ntheoretical approach identifying the major executive processes (see below,\npp. 257–262).\nThird, the notion that the visuo-spatial sketchpad is a specialised and\nrelatively independent processing system is doubtful. There is much evi-\ndence (Morey, 2018) that it typically interacts with other working memory\ncomponents (especially the central executive).\nFourth, we need more research on the interactions among the four\ncomponents of working memory (e.g., how the episodic buffer integrates\ninformation from the other components and from long-term memory).\nFifth, the common assumption that conscious awareness is necessar-\nily associated with processing in all working memory components requires\nfurther consideration. For example, executive processes associated with\nthe functioning of the central executive can perhaps occur outside con-\nscious awareness (Soto & Silvanto, 2014). As discussed in Chapter 16,\nmany complex processes can apparently occur in the absence of conscious\nawareness.\nWORKING MEMORY: INDIVIDUAL DIFFERENCES\nAND EXECUTIVE FUNCTIONS\nThere have been numerous recent attempts to enhance our understanding of\nworking memory. Here we will focus on two major theoretical approaches.\nFirst, some theorists (e.g., Engle & Kane, 2004) have focused on working\nmemory capacity. In essence, they claim performance across numerous\ntasks (including memory ones) is strongly influenced by individual differ-\nences in working memory capacity. Second, many theorists have replaced\na unitary central executive with several more specific executive functions.\nWorking memory capacity\nSeveral theorists (e.g., Engle & Kane, 2004) have considered working\nmemory from the perspective of individual differences in working memory\ncapacity, “the ability to hold and manipulate information in a temporary\nKEY TERM\nWorking memory\ncapacity\nAn assessment of how\nmuch information can be\nprocessed and stored at\nthe same time; individuals\nwith high capacity have\nhigher intelligence and\nmore attentional control.\nInteractive exercise:\nWorking memory\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n255\nactive state” (DeCaro et al., 2016, p. 39). Daneman and Carpenter (1980)\nused reading span to assess this capacity. Individuals read sentences for\ncomprehension (processing task) and then recalled the final word of each\nsentence (storage task). The reading span was defined as the largest number\nof sentences from which individuals could recall the final words over 50%\nof the time.\nOperation span is another measure of working memory capacity. Items\n(e.g., IS (4 × 2) – 3 = 5? TABLE) are presented. Individuals answer each\narithmetical question and try to remember all the last words. Operation\nspan is the maximum number of items for which individuals can remem-\nber all the last words over half the time. It correlates highly with reading\nspan.\nWorking memory capacity correlates positively with intelligence.\nWe can clarify this relationship by distinguishing between crystallised\nintelligence (which depends on knowledge, skills and experience) and fluid\nintelligence (which involves a rapid understanding of novel relationships;\nsee Glossary). Working memory capacity correlates more strongly with\nfluid intelligence (sometimes as high as +.7 or +.8; Kovacs & Conway,\n2016). The correlation with crystallised intelligence is relatively low because\nit involves acquired knowledge whereas working memory capacity depends\non cognitive processes and temporary information storage.\nEngle and Kane (2004) argued individuals who are high and low in\nworking memory capacity differ in attentional control. In their influential\ntwo-factor theory, they emphasised two key aspects of attentional control:\n(1) the maintenance of task goals; (2) the resolution of response competi-\ntion or conflict. Thus, high-capacity individuals are better at maintaining\ntask goals and resolving conflict.\nHow does working memory capacity relate to Baddeley’s working\nmemory model? The two approaches differ in emphasis. Researchers inves-\ntigating working memory capacity focus on individual differences in pro-\ncessing and storage capacity whereas Baddeley focuses on the underlying\nstructure of working memory. However, there has been some convergence\nbetween the two theoretical approaches. For example, Kovacs and Conway\n(2016, p. 157) concluded that working memory capacity “reflects individual\ndifferences in the executive component of working memory, particularly\nexecutive attention and cognitive control”.\nIn view of the association between working memory capacity and\nintelligence, we would expect high-capacity individuals to outperform\nlow-capacity ones on complex tasks. That is, indeed, the case (see Chapter\n10). However, Engle and Kane’s (2004) theory also predicts high-capacity\nindividuals might perform better than low-capacity ones even on relatively\nsimple tasks if it were hard to maintain task goals.\nFindings\nThere are close links between working memory capacity and the executive\nfunctions of the central executive. For example, McCabe et al. (2010) found\nmeasures of working memory capacity correlated highly with measures of\nexecutive functioning. Both types of measures reflect executive attention\n(which maintains task goals).\nKEY TERMS\nReading span\nThe largest number\nof sentences read for\ncomprehension from\nwhich an individual can\nrecall all the final words\nover 50% of the time.\nOperation span\nThe maximum number\nof items (arithmetical\nquestions + words) for\nwhich an individual can\nrecall all the words more\nthan 50% of the time.\nCrystallised intelligence\nA form of intelligence\nthat involves the ability to\nuse one’s knowledge and\nexperience effectively.\nCreated from usyd on 2022-02-14 13:22:32.",
    "256\nMemory\nThe hypothesis that high-capacity individuals have greater attentional\ncontrol than low-capacity ones has received experimental support. Sörqvist\n(2010) studied distraction effects caused by the sounds of planes flying\npast. Recall of a prose passage was adversely affected by distraction only\nin low-capacity individuals. Yurgil and Golob (2013), using event- related\npotentials (ERPs; see Glossary), found that high-capacity individuals\nattended less than low-capacity ones to distracting auditory stimuli.\nWe have seen goal maintenance or attentional control in low- capacity\nindividuals is disrupted by external distraction. It is also disrupted by inter-\nnal task-unrelated thoughts (mind-wandering). McVay and Kane (2012)\nused a sustained-attention task in which participants responded to frequent\ntarget words but withheld responses to rare non-targets. Low-capacity\nindividuals performed worse than high-capacity ones on this task because\nthey engaged in more mind-wandering.\nRobison and Unsworth (2018) identified two main reasons why this might\nbe the case. First, low-capacity individuals’ inferior attentional control may\nlead to increased amounts of spontaneous or unplanned mind- wandering.\nSecond, low-capacity individuals may be less motivated to perform cognitive\ntasks well and so engage in increased deliberate mind-wandering. Robison\nand Unsworth’s findings provided support only for the first reason.\nIndividuals having low working memory capacity may have worse\ntask performance than high-capacity ones because they consistently have\npoorer attentional control and ability to maintain the current task goal.\nAlternatively, their failures of attentional control may only occur relatively\ninfrequently. Unsworth et  al. (2012) compared these two explanations.\nThey used the anti-saccade task: a flashing cue is presented to the left (or\nright) of fixation followed by a target presented in the opposite location.\nReaction times to identify the target were recorded.\nUnsworth et  al. (2012) divided each participant’s reaction times into\nquintiles (five bins representing the fastest 20%, the next fastest 20% and\nso on). Low-capacity individuals were significantly slower than the high-\ncapacity ones only in the slowest quintile (see Figure 6.8). Thus, they expe-\nrienced failures of goal maintenance or attentional goal on only a small\nfraction of trials.\nFigure 6.8\nMean reaction times (RTs)\nquintile-by-quintile on the\nanti-saccade task by groups\nhigh and low in working\nmemory capacity.\nFrom Unsworth et al. (2012).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n257\nEvaluation\nTheory and research on working memory capacity indicate the value of\nfocusing on individual differences. There is convincing evidence high- and\nlow-capacity individuals differ in attentional control. More specifically,\nhigh-capacity individuals are better at controlling external and internal\ndistracting information. In addition, they are less likely than low-capacity\nindividuals to experience failures of goal maintenance. Of importance, indi-\nvidual differences in working memory capacity are relevant to performance\non numerous different tasks (see Chapter 10).\nWhat are the limitations of research in this area? First, the finding that\nworking memory capacity correlates highly with fluid intelligence means\nmany findings ascribed to individual differences in working memory capac-\nity may actually reflect fluid intelligence. However, it can be argued that\ngeneral executive functions relevant to working memory capacity partially\nexplain individual differences in fluid intelligence (Kovacs & Conway, 2016).\nSecond, research on working memory capacity is somewhat narrowly\nbased on behavioural research with healthy participants. In contrast, the\nunity/diversity framework (discussed next) has been strongly influenced\nby neuroimaging and genetic research and by research on brain-damaged\npatients.\nThird, there is a lack of conceptual clarity. For example, theorists\ndiffer as to whether the most important factor differentiating individuals\nwith high- or low-capacity is “maintenance of task goals”, “resolution of\nconflict”, “executive attention” or “cognitive control”. We do not know\nhow closely related these terms are.\nFourth, the inferior attentional or cognitive control of low-capacity\nindividuals might manifest itself consistently throughout task performance\nor only sporadically. Relatively little research (e.g., Unsworth et al., 2012)\nhas investigated this issue.\nFifth, the emphasis in theory and research has been on the benefits for\ntask performance associated with having high working memory capacity.\nHowever, some costs are associated with high capacity. These costs are\nmanifest when the current task requires a broad focus of attention but\nhigh-capacity individuals adopt a narrow and inflexible focus (e.g., DeCaro\net al., 2016, 2017; see Chapter 12).\nExecutive functions: unity/diversity framework\nExecutive functions are “high-level processes that, through their influ-\nence on lower-level processes, enable individuals to regulate their thoughts\nand actions during goal-directed behaviour” (Friedman & Miyake, 2017,\np.  186). The crucial issue is to identify the number and nature of these\nexecutive functions or processes. Various approaches can address this issue:\n(1) Psychometric approach: several tasks requiring the use of execu-\ntive functions are administered and the pattern of inter-correlations\namong the tasks is assessed. Consider the following hypothetical\nexample. There are four executive tasks (A, B, C and D). There is a\nmoderate positive correlation between tasks A and B and between C\nKEY TERMS\nExecutive functions\nProcesses that organise\nand coordinate the\nworkings of the cognitive\nsystem to achieve current\ngoals; key executive\nfunctions include\ninhibiting dominant\nresponses, shifting\nattention and updating\ninformation in working\nmemory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "258\nMemory\nand D but the remaining correlations are small. Such a pattern sug-\ngests tasks A and B involve the same executive function whereas tasks\nC and D involve a different executive function.\n(2) Neuropsychological approach: the focus is on individuals with brain\ndamage causing impaired executive functioning. Patterns of impaired\nfunctioning are related to the areas of brain damage to identify exec-\nutive functions and their locations within the brain. Shallice and\nCipiolotti (2018) provide a thorough discussion of the applicability of\nthis approach to understanding executive functioning.\n(3) Neuroimaging approach: the focus is on assessing similarities and dif-\nferences in the patterns of brain activation associated with various\nexecutive tasks. For example, the existence of two executive functions\n(A and B) would be supported if they were associated with different\npatterns of brain activation.\n(4) Genetic approach: twin studies are conducted with an emphasis on\nshowing different sets of genes are associated with each executive\nfunction (assessed by using appropriate cognitive tasks).\nSeveral theories have been proposed on the basis of evidence using the\nabove approaches (see Friedman and Miyake, 2017, for a review). Here\nwe will focus on the very influential theory originally proposed by Miyake\net al. (2000) and developed subsequently (e.g., Friedman & Miyake, 2017).\nUnity/diversity framework\nIn their initial study, Miyake et al. (2000) used the psychometric approach:\nthey administered several executive tasks and then focused on the pattern of\ninter-correlations among the tasks. They identified three related (but sepa-\nrable) executive functions:\n(1) Inhibition function: used to deliberately override dominant responses\nand to resist distraction. For example, it is used on the Stroop task (see\nFigure 1.3 on p. 5), which involves naming the colours in which words\nare printed. When the words are conflicting colour words (e.g., the\nword BLUE printed in red), it is necessary to inhibit saying the word.\n(2) Shifting function: used to switch flexibly between tasks or mental sets.\nSuppose you are presented with two numbers on each trial. Your task\nis to switch between multiplying the two numbers and dividing one by\nthe other on alternate trials. Such task switching requires the shifting\nfunction.\n(3) Updating function: used to monitor and engage in rapid addition or\ndeletion of working memory contents. For example, this function is\nused if you must keep track of the most recent member of each of\nseveral categories.\nSubsequent research (e.g., Friedman et  al., 2008; Miyake & Friedman,\n2012) led to the development of the unity/diversity framework. The basic\nidea is that each executive function consists of what is common to all three\nexecutive functions (unity) plus what is unique to that function (diversity)\n(see Figure 6.9). After accounting for what was common to all executive\nKEY TERMS\nStroop task\nA task in which\nparticipants have to name\nthe ink colours in which\ncolour words are printed;\nperformance is slowed\nwhen the to-be-named\ncolour (e.g., green)\nconflicts with the colour\nword (e.g., red).\nInteractive exercise:\nStroop\nCase study:\nAutomatic processes,\nattention and the\nemotional Stroop effect\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n259\nfunctions, Friedman et al. found there was no unique variance left for the\ninhibition function. Of importance, separable shifting and updating factors\nhave consistently been identified in subsequent research (Friedman &\nMiyake, 2017).\nWhat is the nature of the common factor? According to Friedman\nand Miyake (2017, p. 194), “It reflects individual differences in the ability\nto maintain and manage goals, and use those goals to bias ongoing pro-\ncessing.” Goal maintenance (resembling concentration) may be especially\nimportant on inhibition tasks where it is essential to focus on task require-\nments to avoid distraction or incorrect competing responses. This could\nexplain why such tasks load only on the common factor.\nSupport for the notion that the common factor reflects goal mainte-\nnance was reported by Gustavson et al. (2015). Everyday goal- management\nfailures (assessed by questionnaire) correlated negatively with the common\nfactor.\nFindings\nSo far we have focused on the psychometric approach. The unity/ diversity\nframework is also supported by research using the genetic approach.\nFriedman et al. (2008) had monozygotic (identical) and dizygotic (fraternal)\ntwins perform several executive function tasks. One key finding was that\nindividual differences in all three executive functions (common; updating;\nshifting) were strongly influenced by genetic factors. Another key finding\nwas that different sets of genes were associated with each function.\nWe turn now to neuroimaging research. Such research partly supports\nthe unity/diversity framework. Collette et  al. (2005) found all three of\nMiyake et  al.’s (2000) functions (i.e., inhibition; shifting; updating) were\nFigure 6.9\nSchematic representation of the unity and diversity of three executive functions (EFs).\nEach executive function is a combination of what is common to all three and what is\nspecific to that executive function. The inhibition-specific component is absent because\nthe inhibition function correlates very highly with the common executive function.\nFrom Miyake and Friedman (2012). Reprinted with permission of SAGE Publications.\nCreated from usyd on 2022-02-14 13:22:32.",
    "260\nMemory\nassociated with activation in different prefrontal areas. However, all tasks\nproduced activation in other areas (e.g., the left lateral prefrontal cortex,\nwhich is consistent with Miyake and Friedman’s (2012) unity notion).\nNiendam et  al. (2012) carried out a meta-analysis (see Glossary) of\nfindings from 193 studies where participants performed many tasks involv-\ning executive functions. Of most importance, several brain areas were\nactivated across all executive functions (see Figure 6.10). These areas\nincluded the dorsolateral prefrontal cortex (BA9/46), fronto-polar cortex\n(BA10), orbitofrontal cortex (BA11) and anterior cingulate (BA32). This\nbrain network corresponds closely to the common factor identified by\nMiyake and Friedman (2012). In addition, Niendam et al. found some dif-\nferences in activated brain areas between shifting and inhibition function\ntasks.\nStuss and Alexander (2007) argued the notion of a dysexecutive syn-\ndrome (see Glossary; discussed earlier, p. 251) erroneously implies brain\ndamage to the frontal lobes damages all central executive functions. While\nthere may be a global dysexecutive syndrome in patients having wide-\nspread damage to the frontal lobes, this is not so in patients having limited\nprefrontal damage. Among such patients, Stuss and Alexander identified\nthree executive processes, each associated with a different region within the\nfrontal cortex (approximate brain locations are in brackets):\n(1) Task setting (left lateral): this involves planning; it is “the ability to\nset a stimulus-response relationship . . . necessary in the early stages\nof learning to drive a car or planning a wedding” (p. 906).\nFigure 6.10\nActivated brain regions across all executive functions in a meta-analysis of 193 studies\n(shown in red).\nFrom Niendam et al. (2012).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n261\n(2) Monitoring (right lateral): this involves checking the adequacy of one’s\ntask performance; deficient monitoring leads to increased variability\nof performance and increased errors.\n(3) Energisation (superior medial): this involves sustained attention or\nconcentration; deficient energisation leads to slow performance on all\ntasks requiring fast responding.\nThe above three executive processes are often used in combination when\nsomeone performs a complex task. Note that these three processes differ\nfrom those identified by Miyake et  al. (2000). However, there is some\noverlap: task setting and monitoring both involve aspects of cognitive\ncontrol as do the processes of inhibition and shifting.\nStuss (2011) confirmed the importance of the above three executive\nfunctions. In addition, he identified a fourth executive process he called\nmetacognition/integration (located in BA10: fronto-polar prefrontal cortex).\nAccording to Stuss (p. 761), “This function is integrative and coordinat-\ning-orchestrating . . . [it includes] recognising the differences between what\none knows from what one believes.” Evidence for this process has come\nfrom research on patients with damage to BA10 (Burgess et al., 2007).\nEvaluation\nThe unity/diversity framework provides a coherent account of the major\nexecutive functions and is deservedly highly influential. One of its great-\nest strengths is that it is supported by research using several different\napproaches (e.g., psychometric; genetic; neuroimaging; neuropsycholog-\nical). The notion of a hierarchical system with one very general function\n(common executive function) plus more specific functions (e.g., shifting;\nupdating) is consistent with most findings.\nWhat are the limitations of the unity/diversity framework? First, as\nFriedman and Miyake (2017, p. 199) admitted, “The results of lesion\nstudies are in partial agreement with the unity/diversity framework . . .\nthe processes [identified] in these studies are not clearly the same as those\n[identified] in studies of normal individual differences.” For example, Stuss\n(2011) obtained evidence for task setting, monitoring, energisation and\nmetacognition/integration functions in research on brain-damaged patients.\nSecond, many neuroimaging findings appear inconsistent with the\nframework. For example, Nee et  al. (2013) carried out a meta-analysis\nof 36 neuroimaging studies on executive processes. There was little evi-\ndence that functions such as shifting, updating and inhibition differed in\ntheir patterns of brain activation. Instead, one frontal region was mostly\ninvolved in processing spatial content (where-based processing) and a\nsecond frontal region was involved in processing non-spatial content\n(what-based processing).\nThird, Waris et al. (2017) also found evidence for content-based factors\ndiffering from the executive factors emphasised within the unity/diversity\nframework. They factor-analysed performance on ten working memory\ntasks and identified two specific content-based factors: (1) a visuo-spatial\nfactor; and (2) a numerical-verbal factor. There is some overlap between\nthese factors and those identified by Nee et al. (2013).\nCreated from usyd on 2022-02-14 13:22:32.",
    "262\nMemory\nFourth, an important assumption within the unity/diversity frame-\nwork is that all individuals have the same executive processes (Friedman\n& Miyake, 2017). The complexities and inconsistencies of the research evi-\ndence suggest this assumption may be only partially correct.\nLEVELS OF PROCESSING (AND BEYOND)\nWhat determines long-term memory? According to Craik and Lockhart\n(1972), how information is processed during learning is crucial. In their\nlevels-of-processing approach, they argued that attentional and perceptual\nprocesses of learning determine what information is stored in long-term\nmemory. Levels of processing range from shallow or physical analysis of a\nstimulus (e.g., detecting specific letters in words) to deep or semantic anal-\nysis. The greater the extent to which meaning is processed, the deeper the\nlevel of processing.\nHere are Craik and Lockhart’s (1972) main theoretical assumptions:\n●\nThe level or depth of stimulus processing has a large effect on its mem-\norability: the levels-of-processing effect.\n●\nDeeper levels of analysis produce more elaborate, longer-lasting and\nstronger memory traces than shallow levels.\nCraik (2002) subsequently moved away from the notion that there is a\nseries of processing levels going from perceptual to semantic. Instead, he\nargued that the richness or elaboration of encoding is crucial for long-term\nmemory.\nHundreds of studies support the levels-of-processing approach. For\nexample, Craik and Tulving (1975) compared deep processing (decide\nwhether each word fits the blank in a sentence) and shallow processing\n(decide whether each word is in uppercase or lowercase letters). Recognition\nmemory was more than three times higher with deep than with shallow\nprocessing. Elaboration of processing (amount of processing of a given\nkind) was also important. Cued recall following the deep task was twice\nas high for words accompanying complex sentences (e.g., “The great bird\nswooped down and carried off the struggling ____”) as those accompany-\ning simple sentences (e.g., “She cooked the ____”).\nRose et  al. (2015) reported a levels-of-processing effect even with an\napparently easy memory task: only a single word had to be recalled and\nthe retention interval was only 10 seconds. More specifically, words asso-\nciated with deep processing were better recalled than those associated\nwith shallow processing when the retention interval was filled with a task\ninvolving adding or subtracting).\nBaddeley and Hitch (2017) pointed out the great majority of studies\nhad used verbal materials (e.g., words). Accordingly, they decided to see\nwhether a levels-of-processing effect would be obtained with different learn-\ning materials. In one study, they found the effect with recognition memory\nwas much smaller with doors and clocks than with food names (see\nFigure 6.11). The most plausible explanation is that it is harder to produce\nan elaborate semantic encoding with doors or clocks than with most\nwords.\nInteractive exercise:\nLevels of processing\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n263\nMorris et  al. (1977) disproved the\nlevels-of-processing theory. Participants\nanswered semantic or shallow (rhyme)\nquestions for words. Memory was tested\nby a standard recognition test (select list\nwords and reject non-list words) or a\nrhyming recognition test (select words\nrhyming with list words – the list words\nthemselves were not presented). There\nwas the usual superiority of deep pro-\ncessing on the standard recognition test.\nHowever, the opposite was the case on\nthe rhyme test, a finding inconsistent with\nthe theory. According to Morris et  al.’s\ntransfer-appropriate processing theory,\nretrieval requires that the processing\nduring learning is relevant to the demands\nof the memory test. With the rhyming\ntest, rhyme information is relevant but\nsematic information is not.\nChallis et al. (1996) compared the levels-of-processing effect on explicit\nmemory tests (e.g., recall; recognition) involving conscious recollection\nand on implicit memory tests not involving conscious recollection (see\nChapter 7). The effect was generally greater in explicit than implicit memory.\nParks (2013) explained this difference in terms of transfer-appropriate pro-\ncessing. Shallow processing involves more perceptual but less conceptual\nprocessing than deep processing. Accordingly, the levels-of-processing effect\nshould generally be smaller when the memory task requires demanding\nperceptual processing (as is the case with most implicit memory tasks).\nDistinctiveness\nAnother important factor influencing long-term memory is distinctiveness.\nDistinctiveness means a memory trace differs from other memory traces\nbecause it was processed differently during learning. According to Hunt\nand Smith (2014, p. 45), distinctive processing is “the processing of differ-\nence in the context of similarity”.\nEysenck and Eysenck (1980) studied distinctiveness using nouns having\nirregular pronunciations (e.g., comb has a silent “b”). In one condition, par-\nticipants said these nouns in a distinctive way (e.g., pronouncing the “b” in\ncomb). Thus, the processing was shallow (i.e., phonemic) but the memory\ntraces were distinctive. Recognition memory was much higher than in a\nphonemic condition involving non-distinctive processing (i.e., pronouncing\nnouns as normal). Indeed, memory was as good with distinctive phonemic\nprocessing as with deep or semantic processing.\nHow can we explain the beneficial effects of distinctiveness on long-\nterm memory? Chee and Goh (2018) identified two potential explanations.\nFirst, distinctive items may attract additional attention and process-\ning at the time of study. Second, distinctive items may be well remem-\nbered because of effects occurring at the time of retrieval, an explanation\nFigure 6.11\nRecognition memory performance as a function of processing\ndepth (shallow vs deep) for three types of stimuli: doors, clocks\nand menus.\nFrom Baddeley and Hitch (2017). Reprinted with permission of Elsevier.\n0\nDoors\n0.1\n0.2\n0.3\n0.4\n0.5\np (correct)\n0.6\n0.7\n0.8\n0.9\n1\nClocks\nMenus\nShallow\nDeep\nKEY TERMS\nExplicit memory\nMemory that involves\nconscious recollection of\ninformation.\nImplicit memory\nMemory that does not\ndepend on conscious\nrecollection.\nDistinctiveness\nThis characterises memory\ntraces that are distinct\nor different from other\nmemory traces stored in\nlong-term memory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "264\nMemory\noriginally proposed by Eysenck (1979). For example, suppose the distinc-\ntive item is printed in red whereas all the other items are printed in black.\nThe retrieval cue (recall the red item) uniquely specifies one item and so\nfacilitates retrieval.\nChee and Goh (2018) contrasted the two above explanations. They\npresented a list of words referring to species of birds including the word\nkiwi. Of importance, kiwi is a homograph (two words having the same\nspelling but two different meanings): it can mean a species of bird or a type\nof fruit. Participants were instructed before study (encoding condition) or\nafter study (retrieval condition) that one of the words would be a type of\nfruit. The findings are shown in Figure 6.12. A distinctiveness effect was\nfound in the retrieval condition in the absence of distinctive processing at\nstudy. These findings strongly support a retrieval-based explanation of the\ndistinctiveness effect.\nEvaluation\nThere is compelling evidence that processes at learning have a major impact\non subsequent long-term memory (Roediger, 2008). Another strength of the\ntheory is the central assumption that learning and remembering are byprod-\nucts of perception, attention and comprehension. The levels-of- processing\napproach led to the identification of elaboration and distinctiveness of\nprocessing as important factors in learning and memory. Finally, “The\nlevels-of-processing approach has been fruitful and generative, providing\na powerful set of experimental techniques for exploring the phenomena of\nmemory” (Roediger & Gallo, 2001, p. 44).\nThe levels-of-processing approach has several limitations. First, Craik\nand Lockhart (1972) underestimated the importance of the retrieval envi-\nronment in determining memory performance (e.g., Morris et  al., 1977).\nSecond, the relative importance of processing depth, elaboration of process-\ning and distinctiveness of processing to long-term memory remains unclear.\nThird, the terms “depth”, “elaboration” and “distinctiveness” are vague\nand hard to measure (Roediger & Gallo, 2001). Fourth, we do not know\n0\nPreceding\n0.1\n0.2\n0.3\n0.4\n0.5\nProportion of recall\n0.6\n0.7\n0.8\n0.9\n1\nCritical\nitem type\nFollowing\nControl\nInstruction type\nEncoding\nRetrieval\nFigure 6.12\nPercentage recall of the\ncritical item (e.g., kiwi) in\nencoding, retrieval and\ncontrol conditions; also\nshown is the percentage\nrecall of preceding and\nfollowing items in the three\nconditions.\nFrom Chee and Goh (2018).\nReprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n265\nprecisely why deep processing is so effective or why the  levels-of-processing\neffect is small in implicit memory. Fifth, the levels-of-processing effect is\ntypically smaller with non-verbal stimuli than with words (Baddeley &\nHitch, 2017).\nLEARNING THROUGH RETRIEVAL\nHow can we maximise our learning (e.g., of some topic in cognitive psy-\nchology)? Many people (including you?) think what is required is to study\nand re-study the to-be-learned material with testing serving only to estab-\nlish what has been learned. In fact, this is not the case. As we will see, there\nis typically a testing effect: “the finding that intermediate retrieval practice\nbetween study and a final memory test can dramatically enhance final-test\nperformance when compared with restudy trials” (Kliegl & Bäuml, 2016).\nThe testing effect is generally surprisingly strong. Dunlosky et  al.\n(2013) discussed ten learning techniques including writing summaries,\nforming images of texts and generating explanations for stated facts, and\nfound repeated testing was the most effective technique. Rowland (2014)\ncarried out a meta-analysis: 81% of the findings were positive. Most of\nthese studies were laboratory-based. Reassuringly, Schwieren et al. (2017)\nfound the magnitude of the testing effect was comparable in real-life\ncontexts (teaching psychology) and laboratory conditions.\nExplanations of the testing effect\nWe start by identifying two important theoretical approaches to explaining\nthe testing effect. First, several theorists have emphasised the importance\nof retrieval effort (Rowland, 2014). The core notion here is that the testing\neffect will be greater when the difficulty or effort involved in retrieval during\nthe learning period is high rather than low.\nWhy does increased retrieval effort have this beneficial effect? Several\nanswers have been suggested. For example, there is the elaborative retrieval\nhypothesis, which is applicable to paired-associate learning (e.g., learn-\ning to associate the cue Chalk with the target Crayon). According to this\nhypothesis, “the act of retrieving a target from a cue activates cue- relevant\ninformation that becomes incorporated with the successfully retrieved\ntarget, providing a more elaborate representation” (Carpenter & Yeung,\n2017, p. 129). According to a more specific version of this hypothesis (the\nmediator effectiveness hypothesis), retrieval practice promotes the use of\nmore effective mediators. In the above example, Board might be a mediator\ntriggered by the cue Chalk.\nRickard and Pan (2018) proposed a related (but more general)\ndual-memory theory. In essence, restudy causes the memory trace formed\nat initial study to be strengthened. Testing with feedback (which involves\neffort) also strengthens the memory trace formed at initial study. More\nimportantly, it leads to the formation of a second memory trace (see\nFigure 6.13). The strength of this second memory trace probably depends\non the amount of retrieval effort during testing. Thus, testing generally pro-\nmotes superior memory to restudy because it promotes the acquisition of\ntwo memory traces for each item rather than one.\nKEY TERM\nTesting effect\nThe finding that long-\nterm memory is enhanced\nwhen some of the\nlearning period is devoted\nto retrieving to-be-learned\ninformation rather than\nsimply studying it.\nCreated from usyd on 2022-02-14 13:22:32.",
    "266\nMemory\nSecond, there is the bifurcation model (bifurcation means division\ninto two) proposed by Kornell et  al. (2011). According to this model,\nitems successfully retrieved during testing practice are strengthened more\nthan restudied items. However, the crucial assumption is that items not\nretrieved during testing practice are strengthened less than restudied\nitems; indeed, their memory strength does not change. Thus, there should\nbe  circumstances in which the testing effect is reversed.\nFindings\nSeveral findings indicate that the size of the testing effect depends on\nretrieval effort (probably because it leads to the formation of a strong\nsecond memory trace). Endres and Renkl (2015) asked participants to rate\nthe mental effort they used during retrieval practice and restudying. They\nobtained a testing effect that disappeared when mental effort was controlled\nfor statistically. As predicted, more effortful or difficult retrieval tests (e.g.,\nfree recall) typically led to a greater testing effect than easy retrieval tests\n(e.g., recognition memory) (Rowland, 2014). All these findings provide\nindirect support for the dual-memory theory.\nIt seems reasonable to assume retrieval practice is more effortful and\ndemanding when initial memory performance is low rather than high. As\nFigure 6.13\n(a) Restudy causes\nstrengthening of the\nmemory trace formed\nafter initial study; (b)\ntesting with feedback\ncauses strengthening of\nthe original memory trace;\nand (c) the formation of\na second memory trace.\nt = the response threshold\nthat must be exceeded\nfor any given item to be\nretrieved on the final test.\nFrom Rickard & Pan (2018).\nAfter training\nStrength\nAfter initial study\nStudy memory\nt\nRestudy\n(a)\n(b)\nAfter training\nStrength\nAfter initial study\nStudy memory\nt\nTesting\nwith\nfeedback\n(c)\nAfter training\nStrength\nTest memory\nt\nTesting\nwith\nfeedback\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n267\npredicted, the testing effect is greater when initial memory performance\nwas low in studies providing feedback (re-presentation of the learning\nmaterials) (Rowland, 2014).\nSuppose you are trying to learn the word pair wingu–cloud. You might\ntry to link the words by using the mediator plane. When subsequently\ngiven the cue (wingu) and told to recall the target word (cloud), you might\ngenerate the sequence wingu–wing–cloud according to the mediator effec-\ntiveness hypothesis. Pyc and Rawson (2010) instructed participants to\nlearn Swahili-English pairs (e.g., wingu–cloud). In one condition, each\ntrial after the initial study trial involved only restudy. In the other con-\ndition (test-restudy), each trial after the initial study trial involved a cued\nrecall test followed by restudy. Participants generated and reported medi-\nators on the study and restudy trials. There were three recall conditions\non the final memory test 1 week later: (1) cue only; (2) cue + the medi-\nator generated during learning; (3) cue + prompt to try to generate the\nmediator.\nThe findings were straightforward (see\nFigure 6.14(a)):\n(1)  Memory performance in the cue only\ncondition replicated the basic testing\neffect.\n(2)  Performance in the cue + mediator con-\ndition shows test-restudy participants\ngenerated more effective mediators than\nrestudy-only participants.\n(3)  Test-restudy\nparticipants\nperformed\nmuch better than restudy-only ones\nin the cue + prompt condition. Test-\nrestudy participants remembered the\nmediators\nmuch\nbetter.\nRetrieving\nmediators was important for the test-\nrestudy  participants – their performance\nwas poor when they failed to recall\nmediators.\nPyc and Rawson (2012) developed the medi-\nator effectiveness hypothesis. Participants\nwere more likely to change their mediators\nduring test-restudy practice than restudy-only\npractice. Of most importance, participants\nengaged in test-restudy practice were more\nlikely to change their mediators following\nretrieval failure than retrieval success. Thus,\nretrieval practice allows people to evaluate the\neffectiveness of their mediators and to replace\nineffective ones with effective ones.\nWe turn now to the bifurcation model,\nthe main theoretical approach predicting\nreversals of the testing effect. Support was\nFigure 6.14\n(a) Final recall for restudy-only and test-restudy group\nparticipants provided at test with cues (C), cues + the\nmediators generated during learning (CM) or cues plus\nprompts to recall their mediators (CMR). (b) Recall performance\nin the CMR group as a function of whether the mediators were\nor were not retrieved.\nFrom Pyc and Rawson (2010). © American Association for Advancement\nof Science. Reprinted with permission of AAAS.\nCreated from usyd on 2022-02-14 13:22:32.",
    "268\nMemory\nreported by Pastötter and Bäuml (2016). Participants\nhad retrieval/testing or restudy practice for paired\nassociates during Session  1. In Session 2 (48 hours\nlater), Test 1 was immediately followed by feedback\n(re-presentation of the word pairs) and 10 minutes\nlater by Test 2.\nThere was a testing effect on Test 1 but a reversed\ntesting effect on Test 2 (see Figure 6.15). According\nto the bifurcation model, non-recalled items on Test\n1 should be weaker if previously subject to retrieval\npractice rather than restudy. Thus, they should benefit\nless from feedback. That is precisely what happened\n(see Figure 6.15).\nMost research on the testing effect has involved\nthe use of identical materials during both initial and\nfinal retrieval tests. For many purposes, however, we\nwant retrieval to produce more general and flexible\nlearning that transfers to related (but non-tested)\ninformation. Pan and Rickard (2018) found in a\nmeta-analysis that retrieval practice on average has a\nmoderately beneficial effect on transfer of learning. This was especially the\ncase when retrieval practice involved elaborative feedback (e.g., extended\nand detailed feedback) than when only basic feedback (i.e., the correct\nanswer) was provided.\nEvaluation\nThe testing effect is strong and has been obtained with many different\ntypes of learning materials. Testing during learning has the advantage it\ncan be used almost regardless of the nature of the to-be-learned material.\nOf importance, retrieval practice often produces learning that generalises\nor transfers to related (but non-tested) information. Testing has benefi-\ncial effects because it produces a more elaborate memory trace (elabora-\ntive retrieval hypothesis) or a second memory trace (dual-memory theory).\nHowever, testing can be ineffective if the studied material is not retrieved\nand there is no feedback (the bifurcation model).\nWhat are the limitations of theory and research in this area?\n(1) There are several ways retrieval practice might produce more elabo-\nrate memory traces (e.g., additional processing of external context;\nthe production of more effective internal mediators). The precise form\nof such elaborate memory traces is hard to predict.\n(2) The dual-memory theory provides a powerful explanation of the\ntesting effect. However, more research is required to demonstrate\nthe conditions in which testing leads to the formation of a second\nmemory trace differing from the memory trace formed during initial\nstudy.\n(3) The bifurcation model has received empirical support. However, it\ndoes not specify the underlying processes or mechanisms responsible\nfor the reversed testing effect.\nFigure 6.15\nMean recall percentage in Session 2 on Test 1\n(followed by feedback) and Test 2 10 minutes later\nas function of retrieval practice (in blue) or restudy\npractice (in green) in Session 1.\nFrom Pastötter & Bäuml (2016).\n30\n40\n50\n60\n70\n80\n90\n100\n% Recall\nTest 1\n***\nTest 2\nSession 2\n**\nRetrieval practice\nRestudy practice\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n269\nKEY TERM\nImplicit learning\nLearning complex\ninformation without\nconscious awareness of\nwhat has been learned.\n(4) The fact that the testing effect has been found with numerous types of\nlearning material and testing conditions suggests that many different\nprocesses can produce that effect. Thus, currently prominent theories\nare probably applicable to only some findings.\nIMPLICIT LEARNING\nEarlier in the chapter we discussed learning through retrieval and learn-\ning from the levels-of-processing perspective. In both cases, the empha-\nsis was  on explicit learning: it generally makes substantial demands on\nattention and working memory and learners are aware of what they are\nlearning.\nCan we learn something without an awareness of what we have learned?\nIt sounds improbable. Even if we learned something without realising, it\nseems unlikely we would make much use of it. In fact, there is much evi-\ndence for implicit learning: “learning that occurs without full conscious\nawareness of the regularities contained in the learning material itself and/\nor that learning has occurred” (Sævland & Norman, 2016, p. 1). As we will\nsee, it is often assumed implicit learning differs from explicit learning in\nbeing less reliant on attention and working memory.\nWe can also distinguish between implicit learning and implicit memory\n(memory not involving conscious recollection; discussed in Chapter 7). There\ncan be implicit memory for information acquired through explicit learn-\ning if learners lose awareness of that information over time. There can\nalso be explicit memory for information acquired through implicit learn-\ning if learners are provided with informative contextual cues when trying\nto remember that information. However, implicit learning is typically fol-\nlowed by implicit memory whereas explicit learning is followed by explicit\nmemory.\nThere is an important difference between research on implicit learning\nand implicit memory. Research on implicit learning mostly involves focus-\ning on performance changes occurring over a lengthy sequence of learning\ntrials. In contrast, research on implicit memory mostly involves one or a\nfew learning trials and the emphasis is on the effects of various factors\n(e.g., retention interval; retrieval cues) on memory performance. In addi-\ntion, research on implicit learning often uses fairly complex, novel tasks\nwhereas much research on implicit memory uses simple, familiar stimulus\nmaterials.\nReber (1993) made five assumptions concerning major differences\nbetween implicit and explicit learning (none established definitively):\n(1) Age independence: implicit learning is little influenced by age or devel-\nopmental level.\n(2) IQ independence: performance on implicit tasks is relatively unaffected\nby IQ.\n(3) Robustness: implicit systems are relatively unaffected by disorders\n(e.g., amnesia) affecting explicit systems.\n(4) Low variability: there are smaller individual differences in implicit\nlearning than explicit learning.\n(5) Commonality of process: implicit systems are common to most species.\nCreated from usyd on 2022-02-14 13:22:32.",
    "270\nMemory\nHere we will briefly consider the first two assumptions (the third\nassumption is discussed later, p. 277). With respect to the first assump-\ntion, some studies have reported comparable implicit learning in older and\nyoung adults. However, implicit learning is mostly significantly impaired in\nolder adults. How can we explain this deficit? Older adults generally have\nreduced volume of frontal cortex and the striatum, an area strongly associ-\nated with implicit learning (King et al., 2013a).\nWith respect to the second assumption, Christou et  al. (2016) found\non a visuo-motor task that the positive effects of high working memory\ncapacity on task performance were due to explicit but not implicit learn-\ning. When the visuo-motor task was changed to reduce the possibility of\nexplicit learning, high working memory capacity was unrelated to perfor-\nmance. Overall, intelligence is associated more strongly with explicit learn-\ning. However, the association between intelligence and implicit learning\nappears greater than predicted by Reber (1993).\nIN THE REAL WORLD: SKILLED TYPISTS AND IMPLICIT LEARNING\nMillions of individuals have highly developed typing skills (e.g., the typical American student who\ntouch types produces 70 words a minute) (Logan & Crump, 2009). Nevertheless, many expert\ntypists find it hard to think exactly where the letters are on the keyboard. For example, the first\nauthor of this book has typed 8 million words for publication but has limited conscious awareness\nof the locations of most letters! This suggests expert typing relies heavily on implicit learning and\nmemory. However, typing initially involves mostly explicit learning as typists learn to associate\nfinger movements with specific letter keys.\nSnyder et al. (2014) studied college students averaging 11.4 years of typing practice. In the first\nexperiment, typists saw a blank keyboard and were instructed to write the letters in their correct\nlocations (see Figure 6.16). They located only 14.9 (57.3%) of the letters accurately. If you are a\nskilled typist, try this task before checking your answers (shown in Figure 6.22).\nAccurate identification of letters’ keyboard locations could occur because typists engage in\nsimulated typing. In their second experiment, Snyder et al. (2014) found the ability to identify the\nkeyboard locations of letters was reduced when simulated typing was prevented. Thus, explicit\nmemory for letter locations is lower than 57%.\nFigure 6.16\nSchematic representation of a traditional keyboard.\nFrom Snyder et al. (2014). © 2011 Psychonomic Society. Reprinted with permission from Springer.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n271\nIn a final experiment, Snyder et al. (2014) gave typists two hours’ training on the Dvorak keyboard,\non which the letter locations differ from the traditional QWERTY keyboard. The ability to locate\nletters on the Dvorak and QWERTY keyboards was comparable. Thus, typists have no more explicit\nknowledge of letter locations on a keyboard after 11 years than after 2 hours!\nWhat is the nature of experienced typists’ implicit learning? Logan (2018) addressed this\nissue. Much of this learning involves forming associations between individual letters and finger\nmovements. In addition, however, typists learn to treat each word as a single chunk or unit. As a\nresult, they type words much faster than non-words containing the same number of letters. Thus,\nimplicit learning occurs at both the word and letter levels (Logan, 2018).\nIf experts rely on implicit learning and memory, we might predict performance impairments if\nthey focused consciously on their actions. There is much support for this prediction. For example,\nFlegal and Anderson (2008) gave skilled golfers a putting task before and after they described\ntheir actions in detail. Their putting performance was markedly worse after describing their actions\nbecause conscious processes disrupted implicit ones.\nAssessing implicit learning\nYou might think it is easy to decide whether implicit learning has occurred –\nwe simply ask participants after performing a task to indicate their con-\nscious awareness of their learning. Implicit learning is shown if there is no\nsuch conscious awareness.\nAlas, individuals sometimes fail to report fully their conscious aware-\nness of their learning (Shanks, 2010). For example, there is the “retrospec-\ntive problem” (Shanks & St. John, 1994) – participants may be consciously\naware of what they are learning at the time but have forgotten it when\nquestioned subsequently.\nShanks and St. John (1994) proposed two criteria (incompletely imple-\nmented in most research) for implicit learning to be demonstrated:\n(1) Information criterion: The information participants are asked to\nprovide on the awareness test must be the information responsible for\nthe improved performance.\n(2) Sensitivity criterion: “We must . . . show our test of awareness is sen-\nsitive to all of the relevant knowledge” (Shanks & St. John, 1994,\np. 374). We may underestimate participants’ consciously accessible\nknowledge if we use an insensitive awareness test.\nWhen implicit learning studies fail to obtain significant evidence of explicit\nlearning, researchers often (mistakenly) conclude there was no explicit\nlearning. Consider research on contextual cueing: participants search for\ntargets in visual displays and targets are detected increasingly rapidly (espe-\ncially with repeated rather than random displays). Subsequently, partici-\npants see the repeating patterns and new random ones and indicate whether\nthey have previously seen each one. Typically, participants fail to identify\nthe repeating patterns significantly more often than the random ones. Such\nnon-significant findings imply all task learning is implicit.\nVadillo et  al. (2016) argued many of the above non-significant find-\nings occurred because insufficiently large samples were used. In their review\nof 73 studies, 78.5% of awareness tests produced non-significant findings.\nCreated from usyd on 2022-02-14 13:22:32.",
    "272\nMemory\nNevertheless, participants in 67% of the studies performed above chance\n(a highly significant finding). Thus, some explicit learning is involved in\ncontextual cueing even though the opposite is often claimed.\nFinally, we consider the process-dissociation procedure. Suppose\nparticipants perform a task involving a repeating sequence of stimuli. They\neither guess the next stimulus (inclusion condition) or try to avoid guess-\ning the next stimulus accurately (exclusion condition). If learning is wholly\nimplicit, performance should be comparable in both conditions because\nparticipants would have no conscious access to relevant information. If it\nis partly or wholly explicit, performance should be better in the inclusion\ncondition.\nThe process-dissociation procedure is based on the assumption that\nthe influence of implicit and explicit processes is unaffected by instruc-\ntions (inclusion vs exclusion). However, Barth et al. (2019) found explicit\nknowledge was less likely to influence performance in the exclusion than\nthe inclusion condition. Such findings make it hard to interpret findings\nobtained using the process-dissociation procedure.\nFindings\nThe serial reaction time task has often been used to study implicit learn-\ning. On each trial, a stimulus appears at one of several locations on a com-\nputer screen and participants respond using the response key corresponding\nto its location. There is typically a complex, repeating sequence over trials\nbut participants are not told this. Towards the end of the experiment, there\nis often a block of trials conforming to a novel sequence but the partici-\npants are not informed.\nParticipants speed up over trials on the serial reaction time task but\nrespond much more slowly during the novel sequence (Shanks, 2010).\nWhen questioned at the end of the experiment, participants usually claim\nno conscious awareness of a repeating sequence or pattern. However, par-\nticipants sometimes have partial awareness of what they have learned.\nWilkinson and Shanks (2004) gave participants 1,500 trials (15 blocks) or\n4,500 trials (45 blocks) on the task and obtained strong sequence learn-\ning. This was followed by a test of explicit learning based on the process-\ndissociation procedure.\nParticipants’ predictions were significantly better in the inclusion than\nexclusion condition (see Figure 6.17) indicating some conscious or explicit\nknowledge was acquired. In a similar study, Gaillard et al. (2009) obtained\ncomparable findings and discovered conscious knowledge increased with\npractice.\nHaider et al. (2011) argued the best way to assess whether learning is\nexplicit or implicit is to use several measures of conscious awareness. They\nused a version of the serial reaction time task in which a colour word (the\ntarget) was written in ink of the same colour (congruent trials) or a differ-\nent colour (incongruent trials). Participants responded to the colour word\nrather than the ink. There were six different coloured squares below the\ntarget word and participants pressed the coloured square corresponding to\nthe colour word. The correct coloured square followed a regular sequence\n(1-6-4-2-3-5) but participants were not told this.\nKEY TERMS\nProcess-dissociation\nprocedure\nOn learning tasks,\nparticipants try to\nguess the next stimulus\n(inclusion condition)\nor avoid guessing the\nnext stimulus accurately\n(exclusion condition); the\ndifference between the\ntwo conditions indicates\nthe amount of explicit\nlearning.\nSerial reaction time task\nParticipants on this\ntask respond as rapidly\nas possible to stimuli\ntypically presented in a\nrepeating sequence; it is\nused to assess implicit\nlearning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n273\nHaider et  al. (2011) found 34% of par-\nticipants showed a sudden drop in reaction\ntimes at some point. They hypothesised these\nRT-drop participants were consciously aware\nof the regular sequence (explicit learning).\nThe remaining 66% failed to show a sudden\ndrop (the no-RT-drop participants) and were\nhypothesised to have engaged only in implicit\nlearning (see Figure 6.18).\nHaider et  al. (2011) used the process-\ndissociation procedure to test the above\nhypotheses. The RT-drop participants per-\nformed well: 80% correct on inclusion trials\nvs 18% correct on exclusion trials, suggesting\nconsiderable explicit learning. In contrast,\nthe no-RT-drop participants had comparably\nlow performance on inclusion and exclusion\ntrials indicating an absence of explicit learn-\ning. Finally, all participants described the\ntraining sequence (explicit task). Almost all\n(91%) of the RT-drop participants did this\nperfectly compared to 0% of the no-RT-drop\nparticipants. Thus, all the various findings\nsupported Haider et al.’s hypotheses.\nFigure 6.18\nResponse times for participants showing a sudden drop in RTs (right-hand side) or not\nshowing such a drop (left-hand side). The former group showed much greater learning\nthan the latter group (especially on incongruent trials on which the colour word was in a\ndifferent coloured ink).\nFrom Haider et al. (2011). Reprinted with permission from Elsevier.\nFigure 6.17\nMean number of completions (guessed locations)\ncorresponding to the trained sequence (own) or the untrained\nsequence (other) in inclusion and exclusion conditions as a\nfunction of number of trials (15 vs 45 blocks).\nFrom Wilkinson and Shanks (2004). © 2004 American Psychological\nAssociation. Reproduced with permission.\nCreated from usyd on 2022-02-14 13:22:32.",
    "274\nMemory\nIf implicit learning does not require cognitively demanding processes\n(e.g., attention), people should be able to perform two implicit learning\ntasks simultaneously without interference. As predicted, Jiménez and\nVázquez (2011) reported no interference when participants performed the\nserial reaction time task and a second implicit learning task.\nMany tasks involve a combination of implicit and explicit learning.\nTaylor et al. (2014) used a visuo-motor adaptation task on which partic-\nipants learned to point at a target that rotated 45 degrees counterclock-\nwise. Participants initially indicated their aiming direction and then made\na rapid reaching movement. The former provided a measure of explicit\nlearning whereas the latter provided a measure of implicit learning. Thus,\nan advantage of this experimental approach is that it provides separate\nmeasures of explicit and implicit learning.\nHuberdeau et al. (2015) reviewed findings using the above visuo-motor\nadaptation task and drew two main conclusions. First, improved perfor-\nmance over trials depended on both implicit and explicit learning. Second,\nthere was a progressive increase in implicit learning with practice, whereas\nmost explicit learning occurred early in practice.\nCognitive neuroscience\nIf implicit and explicit learning are genuinely different, they should be asso-\nciated with different brain areas. Implicit learning has been linked to the\nstriatum, which is part of the basal ganglia (see Figure 6.19). For example,\nReiss et al. (2005) found on the serial reaction time task that participants\nshowing implicit learning had greater activation\nin the striatum than those not exhibiting implicit\nlearning.\nIn contrast, explicit learning and memory\nare typically associated with activation in the\nmedial temporal lobes including the hippocam-\npus (see Chapter 7). Since conscious awareness\nis most consistently associated with activation\nof the dorsolateral prefrontal cortex and the\nanterior cingulate (see Chapter 16), these areas\nshould be more active during explicit than\nimplicit learning.\nRelevant evidence was reported by Wessel\net  al. (2012) using the serial reaction time\ntask. Some participants showed clear evi-\ndence of explicit learning during training. A\nbrain area centred on the right prefrontal\ncortex became much more active around the\nonset of explicit learning. In similar fashion,\nLawson et  al. (2017) compared participants\nshowing (or not showing) conscious aware-\nness of a repeating pattern on the serial reac-\ntion time task. The fronto-parietal network was\nmore activated for those showing conscious\nawareness.\nFigure 6.19\nThe striatum (which includes the caudate nucleus and the\nputamen) is of central importance in implicit learning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n275\nIt is often hard to establish the brain regions associated with implicit\nand explicit learning because learners often use both kinds of learning.\nDestrebecqz et  al. (2005) used the process-dissociation procedure (see\nGlossary) with the serial reaction time task to distinguish more clearly\nbetween the explicit and implicit components of learning. Striatum acti-\nvation was associated with the implicit component whereas the prefrontal\ncortex and anterior cingulate were associated with the explicit component.\nPenhune and Steele (2012) proposed a model of motor sequence\nlearning (see Figure 6.20). The striatum is involved in learning stimulus–\nresponse associations and motor chunking or organisation. The cerebellum\nis involved in producing an internal model to aid sequence performance\nand error correction. Finally, the motor cortex is involved in storing the\nlearned motor sequence. Of importance, the involvement of each brain\narea varies across stages of learning.\nEvidence for the importance of the cerebellum in motor sequence\nlearning was reported by Shimizu et  al. (2017) using transcranial direct\ncurrent stimulation (tDCS; see Glossary) applied to the cerebellum. This\nKEY TERM\nStriatum\nIt forms part of the basal\nganglia and is located\nin the upper part of the\nbrainstem and the inferior\npart of the cerebral\nhemispheres.\nFigure 6.20\nA model of motor sequence learning. The top panel shows the brain areas (PMC or M1 =\nprimary motor cortex) and associated mechanisms involved in motor sequence learning.\nThe bottom panel shows the changing involvement of different processing components\n(chunking, synchronisation, sequence ordering, error correction) in overall performance.\nEach component is colour-coded to its associated brain region.\nFrom Penhune and Steele (2012). Reprinted with permission of Elsevier.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-14 13:22:32.",
    "276\nMemory\nstimulation influenced implicit learning (enhancing or impairing perfor-\nmance) as predicted theoretically.\nIn spite of the above findings, there are many inconsistencies and com-\nplexities in the research literature (Reber, 2013). For example, Gheysen\net al. (2011) found the striatum contributed to explicit learning of motor\nsequences as well as implicit learning and the hippocampus is sometimes\ninvolved in implicit learning (Henke, 2010).\nWhy are the findings inconsistent? First, there are numerous forms of\nimplicit learning. As Reber (2013, p. 2029) argued, “We should expect to\nfind implicit learning . . . whenever perception and/or actions are repeated\nso that processing comes to reflect the statistical structure of experience.”\nAs a consequence, it is probable that implicit learning can involve several\ndifferent brain networks.\nSecond, we can regard, “the cerebellum, basal ganglia, and cortex as\nan integrated system” (Caligiore et al., 2017, p. 204). This system plays an\nimportant role in implicit and explicit learning.\nThird, as we have seen, there are large individual differences in learn-\ning strategies and the balance between implicit and explicit learning. These\nindividual differences introduce complexity into the overall findings.\nFourth, there are often changes in the involvement of implicit and explicit\nprocesses during learning. For example, Beukema and Verstynen (2018)\nfocused on changes in the involvement of different brain regions during\nthe acquisition of sequential motor skills (e.g., the skills acquired by\ntypists). Explicit processes dependent on the medial temporal lobe (shown\nin magenta) were especially important early in learning whereas implicit\nprocesses dependent on the basal ganglia (shown in blue) became increas-\ningly important later in learning (see Figure 6.21).\nFigure 6.21\nSequential motor skill\nlearning initially depends\non the medial temporal\nlobe (MTL) including the\nhippocampus (shown in\nmagenta) but subsequently\ndepends more on the basal\nganglia (BG) including the\nstriatum (shown in blue).\nFrom Beukema and Verstynen,\n2018).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n277\nBrain-damaged patients\nAmnesic patients with damage to the medial temporal lobes often have\nintact performance on implicit-memory tests but are severely impaired on\nexplicit-memory tests (see Chapter 7). If separate learning systems underlie\nimplicit and explicit learning, we might expect amnesic patients to have intact\nimplicit learning but impaired explicit learning. That pattern of  findings has\nbeen reported several times. However, amnesic patients are often slower\nthan healthy controls on implicit-learning tasks (Oudman et al., 2015).\nEarlier we discussed the hypothesis that the basal ganglia (especially\nthe striatum) are of major importance in implicit learning. Patients with\nParkinson’s disease (a progressive neurological disorder) have damage\nto this region. As predicted, Clark et  al. (2014) found in a meta-analytic\nreview that patients with Parkinson’s disease typically exhibit impaired\nimplicit learning on the serial reaction time task (see Chapter 7). However,\nWilkinson et  al. (2009) found Parkinson’s patients also showed impaired\nexplicit learning on that task. In a review, Marinelli et  al. (2017) found\nthat Parkinson’s patients showed the greatest impairment in motor learn-\ning when the task required conscious processing resources (e.g., attention;\ncognitive strategies).\nMuch additional research indicates Parkinson’s patients have impaired\nconscious processing (see Chapter 7). Siegert et al. (2008) found in a meta-\nanalytic review that such patients exhibited consistently poorer performance\nthan healthy controls on working memory tasks. Roussel et  al. (2017)\nfound 80% of Parkinson’s patients have dysexecutive syndrome which\ninvolves general impairments in cognitive processing. In sum, findings from\nParkinson’s patients provide only limited information concerning the dis-\ntinction between implicit and explicit learning.\nEvaluation\nResearch on implicit learning has several strengths (see also Chapter 7).\nFirst, the distinction between implicit and explicit learning has received\nFigure 6.22\nPercentages of experienced typists given an unfilled schematic keyboard (see\nFigure 6.16) who correctly located (top number), omitted (middle number) or misplaced\n(bottom number) each letter with respect to the standard keyboard.\nFrom Snyder et al. (2014). © 2011 Psychonomic Society. Reprinted with permission from Springer.\nKEY TERM\nParkinson’s disease\nA progressive disorder\ninvolving damage to the\nbasal ganglia (including\nthe striatum); the\nsymptoms include muscle\nrigidity, limb tremor\nand mask-like facial\nexpression.\nCreated from usyd on 2022-02-14 13:22:32.",
    "278\nMemory\nconsiderable support from behavioural and neuroimaging studies on\nhealthy individuals and from research on brain-damaged patients.\nSecond, the basal ganglia (including the striatum) tend to be associated\nwith implicit learning whereas the prefrontal cortex, anterior cingulate and\nmedial temporal lobes are associated with explicit learning. There is accu-\nmulating evidence that complex brain networks are involved in implicit\nlearning (e.g., Penhune & Steele, 2012).\nThird, given the deficiencies in assessing conscious awareness with\nany single measure, researchers are increasingly using several measures.\nThankfully, different measures often provide comparable estimates of the\nextent of conscious awareness (e.g., Haider et al., 2011).\nFourth, researchers increasingly reject the erroneous assumption that\nfinding some evidence of explicit learning implies no implicit learning\noccurred. In fact, learning typically involves implicit and explicit aspects\nand the extent to which learners are consciously aware of what they are\nlearning depends on individual differences and the stage of learning (e.g.,\nWessel et al., 2012).\nWhat are the limitations of research on implicit learning?\n(1) There is often a complex mixture of implicit and explicit learning,\nmaking it hard to determine the extent of implicit learning.\n(2) The processes underlying implicit and explicit learning interact in\nways that remain unclear.\n(3) In order to show the existence of implicit learning we need to demon-\nstrate that learning has occurred in the absence of conscious aware-\nness. This is hard to do – we may fail to assess fully participants’\nconscious awareness (Shanks, 2017).\n(4) The definition of implicit learning as learning occurring without con-\nscious awareness is vague and underspecified, and so is applicable to\nnumerous forms of learning having little in common with each other.\nIt is probable that no current theory can account for the diverse forms\nof implicit learning.\nFORGETTING FROM LONG-TERM MEMORY\nHermann Ebbinghaus (1885/1913) studied forgetting from long-term\nmemory in detail, using himself as the only participant (not recommended!).\nHe initially learned lists of nonsense syllables lacking meaning and then\nrelearned each list between 21 minutes and 31 days later. His basic measure\nof forgetting was the savings method – the reduction in the number of\ntrials during relearning compared to original learning.\nEbbinghaus found forgetting was very rapid over the first hour\nafter learning but then slowed considerably (see Figure 6.23). Rubin and\nWenzel (1996) found the same pattern when analysing numerous for-\ngetting functions and argued a logarithmic function describes forgetting\nover time. In contrast, Averell and Heathcote (2011) argued for a power\nfunction.\nIt is often assumed (mistakenly) that forgetting should always be\navoided. Nørby (2015) identified three major functions served by forgetting:\nKEY TERM\nSavings method\nA measure of forgetting\nintroduced by Ebbinghaus\nin which the number\nof trials for relearning\nis compared against\nthe number for original\nlearning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n279\n(1) It can enhance psychological well-being by reducing access to painful\nmemories.\n(2) It is useful to forget outdated information (e.g., where your friends\nused to live) so it does not interfere with current information (e.g.,\nwhere your friends live now). Richards and Frankland (2017) devel-\noped this argument. They argued a major purpose of memory is to\nenhance decision-making and this purpose is facilitated when we\nforget outdated information.\n(3) When trying to remember what we have read or heard, it is typically\nmost useful to forget specific details and focus on the overall gist or\nmessage (see Box and Chapter 10).\nFigure 6.23\nForgetting over time\nas indexed by reduced\nsavings.\nData from Ebbinghaus\n(1885/1913).\nIN THE REAL WORLD: IS PERFECT MEMORY\nUSEFUL?\nWhat would it be like to have a perfect memory? Jorge Luis Borges\n(1964) answered this question in a story called “Funes the memorious”.\nAfter falling from a horse, Funes remembers everything that happens\nto him in full detail. This had several negative consequences. When he\nrecalled the events of any given day, it took him an entire day to do so!\nHe found it very hard to think because his mind was full of incredibly\ndetailed information. Here is an example:\nNot only was it difficult for him to comprehend that the generic symbol\ndog embraces so many unlike individuals of diverse size and form; it\nbothered him that the dog at three fourteen (seen from the side) should\nhave the same name as the dog at three fifteen (seen from the front).\n(p. 153)\nCreated from usyd on 2022-02-14 13:22:32.",
    "280\nMemory\nThe closest real-life equivalent of Funes was a Russian called Solomon\nShereshevskii. When he worked as a journalist, his editor noticed he could\nrepeat everything said to him verbatim. The editor sent Shereshevskii\n(S) to see the psychologist Luria. He found S rapidly learned complex\nmaterial (e.g., lists of over 100 digits) which he remembered perfectly\n(even in reverse order) several years later. According to Luria (1968),\n“There was no limit either to the capacity of S’s memory or to the\ndurability of the traces he retained.”\nWhat was S’s secret? He had exceptional imagery and an amazing\ncapacity for synaesthesia (the tendency for processing in one modality\nto evoke other sense modalities). For example, when hearing a tone, he\nsaid: “It looks like fireworks tinged with a pink-red hue.”\nDo you envy S’s memory powers? Ironically, his memory was so good\nit disrupted his everyday life. For example, this was his experience when\nhearing a prose passage: “Each word calls up images, they collide with\none another, and the result is chaos.” His mind came to resemble “a\njunk heap of impressions”. His acute awareness of details meant he\nsometimes failed to recognise someone he knew if, for example, their\nfacial colouring had altered because they had been on holiday. These\nmemory limitations made it hard for him to live a normal life and he\neventually ended up in an asylum.\nKEY TERM\nSynaesthesia\nThe tendency for one\nsense modality to evoke\nanother.\nMost forgetting studies focus on declarative or explicit memory involv-\ning conscious recollection (see Chapter 7). Forgetting is often slower in\nimplicit than explicit memory.\nFor example, Mitchell (2006) asked participants to identify pictures\nfrom fragments having seen some of them in an experiment 17 years pre-\nviously. Performance was better with the previously seen pictures, provid-\ning evidence for very-long-term implicit memory. However, there was little\nexplicit memory for the previous experiment. A 36-year-old male partici-\npant confessed, “I’m sorry – I don’t really remember this experiment at all.”\nBelow we discuss major theories of forgetting. These theories are\nnot mutually exclusive – they all identify factors jointly responsible for\nforgetting.\nDecay\nPerhaps the simplest explanation for forgetting of long-term memories is\ndecay, which involves “forgetting due to a gradual loss of the substrate of\nmemory” (Hardt et  al., 2013, p. 111). More specifically, forgetting often\noccurs because of decay processes occurring within memory traces. In spite\nof its plausibility, decay has largely been ignored as an explanation of for-\ngetting. Hardt et al. argued a decay process (operating mostly during sleep)\nremoves numerous trivial memories we form every day. This decay process\nis especially active in the hippocampus (part of the medial temporal lobe\ninvolved in acquiring new memories; see Chapter 7).\nForgetting can be due to decay or interference (discussed shortly).\nSadeh et al. (2016) assumed detailed memories (i.e., containing contextual\ninformation) are sufficiently complex to be relatively immune to interference\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n281\nfrom other memories. As a result, most forgetting of such memories should\nbe due to decay. In contrast, weak memories (i.e., lacking contextual infor-\nmation) are very susceptible to interference and so forgetting of such memo-\nries should be primarily due to interference rather than decay. Sadeh et al.’s\nfindings supported these assumptions. Thus, the role played by decay in\nforgetting depends on the nature of the underlying memory traces.\nInterference theory\nInterference theory was the dominant approach to forgetting during much\nof the twentieth century. According to this theory, long-term memory\nis impaired by two forms of interference: (1) proactive  interference  –\ndisruption of memory by previous learning; (2) retroactive  interference –\ndisruption of memory for previous by other learning or processing during\nthe retention interval. Research using methods such as those shown in\nFigure 6.22 indicates proactive and retroactive interference are both maximal\nwhen two different responses are associated with the same stimulus.\nProactive interference\nProactive interference typically involves competition between the correct\nresponse and an incorrect one. There is greater competition (and thus more\ninterference) when the incorrect response is associated with the same stimu-\nlus as the correct response. Jacoby et al. (2001) found proactive interference\nwas due much more to the strength of the incorrect response than the weak-\nness of the correct response. Thus, it is hard to exclude incorrect responses\nfrom the retrieval process.\nMore evidence for the importance of retrieval processes was reported\nby Bäuml and Kliegl (2013). They tested the hypothesis that proactive\ninterference is often found because rememberers’ memory search is too\nKEY TERMS\nProactive interference\nDisruption of memory by\nprevious learning (often of\nsimilar material).\nRetroactive interference\nDisruption of memory\nfor previously learned\ninformation by other\nlearning or processing\noccurring during the\nretention interval.\nFigure 6.24\nMethods of testing for\nproactive and retroactive\ninterference.\nCreated from usyd on 2022-02-14 13:22:32.",
    "282\nMemory\nbroad, including material previously learned\nbut currently irrelevant. In the remember\n(proactive interference) condition, three word\nlists were presented followed by free recall of\nthe last one. In the forget condition, the same\nlists were presented but participants were told\nafter the first two lists to forget them. Finally,\nthere was a control (no proactive interference)\ncondition where only one list was learned and\ntested.\nParticipants in the control condition\nrecalled 68% of the words compared to only\n41% in the proactive interference condition.\nCrucially, participants in the forget condi-\ntion recalled 68% of the words despite having\nlearned two previous lists. The instruction to\nforget the first two lists allowed participants to\nlimit their retrieval efforts to the third list. This\ninterpretation was strengthened by the finding\nthat retrieval speed was comparable in  the\nforget and control conditions (see Figure 6.25).\nKliegl et  al. (2015) found in a similar\nstudy that impaired encoding (see Glossary) contributes to proactive inter-\nference. Encoding was assessed using electroencephalography (EEG; see\nGlossary). The EEG indicated there was reduced attention during encoding\nof a word list preceded by other word lists (proactive interference condi-\ntion). As in the study by Bäuml and Kliegl (2013), there was also evidence\nthat proactive interference impaired retrieval.\nSuppose participants learn word pairs on the first list (e.g., Cat–Dirt)\nand more word pairs on the second list (e.g., Cat–Tree). They are then\ngiven the first words (e.g., Cat) and must recall the paired word from the\nsecond list (see Figure 6.24).\nJacoby et  al. (2015) argued proactive interference (e.g., recalling\nDirt instead of Tree) often occurs when participants often fail to recog-\nnise changes in the word pairings between lists. As predicted, when they\ninstructed some participants to detect changed pairs, there was proactive\nfacilitation rather than interference. Thus, proactive interference can be\nreduced (or even reversed) if we recollect the changes between information\nlearned originally and subsequently.\nRetroactive interference\nAnecdotal evidence that retroactive interference can be important in every-\nday life comes from travellers claiming exposure to a foreign language\nreduces their ability to recall words in their own language. Misra et  al.\n(2012) studied bilinguals whose native language was Chinese and second\nlanguage was English. They named pictures in Chinese more slowly after\npreviously naming the same pictures in English. The evidence from event-\nrelated potentials suggested participants were inhibiting second- language\nnames when naming pictures in Chinese.\nFigure 6.25\nPercentage of items recalled over time for the conditions: no\nproactive interference (PI), remember (proactive interference)\nand forget (forget previous lists).\nFrom Bäuml & Kliegl (2013). Reprinted with permission of Elsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n283\nAs discussed earlier, Jacoby et al. (2015) found evidence for proactive\nfacilitation rather than interference when participants explicitly focused on\nchanges between the first and second lists (e.g., Cat–Dirt and Cat–Tree).\nJacoby et al. also found that instructing participants to focus on changes\nbetween lists produced retroactive facilitation rather than interference.\nFocusing on changes made it easier for participants to discriminate accu-\nrately between list 1 responses (e.g., Dirt) and list 2 responses (e.g., Tree).\nRetroactive interference is generally greatest when the new learning\nresembles previous learning. However, Dewar et  al. (2007) obtained evi-\ndence of retroactive interference for a word list when participants per-\nformed an unrelated task (e.g., detecting tones) between learning and\nmemory test. Fatania and Mercer (2017) found children were more sus-\nceptible than adults to non-specific retroactive interference, perhaps\nbecause they used fewer effective strategies (e.g., rehearsal) to minimise\nsuch interference.\nIn sum, retroactive interference can occur in two ways:\n(1)  learning material similar to the original learning material;\n(2) distraction involving expenditure of mental effort during the retention\ninterval (non-specific retroactive interference); this cause of retroac-\ntive interference is probably most common in everyday life.\nRetrieval problems play a major role in producing retroactive interference.\nLustig et al. (2004) found that much retroactive interference occurs because\npeople find it hard to avoid retrieving information from the wrong list. How\ncan we reduce retrieval problems? Unsworth et al. (2013) obtained substan-\ntial retroactive interference when two word lists were presented prior to\nrecall of the first list. When focused retrieval was made easier (the words\nin each list belonged to two separate categories such as animals and trees),\nthere was no retroactive interference.\nEcker et al. (2015) also tested recall of the first list following presenta-\ntion of two word lists. When the time interval between lists was long rather\nthan short, recall performance was better. Focusing retrieval on first-list\nwords was easier when the two lists were more separated in time and thus\nmore discriminable.\nEvaluation\nThere is convincing evidence for both proactive and retroactive interfer-\nence, and progress has been made in identifying the underlying processes.\nProactive and retroactive interference depend in part on problems with\nfocusing retrieval exclusively on to-be-remembered information. Proactive\ninterference also depends on impaired encoding of information. Both types\nof interference can be reduced by active strategies (e.g., focusing on changes\nbetween the two lists).\nWhat are the limitations of theory and research in this area? First,\ninterference theory explains why forgetting occurs but does not explain\nwhy forgetting rate decreases over time. Second, we need clarification of\nthe roles of impaired encoding and impaired retrieval in producing inter-\nference effects. For example, there may be interaction effects with impaired\nCreated from usyd on 2022-02-14 13:22:32.",
    "284\nMemory\nencoding reducing the efficiency of retrieval. Third, the precise mechanisms\nresponsible for the reduced interference effects with various strategies have\nnot been identified.\nMotivated forgetting\nInterest in motivated forgetting was triggered by the bearded Austrian psy-\nchologist Sigmund Freud (1856–1939). His approach was narrowly focused\non repressed traumatic and other distressing memories. More recently, a\nbroader approach to motivated forgetting has been adopted. Much infor-\nmation in long-term memory is outdated and useless for present purposes\n(e.g., where you have previously parked your car). Thus, motivated or\nintentional forgetting can be adaptive.\nRepression\nFreud claimed threatening or traumatic memories often cannot gain access\nto conscious awareness: this serves to reduce anxiety. He used the term\nrepression to refer to this phenomenon. He claimed childhood traumatic\nmemories forgotten for many years are sometimes remembered in adult life.\nFreud found these recovered memories were often recalled during therapy.\nHowever, many experts (e.g., Loftus & Davis, 2006) argue most recovered\nmemories are false memories referring to imaginary events.\nRelevant evidence concerning the truth of recovered memories was\nreported by Lief and Fetkewicz (1995). Of adult patients who admitted\nreporting false recovered memories, 80% had therapists who had made\ndirect suggestions they had been subject to childhood sexual abuse. These\nfindings suggest recovered memories recalled inside therapy are more likely\nto be false than those recalled outside.\nGeraerts et al. (2007) obtained support for the above suggestion in a\nstudy on three adult groups who had suffered childhood sexual abuse:\n(1) Suggestive therapy group: their recovered memories were recalled ini-\ntially inside therapy.\n(2) Spontaneous recovery group: their recovered memories were recalled\ninitially outside therapy.\n(3) Continuous memory group: they had continuous memories of abuse\nfrom childhood onwards.\nGeraerts et  al. (2007) argued the genuineness of the memories produced\ncould be assessed approximately by using corroborating evidence (e.g., the\nabuser had confessed). Such evidence was available for 45% of the continu-\nous memory group and 37% of the outside therapy group but for 0% of the\ninside therapy group. These findings suggest recovered memories recalled\noutside therapy are much more likely to be genuine than those recalled\ninside therapy.\nGeraerts (2012) reviewed research comparing women whose recov-\nered memories were recalled spontaneously or in therapy. Of importance,\nthose with spontaneous recovered memories showed more ability to sup-\npress unwanted memories and were more likely to forget they remembered\nKEY TERMS\nRepression\nMotivated forgetting\nof traumatic or other\nthreatening events\n(especially from\nchildhood).\nRecovered memories\nChildhood traumatic\nmemories forgotten for\nseveral years and then\nremembered in adult life.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n285\nsomething previously. Spontaneous recovery memories are often triggered\nby relevant retrieval cues (e.g., returning to the scene of the abuse).\nIt seems surprising that women recovering memories outside therapy\nfailed for many years to remember childhood sexual abuse. However, it is\nso only if the memories are traumatic (as Freud assumed). In fact, only 8%\nof women with recovered memories regarded the relevant events as trau-\nmatic or sexual when they occurred (Clancy & McNally, 2005/2006). The\ngreat majority described their memories as confusing or uncomfortable –\nit seems reasonable that confusing or uncomfortable memories could be\nsuppressed or simply ignored or forgotten.\nIn sum, many assumptions about recovered memories are false. As\nMcNally and Geraerts (2009, p. 132) concluded, “A genuine recovered\nCSA [childhood sexual abuse] memory does not require repression, trauma,\nor even complete forgetting.”\nDirected forgetting\nDirected forgetting is a phenomenon involving impaired long-term\nmemory triggered by instructions to forget information previously pre-\nsented for learning. It is often studied using the item method: several words\nare presented, each followed immediately by an instruction to remem-\nber or forget it. After the words have been presented, participants are\ntested for recall or recognition memory of all the words. Memory perfor-\nmance is worse for the to-be-forgotten words than the to-be-remembered\nones.\nWhat causes directed forgetting? The instructions cause learners to\ndirect their rehearsal processes to to-be-remembered items at the expense\nof to-be-forgotten ones. Inhibitory processes are also involved. Successful\nforgetting is associated with activation in areas within the right frontal\ncortex involved in inhibition (Rizio & Dennis, 2013).\nDirected forgetting is often unsuccessful. Rizio and Dennis (2017)\nfound 60% of items associated with forget instructions (Forget items) were\nsuccessfully recognised compared to 73% for items associated with remem-\nber instructions (Remember items). They then considered brain activation\nfor successfully recognised items associated with a feeling of remembering.\nThere was greater activation in prefrontal areas associated with effortful\nprocessing for recognised Forget items than recognised Remember items.\nThis enhanced effort was required because participants engaged in inhibi-\ntory processing of Forget items at encoding even if they were subsequently\nrecognised.\nThink/No-Think paradigm: suppression\nAnderson and Green (2001) developed the Think/No-Think paradigm to\nassess whether individuals can actively suppress memories. Participants\nlearn a list of cue–target word pairs (e.g., Ordeal–Roach; Steam–Train).\nThen they receive the cues studied earlier (e.g., Ordeal; Steam) and try\nto recall the associated words (e.g., Roach; Train) (respond condition) or\nprevent them coming to mind (suppress condition). Some cues are not\npresented at this stage (baseline condition).\nKEY TERM\nDirected forgetting\nReduced long-term\nmemory caused by\ninstructions to forget\ninformation that had been\npresented for learning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "286\nMemory\nFinally, there are two testing conditions.\nIn the same-probe test condition, the original\ncues are presented (e.g., Ordeal) and partic-\nipants recall the corresponding target words\n(e.g., Roach). In the independent-probe test\ncondition, participants are presented with a\nnovel category cue (e.g., Roach might be cued\nwith Insect–r).\nIf people can suppress unwanted mem-\nories, recall should be lower in the suppress\nthan the respond condition. Recall should also\nbe lower in the suppress condition than the\nbaseline condition. Anderson and Huddleston\n(2012) carried out a meta-analysis of 47\nexperiments and found strong support for\nboth predictions (see Figure 6.26). However,\nsuppression attempts were often unsuccessful:\nin the suppress condition (same-probe test),\n82% of items were recalled.\nWhat strategies do individuals use to\nproduce successful suppression of unwanted\nmemories? Direct suppression (focusing on the cue word and blocking out\nthe associated target word) is an important strategy. Thought substitution\n(associating a different non-target word with each cue word) is also very\ncommon. Bergström et al. (2009) found these strategies were comparably\neffective in reducing recall in the suppress condition.\nAnderson et al. (2016b) pointed out the Think/No-Think paradigm is\nunrealistic in that we rarely make deliberate efforts to retrieve suppressed\nmemories in everyday life. They argued it would be more realistic to assess\nthe involuntary or spontaneous retrieval of suppressed memories. They\nfound suppression was even more effective than voluntary retrieval at\nreducing involuntary retrieval of such memories.\nHow do suppress instructions cause forgetting? Anderson (e.g.,\nAnderson & Huddleston, 2012) argues inhibitory control is important –\nthe learned response to the cue word is inhibited. More specifically, he\nassumes inhibitory control involves the dorsolateral prefrontal cortex and\nother frontal areas. Prefrontal activation leads to reduced activation in the\nhippocampus (of central importance in learning and memory).\nThere is much support for the above hypothesis. First, there is typ-\nically greater dorsolateral prefrontal activation during suppression\nattempts than retrieval but reduced hippocampal activation (Anderson\net al., 2016b). Second, studies focusing on connectivity between the dorso-\nlateral prefrontal cortex and hippocampus indicated the former influ-\nences the latter (Anderson et  al., 2016b). Third, individuals whose left\nand right hemisphere frontal areas involved in inhibitory control are\nmost closely coordinated exhibit superior memory suppression (Smith\net al., 2018).\nFigure 6.26\nPercentage of words correctly recalled across 32 articles in\nthe respond, baseline and suppress conditions (in that order,\nreading from left to right) with same probe and independent\nprobe testing conditions.\nFrom Anderson and Huddleston (2012). Reproduced with permission of\nSpringer Science+Business Media.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n287\nEvaluation\nMost individuals can actively suppress unwanted memories making them\nless likely to be recalled on purpose or involuntarily. Progress has been\nmade in identifying the underlying mechanisms. Of most importance, inhib-\nitory control mechanisms associated with the prefrontal cortex (especially\nthe dorsolateral prefrontal cortex) often reduce hippocampal activation\n(Anderson et al., 2016b).\nWhat are the limitations of theory and research in this area? First,\nmore research is required to clarify the reasons why suppression attempts\nare often unsuccessful. Second, the reduced recall typically obtained in the\nsuppress condition is not always due exclusively to inhibitory processes.\nSome individuals use thought substitution, a strategy which reduces recall\nby producing interference or competition with the correct words (Bergström\net al., 2009). However, del Prete et al. (2015) argued (with supporting evi-\ndence) that inhibitory processes play a part in explaining the successful use\nof thought substitution.\nCue-dependent forgetting\nWe often attribute forgetting to the weakness of relevant memory traces.\nHowever, forgetting often occurs because we lack the appropriate retrieval\ncues (cue-dependent forgetting). For example, suppose you have forgotten\nthe name of an acquaintance. If presented with four names, however, you\nmight well recognise the correct one.\nTulving (1979) argued that forgetting typically occurs when there is\na poor match or fit between memory-trace information and information\navailable at retrieval. This notion was expressed in his encoding  specificity\nprinciple: “The probability of successful retrieval of the target item is a\nmonotonically increasing function of informational overlap between the\ninformation present at retrieval and the information stored in memory”\n(p.  478). (If you are bewildered, note that a “monotonically increasing\nfunction” is one that generally rises and does not\ndecrease at any point.)\nThe encoding specificity principle resembles the\nnotion of transfer- appropriate processing (Morris\net  al., 1977; discussed earlier, see p. 263). The main\ndifference is that the latter focuses more directly on\nthe processes involved in memory.\nTulving (1979) assumed that when we store infor-\nmation about an event, we also store information\nabout its context. According to the encoding specificity\nprinciple, memory is better when the retrieval context\nis the same as that at learning. Note that context can\nbe external (the environment in which learning and\nretrieval occur) or internal (e.g., mood state).\nEysenck (1979) argued that long-term memory\ndoes not depend only on the match between informa-\ntion available at retrieval and stored information. The\nextent to which the retrieval information allows us\nKEY TERM\nEncoding specificity\nprinciple\nThe notion that retrieval\ndepends on the overlap\nbetween the information\navailable at retrieval and\nthe information in the\nmemory trace.\nEndel Tulving.\nCourtesy of Anders Gade.\nCreated from usyd on 2022-02-14 13:22:32.",
    "288\nMemory\nto discriminate between the correct memory trace and incorrect ones also\nmatters (discussed further below, see p. 298).\nFindings\nRecognition memory is typically much better than recall (e.g., we can rec-\nognise names we cannot recall). However, it follows from the encoding\nspecificity principle that recall will be better than recognition memory when\ninformation in the recall cue overlaps more than that in the recognition cue\nwith memory-trace information. This surprising finding has been reported\nmany times. For example, Muter (1978) found people were better at recall-\ning famous names (e.g., author of the Sherlock Holmes stories: Sir Arthur\nConan ___) than selecting the same names on a recognition test (e.g.,\nDOYLE).\nMuch research indicates the importance of context in determining for-\ngetting. On the assumption that information about mood state (internal\ncontext) is often stored in the memory trace, there should be less forget-\nting when the mood state at learning and retrieval is the same rather than\ndifferent. This phenomenon (mood-state-dependent memory) has often\nbeen reported (see Chapter 15). Godden and Baddeley (1975) manipulated\nexternal context. Divers learned words on a beach or 10 feet underwater\nand then recalled the words in the same or the other environment. Recall\nwas much better in the same environment.\nHowever, Godden and Baddeley (1980) found no effect of context in a\nvery similar experiment testing recognition memory rather than recall. This\nprobably happened because the presence of the learned items on the rec-\nognition test provided powerful cues outweighing any impact of context.\nBramão and Johansson (2017) found that having the same picture\ncontext at learning and retrieval enhanced memory for word pairs pro-\nvided that each word pair was associated with a different picture context.\nHowever, having the same picture context at learning and retrieval impaired\nmemory when each word pair was associated with the same picture context.\nIn this condition, the picture context did not provide useful information\nspecific to each of the word pairs being tested.\nThe encoding specificity principle can be expressed in terms of brain\nactivity: “Memory success varies as a function of neural encoding patterns\nbeing reinstated at retrieval” (Staudigl et al., 2015, p. 5373). Several studies\nhave supported the notion that neural reinstatement is important for\nmemory success. For example, Wing et al. (2015) presented scenes paired\nwith matching verbal labels at encoding and asked participants to recall the\nscenes in detail when presented with the labels at retrieval. Recall perfor-\nmance was better when brain activity at encoding and retrieval was similar\nin the occipito-temporal cortex, which is involved in visual processing.\nLimitations on the predictive power of neural reinstatement were shown\nby Mallow et  al. (2015) in a study on trained memory experts learning\nthe locations of 40 digits presented in a matrix. They turned the numbers\ninto concrete objects, which were then mentally inserted into a memorised\nroute. On average, they recalled 86% of the digits in the correct order.\nHowever, none of the main brain areas active during encoding was acti-\nvated during recall: thus, there was remarkably little neural reinstatement.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n289\nThis happened because the processes occurring during encoding were very\ndifferent from (and much more complex than) those occurring at retrieval.\nSuppose you learn paired associates including park–grove and are later\ngiven the cue word park and asked to supply the target or response word\n(i.e., grove). The response words to the other paired associates are either\nassociated with park (e.g., tree; bench; playground) or not associated. In the\nlatter case, the cue is uniquely associated with the target word and so your\ntask should be easier. There is high overload when a cue is associated with\nseveral response words and low overload when it is only associated with\none response word. The target word is more distinctive when there is low\noverload (distinctiveness was discussed earlier in the chapter).\nGoh and Lu (2012) tested the above predictions. Encoding-retrieval\noverlap was manipulated by using three item types. There was maximal\noverlap when the same cue was presented at retrieval and learning (e.g.,\npark–grove followed by park–???); this was an intra-list cue. There was\nmoderate overlap when the cue was a strong associate of the target word\n(e.g., airplane–bird followed by feather–???). Finally, there was little overlap\nwhen the cue was a weak associate of the target word e.g., roof–tin fol-\nlowed by armour–???).\nAs predicted from the encoding specificity principle, encoding- retrieval\noverlap was important (see Figure 6.27). However, cue overload was\nalso important – memory performance was much better when each cue\nwas uniquely associated with a single response word. According to the\nencoding specificity principle, memory performance should be best when\nencoding-retrieval overlap is highest (i.e., with intra-list cues). However,\nthat was not the case with high overload.\nEvaluation\nTulving’s approach based on the encoding\nspecificity principle has several strengths.\nThe overlap between memory-trace informa-\ntion and that available in retrieval cues often\ndetermines retrieval success. The principle\nhas also received some support from neuro-\nimaging studies and research on mood-state-\ndependent memory (see Chapter 15). The\nnotion that contextual information (external\nand internal) strongly influences memory per-\nformance has proved correct.\nWhat are the limitations with Tulving’s\napproach? First, he exaggerated the impor-\ntance of encoding-retrieval overlap as the\nmajor factor determining remembering and\nforgetting. Remembering typically involves\nrejecting incorrect items as well as select-\ning correct ones. For this purpose, a cue’s\nability to discriminate among memory traces\nis important (Bramão & Johansson, 2017;\nEysenck, 1979; Goh & Lu, 2012).\nFigure 6.27\nProportion of words recalled in high- and low-overload\nconditions with intra-list cues, strong extra-list cues and weak\nextra-list cues.\nFrom Goh and Lu (2012). © 2011 Psychonomic Society, Inc. Reprinted\nwith the permission of Springer.\nCreated from usyd on 2022-02-14 13:22:32.",
    "290\nMemory\nSecond, neural reinstatement of encoding brain activity at retrieval is\nsometimes far less important than implied by the encoding specificity prin-\nciple. This is especially the case when the processes at retrieval are very\ndifferent from those used at encoding (e.g., Mallow et al., 2015).\nThird, Tulving’s assumption that retrieval-cue information is compared\ndirectly with memory-trace information is oversimplified. For example,\nyou would probably use complex problem-solving strategies to answer\nthe question, “What did you do six days ago?”. Remembering is a more\ndynamic, reconstructive process than implied by Tulving (Nairne, 2015a).\nFourth, as Nairne (2015a, p. 128) pointed out, “Each of us regularly\nencounters events that ‘match’ prior episodes in our lives . . . but few of\nthese events yield instances of conscious recollection.” Thus, we experience\nless conscious recollection than implied by the encoding specificity principle.\nFifth, it is not very clear from the encoding specificity principle why\ncontext effects are often greater on recall than recognition memory (e.g.,\nGodden & Baddeley, 1975, 1980).\nSixth, memory allegedly depends on “informational overlap” between\nmemory trace and retrieval environment, but this is rarely assessed.\nInferring the amount of informational overlap from memory performance\nis circular reasoning.\nConsolidation and reconsolidation\nThe theories discussed so far identify factors that cause forgetting, but\ndo not indicate clearly why the rate of forgetting decreases over time. The\nanswer may lie in consolidation. According to this theory, consolidation\n“refers to the process by which a temporary, labile memory is transformed\ninto a more stable, long-lasting form” (Squire et al., 2015, p. 1).\nAccording to the standard theory, episodic memories are initially\ndependent on the hippocampus. However, during the process of consoli-\ndation, these memories are stored within cortical networks. This theory is\noversimplified: the process of consolidation involves bidirectional interac-\ntions between the hippocampus and the cortex (Albo & Gräff, 2018).\nThe key assumption of consolidation theory is that recently formed\nmemories are still being consolidated and so are especially vulnerable to\ninterference and forgetting. Thus, “New memories are clear but fragile and\nold ones are faded but robust” (Wixted, 2004, p. 265).\nFindings\nMuch research supports consolidation theory. First, the decreased rate of\nforgetting typically found over time can be explained by assuming recent\nmemories are more vulnerable than older ones due to an ongoing consoli-\ndation process.\nSecond, there is research on retrograde amnesia, which involves\nimpaired memory for events occurring before amnesia onset. As predicted\nby consolidation theory, patients with damage to the hippocampus often\nshow greatest forgetting for memories formed shortly before amnesia onset\nand least for more remote memories (e.g., Manns et al., 2003). However,\nthe findings are somewhat mixed (see Chapter 7).\nKEY TERMS\nConsolidation\nA basic process within\nthe brain involved in\nestablishing long-term\nmemories; this process\nlasts several hours or\nmore and newly formed\nmemories are fragile.\nRetrograde amnesia\nImpaired ability of\namnesic patients to\nremember information\nand events from the time\nperiod prior to the onset\nof amnesia.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n291\nSquire et  al. (1975) assessed recognition memory before and after\npatients were given electroconvulsive therapy. Electroconvulsive therapy\nreduced their memory for programmes up to 3 years beforehand from 65%\nto 42% but had no effect on memories acquired 4 to 17 years earlier.\nThird, individuals who drink excessively sometimes experience\n“blackouts” (an almost total loss of memory for events occurring while\ndrunk). These blackouts probably indicate a failure to consolidate mem-\nories formed while intoxicated. As predicted, Moulton et al. (2005) found\nlong-term memory was impaired in individuals who drank alcohol shortly\nbefore learning. However, alcohol consumption shortly after learning led\nto improved memory. Alcohol may inhibit the subsequent formation of\nnew memories that would interfere with the consolidation process of mem-\nories formed just before alcohol consumption.\nFourth, consolidation theory predicts newly formed memories are\nmore susceptible to retroactive interference than older ones. There is some\nsupport for this prediction when the interfering material is dissimilar to\nthat in the first learning task (Wixted, 2004).\nFifth, consolidation processes during sleep can enhance long-term\nmemory (Paller, 2017). Consider a technique known as target memory\nreactivation: sleeping participants are exposed to auditory or olfactory cues\n(the latter relate to the sense of smell) present in the context where learning\ntook place. This enhances memory consolidation by reactivating brain net-\nworks (including the hippocampus) involved in encoding new information\nand increases long-term memory (Schouten et al., 2017).\nReconsolidation\nConsolidation theory assumes memory traces are “fixated” because of a\nconsolidation process. However, accumulating evidence indicates that is\noversimplified. The current view is that consolidation involves progres-\nsive transformation of memory traces rather than simply fixation (Elsey\net al., 2018). Of most importance, reactivation of previously consolidated\nmemory traces puts them back into a fragile state that can lead to those\nmemory traces being modified (Elsey et al., 2018). Reactivation can lead to\nreconsolidation (a new consolidation process).\nFindings\nReconsolidation is very useful for updating our knowledge because pre-\nvious learning is now irrelevant. However, it can impair memory for the\ninformation learned originally. This is how it happens. We learn some\ninformation at Time 1. At Time 2, we learn additional information. If the\nmemory traces based on the information learned at Time 1 are activated\nat Time 2, they immediately become fragile. As a result, some information\nlearned at Time 2 will mistakenly become incorporated into the memory\ntraces of Time 1 information and thus cause misremembering.\nHere is a concrete example. Chan and LaPaglia (2013) had partici-\npants watch a movie about a fictional terrorist attack (original learning).\nSubsequently, some recalled 24 specific details from the move (e.g., a ter-\nrorist using a hypodermic syringe) to produce reconsolidation (reactivation)\nKEY TERM\nReconsolidation\nThis is a new process of\nconsolidation occurring\nwhen a previously\nformed memory trace\nis reactivated; it allows\nthat memory trace to be\nupdated.\nCreated from usyd on 2022-02-14 13:22:32.",
    "292\nMemory\nwhereas others performed an irrelevant distractor task (no reactivation).\nAfter that, the participants encountered misinformation (e.g., the terrorist\nused a stun gun) or neutral information (relearning). Finally, there was a\nrecognition-memory test for the information in the movie.\nWhat did Chan and LaPaglia (2013) find? Misinformation during the\nrelearning phase led to substantial forgetting of information from the movie\nin the reactivation/reconsolidation condition but not the no- reactivation\ncondition. Reactivating memory traces from the movie triggered reconsol-\nidation making those memory traces vulnerable to disruption from mis-\ninformation. In contrast, memory traces not subjected to reconsolidation\nwere not disrupted.\nScully et al. (2017) reported a meta-analytic review based on 34 exper-\niments. As predicted, memory reactivation made memories susceptible to\nbehavioural interference leading to impaired memory performance for the\noriginal learning event. These findings presumably reflect a reconsolidation\nprocess. However, the mean effect size was small and some studies (e.g.,\nHardwicke et al., 2016) failed to obtain significant effects.\nEvaluation\nConsolidation theory explains why the rate of forgetting decreases over\ntime. It also successfully predicts that retrograde amnesia is greater for\nrecently formed memories and that retroactive interference effects are great-\nest when the interfering information is presented shortly after learning.\nConsolidation processes during sleep are important in promoting long-term\nmemory and progress has been made in understanding the underlying pro-\ncesses (e.g., Vahdat et al., 2017).\nReconsolidation theory helps to explain how memories are updated\nand no other theory can explain the range of phenomena associated\nwith reconsolidation (Elsey et  al., 2018). It is a useful corrective to the\nexcessive emphasis of consolidation theory on the permanent storage of\nmemory traces. Reconsolidation may prove very useful in clinical contexts.\nFor example, patients with post-traumatic stress disorder (PTSD) typically\nexperience flashbacks (vivid re-experiencing of trauma-related events).\nThere is preliminary evidence that reconsolidation can be used successfully\nin the treatment of PTSD (Elsey et al., 2018).\nWhat are the limitations of this theoretical approach?\n(1) Forgetting does not depend solely on consolidation but also depends\non factors (e.g., encoding-retrieval overlap) not considered within the\ntheory.\n(2) Consolidation theory does not explain why proactive and retroactive\ninterference are greatest when two different responses are associated\nwith the same stimulus.\n(3) Much remains to be done to bridge the gap between consolidation\ntheory (with its focus on physical processes within the brain) and\napproaches to forgetting that emphasise cognitive processes.\n(4) Consolidation processes are very complex and only partially under-\nstood. For example, it has often been assumed that cortical networks\nbecome increasingly important during consolidation. In addition,\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n293\nCHAPTER SUMMARY\n•\nShort-term vs long-term memory. The multi-store model assumes\nthere are separate sensory, short-term and long-term stores.\nMuch evidence (e.g., from amnesic patients) provides general\nsupport for the model, but it is greatly oversimplified. According\nto the unitary-store model, short-term memory is the temporarily\nactivated part of long-term memory. That is partially correct.\nHowever, the crucial term “activation” is not precisely defined. In\naddition, research on amnesic patients and neuroimaging studies\nsuggest the differences between short-term and long-term memory\nare greater than assumed by the unitary-store model.\n•\nWorking memory. Baddeley’s original working memory model\nconsisted of three components: an attention-like central executive,\na phonological loop holding speech-based information, and\na visuo-spatial sketchpad specialised for visual and spatial\nprocessing. However, there are doubts as to whether the visuo-\nspatial sketchpad is as separate from other cognitive processes\nand system as assumed theoretically. The importance of the\ncentral executive can be seen in brain-damaged patients whose\ncentral executive functioning is impaired (dysexecutive syndrome).\nThe notions of a central executive and dysexecutive syndrome are\noversimplified because they do not distinguish different executive\nfunctions. More recently, Baddeley added an episodic buffer that\nstores integrated information in multidimensional representations.\n•\nWorking memory: executive functions and individual\ndifferences. Individuals high in working memory capacity have\ngreater attentional control than low-capacity individuals, and so\nare more resistant to external and internal distracting information.\nThere is a lack of conceptual clarity concerning the crucial\ndifferences between high- and low-capacity individuals, and\npotential costs associated with high capacity have rarely been\ninvestigated. According to the unity/diversity framework, research\non executive functions indicates the existence of a common factor\nhowever, consolidation is associated with a reorganisation within the\nhippocampus (Dandolo & Schwabe, 2018).\n(5) How memory retrieval makes consolidated memories vulnerable and\nsusceptible to reconsolidation remains unclear (Bermúdez-Rattoni &\nMcGaugh, 2017).\n(6) It has not always been possible to replicate reconsolidation effects.\nFor example, Hardwicke et  al. (2016) conducted seven studies but\nfound no evidence of reconsolidation.\n(7) Impaired memory performance for reactivated memory traces is\ntypically explained as indicating that reconsolidation has disrupted\nstorage of the original memory traces. However, it may also reflect\nproblems with memory retrieval (Hardwicke et al., 2016).\nCreated from usyd on 2022-02-14 13:22:32.",
    "294\nMemory\nresembling concentration and two specific factors (shifting and\nupdating). Support for this framework has been obtained from the\npsychometric, neuroimaging and genetic approaches. However,\nresearch on brain-damaged patients provides only partial support\nfor the theoretical framework.\n•\nLevels of processing. Craik and Lockhart (1972) focused on\nlearning processes in their levels-of-processing theory. They\nidentified depth of processing, elaboration of processing and\ndistinctiveness of processing as key determinants of long-term\nmemory. Insufficient attention was paid to the relationship\nbetween learning processes and those at retrieval and to the\nrole of distinctive processing in enhancing long-term memory.\nThe theory is not explanatory, and the reasons why depth of\nprocessing influences explicit memory much more than implicit\nmemory remain unclear.\n•\nLearning through retrieval. Long-term memory is typically much\nbetter when much of the learning period is devoted to retrieval\npractice rather than study and the beneficial effects of retrieval\npractice extend to relevant but non-tested information. The\ntesting effect is greater when it is hard to retrieve the to-be-\nremembered information. Difficult retrieval probably enhances the\ngeneration and retrieval of effective mediators. There is a reversal\nof the testing effect when numerous items are not retrieved\nduring testing practice; this reversal is explained by the bifurcation\nmodel.\n•\nImplicit learning. Behavioural findings support the distinction\nbetween implicit and explicit learning even though most measures\nof implicit learning are relatively insensitive. The brain areas\nactivated during implicit learning (e.g., striatum) often differ from\nthose activated during explicit learning (e.g., prefrontal cortex).\nHowever, complexities arise because there are numerous forms\nof implicit learning, and learning is often a mixture of implicit and\nexplicit. Amnesic patients provide some support for the notion of\nimplicit learning because they generally have less impairment of\nimplicit than explicit learning. Parkinson’s patients with damage\nto the basal ganglia show the predicted impairment of implicit\nlearning. However, they generally also show impaired explicit\nlearning and so provide only limited information concerning the\ndistinction between implicit and explicit learning.\n•\nForgetting from long-term memory. Some forgetting from long-\nterm memory is due to a decay process operating mostly during\nsleep. Strong proactive and retroactive interference effects have\nbeen found inside and outside the laboratory. People use active\ncontrol processes to minimise proactive interference. Recovered\nCreated from usyd on 2022-02-14 13:22:32.",
    "Learning, memory and forgetting\n295\nmemories of childhood abuse are more likely to be genuine when\nrecalled outside (rather than inside) therapy. Memories can be\ndeliberately suppressed with inhibitory control processes within\nthe prefrontal cortex producing reduced hippocampal activation.\nForgetting depends in part on encoding-retrieval overlap\n(encoding specificity principle). However, retrieval is often a more\ncomplex and dynamic process than implied by this principle.\nConsolidation theory explains the form of the forgetting curve but\nde-emphasises the role of cognitive processes. Reconsolidation\ntheory explains how memories are updated and provides a\nuseful corrective to consolidation theory’s excessive emphasis on\npermanent storage. However, the complex processes involved in\nconsolidation and reconsolidation are poorly understood.\nFURTHER READING\nBaddeley, A.D., Eysenck, M.W. & Anderson, M.C. (2020). Memory (3rd edn).\nAbingdon, Oxon.: Psychology Press. The main topics covered in this chapter\nare discussed in this textbook (for example, Chapters 8–10 are on theories of\nforgetting).\nEysenck, M.W. & Groome, D. (eds) (2020). Forgetting: Explaining Memory\nFailure. London: Sage. This edited book focuses on causes of forgetting in\nnumerous laboratory and real-life situations. Chapter 1 by David Groome\nand Michael Eysenck provides an overview of factors causing forgetting and a\ndiscussion of the potential benefits of forgetting.\nFriedman, N.P. & Miyake, A. (2017). Unity and diversity of executive functions:\nIndividual differences as a window on cognitive structure. Cortex, 86, 186–204.\nNaomi Friedman and Akira Miyake provide an excellent review of our current\nunderstanding of the major executive functions.\nKarpicke, J.D. (2017). Retrieval-based learning: A decade of progress. In J. Wixted\n(ed.), Learning and Memory: A Comprehensive Reference (2nd edn; pp. 487–514).\nAmsterdam: Elsevier. Jeffrey Karpicke provides an up-to-date account of the\ntesting effect and other forms of retrieval-based learning.\nMorey, C.C. (2018). The case against specialised visual-spatial short-term memory.\nPsychological Bulletin, 144, 849–883. Candice Morey discusses a considerable\nrange of evidence apparently inconsistent with Baddeley’s working memory\nmodel (especially the visuo-spatial sketchpad).\nNorris, D. (2017). Short-term memory and long-term memory are still different.\nPsychological Bulletin, 143, 992–1009. Dennis Norris discusses much evidence\nsupporting a clear-cut separation between short-term and long-term memory.\nOberauer, K., Lewandowsky, S., Awh, E., Brown, G.D.A., Conway, A., Cowan,\nN., (2018). Benchmarks for models of short-term and working memory.\nPsychological Bulletin, 144, 885–958. This article provides an excellent account of\nthe key findings relating to short-term and working memory that would need to\nbe explained by any comprehensive theory.\nShanks, D.R. (2017). Regressive research: The pitfalls of post hoc data selection\nin the study of unconscious mental processes. Psychonomic Bulletin & Review,\n24, 752–775. David Shanks discusses problems involved in attempting to\ndemonstrate the existence of implicit learning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory\nsystems\nINTRODUCTION\nWe have an amazing variety of information stored in long-term memory\n(e.g., details of our last summer holiday; Paris is the capital of France; how\nto ride a bicycle). Much of this information is stored in schemas or organ-\nised packets of knowledge used extensively during language comprehension\n(see Chapter 10).\nThis remarkable variety is inconsistent with Atkinson and Shiffrin’s\n(1968) notion of a single long-term memory store (see Chapter 6). More\nrecently, there has been an emphasis on memory systems (note the plural!).\nEach memory system is distinct, having its own specialised brain areas\nand being involved in certain forms of learning and memory. Schacter and\nTulving (1994) identified four memory systems: episodic memory; seman-\ntic memory; the perceptual representation system; and procedural memory.\nSince then, there has been a lively debate concerning the number and\nnature of long-term memory systems.\nAmnesia\nSuggestive evidence for several long-term memory systems comes from\nbrain-damaged patients with amnesia. If you are a movie fan you may\nhave mistaken ideas about the nature of amnesia (Baxendale, 2004). In the\nmovies, serious head injuries typically cause characters to forget the past\nwhile still being fully able to engage in new learning. In the real world,\nhowever, new learning is typically greatly impaired as well.\nBizarrely, many movies suggest the best cure for amnesia caused by\nsevere head injury is to suffer another blow to the head! Approximately\n40% of Americans believe a second blow to the head can restore memory\nin patients whose amnesia was caused by a previous blow (Spiers, 2016).\nPatients become amnesic for various reasons. Closed head injury is\nthe most common cause. However, patients with closed head injury often\nhave several other cognitive impairments making it hard to interpret their\nmemory deficits. As a result, much research has focused on patients whose\namnesia is due to chronic alcohol abuse (Korsakoff’s syndrome).\nChapter\n7\nKEY TERMS\nAmnesia\nA condition caused by\nbrain damage in which\nthere is severe impairment\nof long-term memory\n(mostly declarative\nmemory).\nKorsakoff’s syndrome\nAmnesia (impaired long-\nterm memory) caused by\nchronic alcoholism.\nCase study:\nAmnesia and long-term\nmemory\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n297\nIN THE REAL WORLD: THE FAMOUS CASE OF HM\nHM (Henry Gustav Molaison) was the most-studied\namnesic patient of all time. When he was 27, his epileptic\ncondition was treated by surgery involving removal of\nhis medial temporal lobes including the hippocampus.\nThis affected his memory more dramatically than his\ngeneral  cognitive functioning (e.g., IQ). Corkin (1984,\np.  255) reported many years later that HM “does not\nknow where he lives, who cares for him, or where he ate\nhis last meal . . . in 1982 he did not recognise a picture\nof himself”.\nResearch on HM (starting with Scoville and Milner,\n1957) transformed our understanding of long-term\nmemory in several ways (see Eichenbaum, 2015):\n(1)\nScoville and Milner’s article was “the origin of\nmodern neuroscience research on memory”\n(Eichenbaum, 2015, p. 71).\n(2)\nHM showed reasonable learning and long-term\nretention on a mirror-tracing task (drawing objects\nseen only in reflection) (Corkin, 1968). He also\nshowed learning on the pursuit rotor (manual tracking of a moving target) suggesting there\nis more than one long-term memory system.\n(3)\nHM had essentially intact short-term memory supporting the important distinction between\nshort-term and long-term memory (see Chapter 6).\n(4)\nHM had generally good memory for events occurring a long time before his operation. This\nsuggests memories are not stored permanently in the hippocampus.\nResearch on HM led to an exaggerated emphasis on the role of the hippocampus in memory\n(Aggleton, 2013). His memory problems were greater than those experienced by the great majority\nof amnesic patients with hippocampal damage. This probably occurred mainly because surgery\nremoved other areas (e.g., the parahippocampal region) and possibly because the anti-epileptic\ndrugs used by HM damaged brain cells relevant to memory (Aggleton, 2013).\nThe notion that HM’s brain damage exclusively affected his long-term memory for memories\nformed after his operation is oversimplified (Eichenbaum, 2015). Evidence suggests HM had various\ndeficits in his perceptual and cognitive capacities. It also indicates he had impaired memory for\npublic and personal events occurring prior to his operation. Thus, HM’s impairments were more\nwidespread than generally assumed.\nIn sum, we need to beware of “the myth of HM” (Aly & Ranganath, 2018, p. 1), which consists of\ntwo mistaken assumptions. First, while the hippocampus and medial temporal lobe are important\nin episodic memory (memory for personal events), episodic memory depends on a network that\nincludes several other brain regions. For example, Vidal-Piñeiro et al. (2018) found that long-lasting\nepisodic memories were associated with greater activation at encoding in inferior lateral parietal\nregions as well as the hippocampus.\nSecond, the role of the hippocampus is not limited to memory. It also includes “other\nfunctions,  such as perception, working memory, and implicit memory [memory not involving\nconscious  recollection]” (Aly & Ranganath, 2018, p. 1). This issue is discussed later (see pp. 332–336).\nHenry Molaison, the most famous amnesic\npatient of all time. Research on him\ntransformed our knowledge of the workings\nof long-term memory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "298\nMemory\nKorsakoff patients are said to suffer from the “amnesic syndrome”:\n●\nanterograde amnesia: a marked impairment in the ability to learn and\nremember information encountered after the onset of amnesia;\n●\nretrograde amnesia: problems in remembering events prior to amnesia\nonset (see Chapter 6);\n●\nonly slightly impaired short-term memory on measures such as digit\nspan (repeating back a random string of digits);\n●\nsome remaining learning ability (e.g., motor skills).\nThe relationship between anterograde and retrograde amnesia is typically\nstrong. Smith et al. (2013) obtained a correlation of +.81 between the two\nforms of amnesia in patients with damage to the medial temporal lobes.\nHowever, new learning is more easily disrupted by limited brain damage\nwithin the medial temporal lobes than is memory for previously acquired\ninformation. This probably occurs because there has typically been consol-\nidation (see Glossary) of previously acquired information prior to amnesia\nonset.\nFurther evidence the brain areas (and processes) underlying the two\nforms of amnesia differ was provided by Buckley and Mitchell (2016).\nDamage to the retrosplenial cortex (connected to the hippocampus) caused\nretrograde amnesia but not anterograde amnesia.\nThere are problems with using Korsakoff patients. First, amnesia typi-\ncally has a gradual onset caused by an increasing deficiency of the vitamin\nthiamine. Thus, it is often unclear whether certain past events occurred\nbefore or after amnesia onset.\nSecond, brain damage in Korsakoff patients typically involves the\nmedial temporal lobes (especially the hippocampus; see Figure 7.1).\nHowever, there is often damage to the frontal lobes as well producing\nvarious cognitive deficits (e.g., impaired cognitive control). This compli-\ncates interpreting findings from these patients.\nThird, the precise area of brain damage (and thus the pattern of\nmemory impairment) varies across patients. For example, some Korsakoff\npatients exhibit confusion, lethargy and inattention.\nKEY TERM\nAnterograde amnesia\nReduced capacity for new\nlearning (and subsequent\nremembering) after the\nonset of amnesia.\nFigure 7.1\nDamage to brain areas\nwithin and close to the\nmedial temporal lobes\n(indicated by asterisks)\nproducing amnesia.\nRepublished with permission of\nRoutledge Publishing Inc.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n299\nFourth, research on Korsakoff patients does not provide direct evi-\ndence concerning the impact of brain damage on long-term memory. Brain\nplasticity and learning of compensatory strategies mean patients can grad-\nually alleviate some memory problems (Fama et al., 2012).\nIn sum, the study of amnesic patients has triggered several theoret-\nical developments. For example, the distinction between declarative and\nnon-declarative memory (see below) was originally proposed in part\nbecause of findings from amnesic patients.\nDeclarative vs non-declarative memory\nHistorically, the most important distinction between different types of\nlong-term memory was between declarative memory and non- declarative\nmemory (Squire & Dede, 2015). Declarative memory involves conscious\nrecollection of events and facts – it often refers to memories that can be\n“declared” or described but also includes memories that cannot be described\nverbally. Declarative memory is sometimes referred to as explicit memory\nand involves knowing that something is the case.\nThe two main forms of declarative memory are episodic and seman-\ntic memory. Episodic memory is concerned with personal experiences of\nevents that occurred in a given place at a specific time. Semantic memory\nconsists of general knowledge about the world, concepts, language and\nso on.\nIn contrast, non-declarative memory does not involve conscious recol-\nlection. We typically obtain evidence of non-declarative memory by observ-\ning changes in behaviour. For example, consider someone learning to ride a\nbicycle. Their cycling ability improves over time even though they cannot\nconsciously recollect what they have learned. Non-declarative memory is\nsometimes known as implicit memory.\nThere are various forms of non-declarative or implicit memory. One\nis memory for skills (e.g., piano playing; bicycle riding). Such memory\ninvolves knowing how to perform certain actions and is known as proce-\ndural memory. Another form of non-declarative memory is priming (also\nknown as repetition priming): it involves facilitated processing of a stimu-\nlus presented recently (Squire & Dede, 2015, p. 7). For example, it is easier\nto identify a picture as a cat if a similar picture of a cat has been presented\npreviously. The earlier picture is a prime facilitating processing when the\nsecond cat picture is presented.\nAmnesic patients find it much harder to form and remember declara-\ntive than non-declarative memories. For example, HM (discussed above)\nhad extremely poor declarative memory for personal events occurring\nafter his operation and for faces of those who became famous in recent\ndecades. In stark contrast, he had reasonable learning ability and memory\nfor non-declarative tasks (e.g., mirror tracing; the pursuit rotor; perceptual\nidentification aided by priming).\nThis chapter contains detailed discussion of declarative and non-\ndeclarative memory. Figure 7.2 presents the hugely influential traditional\ntheoretical account, which strongly influenced most of the research dis-\ncussed in this chapter. However, it is oversimplified. At the end of this\nchapter, we discuss its limitations and possible new theoretical developments\nKEY TERMS\nDeclarative memory\nA form of long-term\nmemory that involves\nknowing something\nis the case; it involves\nconscious recollection\nand includes memory for\nfacts (semantic memory)\nand events (episodic\nmemory); sometimes\nknown as explicit memory.\nNon-declarative memory\nForms of long-term\nmemory that influence\nbehaviour but do not\ninvolve conscious\nrecollection (e.g., priming;\nprocedural memory); also\nknown as implicit memory.\nProcedural memory\nThis is memory concerned\nwith knowing how and it\nincludes the knowledge\nrequired to perform\nskilled actions.\nPriming\nFacilitating the processing\nof (and response) to\na target stimulus by\npresenting a stimulus\nrelated to it shortly\nbeforehand.\nRepetition priming\nThe finding that\nprocessing of a stimulus\nis facilitated if it has been\nprocessed previously.\nCreated from usyd on 2022-02-14 13:22:32.",
    "300\nMemory\nin the section entitled “Beyond memory systems and declarative vs non-\ndeclarative memory” (pp. 332–340).\nDECLARATIVE MEMORY\nDeclarative or explicit memory encompasses numerous different kinds\nof memories. For example, we remember what we had for breakfast this\nmorning and that “le petit déjeuner” is French for “breakfast”. Tulving\n(1972) argued the crucial distinction within declarative memory was\nbetween what he termed “episodic memory” and “semantic memory” (see\nEysenck & Groome, 2015b).\nWhat is episodic memory? According to Tulving (2002, p. 5), “It makes\npossible mental time travel through subjective time from the present to the\npast, thus allowing one to re-experience . . . one’s own previous experiences.”\nNairne (2015b) identified the three “Ws” of episodic memory: remembering\na specific event (what) at a given time (when) in a particular place (where).\nWhat is semantic memory? It is “an individual’s store of knowledge\nabout the world. The content of semantic memory is abstracted from actual\nexperience and is therefore said to be conceptual, that is, generalised and\nwithout reference to any specific experience” (Binder & Desai, 2011, p. 527).\nWhat is the relationship between episodic memory and autobiograph-\nical memory (discussed in Chapter 8)? Both are concerned with personal\npast experiences. However, much information in episodic memory is trivial\nFigure 7.2\nThe traditional theoretical account based on dividing long-term memory into two broad classes: declarative and non-\ndeclarative. Declarative memory is divided into episodic and semantic memory, whereas non-declarative memory\nis divided into procedural memory, priming, simple classical conditioning, and habituation and sensitisation. The\nassumption that there are several forms of long-term memory is accompanied by the further assumption that different\nbrain regions are associated with each one.\nFrom Henke (2010). Reprinted with permission from Nature Publishing Group.\nKEY TERMS\nEpisodic memory\nA form of long-term\nmemory concerned with\npersonal experiences or\nepisodes occurring in a\ngiven place at a specific\ntime.\nSemantic memory\nA form of long-term\nmemory consisting of\ngeneral knowledge about\nthe world, concepts,\nlanguage and so on.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n301\nand is remembered only briefly. In contrast, autobiographical memory typ-\nically stores information for long periods of time about personally signifi-\ncant events and experiences.\nWhat is the relationship between episodic and semantic memory?\nAccording to Tulving (2002), episodic memory developed out of semantic\nmemory during the course of evolution. It also develops later in childhood\nthan semantic memory.\nEpisodic vs semantic memory\nIf episodic and semantic memory form separate memory systems, they\nshould differ in several ways. Consider the ability of amnesic patients to\nacquire new episodic and semantic memories. Spiers et al. (2001) reviewed\n147 cases of amnesia involving damage to the hippocampus or fornix.\nEpisodic memory was impaired in all cases, whereas many patients had rel-\natively small impairment of semantic memory.\nThe above difference in the impact of hippocampal brain damage sug-\ngests episodic and semantic memory are distinctly different. However, the\ngreater vulnerability of episodic memories than semantic ones may occur\nmainly because episodic memories are formed from a single experience\nwhereas semantic memories often combine several learning opportunities.\nWe would have stronger evidence if we discovered brain-damaged\npatients with very poor episodic memory but essentially intact semantic\nmemory. Elward and Vargha-Khadem (2018) reviewed research on patients\nwith developmental amnesia (amnesia due to hippocampal damage at a\nyoung age). These patients, “typically show relatively preserved semantic\nmemory and factual knowledge about the natural world despite severe\nimpairments in episodic memory” (p. 23).\nVargha-Khadem et  al. (1997) studied two patients (Beth and Jon)\nwith developmental amnesia. Both had very poor episodic memory for\nthe day’s activities and television programmes, but their semantic memory\n(language development; literacy; and factual knowledge) were within the\nnormal range. However, Jon had various problems with semantic memory\n(Gardiner et al., 2008). His rate of learning was slower than that of healthy\ncontrols when provided with facts concerning geographical, historical and\nother kinds of knowledge. Similarly slow learning in semantic memory\nhas been found in most patients with developmental amnesia (Elward &\nVargha-Khadem, 2018).\nThe findings from patients with developmental amnesia are surpris-\ning given the typical finding that individuals with an intact hippocampus\ndepend on it for semantic memory acquisition (Baddeley et  al., 2020).\nWhy, then, is their semantic memory reasonably intact? Two answers have\nbeen proposed. First, developmental amnesics typically devote more time\nthan healthy individuals to repeated study of factual information. This\nmay produce durable long-term semantic memories via a process of con-\nsolidation (see Glossary and Chapter 6).\nSecond, episodic memory may depend on the hippocampus whereas\nsemantic memory depends on the underlying entorhinal, perirhinal and\nparahippocampal cortices. Note the brain damage suffered by Jon and Beth\ncentred on the hippocampus. Bindschaedler et al. (2011) studied a boy (VI)\nCreated from usyd on 2022-02-14 13:22:32.",
    "302\nMemory\nwith severe hippocampal damage but relatively preserved  perirhinal and\nentorhinal cortex. His performance on semantic memory tasks (e.g., vocabu-\nlary) improved at the normal rate even though his performance was very poor\non episodic memory tasks. Many amnesics may have severe problems with\nepisodic and semantic memory because the hippocampus and underlying cor-\ntices are both damaged. This is very likely given the two areas are adjacent.\nCurot et  al. (2017) applied electrical brain stimulation to memory-\nrelated brain areas to elicit reminiscences. Semantic memories were mostly\nelicited by stimulation of the rhinal cortex (including the entorhinal and\nperirhinal cortices). In contrast, episodic memories were only elicited by\nstimulation of the hippocampal region.\nBlumenthal et  al. (2017) studied a female amnesic (HC) with severe\nhippocampal damage but intact perirhinal and entorhinal cortices. She was\ngiven the semantic memory task of generating intrinsic features of objects\n(e.g., shape; colour) and extrinsic features (e.g., how the object is used).\nHC performed comparably to controls with intrinsic features but signifi-\ncantly worse than controls with extrinsic features. Thus, the hippocampus\nis important for learning some aspects of semantic memory.\nHow can we explain Blumenthal et  al.’s (2017) findings? The hip-\npocampus is involved in learning associations between objects and contexts\nin episodic memory (see final section of the chapter, pp. 332–340). In a\nsimilar fashion, generating extrinsic features of objects requires learning\nassociations between objects and their uses.\nRetrograde amnesia\nWe turn now to amnesic patients’ problems with remembering information\nlearned prior to the onset of amnesia: retrograde amnesia (see Glossary and\nChapter 6). Many amnesic patients have much greater retrograde amnesia\nfor episodic than semantic memories. Consider the amnesic patient KC.\nAccording to Tulving (2002, p. 13), “He cannot recollect any personally\nexperienced events . . ., whereas his semantic knowledge [e.g. general world\nknowledge] acquired before the critical accident is still reasonably intact.”\nThere is much support for the notion that remote semantic memories\nformed prior to the onset of amnesia are essentially intact (see Chapter 6).\nFor example, amnesic patients often perform comparably to healthy\ncontrols on semantic memory tasks (e.g., vocabulary knowledge; object\nnaming). However, Klooster and Duff (2015) argued such findings may\nreflect the use of insensitive measures. In their study, Klooster and Duff\ngave amnesic patients the semantic memory task of listing features of\ncommon objects. On average, amnesic patients listed only 50% as many\nfeatures as healthy controls.\nRetrograde amnesia for episodic memories in amnesic patients often\nspans several years and has a temporal gradient, i.e., older memories\nshowing less impairment (Bayley et  al., 2006). In contrast, retrograde\namnesia for semantic memories is generally small except for knowledge\nacquired shortly before amnesia onset (Manns et al., 2003).\nIn sum, retrograde amnesia is typically greater for episodic than seman-\ntic memories. However, semantic memories can be subject to  retrograde\namnesia when assessed using sensitive measures.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n303\nSemantic dementia\nPatients with semantic dementia have severe loss of concept knowledge\nfrom semantic memory. However, their episodic memory and most cog-\nnitive functions (e.g., attention; non-verbal problem solving) are reasona-\nbly intact initially. Semantic dementia always involves degeneration of the\nanterior temporal lobes. Areas such as the perirhinal and entorhinal cortex\nare probably involved in the formation of semantic memories. In contrast,\nthe anterior temporal lobes are where such memories are stored semi-\npermanently. However, episodic memory and executive functioning are\nreasonably intact in the early stages.\nPatients with semantic dementia have great problems accessing infor-\nmation about concepts stored in semantic memory (Lambon Ralph et al.,\n2017). However, their performance on many episodic memory tasks is\ngood (e.g., they have intact ability to reproduce complex visual designs:\nIrish et al., 2016). They also have comparable performance to healthy con-\ntrols in remembering what tasks they performed 24 hours earlier and where\nthose tasks were performed (Adlam et al., 2009).\nLandin-Romero et al. (2016) reviewed relevant research. The good epi-\nsodic memory of semantic dementia patients probably occurs because they\nmake effective use of the frontal and parietal regions within the brain.\nIn sum, we have an apparent double dissociation (see Glossary).\nAmnesic patients have very poor episodic memory but often reasonably\nintact semantic memory. In contrast, patients with semantic dementia\nhave very poor semantic memory but reasonably intact episodic memory.\nHowever, the double dissociation is only approximate and it is hard to\ninterpret the somewhat complex findings.\nInterdependence of episodic and semantic memory\nWe have seen the assumption that there are separate episodic and semantic\nmemory systems is oversimplified. Here we focus on the interdependence of\nepisodic and semantic memory. In a study by Renoult et al. (2016), partic-\nipants answered questions belonging to four categories: (1) unique events\n(e.g., “Did you drink coffee this morning?”); (2) general factual knowledge\n(e.g., “Do many people drink coffee?”); (3) autobiographical facts (e.g., “Do\nyou drink coffee every day?”); and (4) repeated personal events (e.g., “Have\nyou drunk coffee while shopping?”). Category 1 involves episodic memory\nand category 2 involves semantic memory. Categories 3 and 4 involve per-\nsonal semantic memory (a combination of episodic and semantic memory).\nRenoult et al. (2016) used event-related potentials (ERPs; see Glossary)\nduring retrieval for all four question categories. There were clear-cut ERP\ndifferences between categories 1 and 2. Of most importance, ERP patterns\nfor category 3 and 4 questions were intermediate between those for cate-\ngories 1 and 2 suggesting they required retrieval from both episodic and\nsemantic memory.\nTanguay et  al. (2018) reported similar findings. They interpreted the\nvarious findings with reference to personal semantics: aspects of autobi-\nographical memory resembling semantic memory in being factual but also\nresembling episodic memory in being “idiosyncratically personal” (p. 65).\nKEY TERMS\nSemantic dementia\nA condition involving\ndamage to the anterior\ntemporal lobes involving\nwidespread loss of\ninformation about the\nmeanings of words and\nconcepts; however,\nepisodic memory and\nexecutive functioning are\nreasonably intact initially.\nPersonal semantics\nAspects of one’s personal\nor autobiographical\nmemory that combine\nelements of episodic\nmemory and semantic\nmemory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "304\nMemory\nGreenberg et al. (2009) showed episodic and semantic memory can be\ninterdependent. Amnesic patients and healthy controls generated as many\nmembers as possible from various categories. Some categories (e.g., kitchen\nutensils) were selected so that performance would benefit from using epi-\nsodic memory, whereas other categories (e.g., things typically red) seemed\nless likely to involve episodic memory. Amnesic patients performed worse\nthan controls especially with categories potentially benefitting from epi-\nsodic memory. With those categories, controls were much more likely than\npatients to use episodic memory as an efficient organisational strategy to\ngenerate category members.\nSemanticisation of episodic memory\nRobin and Moscovitch (2017) argued initially episodic memories are trans-\nformed into semantic memories over time. For example, the first time you\nwent to a seaside resort, you formed episodic memories of your experiences\nthere. As an adult, while you still remember visiting that seaside resort as\na child, you have probably forgotten the personal and contextual informa-\ntion originally associated with your childhood memories. Thus, what was\nan episodic memory has become a semantic memory. This change involves\nsemanticisation of episodic memory and suggests episodic and semantic\nmemories are related.\nRobin and Moscovitch (2017) argued the process of semanticisation\noften involves a memory transformation from an initially detail-rich epi-\nsodic representation to a gist-like or schematic representation involving\nsemantic memory. They provided a theoretical framework within which to\nunderstand these processes (see Figure 7.3).\nThere is much support for this theoretical approach (discussed later).\nFor example, Gilboa and Marlatte (2017) found in a meta-analytic review\nthat the ventromedial prefrontal cortex is typically involved in schema pro-\ncessing within semantic memory.\nSekeres et al. (2016) tested memory for movie clips. There was much\nmore forgetting of peripheral detail over time (episodic memory) than of\nthe gist (semantic memory). St-Laurent et al. (2016) found amnesic patients\nwith hippocampal damage had reduced processing of episodic perceptual\ndetails.\nRobin and Moscovitch (2017) discussed research focusing on changes\nin brain activation during recall as time since learning increased. As pre-\ndicted, there was reduced anterior hippocampal activation but increased\nactivation in the ventromedial prefrontal cortex. These findings reflected\nincreased use of gist or schematic information compensating for reduced\navailability of details.\nOverall evaluation\nThere is some support for separate episodic and semantic memory systems\nin the double dissociation involving amnesia and semantic dementia: the\nformer is associated with greater impairment of episodic than seman-\ntic memory whereas the latter is associated with the opposite pattern.\nHowever, there are complications in interpreting these findings and the\nKEY TERM\nSemanticisation\nThe phenomenon of\nepisodic memories\nchanging into semantic\nmemories over time.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n305\ndouble dissociation is only approximate. In addition, episodic and semantic\nmemory are often interdependent at learning and during retrieval, making\nit hard to disentangle their respective contributions.\nEPISODIC MEMORY\nHow can we assess someone’s episodic memory following learning (e.g., a\nlist of to-be-remembered items)? Recognition and recall are the two main\ntypes of episodic memory test. Recognition-memory tests generally involve\npresenting various items with participants deciding whether each one was\npresented previously (often 50% were presented previously and 50% were\nnot). As we will see, more complex forms of recognition-memory test have\nalso been used.\nThere are three types of recall test: free recall, serial recall and cued recall.\nFree recall involves producing previously presented items in any order in\nthe absence of specific cues. Serial recall involves producing previously pre-\nsented items in the order they were presented. Cued recall involves produc-\ning previously presented items to relevant cues. For example, “cat–table”\nmight be presented at learning and the cue, “cat–???” at test.\nKEY TERMS\nFree recall\nA test of episodic\nmemory in which\npreviously presented\nto-be-remembered items\nare recalled in any order.\nSerial recall\nA test of episodic memory\nin which previously\npresented to-be-\nremembered items must\nbe recalled in the order of\npresentation.\nCued recall\nA test of episodic\nmemory in which\npreviously presented\nto-be-remembered items\nare recalled in response\nto relevant cues.\nFigure 7.3\nEpisodic memories (involving perceptual representations and specific details) depend\non the posterior hippocampus (pHPC); semantic memories (involving schemas)\ndepend on the ventromedial prefrontal cortex (vmPFC); and gist memories (combining\nepisodic and semantic memory) depend on the anterior hippocampus (aHPC). There are\ninteractions between these forms of memory caused by processes such as construction\nand elaboration.\nFrom Robin and Moscovitch (2017). Reprinted with permission of Elsevier.\nParticular, detailed cues:\nParticular, coarse cues:\nGeneric cues:\nCake at\n10th\nbirthday\nparty\nPosterior\nneocortex\nPerceptual\nrepresentations\npHPC\nDetails\naHPC\nGist\nCONSTRUCTION\nELABORATION\nELABORATION\nvmPFC\nSchema /\nmonitoring\n10th\nbirthday\nparty\nMom’s\nhouse\nParty\nHouse\nWEAK ELABORATION\nCreated from usyd on 2022-02-14 13:22:32.",
    "306\nMemory\nRecognition memory: familiarity and recollection\nRecognition memory can involve recollection or familiarity. Recollection\ninvolves recognition based on conscious retrieval of contextual information\nwhereas such conscious retrieval is lacking in familiarity-based recognition\n(Brandt et al., 2016). Here is a concrete example. Several years ago, the first\nauthor walked past a man in Wimbledon, and was immediately confident\nhe recognised him. However, he simply could not think where he had previ-\nously seen the man. After some thought (this is the kind of thing academic\npsychologists think about!), he realised the man was a ticket-office clerk at\nWimbledon railway station. Initial recognition based on familiarity was\nreplaced by recognition based on recollection.\nThe remember/know procedure (Migo et  al., 2012) has often been\nused to assess familiarity and recollection. List learning is followed by\na test where participants indicate whether each item is “Old” or “New”.\nItems identified as “Old” are followed by a know or remember judgement.\nTypical instructions require participants to respond know if they recognise\nthe list words, “but these words fail to evoke any specific conscious recol-\nlection from the study list” (Rajaram, 1993, p. 102). They should respond\nremember if “the ‘remembered’ word brings back to mind a particular\nassociation, image, or something more personal from the time of study”\n(Rajaram, 1993, p. 102).\nDunn (2008) proposed a single-process account: strong memory traces\ngive rise to recollection judgements whereas weak memory traces give rise\nto familiarity judgements. As we will see, however, most evidence supports\na dual- or two-process account, namely, that recollection and familiarity\ninvolve different processes.\nBrain mechanisms\nDiana et al. (2007) provided an influential theoretical account of the key\nbrain areas involved in recognition memory in their binding-of-item-and-\ncontext model (see Figure 7.4):\n(1) The perirhinal cortex receives information about specific items (what\ninformation needed for familiarity judgements).\n(2) The parahippocampal cortex receives information about context\n(where information useful for recollection judgements).\n(3) The hippocampus receives what and where information (both of great\nimportance to episodic memory) and binds them to form item–context\nassociations permitting recollection.\nFindings\nFunctional neuroimaging studies support the above model. In a meta-\nanalytic review, Diana et  al. (2007) found recollection was associated\nwith more activation in parahippocampal cortex and the hippocampus\nthan perirhinal cortex. In contrast, familiarity was associated with more\nactivation in perirhinal cortex than the parahippocampal cortex or\nhippocampus.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n307\nNeuroimaging evidence is correlational and so cannot show the hip-\npocampus is more essential to recollection than familiarity. In principle,\nmore direct evidence could be obtained from brain-damaged patients.\nBowles et  al. (2010) studied amnesic patients with severe hippocampal\ndamage. As predicted, these patients had significantly impaired recollection\nbut not familiarity. However, other research has typically found amnesic\npatients with medial temporal lobe damage have a minor impairment in\nfamiliarity but a much larger one in recollection (Skinner & Femandes,\n2007).\nAccording to the model, patients with damage to the perirhinal cortex\nshould have largely intact recollection but impaired familiarity. Bowles\net al. (2011) tested this prediction with a female patient, NB. As predicted,\nher recollection performance was consistently intact. However, she had\nimpaired familiarity for verbal materials. Brandt et  al. (2016) studied a\nfemale patient, MR, with selective damage to entorhinal cortex (adjacent\nto perirhinal cortex and previously linked to familiarity). As predicted,\nMR had impaired familiarity for words but intact recollection.\nFigure 7.4\n(a) Locations of the\nhippocampus (red), the\nperirhinal cortex (blue) and\nthe parahippocampal cortex\n(green); (b) the binding-of-\nitem-and-context model.\nFrom Diana et al. (2007).\nReprinted with permission of\nOxford University Press.\nCreated from usyd on 2022-02-14 13:22:32.",
    "308\nMemory\nAccording to the original model, the parahippocampal cortex is limited\nto processing spatial context (i.e., where information). This is too limited.\nDiana (2017) used a non-spatial context – words were accompanied by\ncontextual questions (e.g., “Is this word common or uncommon?”). There\nwas greater parahippocampal activation for words associated with correct\n(rather than incorrect) context memory. Since the context (i.e., contextual\nquestions) was non-spatial, the role of the parahippocampal cortex in epi-\nsodic memory extends beyond spatial information.\nDual-process models assume the hippocampus is required to process\nrelationships between items and to bind items to contexts but is not\nrequired to process items in isolation. There are two potential problems\nwith these assumptions (Bird, 2017). First, the term “item” is often impre-\ncisely defined. Second, these models often de-emphasise the importance of\nthe learning material (e.g., faces; names; pictures).\nSmith et  al. (2014) compared immediate memory performance in\nhealthy controls and amnesic patients with hippocampal damage. Fifty\nfamous faces were presented followed by a recognition-memory test.\nThe amnesic patients performed comparably to controls for famous\nfaces not identified as famous but were significantly impaired for famous\nfaces  identified as famous. A plausible interpretation is that unfamiliar\nfaces (i.e., unknown famous faces) are processed as isolated items and\nso do not  require hippocampal processing. In contrast, known famous\nfaces benefit from additional contextual processing dependent on the\nhippocampus.\nBird (2017, p. 161) concluded his research review as follows: “There\nare no clear-cut examples of materials other than [unfamiliar] faces\nthat can be  recognised using extrahippocampal [outside the hippocam-\npus]  familiarity processes.” This is because most “items” are not pro-\ncessed in isolation but require the integrative processing provided by the\nhippocampus.\nScalici et  al. (2017) reviewed research on the involvement of the\nprefrontal cortex in familiarity and recollection. There was greater\nfamiliarity-based than recollection-based activity in the ventromedial and\ndorsomedial prefrontal cortex and lateral BA10 (at the front of the pre-\nfrontal cortex) whereas the opposite was the case in medial BA10 (see\nFigure 7.5). These findings suggest familiarity and recollection involve dif-\nferent processes.\nEvaluation\nRecognition memory depends on rather separate processes of familiar-\nity and recollection, as indicated by neuroimaging studies. However, the\nmost convincing findings come from studying brain-damaged patients. A\ndouble dissociation has been obtained – some patients have reasonably\nintact familiarity but impaired recollection whereas a few patients exhibit\nthe opposite pattern.\nWhat are the limitations of theory and research in this area?\n(1) The typical emphasis on recollection based on conscious aware-\nness of contextual details is oversimplified because we can also have\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n309\nconscious awareness of having previously seen the target items them-\nselves. Brainerd et  al. (2014) found a model assuming two types of\nrecollection predicted behavioural data better than models assuming\nonly one type of recollection.\n(2) Diana et al.’s (2007) model does not identify the processes  underlying\nfamiliarity judgements. However, it is often assumed that items on\na recognition-memory test that are easy to process are judged to be\nfamiliar. Geurten and Willems (2017) tested this assumption using\nunfamiliar pictures. On the recognition-memory test, some pictures\nwere presented with reduced contrast to reduce processing fluency (see\nFigure 7.6). As predicted, recognition-memory performance was better\nwith high- contrast than with low-contrast test pictures (70% vs 59%,\nrespectively).\nFigure 7.5\nLeft lateral (A), medial (B)\nand anterior (C) views of\nprefrontal areas having\ngreater activation to\nfamiliarity-based than\nrecollection-based\nprocesses (in red) and\nareas showing the opposite\npattern (in blue).\nFrom Scalici et al. (2017).\nReprinted with permission of\nElsevier.\nFigure 7.6\nSample pictures on the\nrecognition-memory test.\nThe one on the left is\nhigh-contrast and easy to\nprocess whereas the one on\nthe right is low-contrast and\nhard to process.\nFrom Geurten & Willems (2017).\nReprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "310\nMemory\n(3) More brain mechanisms are involved in recognition memory than\nassumed by Diana et al. (2007).\n(4) The notion of an “item” requires more precise definition (Bird, 2017).\nRecall memory\nHere we will consider briefly similarities and differences between recall\n(especially free recall: see Glossary) and recognition memory. Mickes et al.\n(2013) reported important similarities using the remember/know proce-\ndure with free recall. Participants received a word list and for each word\nanswered one question (e.g., “Is this item animate?”; “Is this item bigger\nthan a shoebox?”). They then recalled the words, made a remember or know\njudgement for each recalled word and indicated which question had been\nassociated with each word (contextual information).\nParticipants were more accurate at remembering which question was\nassociated with recalled words when the words received remember (rather\nthan know) judgements. This is very similar to recognition memory where\nparticipants access more contextual information for remember words than\nknow ones.\nKragel and Polyn (2016) compared patterns of brain activation during\nrecognition-memory and free-recall tasks. Brain areas activated during\nfamiliarity processes in recognition memory were also activated during free\nrecall. There was also weaker evidence that brain areas activated during\nrecollective processes in recognition were activated in free recall.\nAs we have seen, amnesic patients exhibit very poor recognition memory\n(especially recognition associated with recollection). Amnesic patients also\ntypically have very poor free recall (e.g., Brooks & Baddeley, 1976).\nSome aspects of recognition memory depend on structures other than\nthe hippocampus itself (Diana et  al., 2007). In contrast, it has typically\nbeen assumed the hippocampus is crucial for recall memory. Patal et  al.\n(2015) supported these assumptions in patients with relatively selective hip-\npocampal damage. The extent of hippocampal damage in these patients\nwas negatively correlated with their recall performance but uncorrelated\nwith their recognition-memory performance.\nThere are several similarities between the processes involved in recall\nand recognition. However, the to-be-remembered information is physically\npresent on recognition tests but not recall tests. As a result, processing\ndemands should generally be less with recognition. Chan et  al. (2017)\nobtained findings consistent with this analysis in patients with damage to\nthe frontal lobes impairing higher-level cognitive processes. Individual dif-\nferences in intelligence were strongly related to performance on recall tests\nbut not recognition-memory tests. Thus, recall performance depends much\nmore on higher-level cognitive processes.\nIs episodic memory constructive?\nWe use episodic memory to remember experienced past events. Most\npeople believe the episodic memory system resembles a video recorder pro-\nviding us with accurate and detailed information about past events (Simons\n& Chabris, 2011). In fact, “Episodic memory is . . . a fundamentally\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n311\nconstructive, rather than reproductive process that is prone to various kinds\nof errors and illusions” (Schacter & Addis, 2007, p. 773). For example, the\nconstructive nature of episodic memory leads to distorted remembering of\nstories (Chapter 10) and to eyewitnesses producing inaccurate memories of\ncrimes (Chapter 8).\nWhy is episodic memory so error-prone? First, it would require\nmassive processing to produce a semi-permanent record of all our experi-\nences. Second, we typically want to access the gist or essence of our past\nexperiences, omitting trivial details. Third, we often enrich our episodic\nmemories when discussing our experiences with friends even when this pro-\nduces memory errors (Dudai & Edelson, 2016; see Chapter 8).\nWhat are the functions of episodic memory (other than to remember\npast events)? First, we use episodic memory to imagine possible future sce-\nnarios and to plan the future (Madore et al., 2016). Imagining the future\n(episodic simulation) is greatly facilitated by episodic memory’s flexible and\nconstructive nature. According to Addis (2018), remembered and imagined\nevents are both very similar, “simulations of experience from the same\npool of experiential details” (p. 69). However, Schacter and Addis (2007)\nassumed in their constructive episodic simulation hypothesis that episodic\nsimulation is more demanding than episodic memory retrieval because\ncontrol processes are required to combine details from multiple episodes.\nSecond, Madore et al. (2019) found episodic memory influences diver-\ngent creative thinking (thinking of unusual and creative uses for common\nobjects). Creative thinking was associated with enhanced connectivity\nbetween brain areas linked to episodic processing and brain areas associ-\nated with cognitive control.\nFindings\nThe tendency to recall the gist of our previous experiences increases\nthroughout childhood (Brainerd et al., 2008). More surprisingly, children’s\ngreater focus on remembering gist as they become older often increases\nmemory errors. Brainerd and Mojardin (1998) asked children to listen to\nsentences such as “The tea is hotter than the cocoa”. Subsequently, they\ndecided whether test sentences had been presented previously in precisely\nthat form. Sentences having the same meaning as an original sentence but\ndifferent wording (e.g., “The cocoa is cooler than the tea”) were more likely\nto be falsely recognised by older children.\nWe turn now to the hypothesis (Schacter & Addis, 2007; Addis,\n2018) that imagining future events involves very similar processes to those\ninvolved in remembering past episodic events. On that hypothesis, brain\nareas important for episodic memory (e.g., the hippocampus) should also\nbe activated when imagining future events. Benoit and Schacter (2015)\nreported supportive evidence. There were two key findings:\n(1) Several brain regions were activated both while imagining future\nevents (episodic simulation) and during episodic-memory recollection\n(see Figure 7.7A). The overlapping areas included “the hippocam-\npus and parahippocampal cortex within the medial temporal lobes”\n(Benoit & Schacter, 2015, p. 450).\nCreated from usyd on 2022-02-14 13:22:32.",
    "312\nMemory\n(2)  As predicted, several brain areas were more\nstrongly activated during episodic simulation\nthan episodic memory retrieval (see Figure\n7.7B). These included clusters in the dorso-\nlateral prefrontal cortex and posterior infe-\nrior parietal lobes and clusters in the right\nmedial temporal lobe (including the hip-\npocampus) (Benoit & Schacter, 2015, p. 453).\nSome of these areas are involved in cognitive\ncontrol – the borders of the fronto-parietal\ncontrol network (see Chapter 6) are indicated\nby white dashed lines.\nImagining future events is generally associated\nwith hippocampal activation. We would have\nmore direct evidence the hippocampus is nec-\nessarily involved if amnesic patients with hip-\npocampal damage had impaired ability to imagine\nfuture events. Hassabis et al. (2007) found amne-\nsics’ imaginary experiences consisted of iso-\nlated fragments lacking the richness and spatial\ncoherence of healthy controls’ experiences. The\namnesic patient KC with extensive brain damage\n(including to the hippocampus) could not recall a\nsingle episodic memory from the past or imagine\na possible future event (Schacter & Madore,\n2016).\nRobin (2018) argued that spatial context is\nof major importance for both episodic memory\nand imagining future events. For example, Robin\net al. (2016) asked participants to read brief nar-\nratives and imagine them in detail. Even when\nno spatial context was specified in the narrative,\nparticipants nevertheless generated an appropri-\nate spatial context while imagining on 78% of\ntrials.\nThe similarities between recall of past\npersonal  events and imagining future personal\nevents have typically been attributed to episodic\nprocesses common to both tasks. However, some similarities may also\nreflect non-episodic processes. For example, amnesics’ impaired past recall\nand future imagining may reflect an impaired ability to construct detailed\nnarrative. Schacter and Madore (2016) provided convincing evidence\nthat episodic processes are involved in recalling past events and imagin-\ning future ones. Participants received training in recollecting details of a\nrecent experience. If recall of past events and imaging of future events\nboth rely on episodic memory, this induction should benefit performance\nby increasing participants’ production of episodic details in recall and\nimagination. That is what was found.\nFigure 7.7\n(A) Areas activated for both episodic simulation and\nepisodic memory; (B) areas activated more for episodic\nsimulation than episodic memory.\nFrom Benoit and Schacter (2015). Reprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n313\nEvaluation\nIt is assumed episodic memory relies heavily on constructive processes.\nThis assumption is supported by research on eyewitness memory (Chapter\n8) and language comprehension (Chapter 10). The additional assumption\nthat constructive processes used in episodic memory retrieval of past events\nare also involved in imagining future events is an exciting development sup-\nported by much relevant evidence. Episodic memory is also involved in\ndivergent creative thinking.\nWhat are the main limitations of research in this area? First, several\nbrain areas associated with recalling past personal events and imagining\nfuture events have been identified, but their specific contributions remain\nsomewhat unclear. Second, finding a given area is involved in recalling the\npast and imagining the future does not necessarily mean it is associated\nwith the same cognitive processes in both cases. Third, there is greater\nuncertainty about future events than past ones. This may explain why\nimagined future events are less vivid than recalled past events but more\nabstract and dependent on semantic memory (MacLeod, 2016).\nSEMANTIC MEMORY\nOur organised general knowledge about the world is stored in semantic\nmemory. Such knowledge is extremely varied (e.g., information about the\nFrench language; the rules of hockey; the names of capital cities). Much\nof this information consists of concepts: mental representations relating to\nobjects, people, facts and words (Lambon Ralph et al., 2017). These rep-\nresentations are multimodal (i.e., they incorporate information from several\nsense modalities).\nHow is conceptual information in semantic memory organised? We\nstart this section by addressing this issue. First, we consider the notion that\nconcepts are organised into hierarchies. Second, we discuss an alternative\nview, according to which semantic memory is organised on the basis of\nthe semantic distance or semantic relatedness between concepts. After that,\nwe focus on the nature of concepts and on how concepts are used. Finally,\nwe consider larger information structures known as schemas.\nOrganisation: hierarchies of concepts\nSuppose you are shown a photograph of a chair and asked what it is. You\nmight say it is an item of furniture, a chair or an easy chair. This suggests\nconcepts are organised into hierarchies. Rosch et al. (1976) identified three\nlevels within such hierarchies: superordinate categories (e.g., items of furni-\nture) at the top, basic level categories (e.g., chair) in the middle and subordi-\nnate categories (e.g., easy chair) at the bottom.\nWhich level do we use most often? Sometimes we talk about superor-\ndinate categories (e.g., “That furniture is expensive”) or subordinate cate-\ngories (e.g., “I love my iPhone”). However, we typically deal with objects\nat the intermediate or basic level.\nRosch et  al. (1976) asked people to list concept attributes at each\nlevel in the hierarchy. Very few attributes were listed for superordinate\nKEY TERM\nConcepts\nMental representations of\ncategories of objects or\nitems.\nCreated from usyd on 2022-02-14 13:22:32.",
    "314\nMemory\ncategories because they are relatively abstract. Many attributes were listed\nfor categories at the other two levels. However, very similar attributes were\nlisted for different categories at the lowest level. Thus, basic level categories\ngenerally have the best balance between informativeness and distinctiveness:\ninformativeness is low at the highest level of the hierarchy and distinctive-\nness is low at the lowest level. In similar fashion, Rigoli et al. (2017) argued\n(with supporting evidence) that categorising objects at the basic level gen-\nerally allows us to select the most appropriate action with respect to that\nobject while minimising processing costs.\nBauer and Just (2017) found the processing of basic level concepts\ninvolved many more brain regions than the processing of subordinate\nconcepts. More specifically, brain areas associated with sensorimotor and\nlanguage processing were activated with basic level concepts, whereas\nprocessing was focused on perceptual areas with subordinate concepts.\nBasic level categories have other special properties. First, they repre-\nsent the most general level at which individuals use similar motor move-\nments when interacting with category members (e.g., we sit on most chairs\nin similar ways). Second, basic level categories were used 99% of the time\nwhen people named pictures of objects (Rosch et al., 1976).\nHowever, we do not always prefer basic level categories. For example,\nwe expect experts to use subordinate categories. We would be surprised\nif a botanist simply described all the different kinds of plants in a garden\nas plants! We also often use subordinate categories with atypical category\nmembers. For example, people categorise penguins faster as penguins than\nas birds (Jolicoeur et al., 1984).\nFindings\nTanaka and Taylor (1991) studied category naming in bird-watchers and\ndog experts who were shown pictures of birds and dogs. Both groups used\nsubordinate names much more often in their expert domain than their\nnovice domain.\nEven though people generally prefer basic level categories, this does\nnot necessarily mean they categorise fastest at that level. Prass et al. (2013)\npresented photographs of objects very briefly and asked participants to cat-\negorise them at the superordinate level (animal or vehicle), the basic level\n(e.g., cat or dog) or the subordinate level (e.g., Siamese cat vs Persian cat).\nPerformance was most accurate and fastest at the superordinate level (see\nFigure 7.8). In similar fashion, Besson et al. (2017) found categorisation of\nfaces was fastest at the superordinate level.\nWhy does categorisation often occur faster at the superordinate level\nthan the basic level? Close and Pothos (2012) argued that categorisation at\nthe basic level is generally more informative and so requires more detailed\nprocessing. Rogers and Patterson (2007) supported this viewpoint. They\nstudied patients with semantic dementia, a condition involving impair-\nment of semantic memory (discussed earlier in this chapter, p. 303; see\nGlossary).  Patients with severe semantic dementia performed better at\nthe superordinate level than the basic level because less processing was\nrequired.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n315\nOrganisation: semantic distance\nThe assumption that concepts in semantic memory are organised hierar-\nchically is too inflexible and exaggerates how neatly information in seman-\ntic memory is organised. Collins and Loftus (1975) proposed an approach\nbased on the more flexible assumption that semantic memory is organised\nin terms of the semantic distance between concepts. Semantic distance\nbetween concepts has been measured in many ways (Kenett et al., 2017).\nKenett et al. used data from 60 individuals instructed to produce as many\nassociations as possible in 60 seconds to 800 Hebrew cue words in order to\nassess semantic distance in terms of path length: “the shortest number of\nsteps connecting any two cue words” (p. 1473).\nKenett et  al. (2017) asked participants to judge whether word pairs\nwere semantically related. These judgements were well predicted by path\ndistance: 91% of directly linked words (one-step) were judged to be seman-\ntically related, compared to 69% of two-step word pairs and 64% of three-\nstep word pairs.\nOf importance, Kenett et al. (2017) found semantic distance predicted\nperformance on various episodic memory tasks (e.g., free recall). In an\nexperiment on cued recall, participants were presented with word pairs.\nThis was followed by presenting the first word of each pair and instruct-\ning them to recall the associated word. Performance was much higher on\ndirectly linked word pairs (1-step) than three-step word pairs: 30% vs 11%,\nrespectively.\nSemantic distance also predicts aspects of language production. For\nexample, Rose et  al. (2019) had participants name target pictures (e.g.,\neagle) in the presence of distractor pictures that were semantically close\n(e.g., owl) or semantically distant (e.g., gorilla). There was an interference\neffect: naming times were longer when distractors were semantically close.\nWhat is the underlying mechanism responsible for the above findings?\nAccording to Collins and Loftus’s (1975) influential spreading-activation\ntheory, the appropriate node in semantic memory is activated when we\nsee, hear or think about a concept. Activation then spreads rapidly to\nother concepts, with greater activation for concepts closely related seman-\ntically than those weakly related. Such an account can readily explain Rose\net al.’s (2019) findings.\nFigure 7.8\nAccuracy of (a) object\ncategorisation and (b)\nspeed of categorisation at\nthe superordinate, basic\nand subordinate levels.\nFrom Prass et al. (2013).\nReprinted with permission.\nCreated from usyd on 2022-02-14 13:22:32.",
    "316\nMemory\nSpreading-activation theory is also applicable to semantic priming (see\nGlossary and Chapter 9). For example, dog is recognised as a word faster\nwhen the preceding prime is cat than when it is car (Heyman et al., 2018).\nThis can be explained by assuming that presentation of cat activates the\ndog concept and so facilitates recognising it as a word.\nIn sum, the semantic distance of concepts within semantic memory is\nimportant in explaining findings in episodic memory research (e.g., free\nrecall; cued recall) as well as findings relating to language processing.\nHowever, this approach is based on the incorrect assumption that each\nconcept has a single fixed representation in semantic memory. Our process-\ning of any given concept is influenced by context (see next section). For\nexample, think about the meaning of piano. You probably did not focus\non the fact that pianos are heavy. However, you would do so if you read\nthe sentence “Fred struggled to lift the piano”. Thus, the meaning of any\nconcept (and its relation to other concepts) varies as a function of the cir-\ncumstances in which it is encountered.\nUsing concepts: Barsalou’s approach\nWhat do the mental representations of concepts look like? The “traditional”\nview involved the following assumptions about concept representations:\n●\nThey are abstract and so detached from input (sensory) and output\n(motor) processes.\n●\nThey are stable: the same concept representation is used on different\noccasions.\n●\nDifferent individuals have similar representations of any given concept.\nIn sum, it was assumed concept representations “have the flavour of\ndetached encyclopaedia descriptions in a database of categorical knowledge\nabout the world” (Barsalou, 2012, p. 247). This approach forms part of the\nsandwich model (Barsalou, 2016b): cognition (including concept processing)\nis “sandwiched” between perception and action and can be studied without\nconsidering them. How, then, could we use such concept representations\nto perceive the visual world or decide how to behave in a given situation\n(Barsalou, 2016a)?\nBarsalou (2012) argued all the above theoretical assumptions are\nincorrect. We process concepts in numerous different settings and that pro-\ncessing is influenced by the current setting or context. More generally, any\nconcept’s representation varies flexibly across situations depending on the\nindividual’s current goals and the precise situation.\nConsider the concept of a bicycle. A traditional abstract representation\nwould resemble the Chambers Dictionary definition, a “vehicle with two\nwheels one directly in front of the other, driven by pedals”. According to\nBarsalou (2009), the individual’s current goals determine which features\nare activated. For example, the saddle’s height is important if you want to\nride a bicycle, whereas information about the tyres is activated if you have\na puncture.\nAccording to Barsalou’s theoretical approach (e.g., 2012, 2016a,b),\nconceptual processing is anchored in a given context or situation and\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n317\ninvolves the perceptual and motor or action systems. His approach is\ndescribed as grounded cognition: cognition (including concept processing)\nis largely grounded (or based) on the perceptual and motor systems.\nFindings\nEvidence that conceptual processing can involve the perceptual system was\nreported by Wu and Barsalou (2009). Participants wrote down properties\nfor nouns or noun phrases. Those given the word lawn focused on external\nproperties (e.g., plant; blades) whereas those given rolled-up lawn focused\nmore on internal properties (e.g., dirt; soil). Thus, object qualities not visible\nif you were actually looking at the object itself are harder to think of than\nvisible ones.\nWe might expect Barsalou’s grounded cognition approach to be less\napplicable to abstract concepts (e.g., truth; freedom) than concrete ones\n(objects we can see or hear). However, Barsalou et  al. (2018) argued\nthat abstract concepts are typically processed within a relatively concrete\ncontext. In fact, abstract-concept processing sometimes involves perceptual\ninformation but much less often than concrete-concept processing (Borghi\net al., 2018).\nHauk et al. (2004) reported suggestive evidence that the motor system\nis often involved when we access concept information. When participants\nread words such as “lick”, “pick” and “kick”, these verbs activated parts\nof the motor strip overlapping with areas activated when people make\nthe relevant tongue, finger and foot movements. These findings do not\nshow  the motor system is necessary for concept processing – perhaps\nactivation  in areas within the motor strip occurs only after concept\nactivation.\nMiller et  al. (2018) asked participants to make hand or foot\nresponses  after reading hand-associated words (e.g., knead; wipe) or\nfoot- associated words (e.g., kick; sprint). Responses were faster when\nthe word  was compatible with the limb making the response (e.g., hand\nresponse to a hand-associated word) than when word and limb were\nincompatible. These findings apparently support Barsalou’s approach,\naccording to which “The understanding of action verbs requires activa-\ntion of the motor areas used to carry out the named action” (Miller et al.,\n2018, p. 335).\nMiller et  al. (2018) tested the above prediction using event-related\npotentials (see Glossary) to assess limb-relevant brain activity. However,\npresentation of hand- and foot-associated words was not followed rapidly\nby limb-relevant brain activity. Thus, the reaction time findings discussed\nabove were based on processing verb meanings and did not directly involve\nmotor processing.\nHow can we explain the differences in the findings obtained by Hauk\net al. (2004) and by Miller et al. (2018)? Miller et al. used a speeded task\nthat allowed insufficient time for motor imagery (and activation of relevant\nmotor areas) to occur, whereas this was not the case with the study by\nHauk et al.\nAccording to Barsalou, patients with severe motor system damage\nshould have difficulty in processing action-related words (e.g., names of\nCreated from usyd on 2022-02-14 13:22:32.",
    "318\nMemory\ntools). Dreyer et al. (2015) studied HS, a patient with damage to sensori-\nmotor brain systems close to the hand area. He had specific problems in\nrecognising nouns relating to tools rather than those referring to food or\nanimals.\nIn a review, Vannuscorps et  al. (2016) found some studies reported\nfindings consistent with Dreyer et  al.’s (2015) research. In other studies,\nhowever, patients with damage to sensorimotor systems had no deficit\nin conceptual processing of actions or manipulable objects. Vannuscorps\net al. concluded many patients with deficits in processing concepts relating\nto actions and tool have extensive damage to brain areas additional to sen-\nsorimotor areas. The findings from such patients have limited relevance to\nBarsalou’s (2016b) theory.\nVannuscorps et  al. (2016) studied a patient, JR, with brain damage\nprimarily affecting the action production system. JR’s picture-naming\nability was assessed repeatedly over a 3-year period. Even though JR’s\ndisease was progressive, his naming performance with action-related con-\ncepts (e.g., hammer; shovel) remained intact. Thus, processing of action-\nrelated concepts does not necessarily require the involvement of the motor\nsystem.\nEvaluation\nBarsalou’s general theoretical approach has several strengths. First, our\neveryday use of concept knowledge often involves the perceptual and motor\nsystems. Second, concept processing is generally flexible: it is influenced by\nthe present context and the individual’s goals. Third, it is easier to see how\nconcept representations facilitate perception and action within Barsalou’s\napproach than the “traditional” approach.\nWhat are the limitations of Barsalou’s approach? First, Barsalou\nargues it is generally necessary to use perceptual and/or motor processes to\nunderstand concept meanings fully. However, motor processes may often\nnot be necessary (Miller et al., 2018; Vannuscorps et al., 2016).\nSecond, Barsalou exaggerates variations in concept processing across\ntime and contexts. The traditional view that concepts possess a stable,\nabstract core has not been disproved (Borghesani & Piazza, 2017). In\nfact, concepts have a stable core and concept processing is often context-\ndependent (discussed below).\nThird, much concept knowledge does not consist simply of perceptual\nand motor features. Borghesani and Piazza (2017, p. 8) provide the follow-\ning example: “Tomatoes are native to South and Central America.”\nFourth, we recognise the similarities between concepts not sharing\nperceptual or motor features. For example, we categorise watermelon and\nblackberry as fruit even though they are very different visually and we eat\nthem using different motor actions.\nUsing concepts: hub-and-spoke model\nWe have seen concept processing often involves the perceptual and motor\nsystems. However, it is improbable nothing else is involved. First, we would\nnot have coherent concepts if concept processing varied considerably across\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n319\nsituations. Second, as mentioned above, we can detect similarities in con-\ncepts differing greatly in perceptual terms.\nSuch considerations led Patterson et  al. (2007) to propose their hub-\nand-spoke model (see Figure 7.9). The “spokes” consist of several modality-\nspecific regions involving sensory and motor processing. Each concept also\nhas a “hub” – a modality-independent unified representation efficiently\nintegrating our conceptual knowledge.\nIt is assumed hubs are located within the anterior temporal lobes. As\ndiscussed earlier, patients with semantic dementia invariably have damage\nto the anterior temporal lobes and extensive loss of conceptual knowledge\nis their main problem.\nIn the original model, it was assumed the two anterior temporal lobes\n(left and right hemisphere) formed a unified system. This is approximately\ncorrect – there is substantial activation in both anterior temporal lobes\nwhether concepts are presented visually or verbally. However, the left ante-\nrior temporal lobe was more involved than the right in processing verbal\ninformation whereas the opposite was the case in processing visual infor-\nmation (Rice et al., 2015). Lambon Ralph et al. (2017) discussed research\nwhere patients with damage to the left anterior temporal lobe had par-\nticular problems with anomia (object naming). In contrast, patients with\ndamage to the right anterior temporal lobe had particular problems in face\nrecognition.\nFindings\nWe start with research on the “hub”. Mayberry et al. (2011) argued seman-\ntic dementia involves a progressive loss of “hub” information producing\nFigure 7.9\nThe hub-and-spoke model. (a) the hub within the anterior temporal lobe (ATL) has bidirectional connections to the\nspokes (praxis refers to object manipulability; it is action-related); (b) the locations of the hub and spokes are shown,\nsame colour coding as in (a).\nFrom Lambon Ralph et al. (2017).\nCreated from usyd on 2022-02-14 13:22:32.",
    "320\nMemory\na blurring of the boundary between category members and non-members.\nAccordingly, they predicted semantic dementia patients would have par-\nticular problems making accurate category-membership decisions with (1)\natypical category members (e.g., emu is an atypical bird); and (2) pseudo-\ntypical items: non-category members resembling category members (e.g.,\nbutterfly is like a bird). Both predictions were supported with pictures and\nwords, suggesting processing within the anterior temporal lobes is general\nand “hub-like” rather than modality-specific (e.g., confined to the visual\nmodality).\nFindings from patients with semantic dementia suggest the anterior\ntemporal lobes are the main brain areas associated with “hubs”. Binder\net al. (2009) reviewed 120 neuroimaging studies involving semantic memory\nin healthy individuals and found the anterior temporal lobes were consist-\nently activated. Pobric et al. (2010a) applied transcranial magnetic stimu-\nlation (TMS; see Glossary) to interfere with processing in the left or right\nanterior temporal lobe while participants processed concepts presented by\nverbal or pictorial stimuli. TMS disrupted concept processing comparably\nin both anterior temporal lobes.\nHowever, Murphy et  al. (2017) discovered important differences\nbetween ventral (bottom) and anterior (front) regions of the anterior tem-\nporal lobe. Ventral regions responded to meaning and acted as a hub.\nHowever, anterior regions were responsive to differences in input modality\n(visual vs auditory) and thus are not “hub-like”.\nWe turn now to research on the “spokes”. Pobric et al. (2010b) applied\ntranscranial magnetic stimulation (TMS) to interfere briefly with process-\ning within the inferior parietal lobule (involved in processing actions we\ncan make towards objects; the praxis spoke in Figure 7.9). TMS slowed\nnaming times for manipulable objects but not non-manipulable ones indi-\ncating this brain area (unlike the anterior temporal lobes) is involved in\nrelatively specific processing.\nFindings consistent with those of Pobric et al. (2010b) were reported\nby Ishibashi et al. (2018). They applied transcranial direct current stimu-\nlation (tDCS; see Glossary) to the inferior parietal lobule and the anterior\ntemporal lobe. Since they used anodal tDCS, it was expected this stimula-\ntion would enhance performance on tasks requiring rapid access to seman-\ntic information concerning tool function (e.g., scissors are used for cutting)\nor tool manipulation (e.g., pliers are gripped by the handles).\nAs predicted, anodal tDCS applied to the anterior temporal lobe facil-\nitated performance on both tasks because this brain area contains much\ngeneral object knowledge (see Figure 7.10). The effects of anodal tDCS\napplied to the inferior parietal lobule were limited to the manipulation\ntask as predicted because this area processes action-related information.\nSuppose we studied patients whose brain damage primarily affected\none or more of the “spokes”. According to the model, we should find\ncategory-specific deficits (problems with specific categories of objects).\nThere is convincing evidence for the existence of various category-specific\ndeficits and these deficits are mostly associated with the model’s spokes\n(Chen et al., 2017).\nHowever, it is often hard to interpret the findings from patients with\ncategory-specific deficits. For example, many patients find it much harder\nKEY TERM\nCategory-specific\ndeficits\nDisorders caused by brain\ndamage in which semantic\nmemory is disrupted\nfor certain semantic\ncategories.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n321\nto identify pictures of living than non-living things. Several factors are\ninvolved: living things have greater contour overlap than non-living things,\nthey are more complex structurally and they activate less motor informa-\ntion (Marques et al., 2013). It is difficult to disentangle the relative impor-\ntance of these factors.\nFinally, we consider a study by Borghesani et al. (2019). Participants\nread words (e.g., elephant) having conceptual features (e.g., mammal)\nand perceptual features (e.g., big; trumpeting). There were two main find-\nings. First, conceptual and perceptual features were processed in different\nbrain areas. Second, initial processing of both types of features occurred\napproximately 200 ms after word onset. These findings support the model’s\nassumptions that there is somewhat independent processing of “hub” infor-\nmation (i.e., conceptual features) and “spoke” information (i.e., perceptual\nfeatures). However, the findings are inconsistent with Barsalou’s approach,\naccording to which perceptual processing should precede (and influence)\nconceptual processing.\nEvaluation\nThe hub-and-spoke model provides a comprehensive approach combin-\ning aspects of the traditional view of concept processing and Barsalou’s\napproach. The notion within the model that concepts are represented by\nabstract core information and modality-specific information has strong\nsupport. Brain areas associated with different aspects of concept processing\nhave been identified.\nWhat are the model’s limitations? First, it emphasises mostly the\nstorage and processing of single concepts. However, we also need to con-\nsider relations between concepts. For example, we can distinguish between\ntaxonomic relations based on similarity (e.g., dog–bear) and thematic rela-\ntions based on proximity (e.g., dog–leash). The anterior temporal lobes are\nimportant for taxonomic semantic processing whereas the temporo-parietal\nFigure 7.10\nPerformance accuracy on tool function and tool manipulation tasks with anodal\ntranscranial direct current stimulation to the anterior temporal lobe (ATL-A) or to the\ninferior parietal lobule (IPL-A) and in a control condition (Sham).\nFrom Ishibashi et al. (2018).\n0.5\nFunction\n0.55\n0.6\nAccuracy\n0.65\n0.7\nManipulation\nTask\nSham\nATL-A\nIPL-A\nCreated from usyd on 2022-02-14 13:22:32.",
    "322\nMemory\ncortex is important for thematic semantic processing (Mirman et al., 2017).\nThe model has problems with the latter finding given its focus on the ante-\nrior temporal lobes.\nSecond, the role of the anterior temporal lobes in semantic memory\nis more complex than assumed theoretically. For example, Mesulam et al.\n(2013) found semantic dementia patients with damage primarily to the left\nanterior temporal lobe had much greater problems with verbal concepts\nthan visually triggered object concepts. Thus, regions of the left anterior\ntemporal lobe form part of a language network rather than a very general\nmodality-independent hub.\nThird, we have only a limited understanding of the division of labour\nbetween the hub and the spokes during concept processing (Lambon\nRalph, 2014). For example, we do not know how the relative importance\nof hub-and-spoke processing depends on task demands. It is also unclear\nhow  information from hubs and spokes is integrated during concept\nprocessing.\nSchemas vs concepts\nWe may have implied semantic memory consists exclusively of concepts. In\nfact, there are also larger information structures called schemas. Schemas\nare “superordinate knowledge structures that reflect abstracted common-\nalities across multiple experiences” (Gilboa & Marlatte, 2017, p. 618).\nScripts are schemas containing information about sequences of events.\nFor example, your restaurant script probably includes the following: being\ngiven a menu, ordering food and drink, eating and drinking and paying the\nbill (Bower et al., 1979).\nScripts (and schemas more generally) are discussed in Chapter 10 (in\nrelation to language comprehension and memory) and Chapter 8 (relat-\ning to failures of eyewitness memory). Here we first consider brain areas\nassociated with schema-related information. We then explore implications\nof the theoretical assumption that semantic memory contains abstract con-\ncepts corresponding to words and broader organisational structures based\non schemas. On that assumption, we might expect some brain-damaged\npatients would have greater problems accessing concept-based information\nthan schema-based information, whereas others would exhibit the opposite\npattern. This is a double dissociation (see Glossary).\nBrain networks\nSchema information and processing involves several brain areas. However,\nthe ventromedial prefrontal cortex (vmPFC) is especially important. It\nincludes several Brodmann Areas including BA10, BA11, BA12, BA14\nand BA25 (see Figure 1.5). Gilboa and Marlatte (2017) reviewed 12 fMRI\nexperiments where participants engaged in schema processing. Much of the\nventromedial prefrontal cortex was consistently activated, plus other areas\nincluding the hippocampus.\nResearch on brain-damaged patients also indicates the important role\nof the ventromedial prefrontal cortex in schema processing. Ghosh et  al.\n(2014) gave participants a schema (“going to bed at night”) and asked\nKEY TERMS\nSchema\nAn organised packet of\ninformation about the\nworld, events or people\nstored in long-term\nmemory.\nScript\nA form of schema\ncontaining information\nabout a sequence of\nevents (e.g., events during\na typical restaurant meal).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n323\nthem to decide rapidly whether each of a series of words was closely\nrelated to it. Patients with damage to the ventromedial prefrontal cortex\nperformed worse than healthy controls on this task, indicating impaired\nschema- related processing.\nWarren et  al. (2014) presented participants with words belonging to\na single schema (e.g., winter; blizzard; cold) followed by recall. Healthy\nindividuals often falsely recall a schema-relevant non-presented word (e.g.,\nsnow) because their processing and recall involve extensive schema process-\ning. If patients with damage to the ventromedial prefrontal cortex engage\nin minimal schema processing, they should show reduced false recall. That\nis what Warren et al. found.\nDouble dissociation\nAs discussed earlier, brain-damaged patients with early-stage semantic\ndementia (see Glossary) have severe problems accessing word and object\nmeanings. Bier et al. (2013) assessed the ability of three semantic demen-\ntia patients to use schema-relevant information by asking them what they\nwould do if they had unknowingly invited two guests to lunch. The required\nscript actions included dressing to go outdoors, going to the grocery store,\nshopping for food, preparing the meal and clearing up afterwards.\nOne patient successfully described all the above script actions accu-\nrately despite severe problems with accessing concept information from\nsemantic memory. The other patients had particular problems with plan-\nning and preparing the meal. However, they remembered script actions\nrelating to dressing and shopping. Note we might expect semantic demen-\ntia patients to experience problems with using script knowledge because\nthey would need access to relevant concept knowledge (e.g., knowledge\nabout food ingredients) when using script knowledge (e.g., preparing a\nmeal).\nOther patients have greater problems with accessing script information\nthan concept meanings. Scripts typically have a goal-directed quality (e.g.,\nusing a script to achieve the goal of enjoying a restaurant meal). Since\nthe prefrontal cortex is of major importance in goal-directed activity, we\nmight expect patients with prefrontal damage (e.g., ventromedial prefron-\ntal cortex) to have particular problems with script memory.\nCosentino et  al. (2006) studied patients having semantic dementia or\nfronto-temporal dementia (involving extensive damage to the prefron-\ntal cortex and the temporal lobes) with scripts containing sequencing or\nscript errors (e.g., dropping fish in a bucket before casting the fishing\nline). Patients with extensive prefrontal damage failed to detect far more\nsequencing or script errors than those with semantic dementia.\nFarag et  al. (2010) confirmed that patients with fronto-temporal\ndementia are generally less sensitive than those with semantic dementia to\nthe appropriate order of script events. They identified the areas of brain\ndamage in their participants (see Figure 7.11). Patients (including fron-\nto-temporal ones) insensitive to script sequencing had damage in inferior\nand dorsolateral prefrontal cortex. In contrast, patients (including those\nwith semantic dementia) sensitive to script sequencing showed little evi-\ndence of prefrontal damage.\nCreated from usyd on 2022-02-14 13:22:32.",
    "324\nMemory\nZahn et al. (2017) also studied patients with fronto-temporal dementia\nwith damage to the fronto-polar cortex (BA10, part of the ventromedial\nprefrontal cortex) and the anterior temporal lobe. They assessed patients’\nknowledge of social concepts (e.g., adventurous) and script knowledge\n(e.g., the likely long-term consequences of ignoring their employer’s\nrequests).  Patients with greater damage to the fronto-polar cortex than\nthe anterior temporal lobe showed relatively poorer script knowledge\nthan knowledge of social concepts. In contrast, patients with the oppo-\nsite pattern of brain damage had relatively poorer knowledge of social\nconcepts.\nIn sum, semantic memory for concepts centres on the anterior tempo-\nral lobe. Patients with semantic dementia have damage to this area causing\nseverely impaired concept memory. In contrast, semantic memory for scripts\nor schemas involves the prefrontal cortex (especially ventromedial prefron-\ntal cortex). However, when we use our script knowledge (e.g., preparing a\nFigure 7.11\n(a) Brain areas damaged in patients with fronto-temporal degeneration or progressive non-fluent aphasia. (b) Brain areas\ndamaged in patients with semantic dementia or mild Alzheimer’s disease.\nFrom Farag et al. (2010). By permission of Oxford University Press.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n325\nmeal), it is important to access relevant concept  knowledge  (e.g.,  knowl-\nedge about food ingredients). As a consequence, semantic dementia patients\nwhose primary impairment is to concept knowledge also have great diffi-\nculties in accessing and using script knowledge.\nNON-DECLARATIVE MEMORY\nNon-declarative memory does not involve conscious recollection but\ninstead reveals itself through behaviour. As mentioned earlier, priming (the\nfacilitated processing of repeated stimuli) and procedural memory (mainly\nskill learning) are two major forms of non-declarative memory. Note that\nprocedural memory is typically involved in implicit learning (discussed in\nChapter 6).\nThere are two major differences between priming (also known as repe-\ntition priming) and procedural memory:\n(1)  Priming often occurs rapidly whereas procedural memory or skill\nlearning is typically slow and gradual (Knowlton & Foerde, 2008).\n(2) Priming is tied fairly closely to specific stimuli whereas skill learning\ntypically generalises to numerous stimuli. For example, it would be\nuseless if you could hit a good backhand at tennis only when the ball\napproached you from a given direction at a given speed!\nThe strongest evidence for distinguishing between declarative and non-\ndeclarative memory comes from amnesic patients. Such patients mostly have\nseverely impaired declarative memory but almost intact non- declarative\nmemory (but see next section for a more complex account). Oudman et al.\n(2015) reviewed research on priming and procedural memory or skill learn-\ning in amnesic patients with Korsakoff’s syndrome (see Glossary). Their per-\nformance was nearly intact on tasks such as the pursuit rotor (a stylus must\nbe kept in contact with a target on a rotating turntable) and the serial reac-\ntion time task (see Glossary).\nAmnesic patients performed poorly on some non-declarative tasks\nreviewed by Oudman et  al. (2015) for various reasons. First, some tasks\nrequire declarative as well as non-declarative memory. Second, some\nKors akoff’s patients have widespread brain damage (including areas involved\nin non-declarative memory). Third, the distinction between declarative and\nnon-declarative memory is less clear-cut and important than  traditionally\nassumed (see later discussion).\nRepetition priming\nWe can distinguish between perceptual and conceptual priming.\nPerceptual priming occurs when repeated presentation of a stimulus\nleads to facilitated processing of its perceptual features. For example,\nit is easier to identify a degraded stimulus if it was presented shortly\nbeforehand. Conceptual priming occurs when repeated presentation of a\nstimulus  leads to facilitated processing of its meaning. For example, we\ncan  decide faster whether an object is living or non-living if we saw it\nrecently.\nKEY TERMS\nPerceptual priming\nA form of priming\nin which repeated\npresentations of a\nstimulus facilitates its\nperceptual processing.\nConceptual priming\nA form of priming in\nwhich there is facilitated\nprocessing of stimulus\nmeaning.\nCreated from usyd on 2022-02-14 13:22:32.",
    "326\nMemory\nThere are important differences between perceptual priming and\nconceptual priming. Gong et  al. (2016) found patients with frontal lobe\ndamage performed poorly on conceptual priming but had intact perceptual\npriming. In contrast, patients with occipital lobe damage (an area associ-\nated with visual processing) had intact conceptual priming but impaired\nperceptual priming.\nIf repetition priming involves non-declarative memory, amnesic\npatients should show intact repetition priming. This prediction has much\nsupport. For example, Cermak et  al. (1985) found amnesic patients had\ncomparable perceptual priming to controls. However, patients sometimes\nexhibit a modest priming impairment.\nLevy et al. (2004) studied conceptual priming: deciding whether words\npreviously studied (vs not studied) belonged to given categories. Two\nmale amnesic patients (EP and GP) with large lesions in the medial tem-\nporal lobes had intact conceptual priming to healthy controls, but they\nperformed much worse than controls on recognition memory (involving\ndeclarative memory).\nMuch additional research was carried out on EP, who had extensive\ndamage to the perirhinal cortex (BA35 and BA36) plus other regions within\nthe medial temporal lobe (Insausti et al., 2013). His long-term declarative\nmemory was massively impaired. For example, he had very poor ability to\nidentify names, words and faces that became familiar only after amnesia\nonset. However, EP’s performance was intact on non-declarative tasks\n(e.g., perceptual priming; visuo-motor skill learning; see Figure 7.12). His\nperformance was at chance level on recognition memory but as good as\nthat of healthy controls on perceptual priming.\nSchacter and Church (1995) reported further evidence amnesic\npatients have intact perceptual priming. Participants initially heard\nwords all spoken in the same voice and then identified the same words\npassed through an auditory filter. There was priming because identifi-\ncation performance was better when the\nwords were spoken in the same voice as\ninitially.\nThe\nnotion\nthat\npriming\ndepends\non memory systems different from those\ninvolved  in declarative memory would be\nstrengthened if we found patients having\nintact declarative memory but impaired\npriming. This would provide a double dis-\nsociation when considered together with\namnesics having intact priming but impaired\ndeclarative memory. Gabrieli et  al. (1995)\nstudied a  patient, MS with damage to the\nright occipital lobe. MS had intact perfor-\nmance on recognition and cued recall (declar-\native memory) but impaired performance on\nperceptual priming. This latter finding is con-\nsistent with findings reported by Gong et al.\n(2016) in patients with occipital lobe damage\n(discussed earlier).\nFigure 7.12\nPercentages of priming effect (left-hand side) and recognition-\nmemory performance of healthy controls (CON) and\npatients (EP).\nFrom Insausti et al. (2013). © National Academy of Sciences.\nReproduced with permission.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n327\nThe above picture is too neat-and-tidy. Like Schacter and Church\n(1995), Schacter et  al. (1995) studied perceptual priming based on audi-\ntory word identification. However, the words were initially presented in six\ndifferent voices. On the word-identification test, half were presented in the\nsame voice as initially and the other half were spoken by one of the other\nvoices (re-paired condition). Healthy controls (but not amnesic patients)\nhad more priming for words presented in the same voice.\nHow can we explain these findings? In both conditions, participants\nwere exposed to words and voices previously heard. The only advantage in\nthe same voice condition was that the pairing of word and voice was the\nsame as before. However, only those participants who had linked or asso-\nciated words and voices at the original presentation would have benefited\nfrom the repeated pairings. Thus, amnesics are poor at binding together\ndifferent kinds of information even on priming tasks apparently involving\nnon-declarative memory (see later discussion pp. 333–336).\nRelated findings were obtained by Race et al. (2019). Amnesic patients\nhad intact repetition priming when the task involved relatively simple asso-\nciative learning. However, their repetition priming was impaired when the\ntask involved more complex and abstract associative learning. Race et al.\nconcluded “These results highlight the multiple, distinct cognitive and\nneural mechanisms that support repletion priming” (p. 102).\nPriming processes\nWhat processes are involved in priming? A popular view is based on per-\nceptual fluency: repeated presentation of a stimulus means it can be pro-\ncessed more efficiently using fewer resources. This view is supported by the\nfrequent finding that brain activity decreases with stimulus repetition: this is\nrepetition suppression. However, this finding on its own does not demon-\nstrate a causal link between repetition suppression and priming.\nWig et al. (2005) reported more direct evidence using transcranial mag-\nnetic stimulation to disrupt processing. TMS abolished repetition suppres-\nsion and conceptual priming suggesting that repetition suppression was\nnecessary for conceptual priming.\nStimulus repetition is sometimes associated with repetition enhance-\nment involving increased brain activity with stimulus repetition. de Gardelle\net al. (2013) presented repeated faces and found evidence of both stimulus\nsuppression and stimulus enhancement.\nWhat determines whether there is repetition suppression or enhance-\nment? Ferrari et  al. (2017b) presented participants with repeated neutral\nand emotional scenes. Repetition suppression was found when scenes were\nrepeated many times in rapid succession, probably reflecting increased per-\nceptual fluency. In contrast, repetition enhancement was found when rep-\netitions were spaced out in time. This was probably due to spontaneous\nretrieval of previously presented stimuli.\nKim (2017a) reported a meta-analysis of studies on repetition suppres-\nsion and enhancement in repetition priming (see Figure 7.13). There were\ntwo main findings. First, repetition suppression was associated with reduced\nactivation in the ventromedial prefrontal cortex and related areas, suggest-\ning it reflected reduced encoding of repeated stimuli.\nKEY TERMS\nRepetition suppression\nThe finding that stimulus\nrepetition often leads\nto reduced brain activity\n(typically with enhanced\nperformance via priming).\nRepetition enhancement\nThe finding that stimulus\nrepetition sometimes\nleads to increased brain\nactivity.\nCreated from usyd on 2022-02-14 13:22:32.",
    "328\nMemory\nSecond, repetition enhancement was associated with increased acti-\nvation in dorsolateral prefrontal cortex and related areas. According to\nKim (2017a, p. 1894), “The mechanism for repetition enhancement is . . .\nexplicit retrieval during an implicit memory task.” Thus, explicit or declar-\native memory is sometimes involved in allegedly non-declarative priming\ntasks.\nIn sum, progress has been made in understanding the processes under-\nlying priming. Of importance is suggestive evidence that priming some-\ntimes involves declarative as well as non-declarative memory (Kim, 2017).\nThe mechanisms involved in repetition suppression and priming are still\nnot fully understood. However, these effects depend on complex interac-\ntions among the time interval between successive stimuli, the task and the\nallocation of attention (Kovacs & Schweinberger, 2016).\nProcedural memory or skill learning\nMotor skills are important in everyday life – examples include word pro-\ncessing, writing, playing netball and playing a musical instrument. Skill\nlearning or procedural memory includes sequence learning, mirror tracing\n(tracing a figure seen in a mirror), perceptual skill learning, mirror reading\n(reading a text seen in a mirror) and artificial grammar learning (Foerde\n& Poldrack, 2009; see Chapter 6). However, although these tasks are all\ncategorised as skill learning, they differ in terms of the precise cognitive\nprocesses involved.\nHere we consider whether the above tasks involve non-declarative or\nprocedural memory and thus involve different memory systems from those\nunderlying episodic and semantic memory. We will consider skill learn-\ning in amnesic patients. If they have essentially intact skill learning but\nseverely impaired declarative memory, that would provide evidence that\ndifferent memory systems are involved.\nBefore considering the relevant evidence, we address an important\ngeneral issue. It is sometimes incorrectly assumed any given task is always\nFigure 7.13\nBrain regions showing repetition suppression (RS; orange colour) or response\nenhancement (RE; blue colour) in a meta-analysis.\nFrom Kim (2017a).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n329\nperformed using non-declarative or declarative memory. Consider the\nweather-prediction task where participants use various cues to predict\nwhether the weather will be sunny or rainy. Reber et  al. (1996) found\namnesics learned this task as rapidly as healthy controls, suggesting it\ninvolves procedural (non-declarative) memory. However, Rustemeier et al.\n(2013) found 61% of participants used a non-declarative strategy through-\nout learning but 12% used a declarative strategy throughout. In addition,\n27% shifted from an early declarative to a later declarative strategy.\nFindings\nAmnesics often have essentially intact skill learning on numerous\nskill-learning tasks. For example, using the pursuit rotor (manual track-\ning of a moving target), Tranel et al. (1994) found that 28 amnesic patients\nhad intact learning. Even a patient (Boswell) with unusually extensive brain\ndamage to brain areas strongly associated with declarative memory had\nintact learning.\nMuch research has used the serial reaction time task (see Glossary). As\ndiscussed in Chapter 6, amnesics’ performance on this task is typically rea-\nsonably intact. It is somewhat hard to interpret the findings because per-\nformance on this task by healthy controls often involves some consciously\naccessible knowledge (Gaillard et al., 2009).\nSpiers et al. (2001) considered the non-declarative memory performance\nof 147 amnesic patients. All showed intact performance on tasks involving\npriming and learning skills or habits. However, as mentioned earlier, some\nstudies have shown modest impairment in amnesic patients (Oudman et al.,\n2015). In addition, amnesics’ procedural memory has important limitations:\n“[Amnesic patients] typically do not remember how or where informa-\ntion was obtained, nor can they flexibly use the acquired information. The\nknowledge therefore lacks a . . . context” (Clark & Maguire, 2016, p. 68).\nMost tasks assessing skill learning in amnesics require learning far\nremoved from everyday life. However, Cavaco et  al. (2004) used five\nskill-learning tasks (e.g., a weaving task) involving real-world skills.\nAmnesic patients showed comparable learning to healthy controls despite\nsignificantly impaired declarative memory for the same tasks. Anderson\net al. (2007) studied the motor skill of car driving in two severely amnesic\npatients. Their steering, speed control, safety errors and driving with\ndistraction were intact.\nFinally, we discuss patients with Parkinson’s disease (see Glossary).\nThese patients have damage to the striatum (see Glossary), which is of\ngreater importance to non-declarative learning than declarative learning.\nAs predicted, Parkinson’s patients typically have severely impaired non-\ndeclarative learning and memory (see Chapter 6). For example, Kemeny\net al. (2018) found on the serial reaction time task that Parkinson’s patients\nshowed practically no evidence of learning (see Figure 7.14).\nHowever, Parkinson’s patients sometimes have relatively intact epi-\nsodic memory. For example, Pirogovsky-Turk et al. (2015) found normal\nperformance by Parkinson’s patients on measures of free recall, cued\nrecall and recognition memory. These findings strengthen the case for a\ndistinction between declarative and non-declarative memory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "330\nMemory\nOther research complicates the picture. First, Parkinson’s patients\n(especially as the disease progresses) often have damage to brain areas\nassociated with episodic memory. Das et  al. (2019) found impairments\nin recognition memory (a form of episodic memory) among Parkinson’s\npatients were related to damage within the hippocampus (of central impor-\ntance in episodic memory). Many Parkinson’s patients also have problems\nwith attention and executive functions (Roussel et  al., 2017). Bezdicek\net al. (2019) found impaired episodic memory in Parkinson’s patients was\nrelated to reduced functioning of brain areas associated with attention and\nexecutive functions as well as reduced hippocampal functioning.\nSecond, there are individual differences in the strategies used on many\ntasks (e.g., weather-prediction task discussed earlier). Kemeny et al. (2018)\nfound Parkinson’s patients and healthy controls had comparable perfor-\nmance on the weather-prediction task. However, most Parkinson’s patients\nused a much simpler strategy than healthy controls. Thus, the patients’\nprocessing was affected by the disease although this was not apparent from\ntheir overall performance.\nInteracting systems\nA central theme of this chapter is that traditional theoretical views are over-\nsimplified (see next section pp. 332–340). For example, skill learning often\ninvolves brain circuitry including the hippocampus (traditionally associated\nexclusively with episodic memory). Döhring et  al. (2017) studied patients\nwith transient global amnesia who had dysfunction of the hippocam-\npus lasting for several hours. This caused profound deficits in declarative\nmemory but also reduced learning on a motor learning task involving finger\nsequence tapping. Thus, optimal motor learning can require interactions of\nthe procedural and declarative memory systems.\nAlbouy et  al. (2013) discussed research on motor sequence learning\n(skill learning). The hippocampus (centrally involved in the formation of\nFigure 7.14\nMean reaction times on the\nserial reaction time task by\nParkinson’s disease patients\n(PD) and healthy controls\n(HC).\nFrom Kemeny et al. (2018).\nBlock 1\nBlock 2\nBlock 3\nBlock 4\nBlock 5\nBlock 6\nBlock 7\nBlock 8\nBlock 9\nBlock 10\nBlock 11\nBlock 12R\n700\nMean RTs (ms)\n750\n800\n850\n900\n950\n1,000\n1,050\n1,100\n1,150\n1,200\nPD\nHC\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n331\ndeclarative memories) played a major role in the acquisition and storage\nof procedural memories and there were numerous interactions between\nhippocampal-cortical and striato-cortical systems. Doyon et  al. (2018)\nreviewed changes during motor sequence learning. Early learning mainly\ninvolved striatal regions in conjunction with prefrontal and premotor cor-\ntical regions. The contribution of the striatum and motor cortical regions\nincreases progressively during later learning. These findings suggest proce-\ndural learning is dominant later in learning but that declarative memory\nplays a part early in learning. Similar findings are discussed by Beukema\nand Verstynen (2018) (see p. 276).\nHow different are priming and skill learning?\nPriming and skill learning are both forms of non-declarative memory.\nHowever, as Squire and Dede (2015, p. 2) pointed out, “Non-declarative\nmemory is an umbrella term referring to multiple forms of memory.” Thus,\nwe might expect to find differences between priming and skill learning. As\nmentioned earlier, priming generally occurs more rapidly and the learning\nassociated with priming is typically less flexible.\nIf priming and skill learning involve different processes, we would\nnot necessarily expect individuals good at skill learning to also be good at\npriming. Schwartz and Hashtroudi (1991) found no correlation between\nperformance on a priming task (word identification) and a skill-learning\ntask (inverted text reading).\nFindings based on neuroimaging or on brain-damaged patients might\nclarify the relationship between priming and skill learning. Squire and\nDede (2015) argued the striatum is especially important in skill learning\nwhereas the neocortex (including the prefrontal cortex) is of major impor-\ntance in priming.\nSome evidence (including research discussed above) is supportive of\nSquire and Dede’s (2015) viewpoint. However, other research is less sup-\nportive. Osman et al. (2008) found Parkinson’s patients had intact proce-\ndural learning when learning about and controlling a complex system (e.g.,\nwater-tank system). This suggests the striatum is not needed for all forms\nof skill learning. Gong et al. (2016; discussed earlier, p. 326) found patients\nwith frontal damage nevertheless had intact perceptual priming.\nThe wide range of tasks used to assess priming and skill learning means\nnumerous brain regions are sometimes activated on both kinds of tasks.\nWe start with skill learning. Penhune and Steele (2012; see Chapter 6) pro-\nposed a theory assuming skill learning involves several brain areas includ-\ning the primary motor cortex, cerebellum and striatum. So far as priming\nis concerned, Segaert et  al. (2013) reviewed 29 neuroimaging studies and\nconcluded that “Repetition enhancement effects have been found all over\nthe brain” (p. 60).\nEvaluation\nMuch evidence suggests priming and skill learning are forms of non-\ndeclarative memory involving different processes and brain areas from\nthose involved in declarative memory. There is limited evidence of a double\nCreated from usyd on 2022-02-14 13:22:32.",
    "332\nMemory\ndissociation: amnesic patients often exhibit reasonably intact priming\nand skill learning but severely impaired declarative memory. In contrast,\nParkinson’s patients (especially in the early stages of the disease) sometimes\nhave intact declarative memory but impaired procedural memory.\nWhat are the main limitations of research in this area?\n(1) There is considerable flexibility in the processes used on many memory\ntasks. As a result, it is often an oversimplification to describe a task as\ninvolving only “non-declarative memory”.\n(2) Numerous tasks have been used to assess priming and skill learning.\nMore attention needs to be paid to differences among tasks in the\nprecise cognitive processes involved.\n(3) There should be more emphasis on brain networks rather than specific\nbrain areas. For example, motor sequence learning involves a stria-\nto-cortical system rather than simply the striatum. In addition, this\nsystem interacts with a hippocampal-cortical system (Albouy et  al.,\n2013).\n(4) The findings from Parkinson’s patients are mixed and inconsistent.\nWhy is this? As the disease progresses, brain damage in such patients\ntypically moves beyond brain areas involved in non-declarative\nmemory (e.g., the striatum) to areas involved in declarative memory\n(e.g., the hippocampus and prefrontal areas).\nBEYOND MEMORY SYSTEMS AND DECLARATIVE\nVS NON-DECLARATIVE MEMORY\nUntil relatively recently, most memory researchers argued the distinction\nbetween declarative/explicit and non-declarative/implicit memory was of\nmajor theoretical importance. According to this traditional approach, a\ncrucial difference between memory systems is whether they support  conscious\naccess to stored information (see Figure 7.2). It was also often assumed that\nonly memory systems involving conscious access depend heavily on the\nmedial temporal lobe (especially the hippocampus). The traditional approach\nhas proved extremely successful – consider all the accurate predictions\nit made with respect to the research discussed earlier. However, its major\nassumptions are oversimplified and more complex  theories are required.\nExplicit vs implicit memory\nIf the major dividing line in long-term memory is between declarative\n(explicit) and non-declarative (implicit) memory, it is important to devise\ntasks involving only one type of memory. This sounds easy: declara-\ntive memory is involved when participants are instructed to remember\npreviously presented information but not otherwise.\nReality is more complex. Consider the word-completion task.\nParticipants are presented with a word list. Subsequently, they perform an\napparently unrelated task: word fragments (e.g., STR _____ ) are presented\nand they produce a word starting with those letters. Implicit memory is\nrevealed by the extent to which their word completions match list words.\nSince the instructions make no reference to recall, this task is apparently\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n333\nan implicit/non-declarative task. However, participants who become aware\nof the connection between the word list and the word-completion task\nperform better than those who do not (Mace, 2003).\nHippocampal activation is generally associated with declarative\nmemory whereas activity of the striatum is associated with non- declarative\nmemory. However, Sadeh et  al. (2011) obtained more complex find-\nings. Effective learning on an episodic memory task was associated with\ninteractive activity between the hippocampus and striatum. Following a\nfamiliar route also often involves complex interactions between the hip-\npocampus and striatum with declarative memory assisting in the guid-\nance of ongoing actions retrieved from non-declarative memory (Goodroe\net al., 2018).\nThe involvement of declarative/explicit memory and non-declarative/\nimplicit memory on any given task sometimes changes during the course\nof learning and/or there are individual differences in use of the two forms\nof memory. Consider the acquisition of sequential motor skills. There\nis often a shift from an early reliance on explicit processes to a later reli-\nance on  implicit processes (Beukema & Verstynen, 2018; see Chapter 6).\nLawson et al. (2017) reported individual differences during learning on the\nserial reaction time task (see Chapter 6). Some learners appeared to rely\nsolely on implicit processes whereas others also used explicit processes.\nHenke’s processing-based theoretical account\nSeveral theories differing substantially from the traditional theoretical\napproach have been proposed. For example, compare Henke’s (2010)\nprocessing-based model (see Figure 7.15) against the traditional model\n(see Figure 7.2). Henke’s model differs crucially in that “Consciousness of\nencoding and retrieval does not select for memory systems and hence does\nnot feature in this model” (p. 528).\nAnother striking difference relates to declarative memory. In the tra-\nditional model, all declarative memory (episodic plus semantic memory)\ndepends on the medial temporal lobes (especially the hippocampus) and\nthe diencephalon. In Henke’s model, in contrast, episodic memory depends\non the hippocampus and neocortex, semantic memory can involve brain\nareas outside the hippocampus, and familiarity in recognition memory\ndepends on the parahippocampal gyrus and neocortex (and also the per-\nirhinal cortex).\nFigure 7.15 is oversimplified. Henke (2010) argued semantic knowl-\nedge can be learned in two different ways: one way is indicated in the figure\nbut the other way “uses the hippocampus and involves episodic memory\nformation” (p. 528). The assumption that semantic memory need not\ndepend on the hippocampus helps to explain why amnesic patients’ seman-\ntic memory is generally less impaired than their episodic memory (Spiers\net al., 2001).\nThere are three basic processing modes in Henke’s (2010) model:\n(1) Rapid encoding of flexible associations: this involves episodic memory\nand depends on the hippocampus. It is also assumed semantic memory\noften involves the hippocampus.\nResearch activity:\nWord-stem completion task\nCreated from usyd on 2022-02-14 13:22:32.",
    "334\nMemory\n(2) Slow encoding of rigid associations: this involves procedural memory,\nsemantic memory and classical conditioning, and depends on the\nbasal ganglia (e.g., the striatum) and cerebellum.\n(3) Rapid encoding of single or unitised items (formed into a single unit):\nthis involves priming and familiarity in recognition memory and\ndepends on the parahippocampal gyrus.\nMany predictions are common to Henke’s (2010) model and the traditional\nmodel. For example, amnesic patients with hippocampal damage should\nhave generally poor episodic memory but intact procedural memory and\npriming. However, the two models make different predictions:\n(1)  Henke’s (2010) model predicts that amnesic patients with hippocam-\npal damage should have severe impairments of episodic memory\n(and semantic memory) for flexible relational associations but not\nfor single or unitised items. In contrast, according to the traditional\nmodel, amnesic patients should have impaired episodic and semantic\nmemory for single or unitised items as well as for flexible relational\nassociations.\n(2) Henke’s (2010) model predicts the hippocampus is involved in the\nencoding of flexible associations with unconscious and conscious\nFigure 7.15\nA processing-based memory model. There are three basic processing modes: (1) rapid\nencoding of flexible associations; (2) slow encoding of rigid associations; and (3) rapid\nencoding of single or unitised items formed into a single unit. The brain areas associated\nwith each of these processing modes are indicated towards the bottom of the figure.\nFrom Henke (2010). Reproduced with permission from Nature Publishing Group.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n335\nlearning. In contrast, the traditional model assumes the hippocampus\nis involved only in conscious learning.\n(3) Henke’s model predicts the hippocampus is not directly involved in\nfamiliarity judgements in recognition memory. In contrast, the tra-\nditional model assumes all forms of episodic memory depend on the\nhippocampus.\nFindings\nWe start with the first prediction above as it applies to episodic memory.\nQuamme et  al. (2007) studied recognition memory for word pairs\n(e.g., CLOUD–LAWN). In the key condition, each word pair was uni-\ntised (e.g., CLOUD-LAWN was interpreted as a lawn used for viewing\nclouds). Amnesic patients with hippocampal damage had a much smaller\nrecognition-memory deficit when the word pairs were unitised than when\nthey were not. Olson et al. (2015) presented faces with a fixed or variable\nviewpoint followed by a recognition-memory test. It was assumed flexible\nassociations would be formed only in the variable-viewpoint condition.\nAs predicted, a female amnesic (HC) had intact performance only in the\nfixed-viewpoint condition (see Figure 7.16).\nResearch by Blumenthal et  al. (2017; discussed earlier, p. 302) on\nsemantic memory is also relevant to the first prediction. An amnesic patient\nwith hippocampal damage had impaired semantic memory performance\nwhen it depended on having formed relational associations. However, her\nsemantic memory performance was intact when relational associations\nwere not required.\nSupport for the second prediction was reported by Duss et al. (2014).\nUnrelated word pairs (e.g., violin–lemon) were presented subliminally to\namnesic patients and healthy controls. The amnesic patients had signifi-\ncantly poorer relational or associative encoding and retrieval than the con-\ntrols. However, their encoding (and retrieval) of information about single\nFigure 7.16\nRecognition memory for faces presented in a fixed or variable viewpoint and tested in a\nfixed or variable viewpoint; HC is a female amnesic patient.\nFrom Olson et al. (2015).\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nRepeated\nTested viewpoint\nCorrected recognition\nNovel\nControls fxed\nHC fxed\nControls variable\nHC variable\nCreated from usyd on 2022-02-14 13:22:32.",
    "336\nMemory\nwords (e.g., angler) was comparable to controls. Only the relational task\ninvolved hippocampal activation.\nHannula and Greene (2012) discussed several studies showing associa-\ntive or relational learning can occur without conscious awareness. Of most\nrelevance here, however, is whether the hippocampus is activated during\nnon-conscious encoding and retrieval. Henke et  al. (2003) presented par-\nticipants with task–occupation pairs below the level of conscious aware-\nness. There was hippocampal activation during nonconscious encoding of\nthe face–occupation pairs. There was also hippocampal activation during\nnon-conscious retrieval of occupations associated with faces.\nFinally, we turn to Henke’s third prediction, namely, that the hip-\npocampus is not required for familiarity judgements in recognition\nmemory. If so, we might predict amnesic patients should have intact famil-\niarity judgements. As predicted, amnesics have intact recognition memory\n(including familiarity judgements) for unfamiliar faces (Bird, 2017; dis-\ncussed earlier, p. 308).\nHowever, the findings with unfamiliar faces are unusual because\npatients generally have only reasonably (but not totally) intact familiarity\njudgements for other types of material (Bird, 2017; Bowles et  al., 2010;\nSkinner & Femandes, 2007) (discussed earlier, pp. 307–308). However,\nthese findings may not be inconsistent with Henke’s (2010) model because\namnesics’ brain damage often extends beyond the hippocampus to areas\nassociated with familiarity (perirhinal cortex). A male amnesic patient\n(KN) with hippocampal damage but no perirhinal damage had intact\nfamiliarity performance (Aggleton et al., 2005).\nAs shown in Figure 7.15, Henke (2010) assumed that familiarity\njudgements depend on activation in brain areas also involved in priming.\nAs predicted, Thakral et  al. (2016) found similar brain areas were asso-\nciated with familiarity and priming, suggesting they both involve similar\nprocesses.\nEvaluation\nHenke’s (2010) model with its emphasis on memory processes rather than\nmemory systems is an advance. We have considered several examples where\npredictions from her model have proved superior to predictions from the\ntraditional approach.\nWhat are the model’s limitations? First, more research and theoris-\ning are needed to clarify the role of consciousness in memory. Conscious\nawareness is associated with integrated processing across several brain areas\n(Chapter 16) and so is likely to enhance learning and memory. However,\nhow this happens is not specified.\nSecond, the model resembles a framework rather than a model. For\nexample, it is assumed the acquisition of semantic memories is sometimes\nclosely related to episodic memory. However, we cannot make precise pre-\ndictions unless we know the precise conditions determining when this is\nthe case and how processes associated with semantic and episodic memory\ninteract.\nThird, the model does not consider the brain networks associated with\ndifferent types of memory (see below).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n337\nDoes each memory system depend on a few brain\nareas?\nAccording to the traditional theoretical approach (see Figure\n7.2), each memory system depends on only a few key brain areas\n(a similar assumption was made by Henke, 2010). Nowadays,\nhowever, it is generally assumed each type of memory involves\nseveral brain areas forming one or more networks.\nHow can we explain the above theoretical shift? Early\nmemory research relied heavily on findings from brain-damaged\npatients. Such findings (while valuable) are limited. They can\nindicate a given brain area is of major importance. However,\nneuroimaging research allows us to identify all brain areas asso-\nciated with a given type of memory. Examples of the traditional\napproach’s limitations are discussed below.\nFirst, it was assumed that episodic memory depends primar-\nily on the medial temporal lobe (especially the hippocampus).\nNeuroimaging research indicates that several other brain areas\ninterconnected with the medial temporal lobe are also involved.\nIn a review, Bastin et  al. (2019) concluded there is a general\nrecollection network specific to episodic memory including the\ninferior parietal cortex, the medial prefrontal cortex and the pos-\nterior cingulate cortex.\nKim and Voss (2019) assessed brain activity during the forma-\ntion of episodic memories. They discovered that activation within\nlarge brain networks predicted subsequent  recognition-memory\nperformance (see Figure 7.17). Why did activation in certain\nareas predict lower recognition- memory performance? The most\nimportant reason is that such activation often reflects various\nkinds of task-irrelevant processing.\nSecond, in the traditional approach (and Henke’s, 2010,\nmodel), autobiographical memories were regarded simply as\na form of episodic memory. However, the retrieval of auto-\nbiographical memories often involves more brain networks\nthan the retrieval of simple episodic memories. As is shown\nin Figure 8.7, retrieval of autobiographical memories involves\nthe fronto- parietal network, the cingulo- operculum network, the\nmedial prefrontal cortex network and the medial temporal lobe\nnetwork. Only the last of these networks is emphasised within the\ntraditional approach (and Henke’s model).\nThird, more brain areas are associated with semantic\nmemory than the medial temporal lobes emphasised in the tra-\nditional model. In a meta- analysis, Binder et  al. (2009) identified a left-\nhemisphere network consisting of seven regions including the middle\ntemporal gyrus, dorsomedial prefrontal cortex and ventromedial prefron-\ntal cortex.\nFourth, it was assumed within the traditional approach that priming\ninvolves the neocortex. In fact, what is involved is more complex. Kim\n(2017a; discussed earlier, pp. 327–328) found in a meta-analysis that\npriming is associated with reduced activation in the fronto-parietal control\nFigure 7.17\nBrain areas whose activity during\nepisodic learning predicted increased\nrecognition-memory performance\n(task-positive; in red) or decreased\nperformance (task-negative; in blue).\nFrom Kim & Voss (2019).\nTask-positive\nTask-negative\nCreated from usyd on 2022-02-14 13:22:32.",
    "338\nMemory\nnetwork and the dorsal attention network but increased activation in the\ndorsolateral prefrontal cortex and related areas.\nAre memory systems independent?\nA key feature of the traditional theoretical approach (see Figure 7.2) was\nthe assumption that each memory system operates independently. As a con-\nsequence, any given memory task should typically involve only a single\nmemory system. This assumption is an oversimplification. As Ferbinteanu\n(2019, p. 74) pointed out, “The lab conditions, where experiments are care-\nfully designed to target specific types of memories, most likely do not uni-\nversally apply in natural settings where different types of memories combine\nin fluid and complex manners to guide behaviour.”\nFirst, consider episodic and semantic memory. Earlier we consid-\nered cases where episodic and semantic memory were both involved. For\nexample, people answering questions about repeated personal events (e.g.,\n“Have you drunk coffee while shopping?”) rely on both episodic and\nsemantic memory (Renoult et al., 2016).\nSecond, consider skill learning and memory. Traditionally, it was\nassumed that skill learning depends primarily on implicit processes.\nHowever, as we saw earlier, explicit processes are often involved early in\nlearning processes (Beukema & Verstynen, 2018; see Chapter 6).\nComponent-process models\nThe traditional theoretical model is too neat and tidy: it assumes the\nnature of any given memory task rigidly determines the processes used.\nWe need a theoretical approach assuming that memory processes are\nmuch more flexible than assumed within the traditional model (or\nHenke’s model). Dew and Cabeza (2011) proposed such an approach\n(see Figure 7.18). Five brain areas were identified varying along three\ndimensions:\n(1)  cognitive process: perceptually or conceptually driven;\n(2)  stimulus representation: item or relational;\n(3)  level of intention: controlled vs. automatic.\nThis approach is based on two major assumptions, which differ from those\nof previous approaches. First, there is considerable flexibility in the com-\nbination of processes (and associated brain areas) involved in the perfor-\nmance of any memory task. Second, “The brain regions operative during\nexplicit or implicit memory do not divide on consciousness per se” (Dew &\nCabeza, 2011, p. 185).\nCabeza et al. (2018) proposed a component-process model resembling\nthat of Dew and Cabeza (2011). This model assumes that processing is very\nflexible and depends heavily on process-specific alliances (PSAs) or mini-\nnetworks. According to Cabeza et  al., “A PSA is a small team of brain\nregions that rapidly assemble to mediate a cognitive process in response\nto task demands but quickly disassemble when the process is no longer\nneeded  . . . PSAs are flexible, temporary, and opportunistic” (p. 996).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n339\nFerbinteanu (2019) proposed a dynamic\nnetwork model based on very similar\nassumptions.\nA major motivation for this theoretical\napproach was neuroimaging evidence. Here\nis an example involving the left angular\ngyrus in the parietal lobe. This region is\ninvolved in both the recollection of episodic\nmemories and numerous tasks requiring\nsemantic processing (see Figure 7.19).\nMoscovitch et  al. (2016) pointed\nout that the hippocampus’s connections\nto several other brain areas (e.g., those\ninvolved in visual perception) suggests it\nis not only involved in episodic memory.\nConsider research on boundary exten-\nsion: “the  . . . tendency to reconstruct a\nscene with a larger background than actu-\nally was presented” (Moscovitch et  al.,\n2016, p. 121). Boundary extension is\naccompanied by hippocampal activation\nand is greatly reduced in amnesic patients\nwith hippocampal damage.\nMcCormick et  al. (2018) reviewed\nresearch on patients with damage to\nthe hippocampus. Such patients mostly\nshowed decreased future thinking and\nimpaired scene construction, navigation\nand moral decision-making as well as\nimpaired episodic memory. McCormick\net  al. also reviewed research on patients\nwith damage to the ventromedial prefron-\ntal cortex (centrally involved in schema\nprocessing in semantic memory), which\nis also connected to several other brain\nareas. Such patients had decreased future\nthinking and impaired scene construction,\nnavigation and emotion regulation.\nEvaluation\nThe component-process approach has\nseveral strengths. First, there is compelling\nevidence that processes associated with\ndifferent memory systems combine very\nflexibly on numerous memory tasks. This flexibility depends on the precise\ntask demands (e.g., processes necessary early in learning may be less so\nsubsequently) and on individual differences in learning/memory skills and\nprevious knowledge. In other words, we use whatever processes (and asso-\nciated brain areas) are most useful for the current learning or memory task.\nFigure 7.18\nA three-dimensional model of memory: (1) conceptually\nor perceptually driven; (2) relational or item stimulus\nrepresentation; (3) controlled or automatic/involuntary\nintention. The brain areas are the visual cortex (Vis Ctx),\nparahippocampal cortex (PHC), hippocampus (Hipp), rhinal\ncortex (RhC) and left ventrolateral prefrontal cortex (L VL PFC).\nFrom Dew and Cabeza (2011). © 2011 New York Academy of Sciences.\nReprinted with permission of Wiley & Sons.\nFigure 7.19\nProcess-specific alliances including the left angular gyrus (L-AG) are\ninvolved in recollection of episodic memories (left-hand side) and\nsemantic processing (right-hand side).\nFrom Cabeza et al. (2018).\nEpisodic recollection\nExample PSAs including L-AG\nSemantic processing\nAG\nHC\nvATL\nAG\nAG\nHC\nvATL\nAG\nCreated from usyd on 2022-02-14 13:22:32.",
    "340\nMemory\nSecond, this approach is more consistent with the neuroimaging evi-\ndence than previous approaches. It can account for the fact that many\nmore brain areas are typically active during most memory tasks than\nexpected from the traditional approach.\nThird, the component-process approach has encouraged researchers to\nabandon the traditional approach of studying memory as an isolated mental\nfunction. For example, processes associated with episodic memory are also\ninvolved in scene construction, aspects of decision-making, navigation,\nimagining the future and empathy (McCormick et  al., 2018; Moscovitch\net  al., 2016). More generally, “The border between memory and percep-\ntion/action has become more blurred” (Ferbinteanu, 2019, p. 74).\nWhat are the limitations of the component-process approach? First, it\ndoes not provide a detailed model. This makes it hard to make specific pre-\ndictions concerning the precise combination of processes individuals will\nuse on any given memory task.\nSecond, our ability to create process-specific alliances rapidly and\nefficiently undoubtedly depends on our previous experiences and various\nforms of learning (Ferbinteanu, 2019). However, the nature of such learn-\ning remains unclear.\nThird, as Moscovitch et  al. (2016, p. 125) pointed out, “Given that\nPSAs are rapidly assembled and disassembled, they require a mechanism\nthat can quickly control communication between distant brain regions.”\nMoscovitch et al. argued the prefrontal cortex is centrally involved, but we\nhave very limited evidence concerning its functioning.\nFourth, process-specific alliances are typically mini-networks involving\ntwo or three brain regions. However, as we have seen, some research has\nsuggested the involvement of larger brain networks consisting of numer-\nous brain regions (e.g., Kim & Voss, 2019). The optimal network size for\nexplaining learning and memory remains unclear.\nCHAPTER SUMMARY\n•\nIntroduction. The notion there are several memory systems is very\ninfluential. Within that approach, the crucial distinction is between\ndeclarative memory (involving conscious recollection) and non-\ndeclarative memory (not involving conscious recollection). This\ndistinction has received strong support from amnesic patients\nwith severely impaired declarative memory but almost intact non-\ndeclarative memory. Declarative memory is divided into semantic\nand episodic/autobiographical memory, whereas non-declarative\nmemory is divided into priming and skill learning or procedural\nmemory.\n•\nDeclarative memory. Evidence from patients supports the\ndistinction between episodic and semantic memory. Amnesic\npatients with damage to the medial temporal lobes including\nthe hippocampus typically have more extensive impairment of\nepisodic than semantic memory. In contrast, patients with semantic\ndementia (involving damage to the anterior temporal lobes) have\nKEY TERM\nBoundary extension\nMisremembering a\nscene as having a larger\nsurround area than was\nactually the case.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n341\nmore extensive impairment of semantic than episodic memory.\nHowever, a complicating factor is that many memory tasks involve\ncombining episodic and semantic memory processes. Another\ncomplicating factor is semanticisation (transformation of episodic\nmemories into semantic ones over time): perceptual details within\nepisodic memory are lost over time and there is increased reliance\non gist and schematic information within semantic memory.\n•\nEpisodic memory. Episodic memory is often assessed by\nrecognition tests. Recognition memory can involve familiarity or\nrecollection. Evidence supports the binding-of-item-and-context\nmodel: familiarity judgements depend on perirhinal cortex whereas\nrecollection judgements depend on binding what and where\ninformation in the hippocampus. In similar fashion, free recall can\ninvolve familiarity or recollection with the latter being associated\nwith better recall of contextual information. Episodic memory\nis basically constructive rather than reproductive, and so we\nremember mostly the gist of our past experiences. Constructive\nprocesses associated with episodic memory are used to imagine\nfuture events. However, imaging future events relies more heavily\non semantic memory than does recalling past events. Episodic\nmemory is also used in divergent creative thinking.\n•\nSemantic memory. Most objects can be described at the\nsuperordinate, basic and subordinate levels. Basic level categories\nare typically used in everyday life. However, categorisation is\noften faster at the superordinate level than the basic level because\nless information processing is required. According to Barsalou’s\nsituated simulation theory, concept processing involves perceptual\nand motor information. However, it is unclear whether perceptual\nand motor information are both necessary and sufficient for\nconcept understanding (e.g., patients with damage to the motor\nsystem can understand action-related words). Concepts have an\nabstract central core of meaning de-emphasised by Barsalou.\nAccording to the hub-and-spoke model, concepts consist of\nhubs (unified abstract representations) and spokes (modality-\nspecific information). The existence of patients with category-\nspecific deficits supports the notion of spokes. Evidence from\npatients with semantic dementia indicates hubs are stored in the\nanterior temporal lobes. It is unclear how information from hubs\nand spokes is combined and integrated.\nSchemas are stored in semantic memory with the ventromedial\nprefrontal cortex being especially involved in schema processing.\nPatients with damage to that brain area often have greater\nimpairments in schema knowledge than concept knowledge. In\ncontrast, patients with semantic dementia (damage to the anterior\ntemporal lobes) have greater impairments in concept knowledge\nthan schema knowledge. Thus, there is some evidence for a\ndouble dissociation.\nCreated from usyd on 2022-02-14 13:22:32.",
    "342\nMemory\n•\nNon-declarative memory. Priming is tied to specific stimuli\nand occurs rapidly. Priming often depends on enhanced neural\nefficiency shown by repetition suppression of brain activity. Skill\nlearning occurs slowly and generalises to stimuli not presented\nduring learning. Amnesic patients (with hippocampal damage)\ntypically have fairly intact performance on priming and skill learning\nbut severely impaired declarative memory. In contrast, Parkinson’s\npatients (with striatal damage) exhibit the opposite pattern.\nAmnesic and Parkinson’s patients provide only an approximate\ndouble dissociation. Complications arise because some tasks can\nbe performed using either declarative or non-declarative memory,\nbecause different memory systems sometimes interact during\nlearning, and because non-declarative learning often involves\nnetworks consisting of several brain areas.\n•\nBeyond memory systems and declarative vs non-declarative\nmemory. The traditional emphasis on the distinction between\ndeclarative and non-declarative memory is oversimplified. It does\nnot fully explain amnesics’ memory deficits and exaggerates the\nrelevance of whether processing is conscious or not. Henke’s\nmodel (with its emphasis on processes rather than memory\nsystems) provides an account that is superior to the traditional\napproach. According to the component-process model, memory\ninvolves numerous brain areas and processes used in flexible\ncombinations rather than a much smaller number of rigid memory\nsystems. This model has great potential. However, it is hard to\nmake specific predictions about the combinations of processes\nindividuals will use on any given memory task.\nFURTHER READING\nBaddeley, A.D., Eysenck, M.W. & Anderson, M.C. (2020). Memory (3rd edn).\nAbingdon, Oxon.: Psychology Press. Several chapters are of direct relevance to\nthe topics covered in this chapter.\nBastin, C., Besson, G., Simon, J., Delhaye, E., Geurten, M., Willems, S., (2019). An\nintegrative memory model of recollection and familiarity to understand memory\ndeficits. Behavioral and Brain Sciences, 1–66 (epub: 5 February 2019). Christine\nBastin and colleagues provide a comprehensive theoretical account of episodic\nmemory.\nCabeza, R., Stanley, M.L. & Moscovitch, M. (2018). Process-specific alliances\n(PSAs) in cognitive neuroscience. Trends in Cognitive Sciences, 22, 996–1010.\nRoberto Cabeza and colleagues how cognitive processes (including memory)\ndepend on flexible interactions among brain regions.\nFerbinteanu, J. (2019). Memory systems 2018 – Towards a new paradigm.\nNeurobiology of Learning and Memory, 157, 61–78. Janina Ferbinteanu discusses\nrecent theoretical developments in our understanding of memory systems.\nKim, H. (2017). Brain regions that show repetition suppression and enhancement:\nA meta-analysis of 137 neuroimaging experiments. Human Brain Mapping, 38,\n1894–1913. Hongkeun Kim discusses the processes underlying repetition priming\nwith reference to a meta-analysis of the relevant brain areas.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Long-term memory systems\n343\nLambon Ralph, M.A., Jefferies, E., Patterson, K. & Rogers, T.T. (2017). The neural\nand computational bases of semantic cognition. Nature Reviews Neuroscience, 18,\n42–55. Our current knowledge and understanding of semantic memory are dis-\ncussed in the context of the hub-and-spoke model.\nVerfaillie, M. & Keane, M.M. (2017). Neuropsychological investigations of human\namnesia: Insights into the role of the medial temporal lobes in cognition. Journal\nof the International Neuropsychological Society, 23, 732–740. Research on amnesia\nand memory is discussed in detail in this article.\nYee, E., Jones, M.N. & McRae, K. (2018). Semantic memory. In S.L. Thompson-\nSchill & J.T. Wixted (eds), Stevens’ Handbook of Experimental Psychology and\nCognitive Neuroscience, Vol. 3: Language and Thought: Developmental and social\npsychology (4th edn; pp. 319–356). New York: Wiley. This chapter provides a\ncomprehensive account of theory and research on semantic memory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\nINTRODUCTION\nMost memory research discussed in Chapters 6 and 7 was laboratory-based\nbut nevertheless of reasonably direct relevance to how we use memory in\nour everyday lives. In this chapter, we focus on topics rarely researched\nuntil approximately 50 years ago but arguably even more directly relevant\nto our everyday lives. Two such topics are autobiographical memory and\nprospective memory, which are both strongly influenced by our everyday\ngoals and motives. This is very clear with prospective memory (remember-\ning to carry out intended actions). Our intended actions assist us to achieve\nour current goals. For example, if you have agreed to meet a friend at\n10 am, you need to remember to set off at the appropriate time to achieve\nthat goal.\nThe other main topic discussed in this chapter is eyewitness testimony.\nSuch research has obvious applied value with respect to the judicial system.\nHowever, most research on eyewitness testimony has been conducted in\nlaboratory settings. Thus, it would be wrong to distinguish sharply between\nlaboratory research and everyday memory or applied research.\nIn spite of what has been said so far, everyday memory sometimes\ndiffers from more traditional memory research in various ways. First, social\nfactors are often important in everyday memory (e.g., a group of friends\ndiscuss some event or holiday they have shared together). In contrast,\nparticipants in traditional memory research typically learn and remember\ninformation on their own.\nSecond, participants in traditional memory experiments are generally\nmotivated to be as accurate as possible. In contrast, everyday memory\nresearch is typically based on the notion that “Remembering is a form of\npurposeful action” (Neisser, 1996, p. 204). This approach involves three\nassumptions about everyday memory:\n(1) It is purposeful (i.e., motivated).\n(2) It has a personal quality about it, meaning it is influenced by the indi-\nvidual’s personality and other characteristics.\nChapter\n8\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n345\n(3) It is influenced by situational demands (e.g., the wish to impress one’s\naudience).\nThe essence of Neisser’s (1996) argument is this: what we remember in\neveryday life is determined by our personal goals, whereas what we remem-\nber in traditional memory research is mostly determined by the experi-\nmenter’s demands for accuracy. Sometimes we strive for maximal memory\naccuracy in our everyday life (e.g., during an examination), but that is\ntypically not our main goal.\nFindings\nEvidence that the memories we report in everyday life are sometimes delib-\nerately distorted was reported by Brown et al. (2015). They found 58% of\nstudents admitted to having “borrowed” other people’s personal memories\nwhen describing experiences that had allegedly happened to them. This was\noften done to entertain or impress an audience.\nIf what you say about an event is deliberately distorted, does this\nchange the memory itself? It often does. Dudokovic et  al. (2004) asked\npeople to recall a story accurately (as in traditional memory research) or\nentertainingly (as in the real world). Unsurprisingly, entertaining retellings\nwere more emotional but contained fewer details.\nThe participants were then instructed to recall the story accurately.\nThose who had previously recalled it entertainingly recalled fewer details\nand were less accurate than those who previously recalled it accurately.\nThis exemplifies the saying-is-believing effect – tailoring what one says\nabout an event to suit a given audience causes inaccuracies in memory for\nthat event.\nFurther evidence of the saying-is-believing effect was reported by\nHellmann et  al. (2011). Participants saw a video of a pub brawl involv-\ning two men. They then described the brawl to a student having previously\nbeen told this student believed person A was (or was not) the culprit. The\nparticipants’ retelling of the event reflected the student’s biased views. On a\nsubsequent unexpected test of free recall for the crime event, participants’\nrecall was systematically influenced by their earlier retelling. Free recall was\nmost distorted in those participants whose retelling of the event had been\nmost biased.\nWhat should be done?\nResearch on human memory should ideally possess ecological validity (i.e.,\napplicability to real life; see Glossary). Ecological validity has two aspects:\n(1) representativeness (the naturalness of the experimental situation and\ntask); and (2) generalisability (the extent to which a study’s findings apply\nto the real world).\nIt is often (mistakenly) assumed that everyday memory research has\ngreater ecological validity than traditional laboratory research. This is\nsimply incorrect. Generalisability is more important than representative-\nness (Kvavilashvili & Ellis, 2004). Laboratory research is generally carried\nout under well-controlled conditions and very often produces findings that\nKEY TERM\nSaying-is-believing effect\nTailoring a message\nabout an event to suit a\ngiven audience causes\nsubsequent inaccuracies\nin memory for that event.\nCreated from usyd on 2022-02-14 13:22:32.",
    "346\nMemory\napply to the real world. Indeed, the fact that the level of experimental\ncontrol is generally higher in laboratory research than in more naturalistic\nresearch means that the findings obtained often have greater generalisabil-\nity. Laboratory research also often satisfies the criterion of representative-\nness because the experimental situation captures key features of the real\nworld.\nIn sum, the distinction between traditional laboratory research and\neveryday memory research is blurred and indistinct. In practice, there\nis much cross-fertilisation, with the insights from both kinds of memory\nresearch enhancing our understanding of human memory.\nAUTOBIOGRAPHICAL MEMORY: INTRODUCTION\nWe have hundreds of thousands of memories relating to an endless variety\nof things. However, those relating to the experiences we have had and those\nof other people important to us have special significance and form our\nautobiographical memory (memory for the events of one’s own life).\nWhat is the relationship between autobiographical memory and epi-\nsodic memory (concerned with events at a given time in a specific place;\nsee Chapter 7)? One important similarity is that both types of memory\nrelate to personally experienced events. In addition, both are susceptible to\nproactive and retroactive interference and unusual or distinctive events are\nespecially well remembered.\nThere are also several differences between them. First, autobiograph-\nical memory typically relates to events of personal significance whereas\nepisodic memory (sometimes called “laboratory memory”) often relates to\ntrivial events (e.g., was the word chair presented in the first list?). As a con-\nsequence, autobiographical memories are often thought about more often\nthan episodic ones. They also tend to be more organised than  episodic\nmemories because they relate to the self.\nSecond, neuroimaging evidence suggests autobiographical memory is\nmore complex and involves more brain regions than episodic memory.\nAndrews-Hanna et  al. (2014) carried out a meta-analysis (see Glossary)\nof studies on autobiographical memory, episodic memory and mentalis-\ning (understanding the mental states of oneself and others) (see Figure\n8.1). Episodic memory retrieval involved medial temporal regions (includ-\ning the hippocampus) whereas mentalising involved the dorsal medial\nregions (including the dorsal medial prefrontal cortex). Of most impor-\ntance, the brain regions associated with autobiographical memory over-\nlapped with those associated with episodic memory and mentalising. Thus,\nautobiographical memory seems to involve both episodic memory and\nmentalising.\nThird, some people have large discrepancies between their auto-\nbiographical and episodic memory (Roediger & McDermott, 2013). For\nexample, Patihis et  al. (2013) found individuals with exceptionally good\nautobiographical memory had only average episodic memory performance\nwhen recalling information learned under laboratory conditions (see below).\nFourth, the role of motivation differs between autobiographical and\nepisodic memory (Marsh & Roediger, 2012). We are much more inter-\nested in our own personal history than episodic memories formed in the\nKEY TERMS\nAutobiographical\nmemory\nLong-term memory for the\nevents of one’s own life.\nMentalising\nThe ability to perceive\nand interpret behaviour\nin terms of mental states\n(e.g., goals; needs).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n347\nlaboratory. In addition, as mentioned earlier,\nwe are motivated to recall autobiographical\nmemories reflecting well on ourselves. In\ncontrast, we are motivated to recall labora-\ntory episodic memories accurately.\nFifth, some aspects of autobiographical\nmemory involve semantic memory (general\nknowledge; see Glossary) rather than epi-\nsodic memory (Prebble et  al., 2013). For\nexample, we know where and when we\nwere born but this is not based on episodic\nmemory! Further evidence for the involve-\nment of semantic memory in autobiographi-\ncal memory comes from research on amnesic\npatients (Juskenaite et al., 2016). They have\nlittle or no episodic memory but can never-\ntheless recall much information about them-\nselves (e.g., aspects of their own personality).\nEustache et  al. (2016) distinguished\nbetween episodic and  semantic autobio-\ngraphical memory. Both forms of autobio-\ngraphical memory involve personal memories, but the latter differ from the\nformer because they lack any subjective sense of recollection.\nEustache et al. reviewed neuroimaging research supporting the above\ndistinction. Episodic autobiographical memory was associated with activa-\ntion in the occipital cortex and lateral parietal cortex. In contrast, seman-\ntic autobiographical memory was associated with activation in the middle\nand inferior frontal cortex. Other brain areas (e.g., the lateral temporal\ncortex; the hippocampus) were activated by both forms of autobiograph-\nical memory. More research indicating that autobiographical memories\nvary in their relationship to episodic and semantic memory is discussed in\nChapter 7 (e.g., research of Renoult et al., 2016; see p. 303).\nWhat are the main functions of autobiographical memory? Bluck and\nAlea (2009) identified three key reasons:\n(1)  social function: bonding with others (e.g., shared memories);\n(2) directive function: using the past as a guide to the future;\n(3) self-function: creating a sense of self-continuity over time.\nVranić et  al. (2018) obtained support for all three functions in a\nquestionnaire- based approach. The social and self-functions were positively\ncorrelated with each other and there was some evidence these functions\nwere more important than the directive function.\nDemiray and Janssen (2013) identified an additional function: self-\nenhancement. Most people feel closer to their positive memories than their\nnegative ones, and this effect is stronger among individuals having high\nself-esteem.\nBelow we discuss major topics within autobiographical memory. First,\nwe consider unusually vivid autobiographical memories for dramatic per-\nsonal or world events. Second, we focus on those periods in individuals’\nFigure 8.1\nBrain regions activated by autobiographical, episodic retrieval\nand mentalising tasks including regions of episodic (green);\nmentalising (blue); autobiographical (red-brown); episodic +\nmentalising (blue/green); episodic + autobiographical (yellow);\nmentalising + autobiographical (purple); all 3 (white).\nFrom Andrews-Hanna et al. Reprinted with permission of Elsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "348\nMemory\nlives from which disproportionately many or few autobiographical mem-\nories are retrieved. Third, we discuss major theoretical approaches. Note\nthat research on autobiographical memories for traumatic childhood events\nis discussed in Chapter 7.\nIN THE REAL WORLD: HIGHLY SUPERIOR\nAUTOBIOGRAPHICAL MEMORY (HSAM)\nMany people bemoan their deficient autobiographical memories.\nHowever, a few individuals have remarkably efficient autobiographical\nmemory. Consider Jill Price (see photo). She has an incredible ability\nto recall detailed information about almost every day of her life and\nthus possesses what is known as highly superior autobiographical\nmemory (HSAM).\nYou may envy Jill Price’s phenomenal autobiographical memory.\nHowever, she regards it as a disadvantage: “I call it a burden. I run\nmy entire life through my head every day and it drives me crazy!!!”\n(Parker et al., 2006, p. 35). Strangely, her memory generally is very\nordinary (e.g., recalling word lists). You can see Jill Price on YouTube:\n“The Woman Who Could Not Forget – Jill Price”.\nWhy is her autobiographical memory so outstanding? First, she has\nobsessional tendencies and focuses excessively on her personal past.\nAs she said, “This is OCD [obsessive-compulsive disorder]. I have\nOCD of my memories.” Second, she has poor inhibitory processes\nand so finds it very hard to switch off her personal memories. Third,\nshe makes time seem more concrete by representing it in spatial\nform (e.g., positions on a circle).\nMore recent research (e.g., LePort et al., 2012, 2016; Santangelo et al., 2018) indicates the great\nmajority of individuals with HSAM possess similar obsessional characteristics to Jill Price. Indeed,\nthey often have as many obsessional symptoms as patients with obsessive-compulsive disorder.\nJill Price\nDan Tuffs/Getty Images.\nFigure 8.2\nNumber of internal details\n(those specific to an\nautobiographical event)\nrecalled at various time\ndelays (by controls and\nindividuals with highly\nsuperior autobiographical\nmemory (HSAM)).\nFrom LePort et al. (2016).\n0\n1 week\n20\n40\n# Internal details\n60\n1 month\n*\n1 year\n10 years\nDelay\n+\n+\n+\n+\n+\n+\n*\n*\nControls\nHSAMs\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n349\nRecent research also indicates the performance of those with HSAM is only average on standard\nlaboratory memory tasks.\nLePort et al. (2016) found individuals with HSAM had comparable autobiographical memory to\ncontrols one week after an event. However, they were dramatically better than controls thereafter\n(see Figure 8.2). These findings suggest the memory differences between the two groups depended\nmainly on processes occurring after acquisition (e.g., consolidation; frequent rehearsal) rather than\nencoding at the time of the event.\nSantangelo et al. (2018) found that individuals with HSAM retrieved autobiographical memories\n(but not other memories) much faster than controls. During retrieval of autobiographical memories,\ntwice as many brain areas were activated in HSAM individuals as controls and they had enhanced\nconnectivity between brain areas important in memory retrieval.\nSome individuals with HSAM may have brains differing from those of other people (Palombo\net al., 2018). LePort et al. (2012) found that HK (a man with HSAM) had a larger right amygdala\nthan most people and enhanced connectivity between the amygdala and hippocampus. This could\nbe important because the amygdala is involved in emotional processing and the hippocampus is\ncrucial to forming long-term memories. However, such brain differences may be a consequence\n(rather than cause) of remarkable autobiographical memory.\nKEY TERMS\nHighly superior auto-\nbiographical memory\n(HSAM)\nExceptional ability to\nrecall autobiographical\nmemories in detail,\ngenerally accompanied\nby only average ability to\nrecall other memories.\nFlashbulb memories\nVivid and detailed\npersonal memories of\ndramatic events (e.g.,\n9/11).\nFlashbulb memories\nMost people believe they have extremely clear and long-lasting memories\nfor their personal experiences following important and dramatic public\nevents (e.g., the terrorist attacks on the United States on 11 September\n2001). Such memories were termed flashbulb memories by Brown and\nKulik (1977). They claimed dramatic events perceived as surprising and\nas having real consequences for the individual (making them of relevance\nto autobiographical memory) activate a special neural mechanism which\n“prints” the details of such events permanently in memory.\nBrown and Kulik (1977) argued the following information is typically\nincluded in flashbulb memories:\n●\ninformant (person who supplied the information);\n●\nplace where the news was heard;\n●\nongoing event;\n●\nindividual’s own emotional state;\n●\nemotional state of others;\n●\nconsequences of the event for the individual.\nFindings\nSharot et  al. (2007) compared the memories of\nindividuals close to the World Trade Centre (about\n2 miles) on 9/11 with those somewhat further away\n(about 4½ miles) three years afterwards. The flash-\nbulb memories of those close to the event were more\nvivid and detailed and involved more activation of\nthe amygdala (strongly involved in emotion). These\nfindings suggest it may require intense emotional\nexperience to produce genuine flashbulb memories.\nWorld Trade Center attacks on 9/11.\nTammy KLEIN/Gamma-Rapho via Getty Images.\nCreated from usyd on 2022-02-14 13:22:32.",
    "350\nMemory\nSupport for the involvement of the amygdala was reported by Spanel\net al. (2018). Recall of flashbulb memories was much worse in patients with\ndamage to the amygdala than those without damage to that brain area.\nFlashbulb memories not based on an intense emotional experience\nare often surprisingly inaccurate. For example, videotape of the first plane\nstriking the first tower on 9/11 was not available on the day it happened.\nHowever, 73% of those questioned said they had seen it on that day\n(Pezdek, 2003)! Their memories were distorted because videotape of the\nsecond tower being hit was available on the day itself.\nHirst et  al. (2015) studied flashbulb memories and event memories\n(memories for facts associated with events causing flashbulb memories) of\n9/11 over a 10-year period. There was rapid forgetting for both types of\nmemories within the first year after 9/11 but very little thereafter. Of inter-\nest, participants had very high confidence in the accuracy of their flashbulb\nmemories despite considerable forgetting.\nRimmele et  al. (2012) studied the consistency of flashbulb memories\n(i.e., lack of change) over time. There was high consistency between one\nweek and three years after 9/11 for remembering the location at which par-\nticipants heard about the event (83%), but lower consistency for informant\n(70%), ongoing activity (62%) and their own immediate reaction (34%).\nIn spite of much inconsistency in individuals’ flashbulb memories, these\nmemories are generally associated with high confidence levels. Talarico and\nRubin (2003) found flashbulb memories for 9/11 showed no more consist-\nency over a 32-week period than did everyday memories but the reported\nvividness of flashbulb memories was much greater.\nWhy are confidence levels so high? Day and Ross (2014) assessed flash-\nbulb memories for Michael Jackson’s death. Participants having a strong\nsocial bond with Michael Jackson had greater confidence in the accuracy\nof their flashbulb memories than those with a weak social bond, because\nthey experienced Jackson’s death with greater emotional intensity and also\nrehearsed the event more often. However, memory consistency was not\ninfluenced by social bond, emotional intensity or rehearsal.\nConclusions\nMost findings suggest flashbulb memories are not special except perhaps\nwhen their formation is associated with high emotion. Most flashbulb mem-\nories exhibit forgetting and/or distortions resembling those found with ordi-\nnary memories (Hirst & Phelps, 2016). However, such memories may be\nmore detailed and long-lasting if the relevant event directly affected their\nlives (Sharot et al., 2007; see Chapter 15).\nFlashbulb memories are associated with excessively high levels of\nconfidence in their accuracy for various reasons (e.g., the intensity of\nemotional experience involved; rehearsal: Day & Ross, 2014). Excellent\nmemory for the location at which individuals heard about the traumatic\nevent may cause them to exaggerate the accuracy of their flashbulb memo-\nries (Rimmele et al., 2012).\nFinally, there are interesting links between flashbulb memories and\nflashbacks (“the intrusive re-experiencing of traumatic experiences in the\npresent”: Brewin, 2015, p. 1). Healthy individuals viewing a trauma film are\nKEY TERM\nFlashbacks\nIntense emotional\nmemories of traumatic\nevents that are recalled\ninvoluntarily by patients\nsuffering from post-\ntraumatic stress disorder.\nInteractive exercise:\nFlashbulb memories\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n351\nmost likely to experience flashbacks subsequently if the amygdala (involved\nin emotional processing) and areas within the occipital cortex involved in\nimagery are activated (James et al., 2016). With such research, it is possible\nto assess individuals’ immediate cognitive and emotional reactions to the\ntraumatic event, which cannot be done when studying flashbulb memories.\nMEMORIES ACROSS THE LIFETIME\nSuppose we ask 70-year-olds to recall personal memories suggested by cue\nwords (e.g., nouns referring to common objects). From which points in\ntheir lives would most memories come? Rubin et al. (1986) answered this\nquestion by combining findings from several studies. Two findings were of\ntheoretical interest:\n●\nInfantile amnesia (or childhood amnesia) shown by the almost total\nlack of memories from the first three years of life.\n●\nReminiscence bump, consisting of a surprisingly large number of mem-\nories coming from the years between 10 and 30 (especially between 15\nand 25).\nInfantile amnesia\nAdults sometimes claim their first autobiographical memory dates back to\n2 years of age or earlier but such memories are typically fictional (Akhtar\net al., 2018). Adults’ genuine first memories rarely date back to earlier than\n2½ or 3 years of age and they also show limited recall for events occurring\nbetween 3 and 6 (see Figure 8.3). How can we explain this phenomenon\n(infantile amnesia or childhood amnesia)? Freud famously (notoriously?)\nattributed it to repression, with threat-related thoughts and experiences\nbeing consigned to the unconscious (see Chapter 6). This dramatic theory\ndoes not explain why adults cannot remember positive and neutral events\nfrom early childhood.\nPsychological theories\nHowe and Courage (1997) argued the development of the cognitive self\n(self-awareness) occurs during the second year of life. This plays an impor-\ntant role in the end of infantile amnesia and the onset of autobiographical\nmemory. The reason is that possession of a cognitive self provides a frame-\nwork for the organisation of autobiographical memories.\nThe social-cultural developmental theory (e.g., Fivush, 2010) provides\nan alternative account, according to which language and culture are both\ncentral to autobiographical memory development. Language is important\nbecause we use it to communicate our memories. Experiences occurring\nbefore children develop language are hard to express in language later on.\nEvidence indicating the importance of language was reported by Jack et al.\n(2009): the age of first recalled memory was earlier in adolescents whose\nmothers reminisced elaborately about the past with their children.\nJack and Hayne (2010) argued the common assumption of a\ngradual decline in infantile amnesia is incorrect. In their study, adults’\nKEY TERMS\nInfantile amnesia\nThe inability of adults to\nrecall autobiographical\nmemories from early\nchildhood; also known as\nchildhood amnesia.\nReminiscence bump\nThe tendency of older\npeople to recall a\ndisproportionate number\nof autobiographical\nmemories from\nadolescence and early\nadulthood.\nCreated from usyd on 2022-02-14 13:22:32.",
    "352\nMemory\nearliest memory dated from 23 months of\nage. However, their memories for the first\n4–6 years of life were sparse. These find-\nings suggest infantile amnesia is a two-stage\nprocess: (1) absolute amnesia for the first two\nyears of life; and (2) relative amnesia for the\nremaining preschool years.\nHow can we account for these two stages?\nAccording to Jack and Hayne (2010), abso-\nlute amnesia ends with the onset of the cogni-\ntive self (consistent with Howe and Courage’s\ntheory). The subsequent strong tendency for\ninformation recalled about childhood events\nto increase as the individual’s age at the time\nincreases probably reflects children’s rapid\ndevelopment of language in early life (con-\nsistent with Fivush’s theory).\nHippocampal neurogenesis\nInfantile amnesia has been observed in all\naltricial species (those showing considera-\nble post-birth development). Such infantile\namnesia cannot be explained with reference to\nnotions such as the cognitive self or language\ndevelopment. However, it can potentially be\nexplained by processes occurring within the\nhippocampus (crucially involved in declar-\native memory including autobiographical\nmemory). We need to focus on hippocampal neurogenesis, a process in\nwhich new neurons are generated within the hippocampus (especially the\ndentate gyrus) early in development. According to Josselyn and Frankland\n(2012, p. 423), “High neurogenesis levels negatively regulate the ability to\nform enduring memories, most likely by replacing synaptic connections in\npre-existing hippocampal memory circuits.”\nMadsen and Kim (2016) reviewed evidence indicating the importance\nof hippocampal neurogenesis in producing infantile amnesia. For example,\nlong-term retrieval in mice was impaired when drugs increased hippocam-\npal neurogenesis. In contrast, long-term retrieval was enhanced when drugs\nreduced hippocampal neurogenesis. Travaglia et  al. (2016) found rats\nduring the infantile amnesia period formed lasting (but relatively inacces-\nsible) memories. However, when activity in the hippocampus was blocked\nprior to learning, such memories were not acquired. Finally, Travaglia\net  al. showed that changing patterns of activation in the hippocampus\nsignalled the end of the infantile amnesia period.\nForgetting\nDefining “infantile amnesia” on the basis of adults’ inability to recall auto-\nbiographical memories from the earliest years of life can lead to the erroneous\nFigure 8.3\nChildhood amnesia based on data reported by Rubin and\nSchulkind (1997). Participants (20, 35 and 70 years of age)\nreported very few autobiographical memories before the age\nof 3 and there was later a levelling off between the ages of 7\nand 10.\nFrom Josselyn and Frankland (2012). © 2012 Cold Spring Harbor\nLaboratory Press. Reproduced with permission of author and Cold\nSpring Harbor Laboratory Press.\nKEY TERM\nHippocampal\nneurogenesis\nThe process of generating\nnew neurons in the\nhippocampus during early\ndevelopment.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n353\nassumption that young children cannot form autobiographical memories. A\nsimple explanation of infantile amnesia is that young children  form auto-\nbiographical memories but these memories are very susceptible to forgetting.\nSupporting evidence was reported by Tustin and Hayne (2016). Three-\nyear-old children learned how to operate a train and their memory for this\nevent was tested after 1 day and 1 year. They exhibited accurate memory\n(including verbal autobiographical memory) on both tests and there was\nno effect of retention interval. However, the children’s memories of the\nevent contained only a few details which may help to explain why most\nearly memories cannot be recalled by adults.\nOverall evaluation\nInfantile amnesia depends on several factors (see Howe, 2019, for a review).\nAbsolute amnesia can probably be explained by hippocampal neurogene-\nsis. After that, the onset of autobiographical memory in infants probably\ndepends on reductions in hippocampal neurogenesis plus the emergence of\nthe cognitive self. Its subsequent expression depends heavily on social and\ncultural factors and children’s language development and possibly also on\ntheir development of semantic memory.\nWhat are the limitations of research in this area? First, most research\nhas focused on adults’ inability to recall autobiographical memories from the\nfirst three years of life. It is generally unclear whether this inability is due to\nseverely deficient initial encoding of such memories, to difficulties in retrieval\nor both. Second, most research is correlational making it hard to establish\ncausality (e.g., the finding that the end of infantile amnesia occurs around the\ntime the cognitive self emerges does not prove the latter causes the former).\nReminiscence bump\nAs mentioned earlier, older people asked to produce personal memo-\nries recall numerous events from adolescence and early childhood (the\nreminiscence bump). Conway et al. (2005) found a reminiscence bump in\nolder individuals in five countries (America, China, Japan, England and\nBangladesh). Of interest, the Chinese (with a collectivistic culture emphasis-\ning group cohesion) were most likely to recall events with a social or group\norientation. In contrast, the Americans (with an individualistic culture\nemphasising personal responsibility and achievement) were most likely to\nrecall events relating to themselves.\nIt has typically been assumed (incorrectly) there is a single reminis-\ncence bump. Koppel & Berntsen (2015) carried out a meta-analysis using\ntwo techniques to assess the reminiscence bump:\n(1) cue-word method in which individuals generate memories to cue\nwords;\n(2) the important memories method in which individuals report  important\npersonal memories.\nTheir key findings were as follows (see Figure 8.4). First, the midpoint of the\nreminiscence bump was 15.5 years using cue words but 21.5 for important\nInteractive exercise:\nReminiscence bump\nCreated from usyd on 2022-02-14 13:22:32.",
    "354\nMemory\nmemories. Second, the reminiscence bump was much stronger using the\nimportant memories method.\nHow can we explain the reminiscence bump(s)? One influential approach\nis Rubin and Berntsen’s (2003) theory based on the notion of a life script\n(cultural expectations about the major life events in most people’s lives).\nExamples include falling in love, marriage and having children. Most such\nevents occur between the ages of 15 and 30. According to the theory, the\nlife script guides and organises the retrieval of autobiographical memories.\nSeveral predictions from the life-script account have been supported.\nFirst, most life events are emotionally positive, and so we would expect to\nfind a reminiscence bump only for positive events. That is precisely what\nBerntsen et al. (2011) found. As expected, the positive events recalled were\nrated as much more central to the participants’ life story than the nega-\ntive ones. Second, there was no reminiscence bump for positive events not\nforming part of the life script (Berntsen et  al.). Third, Scherman (2013)\nFigure 8.4\nTemporal distribution of\nautobiographical memories\nacross the lifespan.\n(a) Top panel: word-cued\nmemories; (b) bottom\npanel: important memories.\nFrom Koppel & Berntsen (2015).\nReprinted with permission of\nElsevier.\n0–5\n6–10\n11–15\n16–20\n20–25\n26–30\n31–35\n36–40\n41–45\n46–50\n51–55\n56–60\n61–65\n66–70\n0\n5\n10\n15\nPercentage of memories\n20\n(a)\n(b)\nAge in years at time of event\n0–5\n6–10\n11–15\n16–20\n20–25\n26–30\n31–35\n36–40\n41–45\n46–50\n51–55\n56–60\n61–65\n66–70\n0\n5\n10\n15\nPercentage of memories\n20\nAge in years at time of event\nKEY TERM\nLife script\nA schema based on\ncultural expectations\nconcerning the nature and\norder of a typical person’s\nmajor life events.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n355\nfound life scripts had a lifespan distribution resembling the reminiscence\nbump in four countries (Denmark, USA, Turkey and the Netherlands).\nMost positive events forming part of the life script involve major\ntransitions (e.g., going to college; marriage; having children). Evidence\ntransitions not directly forming part of the life script are important were\nreported by Enz et al. (2016). Older adults recalled autobiographical events\noccurring between the ages of 40 and 60. Many events recalled occurred\nclose in time to the major transition of a residential move: a relocation\nbump. Thus, autobiographical memories associated with transitions (even\nif not part of the life script) seem to be especially easy to recall, perhaps\nbecause such memories tend to be novel and distinctive.\nWhy does the reminiscence bump depend on the method used? It has\nbeen argued (Koppel & Berntsen, 2016) that the crucial difference between\nthe cue word and important memories methods is the retrieval strategy\nused. Koppel and Berntsen (2016) asked students (mean age = 23) to gen-\nerate the autobiographical memories they imagined a hypothetical 70-year-\nold would produce. With the important memories method, the timing\nand nature of the reminiscence bump were strikingly similar for imagined\nimportant memories and those of actual 70-year-olds.\nSimilar (but much less striking) findings were obtained when compar-\ning imagined and actual memories using the cue-word method. Koppel\nand Berntsen (2016) concluded the different reminiscence bumps pro-\nduced using the two methods “are largely produced by general schematic\nprocesses operative at retrieval” (p. 97).\nIn sum, the reminiscence bump produced using the important memo-\nries method depends on the life script and its associated cultural expecta-\ntions. In addition, it is probably relevant that major life events generally\ninvolve important transitions. In contrast, memories recalled using the\ncue-word method are much less influenced by the life script (Koppel &\nBerntsen, 2015). The finding (Koppel & Berntsen, 2016) that imagined\nmemories differed substantially from actual ones using that method sug-\ngests specifically memory-based processes underlie the reminiscence bump\nassociated with that method.\nTHEORETICAL APPROACHES TO\nAUTOBIOGRAPHICAL MEMORY\nMany theories of autobiographical memory have been proposed over the\nyears. Here we will focus mainly on Conway and Pleydell-Pearce’s (2000)\nself-memory system model and its subsequent development. Then, we\ndiscuss how cognitive neuroscience has contributed to our understanding of\nautobiographical memory.\nSelf-memory system model\nConway and Pleydell-Pearce (2000) argued we possess a self-memory\nsystem having two major components:\n(1) Autobiographical memory knowledge base: this contains personal\ninformation at three levels of specificity:\nResearch activity:\nMemory for personal events\nCreated from usyd on 2022-02-14 13:22:32.",
    "356\nMemory\n●\nLifetime periods: they are defined by major ongoing events and\ngenerally cover substantial periods of time (mean length between\n4 and 15 years: Thomsen, 2015). Different lifetime periods often\noverlap in time (e.g., living with someone may overlap with\nhaving a particular job).\n●\nGeneral events: these include repeated events (e.g., visits to a sports\nclub) and single events (e.g., a holiday in Botswana). General\nevents are often related to each other and to lifetime periods.\n●\nEvent-specific knowledge: this consists of images, feelings and\nother details relating to general events and spanning time periods\nfrom seconds to hours. Event knowledge is usually organised in\nthe correct temporal order.\n(2) Working self: this is concerned with the self, what it may become\nand the individual’s current goals. The working self’s goals influence\nthe memories stored within the autobiographical memory knowl-\nedge base and the autobiographical memories we recall. As a result,\n“Autobiographical memories are primarily records of success or\nfailure in goal attainment” (Conway & Pleydell-Pearce, 2000, p. 266).\nAccording to the theory, autobiographical memories can be accessed in two\nways.\nFirst, there is generative retrieval which involves deliberately con-\nstructing autobiographical memories by applying the working self to infor-\nmation in the autobiographical memory knowledge base. Second, there is\ndirect retrieval: autobiographical memories are triggered effortlessly or\n“automatically” by specific cues (e.g., hearing the word Paris may trigger\nretrieval of a holiday there).\nIt was predicted recalled autobiographical memories would mostly\nbe goal-relevant regardless of retrieval mode. However, events relating to\ncurrent goals are more likely to be recalled with generative retrieval (which\ninvolves top-down processes) than with direct retrieval (which typically\ndepends on bottom-up processes triggered by environmental cues).\nConway (2005) developed the above theory (see Figure 8.5). The\nknowledge structures divided into the conceptual self and episodic memo-\nries (previously called event-specific knowledge). At the top of the hierar-\nchy, the life story and themes have been added. The life story consists of\nvery general factual and evaluative knowledge we possess about ourselves\nand themes referring to major life domains (e.g., work; relationships).\nConway (2005) argued we want our autobiographical memories to\nexhibit coherence (consistency with our current goals and beliefs). However,\nwe also often want them to exhibit correspondence (accuracy). Over time,\ncoherence tends to win out over correspondence.\nConway (2009) refined the theory. He argued the working self consists\nof the individual’s goal system (goals; plans; projects) plus their concep-\ntual self. It determines which autobiographical memories can be accessed.\nIn addition, it is assumed that simple episodic memories resembling each\nother often form complex episodic memories.\nFinally, Conway et al. (2016) developed the notion of episodic memories\nwithin the self-memory system. They identified a remembering– imagining\nKEY TERMS\nGenerative retrieval\nDeliberate or voluntary\nconstruction of\nautobiographical\nmemories based on an\nindividual’s current goals;\nsee direct retrieval.\nDirect retrieval\nEffortless recall of\nautobiographical\nmemories triggered by a\nspecific cue (e.g., being\nin the same place as\nthe original event); see\ngenerative retrieval.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n357\nsystem where episodic memories formed today are most accessible, with\naccessibility decreasing for episodic memories further in the past or future.\nThis system “serves the purpose of integrating past, current, and future\ngoal-related activities” (p. 256). Participants listed all the personal events they\ncould remember from the past 5 days and events they imagined were likely to\noccur over the next 5 days. The findings were as predicted (see Figure 8.6).\nFindings\nResearch on patients with retrograde amnesia (widespread forgetting of\nevents preceding brain injury; see Chapter 7) supports the notion there are\ndifferent types of autobiographical knowledge. These patients often have\ngreater difficulties recalling episodic memories than general events and life-\ntime periods (Conway & Pleydell-Pearce, 2000). For example, Rosenbaum\net al. (2005) found an amnesic patient (KC) with no episodic memories could\nnevertheless access some general autobiographical knowledge.\nFigure 8.5\nThe knowledge structures\nwithin autobiographical\nmemory, as proposed by\nConway (2005).\nReprinted from Conway (2005).\nReprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "358\nMemory\nHow do amnesic patients (with their severely impaired episodic memory)\ncope when recalling autobiographical events? Lenton-Brym et  al. (2017)\nfound amnesic patients were more likely than healthy controls to recall\nfrequently occurring events. This probably happened because it is easier to\nuse semantic memory processes to recall general rather than unique events.\nMcCormick et  al. (2018) supported this viewpoint in a review. Amnesic\npatients use brain areas associated with retrieval of general or schematic\ninformation (e.g., the ventromedial prefrontal cortex; see Chapter 7) when\nretrieving autobiographical memories.\nAccording to the self-memory system model, the accessibility of auto-\nbiographical memories depends on individuals’ goals. Woike et al. (1999)\ncompared individuals with an agentic personality type (motivated by inde-\npendence, achievement and personal power) and those with a communal\npersonality type (motivated by interdependence and similarity to others).\nWhen they recalled a positive personal memory, 65% of agentic individuals\nrecalled agentic memories (e.g., involving success) whereas 90% of com-\nmunal individuals recalled communal memories (e.g., involving love or\nfriendship). With negative personal memories, 47% of agentic individuals\nrecalled agentic memories whereas 90% of communal individuals recalled\ncommunal memories.\nThe model predicts faster recall of autobiographical memories with\ndirect retrieval than generative retrieval. This prediction has support.\nBarzykowski and Staugaard (2016) both found direct retrieval was twice\nas fast as generative retrieval. According to the model, the individual’s\nworking self and goals are more involved in generative than direct retrieval.\nJohannessen and Berntsen (2010) supported this assumption: memories\nelicited by generative retrieval were more significant and relevant to the\nindividual’s personal identity than those involving direct retrieval.\nAddis et al. (2012) found generative retrieval was associated with more\nactivation in prefrontal areas involved in strategic search for autobio-\ngraphical information. This finding is consistent with the plausible notion\nMonday\nTuesday\nWednesday\nThursday\nFriday\nMonday\nTuesday\nWednesday\nThursday\nFriday\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nNow\nFuture\nPast\nFigure 8.6\nThe mean number of\nevents participants could\nremember from the past\n5 days and those they\nimagined were likely over\nthe next 5 days.\nFrom Conway et al. (2016).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n359\nthat generative retrieval involves more top-down processing than direct\nretrieval.\nIt has typically been assumed direct retrieval is involuntary whereas\ngenerative retrieval is voluntary. This assumption is oversimplified.\nBarzykowski and Staugaard (2016) distinguished between retrieval effort\n(high with generative retrieval and low with direct retrieval) and conscious\nintention (voluntary vs involuntary retrieval). They identified three types of\nautobiographical memories: (1) involuntary memories; (2) directly retrieved\nvoluntary memories; and (3) generatively retrieved voluntary memories.\nAccording to the model, lifetime periods differ importantly from\nspecific episodic memories. Various findings support this assumption\n(Thomsen, 2015). First, lifetime periods are regarded as more important\nthan specific memories to an individual’s identity and personality. Second,\nmemory for lifetime periods is less affected by ageing than specific memo-\nries. Third, lifetime period memories are generally less vivid and emotional\nthan specific memories and are associated with less activation in frontal\nareas and the medial temporal lobes (Ford et al., 2011).\nEvaluation\nThe theoretical approach of Conway and Pleydell-Pearce (2000) and\nConway (2009) provides a comprehensive account of autobiographical\nmemory. Several of their main theoretical assumptions (e.g., the hierar-\nchical structure of autobiographical memory; the intimate relationship\nbetween autobiographical memory and the self; the importance of goals in\nautobiographical memory) are well supported. There is also good support\nfor the distinction between generative and direct retrieval.\nWhat are the limitations of the self-memory system model? First, we need\nto know more about how the working self interacts with the auto biographical\nknowledge base to produce recall of specific autobiographical memories.\nSecond, autobiographical memories vary in how much episodic information\n(e.g., contextual details) and semantic information (e.g., world knowledge)\nthey contain. This issue is not addressed fully within the model. Third, the\ndistinction between direct and generative retrieval is oversimplified. Fourth,\nthe model does not fully account for the complexities of autobiographical\nmemory revealed by cognitive neuroscience studies (discussed next).\nCognitive neuroscience\nThe prefrontal cortex plays a major role in autobiographical memory\nretrieval (especially during generative retrieval). Svoboda et  al. (2006)\nfound in a meta-analytic review that the medial and ventromedial prefron-\ntal cortex was nearly always activated during autobiographical retrieval.\nAutobiographical memories are often of personally significant events\nand so are associated with emotion. The amygdala, buried deep within the\ntemporal lobe, is strongly associated with emotion. As expected, amnesic\npatients who also have damage to the amygdala find it harder to retrieve\nemotional autobiographical memories (Buchanan et al., 2006).\nSt. Jacques et  al. (2011) found four brain networks (with strong\nbidirectional connections between them) were activated when individuals\nCreated from usyd on 2022-02-14 13:22:32.",
    "360\nMemory\nproduced autobiographical memories to emotionally arousing words by\ngenerative retrieval (see Figure 8.7):\n(1) Fronto-parietal network: it is involved in the construction of autobi-\nographical memories, associated with adaptive controlled processes\nand is probably involved in verbal retrieval.\n(2) Cingulo-operculum network: it is also involved in the construction of\nautobiographical memories and with goal maintenance.\n(3) Medial prefrontal cortex network: it is involved in the construction\nand subsequent elaboration of autobiographical memories and self-\nreferential processing.\n(4) Medial temporal lobe network: it is involved in the construction and\nsubsequent elaboration of autobiographical memories and associated\nwith declarative memory conscious recollection.\nInman et  al. (2018) studied dynamic changes in brain activation during\ntwo stages of generative retrieval of autobiographical memories. First, pro-\ncesses involved in searching for and accessing autobiographical memories\ninvolved a ventral frontal to temporal-parietal network. Second, subse-\nquent elaborative processing of these memories involved strong connections\nbetween occipital-parietal areas and dorsal fronto-parietal regions. There\nwas no sudden switch between the two processing stages: rather, the relative\ndominance of access-related and elaboration-related processing altered over\ntime.\nFigure 8.7\nA model of the bidirectional\nrelationships between\nneural networks involved\nin the construction\nand/or elaboration of\nautobiographical memories.\nMTL = medial temporal\nlobe network; medial PFC =\nmedial prefrontal cortex.\nFrom St. Jacques et al. (2011).\nReprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n361\nIN THE REAL WORLD: DEPRESSION AND AUTOBIOGRAPHICAL\nMEMORY\nIt is assumed within the self-memory system model that information stored in (and retrieved from)\nautobiographical memory reflects the individual’s personality and sense of self. This assumption\nhas been applied in studies on depressed individuals.\nResearch has often involved participants recalling autobiographical memories of events lasting\nless than one day to word cues. Depressed individuals typically produce over-general negative\nmemories (Fisk et al., 2019). For example, a depressed person might respond “Arguing with other\npeople” to the cue “angry”.\nMost evidence shows only an association or correlation between over-general memories and\ndepression and so does not demonstrate the former partially causes the latter. Stange et  al.\n(2013) reported more convincing evidence. The extent of over-general autobiographical memory\npredicted increases in depressive symptoms 8 months later in those exposed to high levels of\nfamilial emotional abuse.\nDalgleish et al. (2011) asked patients with current major depressive disorder, patients in remission\nfrom that disorder and healthy controls to list their most important lifetime periods. After that, the\npatients decided which positive and negative items (words or phrases) applied to each period.\nFour measures were identified:\n(1)\nthe proportion of items that was negative;\n(2)\ncompartmentalisation (the extent to which the proportion of items that was negative varied\nacross lifetime periods);\n(3)\npositive redundancy (the extent to which the same positive terms were used across periods);\n(4)\nnegative redundancy (the extent to which the same negative terms were used across\nperiods).\nFigure 8.8\nLife structure scores (proportion negative, compartmentalisation, positive redundancy,\nnegative redundancy) for patients with major depressive disorder, patients in remission\nfrom major depressive disorder and healthy controls.\nFrom Dalgleish et al. (2011). © 2010 American Psychological Association.\nCreated from usyd on 2022-02-14 13:22:32.",
    "362\nMemory\nThe proportion of selected terms that was negative was much greater for current depressed\npatients than controls (see Figure 8.8). In addition, current patients had a less integrated sense of\nself (i.e., greater compartmentalisation). This occurred in part because current depressed patients\nshowed little consistency in their use of positive terms across lifetime periods (i.e., low positive\nredundancy). Finally, depressed patients in remission were intermediate between current patients\nand controls on most measures.\nWhat do these findings mean? First, the organisation of autobiographical knowledge in currently\ndepressed patients is relevant to their working self (Conway & Pleydell-Pearce, 2000). More\ngenerally, current patients’ perceived self is revealed in the predominantly negative and non-\nintegrated structure of their autobiographical knowledge.\nSecond, the structure of autobiographical knowledge is more integrated and less pervasively\nnegative in patients in remission than current patients. Thus, recovery from major depressive\ndisorder involves having a “healthier” perspective on one’s life history.\nThird, patients in remission nevertheless had a more negative and less integrated view of their\nlife history than healthy controls. These findings suggest these patients were at risk of a subsequent\ndepressive episode.\nDalgleish and Werner-Seidler (2014) identified four cognitive biases in depression associated\nwith autobiographical memory recall (see Figure 8.9). First, there is a strong tendency to recall\nnegative autobiographical memories. Second, there is impoverished access to positive memories.\nThird, depressed individuals recall over-general negative memories. Fourth, depressed individuals\nhave an altered relationship to their emotional memories in that they try (typically unsuccessfully)\nto avoid or suppress negative memories.\nFigure 8.9\nFour cognitive biases related to autobiographical memory recall that maintain depression and increase the risk\nof recurrence following remission.\nThe Figure is Figure 1 in an article by Dalgleish and Werner-Seidler (2014) in Trends in Cognitive Sciences published by Cell\nPress.\nBiased recollection\nof negative memories\nImpoverished\npositive memories\nOver-general\nmemory\nDepression\nAltered relationship to\nemotional memories\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n363\nInterventions\nHow can we use our knowledge of depressed individuals’ biases relating to autobiographical\nmemory to reduce their level of depression? Some answers were discussed by Dalgleish and\nWerner-Seidler (2014). One approach is to use MEmory Specificity Training (MEST) where the\nemphasis is on training depressed patients to generate more specific autobiographical memories\n(e.g., for homework, patients produce specific memories to 10 cue words). MEST reduces rumination\n(repeated negative self-focused thoughts and images) and cognitive avoidance. Werner-Seidler\net al. (2018) found in patients with major depressive disorder that MEST increased the specificity\nof their autobiographical memories and reduced their depressive symptoms.\nHitchcock et  al. (2016) used memory flexibility (MemFlex) training with individuals in remission\nfrom depression. This training focuses on the development of three important autobiographical\nmemory skills:\n(1)\nBalancing involves enabling depressed individuals to recollect positive and negative, specific\nand general memories, with equal ease.\n(2)\nElaboration focuses on allowing depressed individuals to store richer and more elaborative\npositive memories by focusing on emotional and situational details of such memories.\n(3)\nFlexibility involves training individuals to control whether the memories they recall are\ngeneral or specific. They also learn to identify situations where specific memories are\noptimal (e.g., solving a problem) and those where general memories are optimal (e.g., when\nconsidering the strength of a friendship).\nHitchcock et al. (2016) found MemFlex training increased the specificity of recalled autobiographical\nmemories, reduced rumination and improved social problem solving.\nIN THE REAL WORLD: IS EYEWITNESS CONFIDENCE TRUSTWORTHY?\nIn the United States, over 200 individuals convicted on the basis of mistaken eyewitness identification\nhave been proved innocent by DNA tests. Garrett (2011) reviewed 161 such cases and discovered\nvirtually all the mistaken eyewitnesses were certain at trial they had identified the culprit. These\nfindings suggest we should ignore the confidence (or otherwise) eyewitnesses express in their\nidentifications. However, that conclusion is not warranted.\nOne case Garrett (2011) examined was that of Ronald Cotton. In 1985, he was found guilty\nof raping Jennifer Thompson because of her confident eyewitness identification of him as the\nculprit. However, he was exonerated by DNA evidence, after having spent over 10 years in prison.\nOf crucial importance, when Jennifer Thompson initially identified Cotton from a photo line-up,\nshe hesitated for almost 5 minutes before eventually saying “I think this is the guy”. This case\nEYEWITNESS TESTIMONY\nSuppose you are the only eyewitness to a very serious crime. Subsequently\nthe person you identify as the murderer on a line-up is found guilty although\nthere is no other strong evidence. Is it safe to rely on eyewitness testimony?\nSimons and Chabris (2011) found 37% of Americans believe the testimony\nof a single confident eyewitness is sufficient to convict a criminal defendant.\nIn fact, as we will see, eyewitness testimony can be very fallible.\nCreated from usyd on 2022-02-14 13:22:32.",
    "364\nMemory\nis not unique. Garrett (2011, p. 49) found “In\n57% of trials transcripts (92 out of 161 cases), the\nwitnesses reported they had not been certain at\nthe time of their earlier identifications”.\nWhy does eyewitness confidence often increase\nsubstantially from initial identification to courtroom?\nWith Jennifer Thompson, positive feedback from\nthe police following her initial identification caused\nher to become increasingly confident she had\nidentified the culprit. Douglass and Steblay (2006)\nshowed the importance of such feedback in a meta-\nanalytic review. Eyewitnesses receiving confirming\nfeedback after an identification (e.g., “Good, you\nidentified the suspect”) believed mistakenly they\nhad been very confident in the accuracy of their\nidentification before receiving feedback: the “post-\nidentification feedback effect”.\nIn sum, two conclusions are warranted. First,\nwe can generally trust eyewitnesses’ confidence\nin their identifications provided we focus on\ntheir  initial level of confidence. Wixted et  al. (2016) supported this conclusion in a large-scale\nreal-life study of eyewitnesses’ initial identifications. When eyewitness confidence was low, only\n20% of  identifications were of the suspect. This increased dramatically to approximately 80%\nwhen  their confidence was high. Second, “Testimony-relevant witness judgements should be\ncollected and documented, preferably with videotape, before feedback can occur” (Steblay et al.,\n2014).\nJennifer Thompson and Ronald Cotton. Ronald\nCotton was mistakenly found guilty of raping Jennifer\nThompson and spent many years in prison before\nbeing exonerated.\nFrom Wixted and Wells (2017). Image provided courtesy of the\nPopTech Institute.\nEyewitness memory is inaccurate for several reasons. We start with\nconfirmation bias – eyewitnesses’ memory is influenced by their expec-\ntations. For example, Lindholm and Christianson (1998) found Swedish\nand immigrant students who saw a simulated robbery were twice as likely\nto select an innocent immigrant as an innocent Swede as the culprit.\nParticipants’ expectations were influenced by the fact that immigrants are\nover-represented in Swedish crime statistics.\nBartlett (1932) argued we have numerous schemas (packets of knowl-\nedge) in long-term memory strongly influencing what we remember (see\nChapter 10). Most people’s bank-robbery schema includes information\nthat robbers are typically male, wear disguises and have a getaway car\nwith a driver (Tuckey & Brewer, 2003a). Tuckey and Brewer showed eye-\nwitnesses a video of a simulated bank robbery. As predicted, eyewitnesses\nrecalled information relevant to the bank-robbery schema better than irrel-\nevant information (e.g., the colour of the getaway car).\nSchemas can also cause memory distortions because we reconstruct an\nevent’s details based on “what must have been true”. In a study by Tuckey\nand Brewer (2003b), some eyewitnesses saw a robber’s head covered by a\nbalaclava (ski mask) so their gender was ambiguous. Eyewitnesses mostly\ninterpreted the ambiguous information as being consistent with their\nbank-robbery schema. Thus, their recall was systematically distorted by\nincluding information from their bank-robbery schema.\nKEY TERM\nConfirmation bias\nA tendency for\neyewitnesses’ memory to\nbe distorted by their prior\nexpectations.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n365\nMisinformation effect\nThe most obvious reason why eyewitnesses’ memories are often inaccurate\nis that they fail to attend fully to the crime situation. After all, it typically\noccurs suddenly and unexpectedly. However, Loftus and Palmer (1974)\nemphasised a different reason – eyewitness memories are fragile and can\neasily be distorted by misleading information provided after the witnessed\nevent: the misinformation effect.\nFindings\nLoftus and Palmer (1974) showed eyewitnesses a film of a car accident.\nAfterwards, some were asked “About how fast were the cars going when\nthey smashed into each other”. For other eyewitnesses, the word “hit”\nreplaced “smashed into”. The estimated speed averaged 41 mph when the\nverb “smashed” was used versus 34 mph when “hit” was used. Thus, infor-\nmation implicit in the question influenced memory for the accident. One\nweek later, all eyewitnesses were asked whether they had seen any broken\nglass. There was no broken glass, but 32% of those previously asked about\nspeed using the verb “smashed” said they had seen broken glass compared\nto only 14% of those asked using the verb “hit”.\nA misinformation effect involving more directly misleading informa-\ntion was reported by Loftus et al. (1978). Eyewitnesses saw several slides,\none showing a red Datsun car stopping at a stop or yield sign. Afterwards\nthey were asked, “Did another car pass the red Datsun while it was stopped\nat the stop sign?” or the word “stop” was replaced by “yield”. In a third\ncondition, the key question did not refer to a sign at all. Finally, the eye-\nwitnesses decided which of two slides (car with a stop sign and car with\na yield sign) they had seen previously. Eyewitness more often selected the\nwrong slide when the earlier question was misleading than when it was\naccurate or did not refer to the sign.\nEyewitness memory can also be distorted by information presented\nbefore an event. Lindsay et  al. (2004) showed eyewitnesses a video of a\nmuseum burglary. Eyewitnesses who had listened to a thematically similar\nnarrative (a palace burglary) the previous day made many more errors\nwhen recalling information from the video than those who had listened to\na thematically dissimilar narrative (a school trip to a palace). This finding\nis important because eyewitnesses often have relevant past experiences that\nmay distort their memory for a crime.\nThe misinformation effect has generally been found for peripheral or\nminor details (e.g., presence of broken glass in the study by Loftus and\nPalmer, 1974) rather than central ones. In similar fashion, Putnam et  al.\n(2017) found the misinformation effect was much greater for relatively\nunmemorable than memorable details (see Figure 8.10).\nPutnam et al. (2017) pointed out that most textbook accounts assume\nthe misinformation effect is nearly always found. However, they obtained\ncontrary evidence. Misinformation led to enhanced recognition memory for\nan event when participants detected (and remembered) changes between\nthat event and the post-event misinformation. What is happening here?\nKEY TERM\nMisinformation effect\nThe distorting effect on\neyewitness memory of\nmisleading information\npresented after a crime or\nother event.\nCreated from usyd on 2022-02-14 13:22:32.",
    "366\nMemory\nMisinformation sometimes acts as a cue that facilitates retrieval of details\nfrom the actual event.\nTheoretical accounts\nHow does misleading information distort what eyewitnesses report? Is the\noriginal memory permanently altered or does it still exist but is inaccessible?\nLoftus (1979) argued misinformation causes the previously formed memory\nof an event to be “overwritten” and destroyed. Loftus (1992) argued for\na less extreme position – the original memory remains but eyewitnesses\n“accept” misinformation as forming part of the event memory.\nEdelson et  al. (2011) had eyewitnesses watch a crime scene in small\ngroups and then recall the crime events three days later (Test 1). Four days\nlater, they were misinformed their fellow eyewitnesses remembered several\nevents differently from them. This was followed immediately by a memory\ntest (Test 2) during which their brain activity was recorded. A week later,\nthe eyewitnesses were told the answers allegedly given by their fellow eye-\nwitnesses had been generated at random. Finally, they received another\nmemory test (Test 3).\nEdelson et al. (2011) decided whether eyewitnesses pretended to agree\nwith the group on Test 2 or whether their memories had genuinely changed\nby seeing if they maintained their incorrect answers on Test 3. Brain activ-\nity during Test 2 indicated enhanced connectivity between the amygdala\nand hippocampus (both centrally involved in memory formation) was\nassociated only with memories that had genuinely changed. Edelson et al.\nFigure 8.10\nSize of the misinformation effect as a function of detail memorability in the neutral\ncondition (i.e., absence of misleading information).\nFrom Putnam et al. (2017).\n1.00\n0.80\n0.60\nHit rate: Neutral condition\nFalse alarm rate: Misinformation condition\n0.40\n0.20\nr = –0.55\n0.00\n0.00\n0.20\n0.40\n0.60\n0.80\n1.00\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n367\n(2011, p. 108) concluded that a long-lasting misinformation effect occurred\nonly when there was a reconsolidation process (see Glossary) that “modi-\nfied the neural representation of memory”.\nOeberst and Blank (2012) argued misinformation does not cause per-\nmanent alteration of memory traces of a witnessed event. According to\nthem, the misinformation effect occurs because eyewitnesses are instructed\nto recall the single correct account of an event. Oeberst and Blank told\neyewitnesses they had received contradictory information and encouraged\nthem to recall everything from the event and the misinformation. This\nmanipulation completely eliminated the misinformation effect! Thus, the\noriginal memory traces were essentially intact.\nBlank and Launay (2014) carried out a meta-analysis of studies on\nthe misinformation effect where eyewitnesses were warned of the presence\nof misinformation after viewing an event. Post-warning reduced the mis-\ninformation effect to between one-third and one-half of its size when no\nwarning was provided (see Figure 8.11). Higham et  al. (2017) found the\nmisinformation effect was eliminated when the post-warning was specific\n(i.e., it identified event details for which misinformation had been pre-\nsented earlier) but not when it was general (i.e., indicating there had been\nmisinformation).\nOne reason event memories are inaccessible is source misattribution\n(Johnson et  al., 1993). In essence, a memory probe (e.g., question) acti-\nvates memory traces overlapping with it in information. Source misattri-\nbution is most likely when the memories from one source resemble those\nfrom a second source (e.g., Lindsay et al., 2004, discussed above, p. 366).\nPrull and Yockelson (2013) reported evidence suggesting the importance\nof source misattribution. The misinformation effect was much smaller\nwhen eyewitnesses received a source-recognition test encouraging them to\nretrieve source information.\nFigure 8.11\nExtent of misinformation effects (expressed as an odds ratio) as a function of condition\n(post-warning vs no warning) for the original memory and endorsement of the\nmisinformation presented previously.\nFrom Blank & Launay (2014). Reprinted with permission of Elsevier.\n0\nPost-warning\nNo warning\nOriginal memory\n1\n2\n3\n4\nOdds ratio\n5\n6\n7\nPost-warning\nNo warning\nMisinformation Endorsement\nNo misinformation efort\nCreated from usyd on 2022-02-14 13:22:32.",
    "368\nMemory\nIn sum, the misinformation effect is often due to inaccessibility of\ninformation about the original event rather than altered memory traces.\nHowever, some evidence supports the latter explanation (Edelson et  al.,\n2011). Overall, the findings suggest the effects of misinformation on\nmemory performance are not direct. Instead, memory performance is influ-\nenced flexibly by the precise strategies used by eyewitnesses to combine and\nintegrate the information available to them.\nOther factors can also be involved (Wright & Loftus, 2008). One\nexample is the vacant slot explanation (misinformation is more likely to be\naccepted when related information from the original event was not stored\nin memory). Another example is the blend explanation (misinformation\nand information from the original event are integrated in memory).\nFinally, the misinformation effect involves retroactive interference (see\nGlossary). Since retroactive interference with standard verbal memory tasks\ncan be caused by several factors (see Chapter 6), it is unsurprising that the\nsame is true of retroactive interference for criminal and other events.\nWeapon focus, anxiety and violence\nHow do anxiety and violence influence eyewitness memory? There is\nevidence for the weapon focus effect – eyewitnesses attend to the criminal’s\nweapon, which reduces their memory for other information. For example,\nBiggs et  al. (2013) found observers fixated weapons more than  neutral\nobjects and so faces were fixated less often in the weapon condition.\nHarada et  al. (2015) found observers’ memory for peripheral stimuli\nwas reduced in the presence of a weapon. This finding is consistent with\nEasterbrook’s (1959) hypothesis. According to this hypothesis, anxiety\ncauses a narrowing of attention to central or important stimuli causing\na reduction in individuals’ ability to remember peripheral details (see\nChapter 15).\nPickel (2009) pointed out that individuals often attend to stimuli that\nare unexpected in the current situation (inconsistent with their situational\nschema), which impairs their memory for other stimuli. She argued the\nweapon focus effect would be greater when the presence of a weapon\nwas very unexpected. As predicted, the effect was especially strong when\na criminal carrying a folding knife was female, because seeing a woman\nwith a knife is unexpected. In similar fashion, the weapon focus effect was\nstronger when a male criminal carrying a handgun was white rather than\nblack because of the mistaken stereotype linking black men with weapons.\nFawcett et al. (2013) carried out a meta-analysis on the weapon focus\neffect. There was a moderate effect that was comparable in the laboratory\nand the real world. Peripheral details were often poorly remembered when\nthe central object was unusual or unexpected in the current situation (even\nwhen the object was not a weapon).\nFawcett et  al. (2016) discussed studies showing the presence of a\nweapon made it harder for eyewitnesses to discriminate the culprit from\ninnocent individuals on a line-up. It also increased the probability of\nmaking false identifications.\nHow do stress and anxiety influence eyewitness memory? Deffenbacher\net al. (2004) carried out a meta-analysis. Culprits’ faces were identified 54%\nKEY TERM\nWeapon focus effect\nThe finding that\neyewitnesses pay so\nmuch attention to the\npresence of a weapon\n(e.g., gun) that they\nignore other details and\nso cannot remember them\nsubsequently.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n369\nof the time in low-stress conditions versus 42% in high-stress conditions\nand the findings were comparable for recall of details. Thus, stress and\nanxiety generally impair eyewitness memory. Morgan et al. (2013) consid-\nered the effects of very high stress. Military personnel endured a 3-minute\nstressful interrogation involving physical assault (e.g., slamming into a\nwall; facial slaps). Participants’ memory was generally poor and over 50%\nfailed to identify their interrogator correctly.\nOne reason stress impairs eyewitness memory is because it causes a\nnarrowing of attention (see Easterbrook’s hypothesis discussed above).\nYegiyan and Lang (2010) presented people with distressing pictures. As\npicture stressfulness increased, recognition memory for the central details\nimproved progressively. In contrast, memory for peripheral details was\nmuch worse with highly stressful pictures than with moderately stress-\nful ones. Thus, the findings supported Easterbrook’s hypothesis. Note,\nhowever, that “memory narrowing” is not always directly caused by\n“attentional narrowing” (see Chapter 15).\nAgeing and memory\nOlder eyewitnesses’ memory is less accurate than that of younger adults and\nthey exhibit greater misinformation effects. Jacoby et al. (2005) presented\nmisleading information to younger and older adults. The older adults had\na 43% chance of producing false memories at recall compared to only 4%\nfor the younger adults. Older adults have impaired ability to use cognitive\ncontrol effectively to focus retrieval on correct information (Keating et al.,\n2017) and are also less likely to monitor their own recall to reduce errors\n(Morcom, 2016).\nWright and Stroud (2002) studied differences between younger and\nolder adults identifying culprits after viewing crime videos. There was an\nown-age bias – both groups performed better when the culprit was of a\nsimilar age to themselves. Eyewitnesses may sometimes attend more closely\nto culprits of their own age. However, Neumann et al. (2015) found young\nadults did not attend more to young faces than older ones.\nOwn-age bias might be due to expertise: most people have greater\nexposure to (and familiarity with) faces of individuals of their own age.\nWiese et  al. (2013) reported supporting evidence. Young geriatric nurses\nhad no own-age bias because, due to their experience with older people,\nthey recognised old faces much better than did young controls.\nEyewitness identification: face recognition\nEyewitness identification typically depends mainly on face recognition\nalthough other factors (e.g., an individual’s build and/or clothing) can be\nrelevant. There is compelling evidence that most people find it surprisingly\nhard to recognise unfamiliar faces; this is of direct relevance to eyewit-\nnesses’ memory for culprits’ faces. Poor recognition of unfamiliar faces\noccurs in part because different photographs of the same person display\nconsiderable variability and are often regarded incorrectly as coming\nfrom different individuals (see Figure 3.18) (Jenkins et al., 2011; Young &\nBurton, 2018).\nKEY TERMS\nOwn-age bias\nThe tendency for\neyewitnesses to identify\nthe culprit more often\nwhen they are of similar\nage to the eyewitness\nthan when they are of a\ndifferent age.\nCreated from usyd on 2022-02-14 13:22:32.",
    "370\nMemory\nThe police often ask eyewitnesses to identify the person responsible for\na crime from several individuals physically present in a line-up or shown\nin photographs. Valentine et  al. (2003) found eyewitness identification is\nvery fallible. Of 640 eyewitnesses trying to identify suspects in 314 real line-\nups, only 40% identified the suspect, 20% identified a non-suspect and 40%\nfailed to make an identification.\nEyewitnesses who are very confident about face identification tend to\nbe more accurate than those less confident (Brewer & Wells, 2011). For\nexample, Odinot et al. (2009) studied the memory of 14 eyewitnesses of an\nactual supermarket robbery in the Netherlands. There was a moderate cor-\nrelation (+.38) between eyewitness confidence and accuracy. Wixted et al.\n(2016; discussed earlier, see p. 364) also found that eyewitness confidence\npredicted accuracy of culprit identification in a real-life study.\nEyewitnesses sometimes remember a face but fail to remember the\nprecise circumstances in which they saw it. Ross et al. (1994) had eyewit-\nnesses observe an event where a bystander and the culprit were present.\nThey were three times more likely to select the bystander from a line-up\nthan someone else not seen before when the culprit was not present. This\nis unconscious transference – a face is correctly recognised as having been\nseen before but incorrectly judged to be responsible for a crime. In similar\nfashion, eyewitnesses are more likely to identify a suspect on a line-up if\nthey have previously been seen in a line-up (Steblay & Dysart, 2016).\nAnother relevant finding is the other-race effect – same-race faces are\nidentified better than other-race faces (Young et al., 2012). Unsurprisingly,\neyewitnesses having the most experience with members of another race\nhave a relatively small other-race effect (Hugenberg et al., 2010).\nContrary to common belief, the other-race effect does not depend\nentirely on problems with remembering other-race faces. Megreya et  al.\n(2013) found perceptual processes are also involved (see Figure 8.12).\nBritish and Egyptian participants viewed a target face and an array of\nten faces. They decided whether the target face was in the array; if so,\nthey identified it. There were minimal memory demands on memory as\nall the photographs were visible. Megreya et  al. obtained the other-race\neffect:  (1)  the target was correctly identified more often with same-race\nfaces than other-race ones (70% vs 64%, respectively); and (2) when\nthe target face was absent, mistaken identification of a non-target face\nwas more frequent with other-race than same-race faces (47% vs 34%,\nrespectively).\nBrown et al. (2017) replicated the other-race effect. There was greater\nactivation of fronto-parietal networks (involved in top-down attention\nand cognitive control) during encoding of same-race than other-race faces.\nThese findings suggest that problems with remembering other-race effects\nare due to reduced attention to (and processing of) such faces.\nIn a study by Jenkins et  al. (2011), observers showed very poor face\nrecognition because photographs of the same face often show considera-\nble variability (see Chapter 3). As a consequence, it is generally hard for\neyewitnesses to make a correct identification from a single photograph as\nthey are typically requested to do. It follows that eyewitnesses’ ability to\nidentify unfamiliar faces might be enhanced if presented with multiple pho-\ntographs of the same person.\nKEY TERMS\nUnconscious\ntransference\nThe tendency of\neyewitnesses to\nmisidentify a familiar (but\ninnocent) face as being\nthe person responsible for\na crime.\nOther-race effect\nThe finding that\nrecognition memory\nfor same-race faces is\ngenerally more accurate\nthan for other-race faces.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n371\nJones et  al. (2017) tested the above implication. Participants viewed\na single front-view photograph of an individual (the target), seven pho-\ntographs of that individual at different orientations or seven computer-\ngenerated synthesised images of that individual at different orientations\n(see Figure 8.13). Subsequently, participants selected the target face from\nFigure 8.13\nPanel (a): seven photographs of the same individual taken from different angles; Panel (b): seven synthesised images of\nthe same individual at different orientations.\nFrom Jones et al. (2017).\nFigure 8.12\nExamples of Egyptian (left) and UK (right) face-matching arrays. The task was to decide whether the person shown at the\ntop was present in the array underneath.\nCreated from usyd on 2022-02-14 13:22:32.",
    "372\nMemory\nan array of five faces. As predicted, face-recognition performance was\nworst following presentation of a single photograph and best following\npresentation of synthesised images. This is important because police can\ngenerate such synthesised images from a single photograph.\nFrom laboratory to courtroom\nCan we apply findings from laboratory studies to real-life crimes? There\nare several differences. First, eyewitnesses are much more likely to be the\nvictims in real life than the laboratory. Second, it is much less stressful to\nwatch a video of a violent crime than to experience it. Third, in laboratory\nresearch the consequences of an eyewitness making a mistake are trivial but\ncan literally be a matter of life or death in an American trial.\nThere are also important similarities. Ihlebaek et  al. (2003) used a\nstaged robbery involving two robbers with handguns. In the live condi-\ntion, eyewitnesses were ordered repeatedly to “Stay down!”. A video taken\nduring the live condition was presented to eyewitnesses in the video con-\ndition. Eyewitnesses in both conditions exaggerated event duration and\nshowed similar patterns in what they remembered. However, those in the\nvideo condition recalled more information. In another study (Pozzulo et al.,\n2008), eyewitnesses observed a staged theft live or via video. Eyewitnesses\nin the live condition reported more stress and arousal but correct identifi-\ncation of the culprit was comparable in the two conditions.\nTollestrup et al. (1994) analysed police records concerning the identi-\nfications by eyewitnesses to crimes involving fraud and robbery. Factors\nimportant in laboratory studies (e.g., weapon focus; retention interval)\nwere also important in real-life crimes.\nIn sum, artificial laboratory conditions typically distort the findings\nonly modestly. If anything, the errors in eyewitness memory under labora-\ntory conditions underestimate memory deficiencies for real-life events. This\nis due in part to the generally greater stressfulness of witnessing real-life\ncrimes. Overall, laboratory research is definitely relevant to the legal system.\nENHANCING EYEWITNESS MEMORY\nThe police obviously have no control over the circumstances at the time\nof the crime (e.g., lighting; event duration). Such uncontrollable factors\nare known as estimator variables (Albright, 2017). There are also factors\n(known as system variables) that can be controlled by the criminal justice\nsystem; they include how line-ups are presented to eyewitnesses and inter-\nview techniques used to question eyewitnesses. These system variables are\ndiscussed below.\nLine-ups\nLine-ups can be divided into those involving double-blind and those involv-\ning single-blind administration. With double-blind administration, the\nline-up is conducted by administrators who do not know which line-up\nmember is the suspect, whereas they do have such knowledge with single-\nblind administration. Double-blind administration is preferable because\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n373\nsingle-blind administration can cause systematic bias in the identification\nmade by the eyewitness (Kovera et al., 2017).\nLine-ups can be simultaneous (the eyewitness sees everyone at the same\ntime) or sequential (the eyewitness sees only one person at a time). Which\napproach is more effective? Steblay et al. (2011) conducted a meta-analysis.\nWhen the culprit was present, they were selected 52% of the time with simul-\ntaneous line-ups compared to 44% with sequential ones. When the culprit\nwas absent, eyewitnesses mistakenly selected someone with simultaneous\nline-ups more often than with sequential ones (54% vs 32%, respectively).\nThus, eyewitnesses adopt a more stringent criterion with sequential line-ups.\nMisidentifications with sequential line-ups in the laboratory can be\nreduced by providing a “not sure” option. This reduced misidentifications\nfrom 22% to only 12% (Steblay & Phillips, 2011). Warning eyewitnesses\nthe culprit may not be in the line-up also reduces misidentification errors\n(Steblay, 1997).\nWells et  al. (2015) carried out a large-scale study differing from most\nstudies reviewed by Steblay et al. (2011) in two main ways. First, it involved\neyewitnesses to actual crimes rather than videoed or staged laboratory crimes.\nSecond, the eyewitnesses were permitted to say they were “not sure” (as\nhappens in most real-life crime cases). In contrast, the great majority of labo-\nratory studies require eyewitnesses to make definite “yes” or “no” decisions.\nWhat did Wells et al. (2015) find? First, the suspect was identified 25%\nof the time with both simultaneous and sequential line-ups. Second, an\ninnocent person was identified incorrectly more often with simultaneous\nthan sequential line-ups (18% vs 11%). Third, eyewitnesses used the “not\nsure” response more often in the sequential line-up: eyewitnesses were\nunsure whether a subsequently viewed person might resemble the culprit\nmore than the current one.\nWixted et  al. (2016) also studied eyewitnesses to real-life crimes and\nobtained confidence ratings from these eyewitnesses when exposed to\nsequential or simultaneous line-ups. Eyewitnesses identified 91% of sus-\npects having independent evidence of guilt against them with simultane-\nous line-ups compared to 76% with sequential line-ups. When account was\ntaken of eyewitnesses’ confidence ratings, their overall performance was\nslightly better with simultaneous line-ups.\nIn sum, eyewitnesses are more likely to identify the culprit with simul-\ntaneous line-ups. However, innocent individuals are also more likely to\nbe selected on simultaneous line-ups. Which type of line-up is preferable\ndepends on the precise magnitude of these two effects.\nCognitive interview\nPsychologists have contributed substantially to the goal of maximising\nthe information provided by eyewitnesses being interviewed by developing\nthe cognitive interview. This is based on four retrieval rules (Geiselman &\nFisher, 1997):\n(1) mental reinstatement of the environment and any personal contact\nexperience during the crime (context reinstatement);\n(2) encouraging the reporting of every detail including minor ones;\nCreated from usyd on 2022-02-14 13:22:32.",
    "374\nMemory\n(3) describing the incident in several different orders (e.g., backwards in\ntime);\n(4) reporting the incident from different viewpoints, including those of\nother eyewitnesses; Anderson and Pichert (1978) found this strategy\nuseful (see Chapter 10).\nThese retrieval rules are based on our knowledge of human memory. The\nfirst two rules derive from the encoding specificity principle (Tulving, 1979;\nsee Chapter 7). According to this principle, recall depends on the overlap or\nmatch between the context in which an event is witnessed and that at recall.\nThe third and fourth rules are based on the assumption that memory traces\ncontain several kinds of information. As a result, crime information can be\nretrieved using different retrieval routes.\nThere have been two major changes in the cognitive interview (Memon\net al., 2010a). First, researchers developed an enhanced cognitive interview.\nThis differed from the basic cognitive interview by emphasising the impor-\ntance of creating rapport between interviewer and eyewitness. Roy (1991,\np. 399) indicated how this can be achieved:\nInvestigators should minimise distractions, induce the eyewitness\nto speak slowly, allow a pause between the response and next ques-\ntion, tailor language to suit the individual eyewitness, follow up with\ninterpretive comment, try to reduce eyewitness anxiety and avoid\njudgemental and personal comments.\nSecond, the police typically shorten the cognitive interview emphasising the\nfirst two retrieval rules discussed earlier. This is done in part because the\nentire cognitive interview can be very time-consuming.\nFindings\nMemon et  al. (2010a) carried out a meta-analysis comparing the cogni-\ntive interview with the standard police interview. Many more details were\ncorrectly recalled by eyewitnesses with the cognitive interview (basic or\nenhanced). However, its beneficial effects were reduced in highly arous-\ning situations or with a long retention interval between the incident and\ninterview. Nevertheless, the cognitive interview remained effective even\nwith high arousal and a long retention interval. The main limitation of the\ncognitive interview was that there was a fairly small increase in recall of\ncorrect details compared to the standard interview. In addition, the cogni-\ntive interview does not reduce the adverse effects of misleading information\npresented beforehand (Menon et al., 2009b).\nAre all four components of the cognitive interview equally important?\nNo. Colomb and Ginet (2012) found mental or context reinstatement of\nthe situation and reporting all the details both enhanced recall. However,\naltering the eyewitness’s perspective and changing the order of recall were\nineffective. Dando et al. (2011) found requiring eyewitnesses to recall infor-\nmation in a backward temporal order reduced correct recall and increased\nmemory errors. These negative effects occurred because backward recall\ndisrupted the temporal organisation of eyewitness memory for the crime.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n375\nHow can we increase eyewitness accuracy using the cognitive inter-\nview? Paulo et al. (2016) found eyewitnesses’ error rate was 6% when they\nseemed certain of what they were recalling but 23% when they seemed\nuncertain. Thus, accuracy can be improved by taking account of eyewit-\nnesses’ confidence. Paulo et  al. (2017) adapted the cognitive interview to\ninclude category clustering recall – eyewitnesses organised their recall in\ncategories (e.g., person details; location details; action details). This pro-\nduced enhanced recall compared to the standard cognitive interview and\nreduced errors. Category clustering recall was effective because it pro-\nvided eyewitnesses with cues providing an organised structure to facilitate\nretrieval of event information.\nEvaluation\nThe cognitive interview has a well-established theoretical and empiri-\ncal basis. It is an effective method for obtaining as much accurate infor-\nmation as possible from eyewitnesses under most circumstances. There is\nincreasing evidence concerning the relative effectiveness of the four main\ncomponents of the cognitive interview. Potentially important refinements\nof the cognitive interview (e.g., category clustering recall; taking account of\neyewitnesses’ confidence) have been proposed.\nWhat are the main limitations with the cognitive interview? First, the\nsmall increase in incorrect eyewitness recall can lead detectives to misinter-\npret the evidence. Second, it does not reduce the negative effects of mis-\ninformation. Third, mental or context reinstatement can have a negative\neffect on recognition memory by increasing the perceived familiarity of\nnon-target faces (Wong & Read, 2011). Fourth, the cognitive interview is\nless effective when the witnessed event was stressful and there is a long\ndelay between the event and the interview.\nPROSPECTIVE MEMORY\nThe great majority of memory studies have focused on retrospective\nmemory, in which the emphasis is on the past (especially individuals’\nability to remember previous events or knowledge stored in long-term\nmemory). In contrast, prospective memory is “the cognitive function we\nuse for formulating plans and promises, for retaining them, and for recol-\nlecting them subsequently either at the right time or on the occurrence of\nappropriate cues” (Graf, 2012, pp. 7–8). Examples include remembering\nto go to meet a friend at a coffee shop or to attend a revision session for a\ncourse in psychology.\nFailures of prospective memory are responsible for at least 50% of\neveryday memory problems. Tragic events occurring as a result of failures\nof prospective memory also indicate its importance. Einstein and McDaniel\n(2005, p. 286) discussed an example:\nAfter a change in his usual routine, an adoring father forgot to turn\ntoward the day-care centre and instead drove his usual route to work\nat the university. Several hours later, his infant son, who had been\nquietly asleep in the back seat, was dead.\nKEY TERMS\nRetrospective memory\nMemory for events,\npeople and so on\nexperienced in the past;\nsee prospective memory.\nProspective memory\nRemembering to carry out\nsome intended action in\nthe absence of an explicit\nreminder to do so; see\nretrospective memory.\nCase study:\nCognitive interview and\neyewitness confidence\nCreated from usyd on 2022-02-14 13:22:32.",
    "376\nMemory\nProspective memory vs retrospective memory\nHow different are retrospective and prospective memory? Failures of the\ntwo types of memory are interpreted differently (Graf, 2012). Failures\nof prospective memory involving promises to another person are often\nregarded as indicating poor motivation and reliability. In contrast, failures\nof retrospective memory are attributed to poor memory. Thus, deficient\nprospective memory means a “flaky person” whereas deficient retrospective\nmemory a means “faulty brain” (Graf, 2012).\nThere are other differences:\n(1)  Retrospective memory generally involves remembering what we know\nabout something and can be high in informational content (Baddeley\net  al., 2015). In contrast, prospective memory typically focuses on\nwhen to do something and has low informational content.\n(2) Prospective memory is more relevant to our everyday plans and goals.\n(3) More external cues (e.g., “What did you have for breakfast yester-\nday?”) are typically available with retrospective than prospective\nmemory. Anderson and McDaniel (2019) found in a naturalistic study\nthat only 39% of individuals’ prospective-memory thoughts were trig-\ngered by external cues.\n(4) Prospective memory is the form of memory “in which the problem is\nnot memory itself, but the uses to which memory is put” (Moscovitch,\n2008, p. 309).\nRemembering and forgetting often involve both prospective and retrospec-\ntive memory. For example, achieving the task of buying goods from the\nlocal supermarket requires memory of the intention to go there (prospec-\ntive memory) and memory of what you had decided to buy (retrospective\nmemory).\nCrawford et al. (2003) identified separate prospective and retrospective\nmemory factors from a questionnaire designed to assess prospective and\nretrospective memory. There was also a general memory factor based on\nelements of prospective and retrospective memory.\nIn sum, there are several similarities and differences between prospec-\ntive and retrospective memory. McBride and Workman (2017) provide a\nthorough review.\nEvent-based vs time-based prospective memory\nThere is an important distinction between time-based and event-based pro-\nspective memory. Time-based prospective memory involves performing\na given action at a particular time (e.g., phone a friend at 8 pm). Event-\nbased prospective memory involves performing an action in the appro-\npriate circumstances (e.g., passing on a message when you see a given\nperson). Unsurprisingly, performance on event-based tasks depends in part\non the accuracy (or inaccuracy) of any given individual’s time estimation\n(Waldum & McDaniel, 2016).\nThere has been much more research on event-based prospective\nmemory. With event-based tasks, researchers can manipulate the precise\nKEY TERMS\nTime-based prospective\nmemory\nA form of prospective\nmemory which involves\nremembering to carry out\nan intended action at the\nappropriate time.\nEvent-based prospective\nmemory\nA form of prospective\nmemory that involves\nremembering to perform\nan intended action (e.g.,\nbuying groceries) when\nthe circumstances are\nappropriate.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n377\nnature and timing of cues indicating the intended action should be per-\nformed. That provides more control over retrieval conditions than is gen-\nerally possible with time-based tasks. In the real world, the requirement\nto use prospective memory typically occurs while individuals are busily\ninvolved in performing some unrelated task. Most laboratory research is\nsimilar because participants are generally engaged in an unrelated ongoing\ntask while performing a prospective-memory task.\nEvent-based tasks tend to be easier than time-based tasks. For example,\nKim and Mayhorn (2008) found event-based prospective memory was supe-\nrior under both laboratory and naturalistic conditions because the intended\nactions are more likely to be triggered by external cues on event-based tasks.\nHicks et al. (2005) confirmed event-based tasks are generally less demand-\ning than time-based ones. However, both kinds of tasks were more demand-\ning when the task was ill-specified (e.g., detect animal words) rather than\nwell-specified (e.g., detect the words nice and hit). A well- specified time-\nbased task was no more demanding than an ill-specified event-based task.\nThe strategies used on time-based and event-based tasks often differ\nconsiderably. The occurrence of prospective-memory cues is typically more\npredictable on time-based tasks. As a result, individuals generally engage in\nonly sporadic monitoring of prospective-memory cues on time-based tasks\nwith this monitoring increasing as the occurrence of the cue approaches\n(Cona et al., 2015).\nIn contrast, as we will see, there is much more evidence of continuous\nmonitoring on event-based tasks because of unpredictability concerning\nthe cue’s occurrence. Cona et al. (2015) showed the importance of predict-\nability with event-based tasks: the pattern of monitoring resembled that\ntypically found with time-based tasks when the occurrence of prospec-\ntive-memory cues was predictable.\nStages in prospective memory\nProspective memory typically involves several separate processes or stages.\nAs a consequence, there are various ways prospective memory can fail.\nZogg et  al. (2012) provided a sketch map of the main processes/stages\ninvolved (see Figure 8.14):\n(1)  Intention formation: the individual forms or encodes an intention\nlinked to a specific cue (e.g., “I will discuss the weekend with my\nfriend when I see him”).\n(2) Retention interval: there is a delay (minutes, hours or weeks) between\nintention formation and intention execution. As we have seen, there is\ntypically frequent environmental monitoring for event cues on event-\nbased tasks but sporadic monitoring for time cues on time-based tasks.\n(3) Cue detection and intention retrieval: the individual detects and recog-\nnises the relevant cue (e.g., sighting your friend; seeing it is 4 o’clock);\nthis is followed by self-initiated retrieval of the appropriate intention.\n(4) Intention recall: the individual retrieves the intention from retrospec-\ntive memory; there may be problems because of the intention’s com-\nplexity, its relationship to other stored intentions or the presence of\ncompeting intentions.\nKEY TERM\nongoing task\nA task performed at\nthe same time as a\nprospective-memory task\nin studies on prospective\nmemory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "378\nMemory\n(5)\nIntention execution: this is typically fairly “automatic” and unde manding.\nProspective memory in real life\nIn this section, we discuss prospective memory in various groups of people.\nIn the Box, we consider individuals (e.g., pilots; air traffic controllers) for\nwhom forgetting of intended actions can prove fatal. We also discuss people\noften regarded as having poor prospective memory.\nFigure 8.14\nA model of the component\nprocesses involved in\nprospective memory.\nIntention formation is\nfollowed by monitoring for\nevent and/or time cues.\nSuccessful monitoring\nleads to cue detection and\nintention retrieval, intention\nrecall and intention\nexecution.\nFrom Zogg et al. (2012).\nReprinted with permission of\nSpringer Science+Business\nMedia.\nIN THE REAL WORLD: PLANE CRASHES – PILOTS AND AIR TRAFFIC\nCONTROLLERS\nDismukes and Nowinski (2006) studied pilot errors involving memory failures. There were failures\nof prospective memory in 74 out of 75 incidents or accidents! There was an almost total absence\nof retrospective memory failures because pilots have excellent knowledge and memory of the\noperations needed to fly a plane.\nHere is an example of a plane crash caused by failure of prospective memory. On 31 August\n1988, a Boeing 727 (Flight 1141) was in a long queue awaiting departure from Dallas-Fort Worth\nairport. The air traffic controller unexpectedly told the crew to move up past the other planes\nto the runway. This caused the crew to forget to set the wing flaps and leading edge slat to\n15 degrees (a failure of prospective memory). As a result, the plane crashed beyond the end of\nthe runway leading to several deaths.\nWhat causes pilots to exhibit prospective-memory failures? Relevant evidence was reported by\nLatorella (1998). Commercial pilots interrupted while flying a simulator made 53% more errors than\nthose not interrupted. Such interruptions are relatively common. Gontar et  al. (2017) discovered\npilots on average experienced eight interruptions (e.g., from colleagues; from outside the cockpit)\nduring preparations for each flight. Unsurprisingly, the adverse effects of interruption on task\nperformance are greater with longer interruptions (Altmann et al., 2017).\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n379\nInterruptions increase performance errors because they impair prospective memory for intentions\nthat could not be performed at the typical point in a sequence of actions. More specifically, we\ncan explain the effects of interruptions with Shelton and Scullin’s (2017) dynamic multiprocess\nframework (discussed later, pp. 382–386). According to this framework, we can remember to\nperform an intended action because of bottom-up processes (e.g., encountering a relevant cue).\nWhen pilots are not interrupted, each item in an action sequence cues the next action. Such\ncueing is lacking if actions are performed out of sequence.\nAccording to Shelton and Scullin (2017), we can also remember to perform an intended action\nbecause of top-down processes (i.e., monitoring for cues and rehearsing the intention). It is effortful\nusing these processes when one is interrupted during task performance (Altmann et al., 2017). As\na result, pilots can find it difficult to continue with a sequence of actions while monitoring and\nrehearsing.\nHow can we reduce pilot errors following interruptions? Engaging in effortful top-down\nprocesses is one answer. Alternatively, retrieval cues such as the humble egg timer could be used\nto remind  pilots to resume an interrupted task (Gontar et  al., 2017). For example, pilots might\nonly activate an egg timer when some task has been interrupted and will need to be attended\nto shortly.\nErrors made by air traffic controllers often involve prospective memory (failures to perform\nintended actions while monitoring a display). Loft and Remington (2010) found prospective-\nmemory errors by participants in a simulated air traffic control task were more common when\ninterruptions led them to deviate from well-practised or strong routines rather than less-practised\nones. This is important because air traffic controllers (and pilots) devote much of their time to\nhabitual tasks involving strong routines. Such tasks are carried out fairly “automatically” due to\nhabit capture which can cause prospective-memory failures when something unexpected happens\n(Dismukes, 2012).\nWilson et al. (2018) explored the effects of interruptions on a simulated air traffic control task.\nThere were three conditions: (1) interruption involved a blank screen; (2) interruption involved a\nsecondary air traffic control (ATC) task resembling the main one; and (3) a no-interruption control\nFigure 8.15\nMean failures to resume an interrupted task (left side) and mean resumption times\nin msec (right side) for the conditions: no-interruption, blank-screen interruption and\nsecondary air traffic control task interruption.\nFrom Wilson et al. (2018).\n0%\nNo-interruption\n5%\n10%\nResumption failure proportion\n15%\n20%\nBlank\nATC\n2.37%\n3.39%\n10.85%\n0\nNo-interruption\n1000\n2000\nResponse time\n3000\n4000\n5000\nBlank\nATC\n2369\n4501\n4951\nCreated from usyd on 2022-02-14 13:22:32.",
    "380\nMemory\ncondition. Both interruption conditions increased the time taken to resume the main air traffic\ncontrol task (see Figure 8.15) because participants took some time to re-activate information\nrelevant to the main ATC task. In addition, there were more failures to resume the interrupted\ntask following a secondary ATC task than in the other two conditions because the demands of the\nsecondary task caused increased forgetting of the interrupted task.\nLoft et  al. (2013, 2016) found prospective-memory errors were reduced when flashing visual\naids accompanied the appearance of target planes. However, participants experiencing severe\nscheduling demands sometimes failed to take advantage of these visual aids.\nObsessive-compulsive disorder and checking behaviour\nMost patients with obsessive-compulsive disorder (OCD) have checking\ncompulsions. They check repeatedly they have locked their front door, the\ngas has been turned off and so on but remain uncertain whether they have\nactually performed their intended actions.\nHow can we explain this checking behaviour? Perhaps obsessional\nindividuals have poor retrospective memory ability causing them to forget\nwhether they have recently engaged in checking behaviour. However, com-\npulsive checkers are generally comparable to healthy controls in retrospec-\ntive memory (Cuttler & Graf, 2009a).\nPerhaps checkers have poor prospective memory. Cuttler and Graf\n(2009b) found checkers had impaired performance on event-based and time-\nbased prospective-memory tasks. Similarly, Yang et al. (2015) found patients\nwith OCD had impaired performance on time-based tasks and were slower\nthan controls on event-based tasks. Yang et al. reported evidence the poor\nprospective memory of OCD patients involved impaired mental flexibility.\nIt is possible poor prospective memory leads obsessionals to engage in\nexcessive checking. However, excessive checking may lead to poor prospec-\ntive memory. Suppose you check several times every day you have locked\nyour front door. You would remember you had checked it numerous times.\nHowever, you might well be unsure whether you have checked your front\ndoor today because of all the competing memories.\nVan den Hout and Kindt (2004) asked some participants to engage in\nrepeated checking of a gas stove. On the final trial, those checking repeat-\nedly had less vivid and detailed memories of what had happened. Linkovski\net  al. (2013) carried out a similar study. They also assessed participants’\nlevel of inhibitory control because obsessional patients have deficient inhib-\nitory control, which may lead to intrusive thoughts and memory problems.\nWhat did Linkovski et  al. (2013) find? Repeated checking did not\nimpair prospective-memory performance. However, it reduced memory\nvividness and detail and also lowered participants’ confidence in their\nmemory. These effects were all much stronger in participants with poor\ninhibitory control (see Figure 8.16).\nToffolo et  al. (2016) emphasised the distinction between memory\nperformance (i.e., memory accuracy) and meta-memory (knowledge and\nbeliefs about one’s own memory).\nMeta-memory encompasses measures of memory confidence, memory\nvividness and memory detail. Toffolo et al. identified three main research\nfindings:\nKEY TERMS\nObsessive-compulsive\ndisorder (OCD)\nAn anxiety disorder in\nwhich the symptoms\ninclude unwanted\nthoughts (obsessions)\nand repetitive behaviours\n(compulsions) in response\nto those thoughts.\nMeta-memory\nBeliefs and knowledge\nabout one’s own memory\nincluding strategies for\nlearning and memory.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n381\n(1) Patients with OCD engage in more checking behaviour than those\nlacking obsessional tendencies.\n(2) Repeated checking typically produces large reductions in meta-\nmemory ratings which are comparable in OCD patients and controls\n(e.g., Radomsky et al., 2014).\n(3) Even though repeated checking reduces meta-memory ratings substan-\ntially, it typically has no effect on memory accuracy (e.g., Radomsky\net al., 2014).\nIn sum, patients with OCD often exhibit impaired prospective memory.\nThe following conclusions seem warranted:\nEven though it is still unknown what comes first (the tendency to use\nmore checking behaviour in general or OCD), . . . when people who\nare vulnerable for OCD use more checking, this may [reduce] memory\nconfidence. This may subsequently lead to the vicious cycle of increased\nchecking behaviour and memory distrust, eventually contributing to\nthe development of new OC [obsessional compulsive] symptoms.\n(Toffolo et al., 2016, p. 60)\nPurdon (2018) discusses further evidence for the notion that checking\nbehaviour impairs memory confidence. She also argues that patients with\nOCD have a need for certainty that contributes to their excessive checking\nbehaviour.\nTHEORETICAL PERSPECTIVES ON PROSPECTIVE\nMEMORY\nOur main emphasis here is on event-based prospective memory. What typ-\nically happens is that two tasks are performed during the same period of\ntime. One task is the ongoing task and the other is the prospective-memory\ntask. As we will see, performance on the prospective-memory task depends\non its relationship to the ongoing task.\nFigure 8.16\nSelf-reported memory vividness, memory details and confidence in memory for\nindividuals with good and poor inhibitory control before (pre-) and after (post-) repeated\nchecking.\nFrom Linkovski et al. (2013). Reprinted with permission of Elsevier.\nCreated from usyd on 2022-02-14 13:22:32.",
    "382\nMemory\nThe multiprocess framework (Einstein and McDaniel, 2005) has been\nvery influential. According to this framework, various cognitive processes\n(including attentional ones) are used during prospective-memory tasks.\nHowever, the detection of cues for response is typically “automatic” (i.e.,\nnot requiring attentional processes) when the following criteria (especially\nthe first) are fulfilled:\n(1) The ongoing task is a focal task – one that “encourages processing\nof the target [on the prospective-memory task] and especially those\nfeatures that were processed at encoding [of the prospective- memory\ntarget]” (McDaniel et al., 2015, p. 2). Here is an example: the ongoing\ntask requires participants to decide whether each letter string is a\nword and the prospective-memory task involves responding to the\nword “sleep”.\n(2) The cue on the prospective-memory task and the to-be-performed\naction are highly associated.\n(3) The cue is conspicuous or salient.\n(4) The intended action is simple.\nMcDaniel et  al. (2015) developed the multiprocess framework into\nthe dual-pathways model (see Figure 8.17) based on the distinction\nbetween focal and non-focal ongoing tasks. A non-focal task “does not\nencourage processing of those features . . . processed at encoding [of\nthe  prospective-memory target]” (p. 2). For example, the ongoing task\nrequires participants to decide whether each letter string is a word and the\nprospective- memory task involves responding to words starting with the\nletter r. Thus, there is much less overlap between the processing required\non the  prospective-memory and ongoing tasks when the latter is non-focal.\nIt is assumed the processes typically used with focal and non-focal\ntasks differ substantially (see Figure 8.17). Strategic monitoring involves\ntop-down attentional control processes to maintain the prospective-\nmemory intention and to search for relevant cues on that task. It is used\nmuch more often with non-focal than with focal tasks.\nAccording to the dual-pathways model, retrieval on the  prospective-\nmemory task can occur in two ways: (1) spontaneous retrieval involves\nbottom-up processes triggered by the relevant stimulus and does not require\nprior monitoring; (2) intentional retrieval is based more on top-down pro-\ncesses and requires prior monitoring. Non-focal tasks involve intentional\nretrieval. In contrast, focal tasks generally involve spontaneous retrieval but\ncan also involve intentional retrieval. Finally, the main brain areas asso-\nciated with the cognitive processes involved in prospective memory are\nidentified.\nShelton and Scullin (2017) presented a dynamic multiprocess frame-\nwork largely consistent with the dual-pathways model. Two cognitive pro-\ncesses underlie successful prospective-memory performance:\n(1) Monitoring: this involves top-down attentional control to search for\ncues indicating the prospective-memory action should be performed.\n(2) Spontaneous retrieval: this involves bottom-up processing triggered by\nprocessing a cue.\nKEY TERMS\nFocal task\nAn ongoing task that\ninvolves similar processing\nto that involved in\nencoding the target on a\nprospective-memory task\nperformed at the same\ntime; see non-focal task.\nNon-focal task\nAn ongoing task that\ninvolves different\nprocesses to those\ninvolved in encoding the\ntarget on a prospective-\nmemory task performed at\nthe same time; see focal\ntask.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n383\nWhat determines which process is used? First, monitoring is effortful\nand often impairs ongoing task performance because it creates competition\nfor processing capacity. As a consequence, monitoring is rarely used when\nthe ongoing task is important (e.g., a committee meeting). Second, moni-\ntoring is used primarily when prospective-memory cues are expected (e.g.,\nwhen close to a wine shop as shown in Figure 8.18).\nFigure 8.17\nThe dual-pathways model\nof prospective memory\n(based on the multiprocess\nframework) for non-focal\nand focal tasks separately.\nThe solid black arrows\nindicate the sequence of\nprocessing over time. The\ndashed-line arrows indicate\nthat strategic monitoring\nprocesses are sometimes\ninvolved even with focal\ntasks.\nFrom McDaniel et al. (2015).\nEncoding\nFocal\nNon-focal\nStrategic monitoring:\nDLPFC, VLPFC, insula, anterior\ncingulate, FEF, lateral BA 10,\nBA 47, precuneus\nMaintenance\nSustained\nactivation\nRetrieval\nTransient\nactivation\nIntentional retrieval:\nBA 40, insula, lateral BA 10,\nanterior cingulate\nSpontaneous retrieval:\nVentral frontoparietal network,\nBA 9, MTL, especially hippocampus\nFigure 8.18\nExample 1: top-down\nmonitoring processes\noperating in isolation;\nExample 2: bottom-up\nspontaneous retrieval\nprocesses operating in\nisolation; Example 3:\ndual processes operating\ndynamically.\nFrom Shelton and Scullin (2017).\nContext:\nTop-down processes\nNo monitoring\nCommittee meeting\nOfce\nExample 1: Monitoring only view\nDriving home\nStore\nsign\nRemember\nto pick up\nwine after work.\nAre you going to\nthe holiday party?\nAdvertisement\nContext:\nTop-down processes\nNo monitoring\nCommittee meeting\nOfce\nExample 2: Spontaneous retrieval only view\nDriving home\nStore\nsign\nRemember\nto pick up\nwine after work.\nAre you going to\nthe holiday party?\nSpontaneous retrieval\nAdvertisement\nSpontaneous retrieval\nSpontaneous retrieval\nContext:\nTop-down processes\nNo monitoring\nCommittee meeting\nOfce\nExample 3: Dynamic multiprocess view\nDriving home\nStore\nsign\nRemember\nto pick up\nwine after work.\nAre you going to\nthe holiday party?\nSpontaneous retrieval\nAdvertisement\nSpontaneous retrieval\nCreated from usyd on 2022-02-14 13:22:32.",
    "384\nMemory\nThird, Shelton and Scullin (2017) assumed top-down and bottom-up\nprocesses interact dynamically on prospective-memory tasks. For example,\nmonitoring depends importantly on meta-cognition (knowledge and\nbeliefs about one’s own cognitive processes and performance). Suppose\nyou perform a prospective-memory task. If you are confident the task will\nbe easy (e.g., there will be strong retrieval cues), you might choose to rely\non spontaneous retrieval rather than monitoring. However, if you expect\nthe task to be difficult (e.g., retrieval cues will be weak or non-existent),\nyou would probably choose to use extensive monitoring.\nIn sum, the dynamic multiprocess framework differs from previous\ntheories in that the processing strategies used on prospective-memory\ntasks are flexibly influenced by meta-cognitive processes. The multiprocess\ntheory is less flexible – it assumes processing on prospective-memory tasks\nis predominantly determined by the task (focal vs non-focal).\nFindings\nThe requirement to perform a prospective-memory task at the same time\nas an ongoing task generally leads to impaired performance on the ongoing\ntask. According to the above theories, this occurs when the ongoing and\nprospective-memory tasks compete for processing resources. Such competi-\ntion is especially great when demanding top-down processes (e.g., monitor-\ning) are used on the prospective-memory task.\nSupport for the above theoretical assumptions was reported by Moyes\net al. (2019). They found impaired performance on the ongoing task when\nit was non-focal and so demanding processing (especially monitoring) was\nrequired on the prospective-memory task. In contrast, performance was\nnot impaired on the ongoing task when it was focal and so demanding\nmonitoring processes on the prospective-memory task were not required.\nIn spite of findings such as those of Moyes et al. (2019), the above the-\noretical assumptions are oversimplified. Rummel et  al. (2017) argued the\nrequirement to perform two tasks at the same time reduces mind- wandering\n(task-unrelated thoughts) as participants try to cope with the overall pro-\ncessing demands. They obtained clear support for this argument.\nRummel et  al. (2017) also found performance on a prospective-\nmemory task was much better (71% vs 42%) when financial incentives were\nprovided for good performance. Strikingly, the extra processing resources\ninvested in the prospective-memory task when incentives were provide d\ndid not affect performance on the ongoing task because incentives reduced\nparticipants’ mind-wandering.\nSupport for the general approach of the dual-pathways model was\nreported by McDaniel et al. (2013). They argued the monitoring required\nto perform a non-focal task would involve top-down attentional control.\nAs a result, there would be sustained activity in the anterior prefrontal\ncortex, an area associated with attentional control. In contrast, the lesser\ndemands of a focal task would produce only transient activity in that brain\narea. That is precisely what they found (see Figure 8.19).\nCona et al. (2016) conducted a meta-analysis of neuroimaging studies\ninvolving focal and non-focal tasks. As predicted by the dual-pathways\nmodel, patterns of brain activity differed between these two task types\nKEY TERMS\nMeta-cognition\nBeliefs and knowledge\nconcerning one’s own\ncognitive processes\nand likely level of\nperformance.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n385\nduring maintenance and retrieval. Overall, non-focal tasks were associated\nwith more activity in parts of the anterior prefrontal cortex (BA10). In\ncontrast, focal tasks were associated with more activity than focal ones in\nthe anterior cerebellum, ventral parietal regions (BA40) and BA9. Cona\net al. (2016, p. 1) concluded as follows: “Prospective remembering is medi-\nated mainly by top-down and stimulus-independent processes in non-focal,\nbut by more automatic, bottom-up, processes in focal tasks.”\nAccording to the dual-pathways model, automatic cue detection some-\ntimes occurs on prospective-memory tasks. Beck et  al. (2014b) provided\nrelevant evidence. Participants initially performed a block of trials with an\nongoing task and a prospective-memory task. This was followed by a block\nof trials where they were instructed not to perform the prospective-memory\ntask even though prospective-memory targets appeared. These instructions\npresumably prevented deliberate target monitoring. Nevertheless, targets in\nthis second block were associated with activation in brain regions (e.g., the\nventral parietal cortex) associated with spontaneous retrieval.\nScullin et  al. (2010) also obtained findings suggesting the existence\nof spontaneous retrieval of prospective-memory cues. They almost elimi-\nnated monitoring for prospective-memory cues by presenting only a single\nprospective-memory target after over 500 trials and by emphasising the\nimportance of the ongoing task. This target was detected by 73% of par-\nticipants when on a focal task but only 18% on a non-focal task. This is\nconsistent with the model’s assumption that spontaneous retrieval occurs\nmuch more often with focal tasks.\nWe turn now to the role of meta-cognition (emphasised within the\ndynamic multiprocess framework). Clear evidence of its importance was\nshown by Lourenço et al. (2015). Two tasks were performed at the same time:\n(1) an ongoing lexical decision task (see Glossary); (2) a prospective-memory\nFigure 8.19\n(a) Sustained (PM Sus) and\n(b) transient (PM) activity in\nthe left anterior prefrontal\ncortex (c) for non-focal\n(blue) and focal (red)\nprospective-memory (PM)\ntasks. The other conditions\nshown (i.e., CTL, Ong PM\nand Ong CTL) are not of\ntheoretical relevance.\nFrom McDaniel (2013).\nReprinted with permission of the\nAssociation for Psychological\nScience.\nCreated from usyd on 2022-02-14 13:22:32.",
    "386\nMemory\ntask that involved responding to animal words. During practice, the target\nanimal words were atypical (e.g., raccoon) or typical (e.g., dog). On the fol-\nlowing experimental trials, only atypical animal words were presented as\nprospective-memory targets.\nWhat did Lourenço et  al. (2015) discover? We will focus on partic-\nipants for whom the target words on the prospective-memory task were\ntypical during practice but atypical on experimental trials. These partici-\npants showed little or no monitoring during the initial experimental trials\nbecause they expected the prospective-memory task to be easy. However,\nthey used monitoring much more when they realised that task was actually\nharder than they had expected. The take-home message is that strategy\nuse is flexible: our use of monitoring increases (or decreases) as a result of\nexperience and expectation.\nSuppose you perform an ongoing task of counting the number of\nliving objects presented on a screen containing approximately 20 objects.\nAt the same time, you must perform a prospective-memory task of detect-\ning a given target (e.g., apple) presented in the upper right corner of the\nscreen. On some trials, an object semantically related to the target (e.g.,\nbanana) is presented on the ongoing task. According to the dynamic mul-\ntiprocess framework, fixating the semantically related object should often\ncause spontaneous retrieval of the intention on the prospective-memory\ntask. This in turn should lead to monitoring (revealed by rapid fixation on\nthe upper right corner of the screen).\nShelton and Christopher (2016) carried out the experiment described\nin the previous paragraph. Their findings were precisely as predicted by the\ndynamic multiprocess framework (see Figure 8.20). Thus, top-down moni-\ntoring is often triggered by bottom-up spontaneous retrieval.\nIn sum, performance on most prospective-memory tasks is determined\nby interactive bottom-up (e.g., spontaneous retrieval) and top-down (e.g.,\nmonitoring) processes. The various theories discussed are mostly consist-\nent with each other. However, the dynamic multiprocess framework has\nadvanced our understanding with its assumption that the strategies used\non prospective-memory tasks are flexibly influenced by meta-cognitive\nprocesses.\nFigure 8.20\nFrequency of cue-driven\nmonitoring following the\npresentation of semantically\nrelated or unrelated cues;\nthere was no prospective-\nmemory task in the control\ncondition.\nFrom Shelton and Christopher\n(2016).\n0\nProspective memory\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\nMonitoring frequency\nControl\nRelated cue\nUnrelated cue\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n387\nImproving prospective memory\nFailures of prospective memory caused by task interruptions can be reduced\nby forming an explicit intention to resume the interrupted task (Dodhia\n& Dismukes, 2009). Alternatively, we can place distinctive reminder cues\nwhere they will be seen at the appropriate time (Dismukes, 2012). For\nexample, if you need to take a book into college tomorrow, you could leave\nit close to your keys.\nMotivation is also important. Cook et  al. (2015) found prospective\nmemory was better using monetary rewards for good performance or mon-\netary punishments for poor performance (Cook et al., 2015). These benefits\nwere achieved without impairing performance of the ongoing task. These\nfindings may have occurred because of reduced mind-wandering (Rummel\net al., 2017, discussed earlier, p. 384) in the high-motivation conditions.\nA relatively simple (but effective) technique for enhancing prospective\nmemory is based on Gollwitzer’s notion of implementation intentions: “‘If\nsituation Y is encountered, then I will perform the goal-directed response\nZ!’ Thus, implementation intentions define exactly when, where, and how\none wants to act toward realizing one’s goals” (Gollwitzer, 2014, p. 306).\nChen et al. (2015) found in a meta-analysis that implementation intentions\nenhanced prospective memory.\nWhy are implementation intentions effective? Scullin et  al. (2017)\nasked participants what they were thinking shortly after receiving imple-\nmentation-intention instructions. These instructions increased the tendency\nfor participants to focus on specific aspects of the prospective-memory task\nand reduced mind-wandering.\nGollwitzer argued that forming an implementation intention is like\nforming an “instant habit” that reduces the processing costs when inten-\ntions are retrieved on a prospective-memory task. Support was reported\nby Rummel et al. (2012). Participants receiving implementation intentions\nperformed better on a prospective-memory task within an ongoing task.\nThey also included trials where participants were told not to respond to\ntarget words from the prospective-memory task. These target words caused\nmore disruption to the ongoing task (see Glossary) for participants previ-\nously given implementation intentions. This happened because participants\nwere more likely to retrieve their intentions relatively “automatically”.\nOverall evaluation\nThere are several ways progress has been made in understanding prospec-\ntive memory:\n(1) The number and nature of the processes involved have been identified\nwith increasing clarity.\n(2) Reasons for prospective-memory failures in various groups (e.g.,\npilots; obsessional individuals) have been identified.\n(3) There have been several theoretical advances. The dynamic multi-\nprocess framework (Shelton & Scullin, 2017) provides a coherent\naccount of most findings with its emphasis on complex interactions\nbetween top-down and bottom-up processes.\nKEY TERM\nImplementation\nintentions\nAction plans designed\nconsciously to achieve\nsome goal (e.g., healthier\neating) based on specific\ninformation concerning\nwhere, when and how the\ngoal will be achieved.\nCreated from usyd on 2022-02-14 13:22:32.",
    "388\nMemory\n(4) The cognitive neuroscience approach has identified brain areas associ-\nated with different prospective-memory processes.\n(5) Researchers are developing a new field of “prospection” or future\nthinking including prospective memory.\nWhat are the limitations of theory and research on prospective memory?\nFirst, it is assumed within several theories (e.g., the dual-pathways\nmodel; see Figure 8.17) that monitoring will typically be used with non-\nfocal ongoing tasks. However, this is not entirely correct. Anderson et al.\n(2018) instructed participants to engage in monitoring on every trial on\nthe  prospective-memory task or simply instructed them to perform that\ntask. Both groups engaged in monitoring but the former group did so to a\ngreater extent: they detected 73% of prospective-memory targets compared\nto only 59% for the latter group.\nSecond, most theories de-emphasise individual differences in processing\non prospective-memory tasks. For example, Scullin et al. (2018) gave par-\nticipants the task of pressing the Q key whenever they saw a word belong-\ning to the category of “fruits”. Thus, they should have encoded fruit as an\nabstract category. However, participants often encoded fruit as a specific\nexample (e.g., apple), or they hardly thought at all about the instruction to\nfocus on “fruits” (see Figure 8.21).\nThird, participants in most laboratory experiments lack strong incen-\ntives to exhibit good prospective-memory performance. In contrast, the\nincentives in real life can include saving lives (e.g., air traffic controllers).\nFourth, moment-by-moment decisions to use top-down or bottom-up\nprocesses often involve meta-cognition (Shelton & Scullin, 2017). However,\nmuch remains to be discovered about meta-cognitive processes.\nFifth, the processes involved in prospective memory are more complex\nthan typically assumed. For example, the joint demands of performing\na prospective-memory task and an ongoing task produce a reduction in\nmind-wandering (Rummel et  al., 2017). Our limited understanding of\nthe factors determining mind-wandering often makes it hard to predict\nprospective-memory performance.\nFigure 8.21\nDifferent ways the\ninstruction to press Q for\nfruit words was encoded.\nFrom Scullin et al. (2018).\nCategory bias\n51.1%\nHardly\nthought\nabout it\n22.5%\nSpecific\nexemplar bias\n26.4%\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n389\nSixth, prospective memory in everyday life differs from the laboratory\nbecause it is more common in everyday life to maintain our intentions for\nlong periods of time, which reduces the involvement of attentional and\nmonitoring processes.\nCHAPTER SUMMARY\n•\nIntroduction. What people remember in traditional memory studies\nis largely determined by the experimenter’s demands for accuracy.\nIn contrast, remembering in everyday life is determined by our\npersonal goals. Tailoring our message to create an impression\ncauses subsequent memory distortions. Memory research should\nstrive for generalisability and representativeness. The distinction\nbetween traditional and everyday memory research is imprecise.\n•\nAutobiographical memory: introduction. Autobiographical\nmemories generally have greater personal significance and\ncomplexity than episodic memories and can involve semantic\nmemory. Autobiographical memory helps to maintain social bonds,\na sense of self-continuity and self-enhancement. Individuals with\nhighly superior autobiographical memory often have obsessional\nsymptoms and devote much time to thinking about past events.\nFlashbulb memories are perceived as more vivid than other\nmemories even though they are often inaccurate and have only\nmoderate consistency. Flashbulb memories generally resemble\nother memories in their susceptibility to interference and forgetting.\n•\nMemories across the lifetime. There is infantile amnesia for\nmemories of the first two years of life. It occurs because the\ncognitive self only emerges towards the end of the second year\nof life and because of hippocampal neurogenesis (generation\nof new neurons within the hippocampus). Relative amnesia for\nthe preschool years ends when children have a good command\nof language. The reminiscence bump for important personal\nmemories is much stronger for positive memories than negative\nones because the retrieval of autobiographical memories is often\nguided by the life script.\n•\nTheoretical approaches to autobiographical memory. According\nto the self-memory system model, autobiographical information is\nstored hierarchically. An individual’s goals and personality influence\nthe retrieval of autobiographical memories. Autobiographical\nmemories can be accessed via direct or generative retrieval. The\nprefrontal cortex (associated with controlled processing) and the\namygdala (involved in emotional processing) are activated during\nautobiographical retrieval. Several interconnected brain networks\nare involved in autobiographical retrieval, with the brain areas\nactivated shifting between initial searching for memories and their\nsubsequent elaboration. Depressed individuals exhibit over-general\nCreated from usyd on 2022-02-14 13:22:32.",
    "390\nMemory\nautobiographical memory. Therapy to increase the specificity\nof depressed patients’ autobiographical memories has proved\nsuccessful in reducing depressive symptoms.\n•\nEyewitness testimony. Eyewitnesses’ initial confidence in their\ninitial identification provides valid evidence concerning its\naccuracy. Eyewitness memory is influenced by several factors\nincluding confirmation bias, stress and ageing. Misinformation\ntypically produces distorted eyewitness memory but often does not\ncause permanent alteration of memory traces. Misinformation can\nenhance eyewitness memory if it acts as a cue facilitating retrieval\nof an event. Eyewitness memory for faces is affected by the cross-\nrace effect, and also by difficulties in recognising a given unfamiliar\nface from different photographs of that person.\n•\nEnhancing eyewitness memory. Culprits are more likely to be\nidentified from simultaneous than from sequential line-ups, but\nmore innocent individuals are identified with simultaneous line-ups.\nWhich type of line-up is preferable depends on the magnitude\nof these two effects. The cognitive interview leads eyewitnesses\nto produce many more detailed memories with a small increase\nin inaccurate memories. Inaccurate memories can be detected\nbecause eyewitnesses often have low confidence in the accuracy\nof such memories. Mental reinstatement and the requirement to\nreport all details are both crucial to the success of the cognitive\ninterview.\n•\nProspective memory. Prospective memory involves successive\nstages of intention formation, monitoring, cue detection, intention\nretrieval and intention execution. Event-based prospective memory\nis often better than time-based prospective memory because the\nintended actions are more likely to be triggered by external cues.\nMany failures of prospective memory (e.g., by pilots) occur when\nindividuals are interrupted while carrying out an action plan and\nlack time to form a new plan. Individuals with obsessive-compulsive\ndisorder engage in excessive checking behaviour which may reduce\ntheir confidence in their prospective-memory ability.\n•\nTheoretical perspectives on prospective memory. According to\nthe dynamic multiprocess framework, prospective memory involves\ninteractions between top-down processes (e.g., monitoring)\nand bottom-up ones (e.g., spontaneous retrieval). The extent to\nwhich effortful monitoring is used depends on meta-cognitive\nprocesses assessing how well the prospective-memory task\nwould be performed in its absence. Neuroimaging evidence\nsupports the distinction between top-down and bottom-up\nprocesses. Implementation intentions enhance prospective-memory\nperformance by facilitating the relatively “automatic” retrieval of\nintentions.\nCreated from usyd on 2022-02-14 13:22:32.",
    "Everyday memory\n391\nFURTHER READING\nBaddeley, A., Eysenck, M.W. & Anderson, M.C. (2020). Memory (3rd edn).\nAbingdon, Oxon.: Psychology Press. This textbook provides detailed coverage of\nresearch and theory on all the main topics discussed in this chapter.\nConway, M.A., Justice, L.V., D’Argembeau, A. (2019). The self-memory system\nrevisited: Past, present, and future. In J.H.Mace (ed). The Organisation and\nStructure of Autobiographical Memory (pp. 28–51). New York: Oxford University\nPress. Martin Conway provides an update of his influential theoretical approach\nto autobiographical memory.\nDavis, D. & Loftus, E.F. (2018). Eyewitness science in the 21st century: What do we\nknow and where do we go from here? In E.A. Phelps, L. Davachi & J.T. Wixted\n(eds), Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience,\nVol. 1: Learning and Memory (4th edn; pp. 529–566). New York: Wiley. Deborah\nDavis and Beth Loftus discuss theory and research in the field of eyewitness\ntestimony.\nPutnam, A.L., Sungkhasettee, V.W. & Roediger, H.L. (2017). When misinforma-\ntion improves memory: The effects of recollecting change. Psychological Science,\n28, 36–46. Adam Putnam and colleagues shed new light on the circumstances in\nwhich eyewitness memory is (or is not) adversely affected by misinformation.\nSheldon, S., Nicholas B., Diamond, N.B., Armson, M.J., Daniela J. Palombo,\nD.J., (2018). Assessing autobiographical memory: Implications for understand-\ning the underlying neurocognitive mechanisms. In E.A. Phelps, L. Davachi &\nJ.T. Wixted (eds), Stevens’ Handbook of Experimental Psychology and Cognitive\nNeuroscience, Vol. 1: Learning and Memory (4th edn; pp. 363–396). New York:\nWiley. This chapter emphasises the importance of cognitive neuroscience to an\nunderstanding of autobiographical memory.\nShelton, J.T. & Scullin, M.K. (2017). The dynamic interplay between bottom-up\nand top-down processes supporting prospective remembering. Current Directions\nin Psychological Science, 26, 352–358. This article updates the influential dynamic\nmultiprocess framework including relevant research.\nSmith, R.E. (2017). Prospective memory in context. Psychology of Learning and\nMotivation, 66, 211–249. Contemporary views on prospective memory are dis-\ncussed by Rebekah Smith with an emphasis on the role played by contextual\ninformation.\nCreated from usyd on 2022-02-14 13:22:32.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-14 13:22:32.",
    "LANGUAGE\nLanguage\nOur lives would be remarkably limited without language. Our social inter-\nactions depend very heavily on language and all students need a good\ncommand of language. The main reason we know much more than previous\ngenerations is because knowledge is passed on from one generation to the\nnext via language.\nWhat is language? According to Harley (2013, p. 5), language: “is a system\nof symbols and rules that enable us to communicate. Symbols stand for\nother things: Words (written or spoken) are symbols. The rules specify\nhow words are ordered to form sentences.” Communication is the primary\nfunction of language. However, Crystal (1997) identified eight different\nfunctions. In addition to communication, we use language for thinking, to\nrecord information, to express emotion (e.g., “I love you”), to pretend to\nbe animals (e.g., “Woof! Woof!”), to express identity with a group (e.g.,\nsinging in church), and so on.\nIt is somewhat surprising there was little research on language prior to the\nlate 1950s. The behaviourists (e.g., Skinner, 1957) argued that the language\nwe produce consists of rewarded conditioned responses. According to\nthis analysis, there is nothing special about language and no reason other\nspecies should not be able to develop language.\nThe situation was transformed by Noam Chomsky (1957, 1959). He claimed\n(correctly!) that the behaviourist approach to language was woefully inade-\nquate. According to him, language possesses several unique features (e.g.,\ngrammar or syntax) and can only be acquired by humans. Chomsky’s ideas\nled to a dramatic increase in language research (Harley & McAndrew, 2015).\nAs a result, language has been of central importance within cognitive psy-\nchology ever since.\nIs language unique to humans?\nBonobos (a species of great ape) have developed better language skills\nthan any other non-human species. Panbanisha (1985–2012) was trained\non a special keypad with about 400 geometric patterns or lexigrams on it.\nPART III\nVISUAL PERCEPTION AND ATTENTION\nCreated from usyd on 2022-02-16 03:16:01.",
    "394\nLanguage\nHe acquired a vocabulary of 3,000 words by the age of 14 years and often\ncombined symbols in their correct order (e.g., “Please can I have an iced\ncoffee?”).\nIt has often been argued that apes’ use of language lacks spontaneity and\nrefers almost exclusively to the present. This matters because these are two\ncriteria for language. However, 74% of the utterances of Panbanisha and\ntwo other great apes were spontaneous (Lyn et al., 2011). In addition, the\napes referred to the past as often as young children and produced more\nresponses referring to future intentions. Lyn et  al. (2014) found bonobos\n(including Panbanisha and her half-brother Kanzi) could communicate about\ndisplaced objects (i.e., those no longer present).\nGenty et al. (2015) found bonobos were more likely to repeat a message\nwith a familiar recipient but to elaborate the original message with an un-\nfamiliar recipient. This ability to vary communications to accommodate the\nrecipient’s needs is characteristic of children’s use of language. Clay and\nGenty (2017) reviewed the research on bonobos, concluding that their\nbehaviour exhibits “considerable communicative complexity, flexibility, and\nintentionality”.\nWhat are the main limitations of bonobos’ language acquisition? First,\nbonobos’ utterances are much less likely than those of young children\n(aged 12–24 months) to reflect motivation to engage in social inter-\naction. Children’s statements often refer to intentions, attention seeking\nor offering something to someone else, whereas 80% of bonobos’ utter-\nances are requests (e.g., for food) (Lyn et  al., 2014). Such evidence led\nScott-Phillips (2015) to argue that apes lack our ability to engage in\n“mind reading”, which allows us to infer how our utterances are likely\nto be interpreted. This is at least partly correct but probably overstated\n(Moore, 2015).\nSecond, children’s language skills develop dramatically after the age of 2\nyears and so become markedly superior to those of bonobos. For example,\nchildren’s language exhibits much more productivity (expressing numerous\nideas) and is much more complex (e.g., sentence length; use of grammati-\ncal structures).\nThird, as Chomsky (quoted in Atkinson et  al., 1993) pointed out, “If an\nanimal had a capacity as biologically advantageous as language but\nsomehow hadn’t used it until now, it would be an evolutionary miracle, like\nfinding an island of humans who could be taught to fly.”\nFourth, an increasingly common view (e.g., Christiansen & Chater, 2008,\n2016; discussed below) is that several non-language cognitive processes\n(e.g., short-term memory; thinking; learning) play a vital role in the develop-\nment of language. Bonobos can acquire only some aspects of language, in\npart because their non-language cognitive processes are considerably infe-\nrior to ours.\nKEY TERM\nLexigrams\nSymbols used to\nrepresent words in studies\non communication.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language\n395\nIs language innate?\nThere has been fierce controversy on the issue of whether language is\ninnate. Chomsky claimed humans possess an innate universal grammar (a\nset of grammatical principles found in all human languages). In Chomsky’s\nown words, “Whatever universal grammar is, it’s just the name for [our]\ngenetic structure” (Baptista, 2012, pp. 362–363).\nAccording to Chomsky, there are several linguistic universals (features\ncommon to nearly every language) that jointly form a universal grammar.\nOne possible linguistic universal (feature common to nearly every language)\nis recursion (embedding clauses within sentences to generate increasingly\nlong sentences). For example, we can use recursion to expand the sentence\n“John met Mary in Brighton” to “John, who was a handsome man, met\nMary in Brighton”. Other possible linguistic universals are lexical catego-\nries (e.g., nouns; verbs; adjectives) and word order (subject-verb-object or\nsubject-object-verb).\nChomsky proposed an innate universal grammar for various reasons. First,\nhe argued, it explains why only humans fully develop language. Second,\nit explains the alleged broad similarities among the world’s languages.\nThird, he claimed that young children develop language much faster than\nwould be predicted on the basis of their exposure to spoken language.\nHowever, experience obviously determines which language any given\nchild learns.\nChristiansen and Chater (2008) totally disagreed with Chomsky. Their main\npoints were as follows:\n(1)\nLanguages differ enormously, which is inconsistent with the notions of\nuniversal grammar and linguistic universals.\n(2)\nThe notion that natural selection has provided us with genes respon-\nsive to abstract features of languages we have never encountered is\nmystifying.\n(3)\nLanguages change amazingly rapidly. For example, all Indo-European\nlanguages emerged from a common source in under 10,000 years\n(Baronchelli et  al., 2012). Natural selection could not have kept\npace.\n(4)\n“Language has been shaped by the brain: language reflects pre-\nexisting, and hence non-language-specific, human learning and pro-\ncessing mechanisms” (Christiansen & Chater, 2008, p. 491). In other\nwords, our language ability is less special and less different from our\nother cognitive abilities than implied by Chomsky.\n(5)\nChildren find it easy to acquire language because it was invented by\nhumans to take account of human abilities: “language has adapted to\nour brains” (Christiansen & Chater, 2008, p. 490).\nIn what follows, we discuss relevant research. As we will see, this research\nhas revealed many limitations in Chomsky’s theoretical approach.\nKEY TERMS\nLinguistic universals\nFeatures (e.g., preferred\nword order; the distinction\nbetween nouns and\nverbs) found in the great\nmajority of the world’s\nlanguages.\nRecursion\nTurning simple sentences\ninto longer and more\ncomplex ones by placing\none or more additional\nclauses within them.\nCreated from usyd on 2022-02-16 03:16:01.",
    "396\nLanguage\nFindings: linguistic universals and genes\nHow different are the world’s languages? The main European languages\nare very similar, but large differences appear when all the world’s 6,000\nto 8,000 languages are considered. Evans and Levinson (2009, p. 429) did\nprecisely that and concluded, “There are vanishingly few universals of lan-\nguage in the direct sense that all languages exhibit them”. For example,\nthere is limited evidence that recursion (discussed above, p. 395) is lacking\nin the Amazonian language Pirahã. However, Futrell et al.’s (2016) thorough\nattempt failed to find any strong evidence for it.\nEvidence concerning other suggested language universals is hotly con-\ntested. Evans and Levinson (2009) concluded some languages (e.g., the\nAustronesian language Charrosso) lack one or more of the lexical cate-\ngories of noun, verbs and adjectives. However Chung (2012) analysed\nCharrosso in considerable detail and concluded that in fact it has nouns,\nverbs and adjectives! She concluded the failure to identify the three main\nlexical categories in some languages occurs because they are insufficiently\nstudied.\nWord order has claims to be a linguistic universal. Greenberg (1963)\nfound the subject preceded the object in 98% of numerous languages.\nThe word order subject-verb-object (S-V-O) was most common followed\nby  subject-object-verb (S-O-V). Sandler et al. (2005) studied the Al-Sayyid\ngroup living in an isolated Israeli community. High levels of congenital deaf-\nness in this community led them to develop Bedouin Sign Language, which\nuses the S-O-V word order even though it differs from other languages to\nwhich they are exposed.\nThe above findings can be interpreted in more than one way. It can be\nargued the central importance of the subject in a sentence means it makes\nsense for the subject to precede the object regardless of any genetic\nconsiderations; and that ordering facilitates communication.\nFedzechkina et  al. (2018) argued that word-order preferences in any lan-\nguage reflect the limitations of human information processing. More spe-\ncifically, they predicted that words strongly associated grammatically (and\nin meaning) should appear close together within sentences to minimise\nprocessing costs. This is, indeed, the case across languages that otherwise\nappear superficially different.\nBickerton (1984) proposed the language bioprogram hypothesis, which\nis closely related to Chomsky’s views. According to this hypothesis, chil-\ndren will create a grammar even if hardly exposed to a proper language.\nSenghas et al. (2004) studied deaf Nicaraguan children at special schools.\nThese children developed a new system of gestures that expanded into a\nbasic sign language (Nicaraguan Sign Language) passed on to successive\ngroups of children. Since this sign language does not resemble Spanish or\nthe gestures of hearing children, it is a genuinely new language. Nicaraguan\nSign Language is still developing – Kocab et al. (2016) found that only later\nCreated from usyd on 2022-02-16 03:16:01.",
    "generations of signers could successfully communicate complex temporal\ninformation.\nThe above findings suggest humans have a strong innate motivation\nto acquire language (including grammatical rules) and to communicate\nwith others. However, they provide only modest support for a universal\ngrammar.\nAccording to Chomsky, only humans have the genetic make-up permitting\nlanguage acquisition. Relevant evidence comes from research on the KE\nfamily in London. Across three generations, about 50% of family members\nhave suffered from severe language problems (e.g., difficulties in under-\nstanding speech; slow and ungrammatical speech). Their complex lan-\nguage disorder was controlled by a specific gene FOCP2 (Lai et al., 2001).\nMore specifically, mutations of this gene were found only in affected family\nmembers.\nWhy does FOXP2 cause these language impairments? It is probably a hub\nin various gene networks leading to impaired functioning of brain areas\ndirectly involved in language. However, we must not exaggerate the impor-\ntance of FOXP2 for various reasons:\n(1)\nThe FOXP2 sequence is found in numerous vertebrate species not\npossessing language.\n(2)\nOther genes such as ATP2C2 and CMIP are also associated with spe-\ncific language impairment (Graham & Fisher, 2013).\n(3)\nMueller et  al. (2016) found common genetic variants in FOXP2 had\nnegligible effects on language ability within a normal sample.\nFindings: child-directed speech\nChomsky claimed children’s rapid acquisition of language cannot be\nexplained solely on the basis of their exposure to language. However, he\nminimised the richness of the linguistic input to which children are exposed.\nParents and other adults use child-directed speech involving very short,\nsimple sentences, a slow rate of speaking and use of a restricted vocabulary.\nUnsurprisingly, children whose parents use a lot of child-directed speech\nshow faster language development than other children (Rowe, 2008). Thus,\nmost parents are “in tune” with children’s current language abilities and so\nprovide strong environmental support.\nChomsky exaggerated the speed with which young children master lan-\nguage. Children’s speech during their first two years of speaking is\nremarkably limited (Bannard et al., 2009) – they use a small set of famil-\niar verbs and often repeat back what they have just heard. Bannard et al.\n(2013) found 3-year-olds often engage in “blind copying” – they imitate\neverything an adult has just said even when part of it does not add any\nuseful information.\nKEY TERM\nChild-directed speech\nThe short, simple, slowly\nspoken sentences used by\nparents and others when\ntalking to young children.\nLanguage\n397\nCreated from usyd on 2022-02-16 03:16:01.",
    "398\nLanguage\nFindings: is language special?\nMuch evidence indicates that language is less special (in the sense of\nbeing different from other cognitive functions) than assumed by Chomsky.\nCampbell and Tyler (2018) reviewed neuroimaging research indicating that\nmany brain regions are included within the “language network”. Most of\nthese areas are associated with general cognitive functions (e.g., attention;\nmemory). However, some brain areas (e.g., BA45; posterior middle tempo-\nral gyrus) form a “syntax system” involved in syntactic processing, which is\ndamaged in patients with impaired syntactic processing. This syntax system\ncould be regarded as “special”.\nOther research has indicated that language comprehension and production\nboth depend on general cognitive processes such as attention and cogni-\ntive control (see McClain & Goldrick, 2018, for a review). There is also much\nevidence for a “language-as-skill” framework, according to which language\nacquisition is a type of skill acquisition resembling learning to play a musical\ninstrument (Chater & Christiansen, 2018). Within this framework “Language\nis connected to basic psychological mechanisms of learning and process-\ning” (p. 207). In other words, language skills are not “special”.\nEvaluation\nChomsky’s theoretical approach receives some support from evidence\nsuggesting only humans possess fully developed language. His general\napproach also receives limited support from the identification of specific\ngenes that sometimes influence language acquisition.\nWhat are the limitations of Chomsky’s approach? First, the world’s lan-\nguages differ far more than he predicted. Second, Chomsky now admits\nthe universal grammar is very restricted in scope and so there are very few\nlinguistic universals. Third, the notion that children’s linguistic input is too\nimpoverished to produce language acquisition is highly debatable. Fourth,\nChomsky de-emphasised the importance of our high-level cognitive abil-\nities in explaining why only humans have fully developed language skills.\nWhorfian hypothesis\nThe best-known theory about the relationship between language and\nthought was proposed by Benjamin Lee Whorf (1956). He was a fire pre-\nvention officer for an insurance company, and his hobby was linguistics.\nWhorf’s views have often been distorted to imply that he believed that lan-\nguage necessarily determines thought (and behaviour).\nWhorf’s actual views were far more reasonable. For example, he discussed\na hypothetical case in which an explosion occurred when workers were\ncareless with cigarettes near empty gasoline drums. The workers’ care-\nlessness may have been due in part to the word empty, which suggests\nthere is nothing in the drum (not even vaporous fumes). This example could\nbe interpreted as meaning that Whorf believed that language determines\nCreated from usyd on 2022-02-16 03:16:01.",
    "thought and behaviour. However, he clarified his views (quoted in Lee,\n1996, p. 153): “I don’t wish to imply that language is the sole or even the\nleading factor in . . . the ﬁre-causing carelessness through misunderstand-\nings induced by language, but that this is simply a coordinate factor along\nwith others.”\nAccording to the Whorfian hypothesis, language influences thinking and\nbehaviour in various ways. Of central importance is the notion of linguistic\nrelativity – how speakers of any given language think are influenced by the\nlanguage they speak.\nFindings\nCategorical perception means observers find it easier to discriminate\nbetween stimuli belonging to different categories than those in the same\ncategory (see Chapter 9). Categorical perception is assumed to depend\nin part on language. Suppose we compared the categorical perception of\ncolour in people speaking different languages that varied in the number of\nbasic colour terms. According to the Whorfian hypothesis, we might predict\nthese linguistic differences would influence the perception (and memory for)\ncolour. Support for this prediction was reported by Winawer et al. (2007).\nRussian differs from English in having separate words for dark blue (siniy)\nand light blue (goluboy). Russian participants found it easier than English\nones to discriminate between dark and light blue stimuli.\nOther studies have produced different findings. For example, Wright et al.\n(2015) compared colour memory in English speakers (11 basic colour terms)\nand Himba speakers (5 basic colour terms) but found no differences. Wright\net  al. also reviewed other research in which the findings were a mixture\nof significant and non-significant with no obvious explanation for the\ndifferences.\nManner of motion (e.g., hopping; running) is expressed more prominently\nin English than Spanish. As a result, Kersten et  al. (2010) argued English\nspeakers should outperform Spanish ones on a task where novel animated\nobjects were categorised on the basis of manner of motion. The find-\nings were as predicted, suggesting language can influence thinking and\nperformance.\nWe must not exaggerate language’s impact on thinking. Consider a study\nby Li et al. (2009). Observers saw objects made of a given substance (e.g.,\na plastic whisk). English speakers focused on the object itself (whisk) rather\nthan the substance (plastic), whereas Mandarin and Japanese speakers\nfocused on the substance.\nThe above differences may reflect differences in the three languages and so\nsupport the Whorfian hypothesis. However, when participants simply indi-\ncated how likely they would be to think of various objects as objects or as\nsubstances, there were no differences across the three languages. Thus, the\neffects of language were very task specific.\nKEY TERMS\nWhorfian hypothesis\nThe theoretical\nassumption that language\ninfluences perception,\nthinking and behaviour.\nLinguistic relativity\nThe notion that speakers\nof different languages\nthink differently.\nLanguage\n399\nCreated from usyd on 2022-02-16 03:16:01.",
    "400\nLanguage\nFrank et  al. (2008) studied the Pirahã, an Amazonian tribe. They have\nno words to express precise quantities or numbers, not even “one”.\nNevertheless, the Pirahã could perform exact quantitative matches even\nwith large numbers of objects. However, their performance was inaccu-\nrate when information needed to be remembered. Thus, language is not\nessential for certain numerical tasks. However, it provides an efficient way of\nencoding information and so boosts performance when memory is required.\nEvaluation\nLanguage influences our thinking and performance on many tasks (Wolff\n& Holmes, 2011). For example, it can enhance memory (Frank et al., 2008)\nand increase categorical perception (Winawer et  al., 2007). This is unsur-\nprising: “Language mobilises ordinary cognitive mechanisms whose effects\non people’s thoughts, feelings, and judgments should be uncontroversial”\n(Casasanto, 2016, p. 715).\nThe crucial issue is not whether the Whorfian hypothesis is correct but\nrather it is to identify the conditions in which language does (and does not)\ninfluence cognition. Regier and Xu (2017) addressed the latter issue by\nfocusing on mental uncertainty. High mental uncertainty “opens the door\nto language to fill in some of the missing elements, and there should be a\nrelatively strong effect of language” (p. 1). For example, Bae et al. (2015)\nasked American participants to identify the colour they had seen immedi-\nately or after a delay. There was greater bias reflecting colour categories in\nthe English language in the latter condition where there was greater uncer-\ntainty concerning the colour presented.\nLanguage chapters\nWe possess four main language skills (listening to speech; reading; speak-\ning; and writing). It is perhaps natural to assume any given person will have\ngenerally strong or weak language skills. That assumption is often incorrect\nwith respect to people’s first language – for example, many people speak\nfluently and coherently but find writing difficult. The assumption is even less\nexact with respect to people’s second language. The first author has spent\nnumerous summer holidays in France and can just about read newspapers\nand easy novels in French. However, he finds it agonisingly hard to under-\nstand rapidly spoken French and his ability to speak French is poor.\nThe three chapters in this section (Chapters 9–11) in this section focus on the\nfour main language skills. Chapter 9 deals with the basic processes involved\nin reading and listening to speech. The emphasis is on how readers and\nlisteners identify and make sense of individual words. As we will see, the\nstudy of brain-damaged patients has clarified the complex processes under-\nlying reading and speech perception.\nChapter 10 deals mostly with the processes involved in the comprehen-\nsion of sentences and discourse (connected text or speech). Most of these\nprocesses are common to text and speech. An important part of sentence\nCreated from usyd on 2022-02-16 03:16:01.",
    "understanding involves parsing (working out the sentence’s grammatical\nstructure). Understanding discourse involves drawing numerous inferences\nand often forming a mental model of the situation described.\nChapter 11 deals with the remaining two main language abilities: speaking\nand writing. We spend much more of our time speaking than writing. This\nhelps to explain why we know much more about speech production than\nwriting. Research on writing has been somewhat neglected until recently.\nThis is regrettable given the importance of writing skills in many cultures.\nThe processes discussed in these three chapters are interdependent. For\nexample, listeners use language production processes to predict what\nspeakers will say next (Pickering & Garrod, 2013). More generally, Chater\net al. (2016, p. 244) argued that “Language comprehension and production\nare facets of a unitary skill”.\nLanguage\n401\nCreated from usyd on 2022-02-16 03:16:01.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception\nand reading\nINTRODUCTION\nHumans excel in their command of language. Language is so important\nthat this chapter and the following two are devoted to it. In this chapter, we\nconsider basic processes involved in recognising spoken words and reading\nwords. As discussed in Chapter 10, many comprehension processes are very\nsimilar whether we listen to someone talking or read a text. For example,\nyou would probably understand the sentence, “You have done exception-\nally well in your cognitive psychology examination”, equally well whether\nyou read or heard it.\nRayner and Clifton (2009) identified two important similarities between\nspeech perception and reading. First, both are typically fast. Adult readers\ncan read between 250 and 350 words per minute. Speech perception is\nslower but can approach typical reading rates. Second, reading and speech\nperception are incremental – much processing (e.g., semantic; syntactic)\noccurs while a word is attended to.\nAnother similarity concerns anticipatory language processing. Readers\nand listeners devote resources during sentence processing to predicting\nupcoming words or phrases (Huettig, 2015). The complexities involved are\ndiscussed fully later (see pp. 415–416).\nThere is a final important similarity. Children learn to understand\nspeech before they learn to read. Unsurprisingly, some processes and abil-\nities involved in understanding speech are also relevant in reading. For\nexample, individuals with severe reading problems frequently have prob-\nlems with auditory processing (Farmer & Klein, 1995). More specifically,\nsuch individuals are often impaired at categorising phonemes (speech\nsounds) (O’Brien et al., 2018).\nThere are also several differences between reading and speech percep-\ntion. In reading, most words can be seen as a whole and remain in vision.\nIn contrast, spoken words are spread out in time and are transitory. In\naddition, it is harder to decide where one word ends and the next starts.\nSpeech generally provides a more ambiguous signal than printed\ntext. For example, when words were spliced out of spoken sentences\nChapter\n9\nCreated from usyd on 2022-02-16 03:16:01.",
    "404\nLanguage\nand presented on their own, they were recognised only 50% of the time\n(Lieberman, 1963).\nOur ability to hear what a speaker is saying is often impaired by other\nspeakers close by and/or irrelevant noises. In contrast, readers are rarely\ndistracted by other visual stimuli. Finally, demands are greater when listen-\ning to speech than reading a text because previous words are inaccessible.\nSo far we have indicated why speech perception can be harder than\nreading. However, speech perception can be easier in some ways. Speech\noften contains prosodic cues (see Glossary and Chapter 10), which are\nhints to sentence structure and intended meaning provided by the speaker’s\npitch, intonation, stress and timing. Speakers also often accompany their\nspeech with meaningful gestures. In contrast, the main cues to sentence\nstructure in text are punctuation marks (e.g., commas; semi-colons). These\ncues are often less informative than speakers’ prosodic cues.\nSome adult brain-damaged patients can understand spoken language\nbut cannot read. Other patients have good reading skills but cannot under-\nstand the spoken word. Thus, reading and speech perception involve some-\nwhat different brain areas and cognitive processes.\nThis chapter starts with the basic processes specific to speech percep-\ntion (e.g., those required to divide the speech signal into separate words\nand to recognise those words). After that, we consider the basic processes\nspecific to reading (e.g., those involved in recognising, reading individual\nwords and guiding our eye movements). Why have we adopted this order-\ning (speech perception followed by reading)? As mentioned earlier, most\nchildren develop competence in speech perception several years before they\ncan read. In addition, some processes that children use while learning to\nread closely resemble those acquired earlier when learning to understand\nspoken language.\nIn Chapter 10, we discuss comprehension processes common to reading\nand listening. The emphasis there is on larger units of language consisting\nof several sentences.\nSPEECH (AND MUSIC) PERCEPTION\nSpeech perception is easily the most important form of auditory perception.\nHowever, “The human relationship with sound is much deeper and more\nancient than our relationship with words” (Kraus & Slater, 2016, p. 84).\nImportant forms of auditory perception not involving words include music\nperception and identifying the nature and sources of environmental sounds.\nThe relationship between speech perception and auditory perception\nis controversial. Perhaps humans have special speech-perception mecha-\nnisms: the “speech is special” approach (e.g. Trout, 2001). Alternatively,\nthe same general mechanisms may process speech and non-speech sounds\n(Carbonell & Lotto, 2014).\nBrandt et al. (2012, p. 1) claimed controversially that we can “describe\nlanguage as a special type of music”. There is some support for this claim.\nFirst, music and language perception both involve the goal of “grouping\nacoustic features together to form meaningful objects and streams” (Kraus\n& Slater, 2016, p. 86).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n405\nSecond, if you listen repeatedly to the same looped recording of speech,\nit often starts to sound like singing when you stop attending to its meaning\n(Tierney et  al., 2013). Brain areas associated with music perception were\nmore activated by repeated speech perceived as song than repeated speech\nnot perceived as song. Tierney et al. (2018) also studied the speech-to-song\nillusion. Ratings of the musicality of spoken phrases increased when these\nphrases were repeated and listeners became more responsive to the musical\nstructure (e.g., melodic structure) of the phrases.\nFurther evidence on the relationship between speech and music percep-\ntion is discussed briefly below.\nCategorical perception\nSuppose listeners are presented with a series of sounds, starting with /ba/\nand gradually moving towards /da/, and report what sound they hear. What\ntypically happens is categorical perception – speech stimuli intermediate\nbetween two phonemes are categorised as one of those phonemes (discussed\nlater in a section entitled “Ganong effect”, p. 415). Below we consider\nwhether categorical perception is unique to speech perception.\nRaizada and Poldrack (2007) presented listeners with two audi-\ntory stimuli and asked them to decide whether they represented the same\nphoneme. There was evidence of categorical perception. The differences in\nbrain activation associated with the two stimuli were amplified when they\nwere on opposite sides of the boundary between the two phonemes. There is\noften only limited evidence for categorical perception with speech sounds. It\nis less evident with vowels than consonants, and listeners are often sensitive\nto variations within a given perceptual category (Monahan, 2018).\nBidelman and Walker (2017) reviewed findings indicating categorical\nperception is also present in music. However, it was stronger for speech\nthan music (especially among non-musician listeners). These findings\nsuggest categorical perception occurs mostly with familiar stimuli.\nFinally, Weidema et  al. (2016) presented various pitch contours\nembedded in linguistic or melodic phrases. There was evidence of categor-\nical perception in both the language and music contexts. However, identi-\ncal pitch contours were categorised differently depending on whether they\nwere perceived as language or music. Thus, there are both similarities and\ndifferences in categorical perception in speech and music.\nDo music and speech perception involve the same\nbrain areas?\nThe relationship between music and speech perception can be studied\nby comparing the brain areas activated with each form of perception.\nHowever, “The extent of neural overlap between music and speech remains\nhotly debated” (Jantzen et al., 2016, p. 1).\nSome neuroimaging research has reported mostly non-overlapping\nbrain regions are involved in music and speech perception. However, Slevc\nand Okada (2015) argued this is not the case when relatively complex tasks\nare used. They found complex music and speech perception both involved\ncognitive control (using the prefrontal cortex areas), which is used “to\nKEY TERM\nCategorical perception\nA sound intermediate\nbetween two phonemes\nis perceived as being one\nor other of the phonemes;\na similar phenomenon is\nfound in vision with colour\nperception.\nCase study:\nAmerican Sign Language\nCreated from usyd on 2022-02-16 03:16:01.",
    "406\nLanguage\ndetect and resolve conflict that occurs when expectations are violated and\ninterpretations must be revised” (p. 637).\nLacroix et al. (2015) conducted a meta-analytic review. Passive music\nand speech listening were both associated with activation in large areas of\nthe superior temporal gyrus. However, the precise areas differed between\nmusic and speech perception (see Figure 9.1). In addition, Broca’s area\n(in the inferior frontal gyrus) was more activated during speech perception\nthan music perception. Lacroix et al. concluded: “Our findings of spatially\ndistinct regions for music and speech clearly suggest the recruitment of\ndistinct brain networks for speech and music” (p. 15).\nResearch on brain-damaged patients has also revealed important dif-\nferences between speech and music perception. Some patients have intact\nspeech perception but impaired music perception whereas others have intact\nmusic perception but impaired speech perception (Peretz & Coltheart, 2003).\nIn sum, there are important similarities between music and speech per-\nception (e.g., the involvement of cognitive control). However, they differ\nwith respect to underlying brain areas and cognitive processes. Note that\nthe specific tasks used to assess music or speech perception greatly  influence\nthe precise brain areas activated (Lacroix et al., 2015).\nProcessing stages\nA sketch map of the main processes involved in speech perception is shown\nin Figure 9.2. Initially, listeners often have to select out the speech signal of\ninterest from several other irrelevant auditory inputs (e.g., other voices; see\nChapter 5). After that, decoding involves extracting discrete elements (e.g.,\nphonemes or other basic speech sounds) from the speech signal.\nThere is controversy as to whether decoding involves identifying\nphonemes (small units of sound; see Glossary) or syllables (speech units\nbased on a vowel sound often plus one or more consonants). Goldinger\nSpeech passive listening > Music passive listening\nMusic passive listening\nSpeech passive listening\nLeft hemisphere\nRight hemisphere\n(a) Single condition activation likelihood estimates: Passive listening to speech & music\n(b) Passive listening  contrasts:\nMusic passive listening > Speech passive listening\na\nb\nc\nd\n–55\n–50\n–46\n–42\n55\n50\n46\n42\nL\nL\nL\nR\nR\nR\n–50\n50\n–8\n6\nb\na\nc\nd\nFigure 9.1\n(a) Areas activated during\npassive music listening\n(blue) and passive speech\nlistening (orange); (b) Areas\nactivated more by listening\nto music than speech (blue)\nor the opposite (orange).\nLacroix et al. (2015).\nKEY TERM\nSyllable\nA unit of speech\nconsisting of one vowel\nsound with or without\none or more additional\nconsonants (e.g., water\nhas two syllables: wa and\nter).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n407\nand Azuma (2003) argued the unit in speech perception varies flexibly.\nListeners heard lists of non-words recorded by speakers who had been\ntold phonemes or syllables were the basic units of perception. Listeners\ndetected phoneme targets faster than syllable targets when the speaker\nbelieved phonemes were the basic units, but the opposite was the case\nwhen the speaker believed syllables were the basic units. These findings\nsuggest either phonemes or syllables can form the perceptual units in\nspeech perception.\nThere is an important distinction between phonemes and allophones\n(variant forms of any given phoneme). Consider the words pit and spit.\nThey both contain the same phoneme /p/. However, there are slight differ-\nences in the way /p/ is pronounced in the two words. Thus, there are two\nallophones relating to /p/ but only one phoneme and so allophones are\ncontext-dependent whereas phonemes are context-independent.\nThere has been controversy as to whether phonemes or allophones\nare the basic units in spoken word recognition. However, Mitterer et  al.\n(2018) reviewed the literature and reported several experiments suggesting\nthat early processing of spoken words is based on allophones rather than\nphonemes.\nThe third stage (word identification) is of special importance. Various\nproblems in word identification are discussed shortly. However, one\nFigure 9.2\nThe main processes\ninvolved in speech\nperception and\ncomprehension.\nFrom Cutler and Clifton (1999).\nBy permission of Oxford\nUniversity Press.\nKEY TERM\nAllophones\nVariant forms of a given\nphoneme; for example,\nthe phoneme /p/ is\nassociated with various\nallophones (e.g., in pit\nand spit; Harley, 2013).\nCreated from usyd on 2022-02-16 03:16:01.",
    "408\nLanguage\nproblem will be mentioned here. All English words are formed from only\nabout 35 phonemes. As a result, most spoken words resemble many other\nwords at the phonemic level, making them hard to distinguish. However,\nthe task becomes easier if listeners make use of allophones rather than\nphonemes (discussed above).\nThe fourth and fifth stages both emphasise speech comprehension. The\nfourth stage focuses on utterance interpretation. This involves constructing\na coherent meaning for each sentence based on information about indi-\nvidual words and their order within the sentence. Finally, the fifth stage\ninvolves integrating the meaning of the current sentence with preceding\nspeech to construct an overall model of the speaker’s message.\nIn sum, speech perception and comprehension involve several pro-\ncessing stages. However, it is an oversimplification to assume speech per-\nception typically involves serial processes occurring in the neat-and-tidy\nfashion shown in Figure 9.2.\nLISTENING TO SPEECH\nUnderstanding speech is often difficult for two broad types of reasons.\nFirst, speech perception depends on several aspects of the speech signal\n(discussed shortly, pp. 409–412). Second, it depends on whether speech\nis heard under optimal or adverse conditions. Mattys et al. (2012, p. 953)\ndefined an adverse condition as “any factor leading to a decrease in speech\nintelligibility on a given task relative to the level of intelligibility when the\nsame task is performed in optimal listening conditions”.\nMattys et al. (2009) identified two major types of adverse conditions.\nFirst, there is energetic masking: distracting sounds cause the intelligibility\nof target words to be degraded. Energetic masking, which mostly affects\nbottom-up processing, is a serious problem in everyday life (e.g., several\npeople talking at once; noise of traffic). Until recently, most laboratory\nresearch on speech perception lacked ecological validity (see Glossary)\nbecause listeners were rarely confronted by distracting sounds.\nSecond, there is informational masking: cognitive load (e.g., per-\nforming a second task while listening to speech) makes speech percep-\ntion harder. Informational masking mainly affects top-down processing.\nFor example, Mitterer and Mattys (2017) found speech perception was\nimpaired by cognitive load even when the second task was visual in nature\n(face processing).\nAlain et  al. (2018) found listeners use different processes depending\non why speech perception is difficult. They conducted a meta-analysis (see\nGlossary) of three types of studies: (1) speech in noise; (2) degraded speech;\nand (3) complexity of the linguistic input. Their key finding was that pat-\nterns of brain activation varied across these three types of studies.\nProblems with the speech signal\nHere are some specific problems with the speech signal often faced by listeners:\n(1) There is segmentation, which involves separating out or distin-\nguishing phonemes (units of sound) and words from the pattern of\nKEY TERM\nSegmentation\nDividing the almost\ncontinuous sounds of\nspeech into separate\nphonemes and words.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n409\nspeech sounds. Most speech has few periods of silence, as you have\nprobably noticed when listening to someone speaking an unfamiliar\nforeign language. This makes it hard to decide when one word ends\nand the next begins.\n(2) There is coarticulation: a speaker’s pronunciation of a phoneme\ndepends on the preceding and following phonemes. Harley (2010,\np. 148) provides an example: “The /b/ phonemes in ‘bill’, ‘ball’, ‘able’,\nand ‘rub’ are all acoustically slightly different.” Coarticulation is\nproblematical because it increases the variability of the speech signal.\nHowever, it can provide a useful cue, because it allows listeners to\npredict the next phoneme to some extent.\n(3) Speakers differ in several ways (e.g., sex; dialect; speaking rate)\nand yet we generally cope well with such variability. Kriengwatana\net  al.  (2016) trained Dutch and Australian-English listeners to\ndiscriminate two Dutch vowels from a single speaker. Both groups\nsubsequently successfully categorised the same vowels when spoken\nby a speaker of the opposite sex. However, both groups performed\npoorly and required feedback when the vowels were spoken by\nsomeone with a different accent. Thus, adapting to a different-sexed\nspeaker is  relatively “automatic” but adapting to a different accent\nrequires active processing of additional information (e.g., feedback;\ncontext).\nExpectations are important (Magnuson & Nusbaum, 2007). Some\nlisteners expected to hear two speakers with similar voices whereas\nothers expected to hear only one speaker. In fact, there was only\none speaker. Those expecting two speakers showed worse listening\nperformance.\n(4) Language is spoken at 10 phonemes (basic speech sounds) per second\nand much acoustic information is lost within 50 ms (Remez et al., 2010).\nAs a consequence, “If linguistic information is not processed rapidly,\nthat information is lost for good” Christiansen & Chater, 2016, p. 1).\n(5) Non-native speakers often produce speech errors (e.g., saying words\nin the wrong order). Listeners cope by using top-down processes to\ninfer what non-native speakers are trying to say (Lev-Ari, 2014; see\nChapter 10).\nCoping with listening problems\nWe have seen listeners experience various problems in understanding the\nspeech signal. How do they cope? Multiple sources of information are used\nflexibly depending on the immediate situation. There are bottom-up pro-\ncesses stemming directly from the acoustic signal. There are also top-down\nprocesses based on the listener’s past knowledge and contextual informa-\ntion (e.g., the speaker’s previous utterance). Below we discuss how these\nprocesses assist speech perception.\nSegmentation\nDividing the speech signal into its constituent words (i.e., segmentation)\nis crucial for listeners. Segmentation involves using several cues. Some are\nKEY TERM\nCoarticulation\nA speaker’s production of\na phoneme is influenced\nby their production of the\nprevious sound and by\npreparations for the next\nsound.\nCreated from usyd on 2022-02-16 03:16:01.",
    "410\nLanguage\nacoustic-phonetic (e.g., coarticulation; stress) whereas others depend on the\nlistener’s knowledge (e.g., of words) and the immediate context (Mattys\net al., 2012).\nSegmentation is influenced by constraints on what words are possible\n(e.g., a stretch of speech lacking a vowel is not a possible word in English).\nListeners found it hard to identify the word apple in fapple because fapple\ncould not possibly be an English word (Morris et al., 1997). In contrast,\nlisteners easily detected the word apple in wuffapple because wuff could be\nan English word.\nEvidence indicating segmentation can be based on possible word con-\nstraints has been obtained in several languages. However, it does not apply\nto Russian, a language which has some single-consonant words lacking a\nvowel (Alexeeva et al., 2017).\nStress is an important acoustic cue. In English, the initial syllable of\nmost content words (e.g., nouns; verbs) is typically stressed. Strings of\nwords without the stress on the first syllable are misperceived (e.g., “conduct\nascents uphill” is perceived as “A duck descends some pill”).\nThere are other acoustic cues. For example, there is generally more\ncoarticulation within than between words. In addition, segments and sylla-\nbles at the start and end of words are lengthened relative to those in the\nmiddle (Kim et al., 2012).\nMattys et  al. (2005) identified three main categories of cues: lexical\n(e.g., syntax; word knowledge); segmental (e.g., coarticulation); and\nmetrical prosody (e.g., word stress) in his hierarchical approach (see\nFigure 9.3).\nWhen all cues are available, we prefer to use lexical cues (Tier 1).\nWhen lexical information is impoverished, we use segmental cues such\nas  coarticulation and allophony (one phoneme may be associated with\ntwo or more similar sounds or allophones) (Tier 2). For example, the\nFigure 9.3\nA hierarchical approach\nto speech segmentation\ninvolving three levels\nor tiers. The relative\nimportance of the different\ntypes of cue is indicated\nby the width of the purple\ntriangle.\nFrom Mattys et al. (2005).\n© American Psychological\nAssociation.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n411\nphoneme /p/ is pronounced differently in pit and spit. Finally, we resort to\nmetrical prosody cues (e.g., stress) when it is hard to use Tier 1 or 2 cues.\nOne reason we often avoid using stress cues is because stress information\ncan be misleading when a word’s initial syllable is not stressed (Cutler &\nButterfield, 1992).\nMattys (2004) found coarticulation (Tier 2) was more useful than\nstress (Tier 3) for identifying word boundaries when the speech signal\nwas  intact.  In contrast, when the speech signal was impoverished\nand made  it hard to use Tier 1 or 2 cues, stress was more useful than\ncoarticulation.\nSpeaker variability\nEarlier we discussed problems listeners have when dealing with variations\nacross speakers in accent, speaking rate, and so on. Cai et al. (2017) pro-\nposed a model to explain how listeners cope with variability (see Figure 9.4).\nThey assumed listeners use information provided by the speech signal to\ninfer characteristics of the speaker (i.e., to construct a speaker model) and\nthis influences how speech is perceived.\nCai et al. (2017) tested their model using words typically having some-\nwhat different meanings when heard in an American or English accent.\nFor example, the American meaning of bonnet is usually hat whereas the\nBritish meaning is usually part of a car. As predicted, British listeners were\nmore likely to interpret such words as having the American meaning when\nspoken in an American rather than British accent.\nThe crucial condition involved presenting such words in a neutral\naccent. These words were presented in the context of other words spoken\nin an American or British accent. As predicted, the neutral words were\nmore likely to be interpreted in their American meaning when the context\nconsisted of words spoken in an American accent. Thus, the listeners’\nspeaker model biased their interpretations.\nMcGurk effect\nListeners (even with intact hearing) often make extensive use of lip-\nreading when listening to speech. McGurk and MacDonald (1976) pro-\nvided a striking demonstration of the McGurk effect (reviewed by\nMarques et  al., 2016). They prepared a videotape of someone saying\n“ba” repeatedly. Then the sound channel changed so there was a voice\nsaying “ga” repeatedly in synchronisation with lip movements still indi-\ncating “ba”. Listeners reported hearing “da”, a blending of the visual\nand auditory information (see this on YouTube: “McGurk effect (with\nexplanation)”.\nOn average, the McGurk effect is strongest when the auditory input\nlags 100 ms behind the visual input (Ipser et  al., 2017). This probably\nhappens because lip movements can be used predictively to anticipate\nthe next sound to be produced. Soto-Faraco and Alsius (2009) found the\nMcGurk effect is unexpectedly robust: listeners showed the effect even\nwhen they were aware of a temporal mismatch between the visual and\nauditory input (one started before the other).\nKEY TERM\nMcGurk effect\nA mismatch between\nspoken and visual (lip-\nbased) information leads\nlisteners to perceive a\nsound or word involving a\nblending of the auditory\nand visual information.\nCreated from usyd on 2022-02-16 03:16:01.",
    "412\nLanguage\nIndexical\npathway\nSpeaker\nmodel\nDialect, age, gender, ...\nstable over words\nWordform\nrepresentations\n... /bonrt/ ...\nChanges over words\nLexical-semantic\npathway\nLexical-semantic\nrepresentations\nDialect modulation\nMeaning access\nWord identifcation\nBonnetUK\nBonnetUS\n...\n...\n...\n...\nPerson identifcation\nVocal features\nAuditory input\nFigure 9.4\nA model of spoken word\ncomprehension. Its key\nassumption is that the\nspeech signal contains\ninformation about who\nis speaking (indexical\ninformation) and what they\nare saying (lexical-semantic\npathway). These two kinds\nof information interact\nduring speech perception.\nCai et al. (2017). Reprinted with\npermission of Elsevier.\nTop-down processes are important. The McGurk effect was stronger\nwhen the crucial word formed by blending auditory and visual input was\npresented in a semantically congruent (rather than incongruent) sentence\n(Windmann, 2004).\nCONTEXT EFFECTS\nContext consists of relevant information not contained directly in the audi-\ntory signal currently available to listeners. There are several types of con-\ntextual information including that provided by previous input (e.g., earlier\nparts of a sentence) and that provided by our knowledge of language and\nwords.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n413\nIt is indisputable that context typically influences spoken word recogni-\ntion. However, it is hard to clarify when and how context exerts its influ-\nence. Harley (2013) identified two extreme positions. According to the\ninteractionist account, contextual information influences processing at an\nearly stage and may influence word perception. In contrast, the autonomous\naccount claims context has its effects late in processing. According to this\naccount: “context cannot have an effect prior to word recognition. It can\nonly contribute to the evaluation and integration of the output of lexical\nprocessing, not its generation” (Harley, 2013). These theoretical approaches\nare discussed in the next section.\nEvidence that context can rapidly influence spoken word recognition\nwas reported by Brock and Nation (2014). Participants viewed a display\ncontaining four objects and then heard a sentence. Their task was to click\non any object mentioned in the sentence. In the first three conditions (see\nbelow), the sentence object was not in the display, but a critical distractor\nobject was present:\nIN REAL LIFE: MISHEARD LYRICS AND MISCARRIAGES OF JUSTICE\nWe easily mishear the lyrics of songs if provided with the wrong words (or context) beforehand.\nThe comedian Peter Kay provides hilarious examples (YouTube: “Peter Kay Misheard Lyrics”).\nFor example, he suggested the song “My heart will go on” from the Titanic movie contains the\nline “I believe the hot dogs go on” instead of the actual line “I believe the heart does go on”.\nThe effect is strong – the first author cannot stop misperceiving that line! As Liden et al. (2016,\np. 12) pointed out, song lyrics are susceptible to misperception because of “atypical pronuncia-\ntion resulting in ambivalent speech signals in combination with . . . the presence of other acoustic\nsignals (i.e., the instrumental music)”.\nMisleading context leading to misperceptions can have serious consequences when we consider\nthe use of covert recordings of suspects in criminal trials. These recordings are often indistinct, and\nso what happens is that detectives provide a transcript of their interpretation of what was said.\nIf this transcript is incorrect (perhaps because detectives assume the suspect is guilty), this can\nstrongly bias what jurors believe they hear (Fraser, 2018a).\nConsider the real-life case of a man sentenced to a 30-year prison sentence for murder largely\nbecause of an inaccurate police transcript. Hear the crucial recording at forensictranscription.com.\nau/audio (the one-minute recording is under the heading “‘Assisting’ listeners to hear words that\naren’t there”). What do you think the man is saying? Jurors at the trial were told what a detective\nclaimed to hear (given at the bottom of this Box).\nFraser (2018b) carried out an experiment in which listeners initially heard the recording without\nany context. No listeners reported hearing anything like the incriminating sentence. When primed\nwith the detective’s transcript, however, 15% said they definitely heard that sentence and 16% said\nthey thought they heard it.\nIn sum, top-down effects of context can be so strong that they lead listeners to misperceive\nspeech. Such effects can be durable. Many listeners told explicitly they were being given incorrect\nwords for a song (visual context) subsequently misperceived the song lyrics in the absence of the\nmisleading visual context (Beck et al., 2014a).\nThe detective’s transcript: “At the start we made a pact.”\nCreated from usyd on 2022-02-16 03:16:01.",
    "414\nLanguage\n(1)  Competitor constraining (e.g., “Alex fas-\ntened the button”; butter in display)\n(2)  Competitor neutral (e.g., “Alex chose\nthe button”; butter in display)\n(3)  Unrelated neutral (e.g., “Alex chose the\nbutton”; lettuce in display)\n(4)  Target neutral (e.g., “Joe chose the\nbutton”; button in display)\nBrock and Nation (2014) recorded eye move-\nments (see Figure 9.5). When the sentence\ncontext made the critical object improbable\n(condition 1), participants were far less likely\nto fixate it than when the sentence context was\nless constraining (condition 2). This difference\nwas apparent early on and indicates sentence\ncontext has almost immediate effects on word\nprocessing. This is consistent with the interac-\ntionist account.\nIn what follows, we discuss various\ncontext effects. These effects will be related to\nthe interactionist and autonomous accounts.\nPhonemic restoration effect\nWarren and Warren (1970) obtained strong evidence that sentence context\ncan influence phoneme perception in the phonemic restoration effect.\nListeners heard a sentence with a missing phoneme that had been replaced\nwith a meaningless sound (cough). The sentences used were as follows (* =\nmissing phoneme):\n●\nIt was found that the *eel was on the axle.\n●\nIt was found that the *eel was on the shoe.\n●\nIt was found that the *eel was on the table.\n●\nIt was found that the *eel was on the orange.\nThe perception of the crucial element in the sentence (i.e., *eel) was\ninfluenced by the sentence in which it appeared. Participants listening to\nthe first sentence heard wheel, those listening to the second sentence heard\nheel, and those exposed to the third and fourth sentences heard meal and\npeel, respectively. The crucial auditory stimulus (i.e., *eel) was always the\nsame so all that differed was the contextual information.\nWhat causes the phonemic restoration effect? There may be a fairly\ndirect effect on speech processing, with the missing phoneme being pro-\ncessed almost as if it were present (Samuel, 2011). Alternatively, there may\nan indirect effect with listeners guessing the identity of the missing phoneme\nafter basic speech processing has occurred.\nLeonard et al. (2016) obtained findings strongly supporting the notion of\na direct effect. The noise input was followed almost immediately by activa-\ntion in language areas within the left frontal cortex associated with predicting\nFigure 9.5\nGaze probability for critical objects over the first 1,000 ms\nsince target word onset for target neutral, competitor neutral,\ncompetitor constraining and unrelated neutral conditions\n(described in text).\nFrom Brock and Nelson (2014).\nKEY TERM\nPhonemic restoration\neffect\nThe finding that listeners\nare unaware that a\nphoneme has been\ndeleted and replaced by\na non-speech sound (e.g.,\ncough) within a sentence.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n415\nwhich word had been presented. This was followed very rapidly by appropri-\nate phonemic processing in the auditory cortex. This latter finding strongly\nsuggests a direct effect consistent with the interactionist perspective rather\nthan an indirect effect consistent with the autonomous approach.\nGanong effect\nEarlier we saw listeners often show categorical perception (see p. 405), with\nspeech signals intermediate between two phonemes being categorised as\none phoneme or the other. Ganong (1980) wondered whether categorical\nperception of phonemes would be influenced by the immediate context.\nAccordingly, he presented listeners with various sounds ranging between a\nword (e.g., dash) and a non-word (e.g., tash). There was a context effect –\nan ambiguous initial phoneme was more likely to be assigned to a given\nphoneme category when it produced a word. This is the Ganong effect.\nIn order to understand the processes underlying the Ganong effect, it\nis important to ascertain when lexical (word-based) processing influences\nphonemic processing. Kingston et al. (2016) obtained clear evidence on this\nissue. Listeners categorised phonemes by choosing between two visually\npresented options (one completing a word and the other not). Listeners\ndirected their eye movements to the word-completing option almost imme-\ndiately. This finding strongly suggests there is a remarkably rapid merging\nof phonemic and lexical processing. This seems inconsistent with the\nnotion that phonemic processing is completed prior to the use of word-\nbased processing.\nInteractionist vs autonomous accounts\nSo far we have considered how contextual information is used with respect\nto specific phenomena (phonemic restoration effect; Ganong effect). More\nbroadly, we can consider the role of prediction in spoken word recognition.\nPredictive influences should generally occur more rapidly on interactionist\nthan autonomous accounts (see Kuperberg and Jaeger, 2016, for a review).\nVan Berkum et  al. (2005) presented sentences in Dutch such as the\nfollowing:\nThe burglar had no trouble locating the secret family safe. Of course, it\nwas situated behind a . . .\nIt is reasonable to predict the following noun will be painting, which has the\nneuter gender in Dutch. The word a was followed by the Dutch adjective\nbig in the neuter gender or common gender. Event-related potentials (ERPs;\nsee Glossary) to the adjective differed depending on whether its gender was\nconsistent with the predicted noun (i.e., painting). Thus, story context can\ninfluence speech processing before the predicted word is presented.\nIn similar fashion, Grisoni et al. (2017) presented spoken sentences in\nwhich the final word was relatively easy to predict (e.g., “I take the pen\nand I [write]”; “I take some grapes and I [eat]”). Patterns of brain activity\nreflected the meaning of the predicted final word before it was presented.\nMore specifically, brain areas associated with hand-related actions were\nKEY TERM\nGanong effect\nThe finding that\nperception of an\nambiguous phoneme is\nbiased towards a sound\nthat produces a word\nrather than a non-word.\nCreated from usyd on 2022-02-16 03:16:01.",
    "416\nLanguage\nactivated prior to a semantically relevant final word (e.g., write) and those\nassociated with face-related actions were also activated prior to a semanti-\ncally relevant word (e.g., eat).\nFurther evidence supporting the interactionist position was reported\nby Wild et  al. (2012; see also Chapter 1). Listeners heard sentences\npresented in clear speech or degraded (but potentially intelligible)\nspeech. Each sentence was accompanied by context: a text matching\nthe spoken words or a random consonant string. The rated perceptual\nclarity of the sentences was greater when they were accompanied by\nmatching text.\nHow can we explain the above context effect? According to the\ninteractionist position, matching context might influence the early stages\nof spoken word processing within primary auditory cortex. In contrast,\nit follows from the autonomous position that context should influence\nonly later processing stages and so should not influence processing in\nthe primary auditory cortex. The findings were entirely consistent with the\ninteractionist position.\nIn similar fashion, Sohoglu et al. (2014) found the perceived clarity of a\ndegraded spoken word was greater when preceded by written text (context)\ncontaining that word. However, when the same contextual information\nwas presented after a spoken word, it had very little effect on the word’s\nperceived clarity. This seems inconsistent with the autonomous position,\naccording to which context has its effects late in processing.\nFinally, we return to Wild et  al.’s (2012) study. There was no effect\nof matching context on activation within primary motor cortex when sen-\ntences were presented in clear speech. Why do these findings differ from\nthose with degraded speech? Speech perception was so straightforward\nwith clear speech there was no need (and also insufficient time) for context\nto activate primary auditory cortex.\nOverall evaluation\nResearch on context effects (including the Ganong and phonemic restora-\ntion effects) mostly indicates context can influence early stages of speech\nperception. It is thus more supportive of the interactionist position than the\nautonomous one. This issue is discussed again later when we consider theo-\nries of speech perception (see pp. 417–429).\nThere are two qualifications on the conclusion that top-down effects\nof context influence the early stages of speech perception. First, such\neffects are less likely to be found when speech is clear and unambigu-\nous (e.g., Wild et  al., 2012). Top-down processes may often be unnec-\nessary when bottom-up processes provide ample information for word\nrecognition.\nSecond, much research on context effects in spoken word  recognition\n(e.g., Grisoni et  al., 2017) has used sentence contexts in which the target\nword is highly predictable. Huettig and Mani (2016) argued that top-\ndown influences may be much weaker when prediction is harder (as is\noften the case in real life). In addition, listeners may often not engage\nin top-down predictive processes because they are too demanding of\nresources.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n417\nTHEORIES OF SPEECH PERCEPTION\nIn this section, we consider theories of processes involved in identifying\nspoken words and sentences. Some of these theories also explain findings\non segmentation and context effects discussed earlier.\nAs we have seen, phonological processing plays a major role in speech\nperception. We start by considering whether orthographic processing (pro-\ncessing related to word spellings) is also involved. Then we discuss major\ntheories of spoken word recognition. First, we consider the motor theory\nof speech perception (e.g., Liberman et  al., 1967), followed by a discus-\nsion of the TRACE and cohort models. The TRACE model (McClelland\n& Elman, 1986) claims word recognition involves interactions between\ntop-down and bottom-up processes. The original cohort model (Marslen-\nWilson & Tyler, 1980) also emphasised such interactions. Subsequently,\nMarslen-Wilson (e.g., 1990) revised his cohort model to increase the\nemphasis on bottom-up processes driven by the speech signal.\nOrthographic influences\nSuppose you listen to spoken words. Would this activate their spellings?\nChiarello et  al. (2018) studied spoken word identification under difficult\nconditions (multi-speaker babble). The researchers computed the propor-\ntion of similar sounding words (phonological neighbours) also spelled simi-\nlarly (orthographic neighbours) for each spoken word. Word identification\nrates were lower for words having many orthographic neighbours as well\nas phonological neighbours. Thus, word identification was influenced by\northography.\nHow does orthography influence speech perception? Perhaps hearing\na word leads fairly “automatically” to activation of its orthographic codes\nand so influences lexical access. Alternatively, a spoken word’s orthogra-\nphy may influence its processing only after lexical access. This issue has\nbeen addressed using event-related potentials (ERPs; see Glossary).\nPattamadilok et  al. (2011) asked listeners to decide whether spoken\nwords had a given final syllable. Orthographic information influenced\nERPs at 175–250 ms, suggesting orthography affects early processing prior\nto lexical access (lexical access is often reflected in the N400 component\nof the ERP occurring 400 ms after word onset). In similar fashion, Kwon\net al. (2016) found, with the Korean language, that orthographic informa-\ntion influenced the P200 component of the ERP (occurring between 150\nand 300 ms) on a spoken word recognition task.\nFinally, Pattamadilok et  al. (2011) reviewed research indicating that\northographic information often influences word processing 300–350 ms\nafter word onset. Such findings suggest orthographic information can\ninfluence various stages of word processing.\nMotor theory\nLiberman et al. (1967) argued that a key issue is explaining how listeners\nperceive spoken words accurately even though the speech signal is varia-\nble. In their motor theory, they proposed listeners mimic the speaker’s\nKEY TERMS\nLexical access\nAccessing detailed\ninformation about a given\nword by entering the\nlexicon.\nCreated from usyd on 2022-02-16 03:16:01.",
    "418\nLanguage\narticulatory movements. It was claimed this motor signal provides much\nless variable and inconsistent information about the speaker’s words than\ndoes the speech signal and so facilitates speech perception.\nHalle and Stevens (1962) also emphasised the role of speech-\nproduction processes in speech perception. They proposed an analysis-by-\nsynthesis approach where “Cues from the input signal triggered guesses\nabout the identity of phonemes [using speech-production processes], and\nsubsequently, the internal synthesis of potential phonemes is compared\nto the input sequence” (Poeppel & Monahan, 2011, p. 2). Thus, speech-\nproduction processes predict the speech input and enhance speech percep-\ntion when the speech signal is ambiguous.\nMuch research has assumed there is a single motor speech system. This\nis a drastic oversimplification. There are actually several motor systems or\nnetworks, but their precise number and nature remain unclear (Skipper\net al., 2017).\nFindings\nAccording to motor theories, the brain areas activated during speech per-\nception and speech production should overlap substantially, whereas such\noverlap should be limited if speech-production processes are not involved\nin speech perception. Skipper et al. (2017) reported a meta-analysis com-\nparing activation during speech perception and production. Several areas\nwere common to speech perception and speech production, including the\npars opercularis, ventral central sulcus, ventral precentral sulcus and gyrus,\nsupplementary motor area, and anterior insula.\nThe above meta-analysis was concerned only with perception and\nproduction of words and non-words. Silbert et al. (2014) reported a more\nnaturalistic study assessing brain areas activated during production and\nperception of a 15-minute spoken narrative. They divided brain areas acti-\nvated during both perception and production into those where activity was\ncorrelated or coupled over time and those where it was not coupled. An\nabsence of coupling may mean a given area is used for different functions\nduring speech perception and speech production.\nWhat did Silbert et  al. (2014) find? Several brain areas exhibited\nperception–production coupling (see Figure 11.1 in Chapter 11). These\nareas included the superior temporal gyrus, the medial temporal gyrus, the\ntemporal pole, the angular gyrus, the inferior temporal gyrus, the insula\nand the premotor cortex.\nThe above neuroimaging research is inconclusive because listeners may\nuse speech-production processes only following speech perception. More\ndirect evidence can be obtained by applying transcranial magnetic stimula-\ntion (TMS; see Glossary) to part of the speech-production system during a\nspeech-perception task to influence its functioning. Liebenthal and Möttönen\n(2018) concluded their review of TMS research as follows: “Disruptions in\nthe articulatory motor areas impair speech perception and modulate early . . .\nprocessing of speech sounds in the auditory areas” (p. 38). Thus, processes\nin speech-production areas can causally influence speech perception.\nAdditional support for motor theories comes from studies using\nevent-related potentials (ERPs; see Glossary). The key finding is that\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n419\narticulatory motor areas are activated early in speech processing (under\n100 ms) (Liebenthal & Möttönen, 2018). Thus, speech-production pro-\ncesses occur early enough to influence speech perception.\nListeners sometimes make more use of speech-production processes\nwhen the speech input is unclear and provides insufficient auditory infor-\nmation. For example, Nuttall et al. (2016) found listeners had greater acti-\nvation in the motor cortex when speech perception was made harder (e.g.,\npresented with background noise). However, they used rather artificial\nspeech stimuli (i.e., syllables). In contrast, Panouillères et  al. (2018) pre-\nsented more naturalistic sentences. Speech-production areas were involved\nin speech processing to the same extent regardless of the extent to which\nnoise reduced the clarity of the speech input.\nEvidence from brain-damaged patients might clarify the role of motor\nprocesses in speech perception. If patients whose motor cortex is destroyed\ncan still perceive speech, we might conclude motor processes are unnec-\nessary for speech perception. This approach is simplistic, because many\ndifferent brain areas are involved in speech production (see Figure 11.1).\nHowever, the overall picture is clear: “Speech perception deteriorates with\na wide range of damage to speech-production systems caused by stroke,\nfocal excitation for epilepsy, cerebral palsy, and Parkinson’s disease”\n(Skipper et al., 2017, p. 95).\nFinally, we consider an important study by Uddin et al. (2018). They\nfocused on how long a target needed to be presented for listeners to rec-\nognise it when presented in isolation or within a relevant sentence context.\nThe target was a noun that could be represented by a word (e.g., sheep) or\nby a sound (e.g., a sheep bleating).\nWhat would we expect to find according to the motor-theory\napproach? First, there should be a beneficial effect of sentence context on\nspeed of target identification because context facilitates prediction of the\nfinal sound.\nSecond, and more importantly, the context effect should be much\ngreater when the target is a word. Why is that? As Uddin et  al. pointed\nout, “It is not possible to make neural predictions via motor systems\n[for] environmental sounds [that] do not have clear speech . . . rep-\nresentations” (p. 140). However, the context effect was as great with\nthe environmental sounds as the words (see Figure 9.6). Thus, listen-\ners make predictions at the level of conceptual meaning (i.e., predicting\nthe meaning that will be represented by the target sound rather than the\nsound itself).\nEvaluation\nAs Skipper et al. (2017, p. 97) concluded their review, “Brain regions and\nnetworks involved in speech production are ubiquitously involved in speech\nperception.” This conclusion is supported by several kinds of evidence:\n(1) neuroimaging evidence for overlapping brain areas for speech percep-\ntion and speech production;\n(2) rapid activation of motor areas during speech perception revealed by\nresearch using event-related potentials;\nCreated from usyd on 2022-02-16 03:16:01.",
    "420\nLanguage\n(3) impaired speech perception following damage to speech-production\nsystems;\n(4) adverse effects on speech perception of transcranial magnetic stimu-\nlation applied to speech-production areas on speech perception.\nWhat are the limitations of motor theories? First, Uddin et  al.’s (2018)\nfindings suggest listeners do not simply predict the sounds that will be pre-\nsented. Instead, most theories of speech perception (including motor the-\nories) “should be modified to include a larger contribution from general\ncognitive processes that take conceptual meaning into account” (Uddin\net al., 2018, p. 141).\nSecond, the available evidence suggests, “Multiple speech production-\nrelated networks and sub-networks dynamically self-organise to con-\nstrain  interpretations of indeterminate acoustic patterns as listening\ncontext requires” (Skipper et  al., 2017, p. 77). No theory explains these\ncomplexities.\nThird, many brain areas are involved in speech perception but not\nspeech production (see Figure 11.1). Thus, motor theories would need\ndevelopment to provide comprehensive accounts of speech perception.\nFourth, when speech input is clear, comprehension can be achieved with\nminimal involvement of speech-production processes. That may limit the\napplicability of motor theories to speech perception in typical conditions.\nTRACE model\nMcClelland and Elman (1986) proposed a network model of speech\nperception based on connectionist principles (see Chapter 1). Their TRACE\nmodel assumes bottom-up and top-down processes interact  flexibly in spoken\nword recognition. It makes the following assumptions (see Figure 9.7):\n●\nThere are individual processing units or nodes at three different levels:\nfeatures (e.g., voicing; manner of production); phonemes; and words.\nGeneral\nSentence ending\nSound\nWord\nIsolated\n0.0\nContext\n0.1\nTarget duration (sec)\n0.2\n0.3\n0.4\nFigure 9.6\nMean target duration\nrequired for target\nrecognition for words\nand sounds presented in\nisolation or within a general\nsentence context.\nFrom Uddin et al. (2018).\nReprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n421\nFigure 9.7\nThe basic TRACE model,\nshowing how activation\nbetween the three levels\n(word, phoneme and\nfeature) is influenced by\nbottom-up and top-down\nprocessing.\n●\nFeature nodes are connected to phoneme nodes, and phoneme nodes\nare connected to word nodes.\n●\nConnections between levels operate in both directions and are always\nfacilitatory.\n●\nThere are connections among units or nodes at the same level; these\nconnections are inhibitory.\n●\nNodes influence each other in proportion to their activation levels and\nthe strengths of their interconnections.\n●\nAs excitation and inhibition spread among nodes, a pattern of activa-\ntion or trace develops.\n●\nAll activated words are involved in a competitive process in which\nthese words inhibit each other. The word with the strongest activation\nwins the competition.\n●\n“Words are recognised incrementally by slowly ramping up the activa-\ntion of the correct words at the phoneme and word levels” (Joanisse &\nMcClelland, 2015, p. 237).\nThe TRACE model assumes bottom-up and top-down processes inter-\nact. Bottom-up activation proceeds upwards from the feature level to the\nphoneme level and on to the word level. In contrast, top-down activation\nproceeds in the opposite direction from the word level to the phoneme level\nand on to the feature level.\nFindings\nSuppose participants hear the word beaker. In front of them is a visual\ndisplay containing four objects’ drawings showing a beaker, beetle, speaker\nand carriage. Eye tracking is used to identify which drawing is being fixated.\nAs Joanisse and McClelland (2015) pointed out, we can make several\nCreated from usyd on 2022-02-16 03:16:01.",
    "422\nLanguage\npredictions from the model assuming there are close links between eye fixa-\ntions and the activation levels of the words fixated:\n(1) The object corresponding to the spoken word (i.e., beaker) should\nreceive the most fixations.\n(2) Phonological competitors (beaker; speaker) should receive more fix-\nations than an unrelated competitor (carriage) because of phonemic\nprocessing.\n(3) A phonological competitor sharing its first phoneme (beetle) with the\nspoken word should receive more fixations than a phonological com-\npetitor sharing its last phoneme (speaker) with the spoken word.\nAllopenna et al. (1998) carried out a study along the lines indicated above.\nTheir findings are shown in Figure 9.8. As you can see, there was a reason-\nably close fit between the behavioural data and predictions following from\nthe model.\nSuppose we asked listeners to detect target phonemes presented in\nwords and non-words. According to the TRACE model, performance\nshould be better in the word condition. Why is that? In that condition, acti-\nvation from the word level to the phoneme level would facilitate phoneme\ndetection.\nMirman et al. (2008) required listeners to detect a target phoneme (/t/\nor /k/) in words and non-words. Words were presented on 80% or 20% of\ntrials. It was assumed attention to (and activation at) the word level would\nbe greater when most auditory stimuli were words, which would increase\nthe performance advantage in the word condition.\nWhat did Mirman et  al. (2008) find? First, there was a consistent\nadvantage for the word conditions over the non-word conditions (see\nFigure 9.9). Second, the magnitude of this effect was greater when 80% of\nthe auditory stimuli were words. These findings indicate the involvement of\ntop-down processes in speech perception.\nThe TRACE model explains the basic Ganong effect (discussed earlier,\np. 415) where there is a bias towards perceiving an ambiguous phoneme so\na word is formed. It is assumed within the TRACE model that top-down\n0.0\n0\n10\n20\n30\n40\n50\n60\n70\n80\n80\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nBehavioral data\nReferent (e.g., “beaker”)\nCohort (e.g., “beetle”)\nRhyme (e.g., “speaker”)\nUnrelated (e.g., “carriage”)\nActivation in TRACE\n(a)\nCycle\n0.0\n0\n200\n400\n600\n800\n1000\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nTRACE model\nReferent (e.g., “beaker”)\nCohort (e.g., “beetle”)\nRhyme (e.g., “speaker”)\nUnrelated (e.g., “carriage”)\nPredicted fxation probability\n(b)\nTime since target onset (scaled to msec)\nFigure 9.8\n(a) Actual eye fixations on\nthe object corresponding\nto a spoken word or related\nto it; (b) predicted eye\nfixations from the TRACE\nmodel.\nFrom Allopenna et al. (1998).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n423\nactivation from the word level is responsi-\nble. Norris et  al. (2003) reported additional\nevidence that phoneme identification can be\ninfluenced directly by top-down processing.\nListeners categorised ambiguous phonemes\nas /f/ or /s/. Those who had previously heard\nthis phoneme in /f/-ending words favoured\nthe /f/ categorisation, whereas those who had\nheard it in /s/-ending words favoured the /s/\ncategorisation.\nThe TRACE model explains categori-\ncal speech perception (discussed earlier) by\nassuming the boundary between phonemes\nbecomes sharper because of mutual inhibi-\ntion between phoneme units. These inhibitory\nprocesses produce a “winner takes all” situa-\ntion with one phoneme becoming increasingly\nmore activated than other phonemes, thus\nproducing categorical perception.\nHigh-frequency words (those encountered\nfrequently) are generally recognised faster\nthan low-frequency ones (Harley, 2013). It\nwould be consistent with the TRACE model’s\napproach to assume this finding occurs because high-frequency words have\nhigher resting activation levels. If so, word frequency should influence even\nearly stages of word processing. Dufour et al. (2013) obtained supporting\nevidence. Word frequency influenced event-related potentials as early as\n350 ms after word onset during spoken word recognition.\nWe turn now to problematical findings for the model. It assumes top-\ndown influences originate at the word level. Thus, top-down effects (e.g.,\nproduced by relevant context) should benefit target identification more\nwhen the target is a word (e.g., sheep) rather than an environmental sound\n(e.g., a sheep bleating). However, context effects are as great with environ-\nmental sounds as with words (Uddin et al., 2018; see Figure 9.6), suggest-\ning top-down processing activates general conceptual meanings rather than\nspecific words.\nFrauenfelder et  al. (1990) asked listeners to detect a given phoneme.\nIn the key condition, a non-word closely resembling an actual word was\npresented (e.g., vocabutaire instead of vocabulaire). The model predicts\ntop-down effects from the word node corresponding to vocabulaire should\nhave impaired the task of identifying the t in vocabutaire. However, they\ndid not.\nMcQueen (1991) asked listeners to categorise ambiguous phonemes at\nthe end of auditory stimuli. Each ambiguous phoneme could be interpreted\nas completing a word or non-word. The TRACE model predicts listeners\nshould have shown a preference for perceiving the phonemes as completing\nwords. This prediction was confirmed when the stimulus was degraded but\nnot when it was not degraded.\nThe TRACE model ignores the role of context provided by verbs in\ninfluencing spoken word recognition. Rohde and Ettlinger (2012) presented\nFigure 9.9\nMean reaction times (in ms) for recognition of /t/ and /k/\nphonemes in words and non-words when words were\npresented on a high (80%) or low (20%) proportion of trials.\nFrom Mirman et al. (2008). Reprinted with permission of the Cognitive\nScience Society Inc.\nCreated from usyd on 2022-02-16 03:16:01.",
    "424\nLanguage\nlisteners with sentences such as the following ( ___ indicates an ambiguous\nphoneme interpretable as he or she):\n(1) Abigail annoyed Bruce because ___ was in a bad mood.\n(2) Luis reproached Heidi because ___ was getting grouchy.\nThey predicted (and found) that listeners would hear the ambiguous phoneme\nas she in both sentences. Annoyed is typically followed by a pronoun refer-\nring to the subject, whereas reproached is followed by a pronoun referring to\nthe object.\nZhang and Samuel (2018) investigated the effects of cognitive load (in\nthe form of a phonological load) on speech perception. The effects were\nmuch greater on later processing (maintaining competing word candidates)\nthan earlier processing (lexical access: see Glossary). Thus, early processes\nare more “automatic” than later ones. These findings are inconsistent with\nthe TRACE model, which “makes no distinctions in terms of automaticity\nof sub-processes during speech recognition” (p. 43).\nEvaluation\nThe TRACE model has several successes to its credit. First, even though\nit was proposed in 1986, “The rate of citations of the original work has\nincreased since 2001” (Joanisse & McClelland, 2015, p. 238).\nSecond, it provides plausible accounts of phenomena such as the pho-\nnemic restoration effect, categorical perception, the Ganong effect and the\nword superiority effect in phoneme monitoring.\nThird, the TRACE model assumes bottom-up and top-down processes\nboth contribute directly to spoken word recognition. As such, it is an excel-\nlent example of the interactionist approach (discussed earlier, pp. 415–416).\nFourth, the TRACE model “copes extremely well with noisy input –\nwhich is a considerable advantage given the noise present in natural\nlanguage” (Harley, 2013). It does so through its emphasis on top-down\nprocesses that become increasingly important when the speech input is\ndegraded and so provides only limited information.\nWhat are the model’s limitations? First, its focus is rather narrow,\nbeing on word recognition, and it has little to say about speech\ncomprehension.\nSecond, the model assumes top-down processes influence the activa-\ntion of specific words. However, Uddin et  al.’s (2018) findings indicate\ntop-down processes can initially activate higher-level conceptual meanings\nrather than specific words. Thus, the model would be enhanced by adding\na conceptual meaning level above the word level (see Figure 9.7).\nThird, the model sometimes exaggerates the importance of top-down\neffects on speech perception. More specifically, the model predicts top-\ndown activation from the word level will cause mispronunciations and\nambiguous sounds to be identified as words more often than actually\nhappens (Frauenfelder et al., 1990; McQueen, 1991).\nFourth, the TRACE model incorporates many different theoreti-\ncal assumptions. This may make the model “too powerful, in that it can\naccommodate any result” (Harley, 2013).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n425\nFifth, the model is incomplete in various ways. For example, it ignores\nthe impact of orthographic information on speech perception. It also\ncannot account for the differential effects of cognitive load on early and\nlate speech-perception processes.\nSixth, Gwilliams et al. (2018) found that the primary auditory cortex\nwas sensitive to ambiguity in a word’s initial phoneme only 50 ms after\nword onset. None of the assumptions incorporated within the TRACE\nmodel provide an explanation of this rapid effect.\nCohort model\nThe cohort model focuses on the processes involved during spoken word\nrecognition. It differs from the TRACE model in focusing more on\nbottom-up processes and less on top-down ones. Several versions have been\nproposed, starting with Marslen-Wilson and Tyler (1980). Here are the\nmain assumptions of the original version:\n●\nEarly in the auditory presentation of a word, all words conform-\ning to the sound sequence heard so far become active: this is the\nword-initial cohort. There is competition among these words to be\nselected.\n●\nWords within the cohort are eliminated if they cease to match further\ninformation from the presented word or because they are inconsistent\nwith the semantic or other context. For example, crocodile and crock-\nery might both belong to the initial cohort with the latter word being\nexcluded when the sound /d/ is heard.\n●\nProcessing continues until information from the word itself and con-\ntextual information permit elimination of all but one of the cohort\nwords. The uniqueness point is the point at which only one word is\nconsistent with the acoustic signal.\nHow do later versions of the cohort model differ from the original version?\nIn the original model, it was assumed any word was in or out of the cohort\nat a given moment. This assumption is too extreme. In revised versions\nof the model (e.g., Marslen-Wilson, 1987, 1990), it is assumed words\nvary in their level of activation and so membership of the word cohort\nis a matter of degree. Marslen-Wilson also assumed the word- initial\ncohort may contain words having similar initial phonemes to the pre-\nsented word rather than consisting only of words having the same initial\nphoneme.\nIn the original version of the model, it was assumed words not match-\ning the context (e.g., preceding words) drop out of the word cohort. As\nMarslen-Wilson (1987) pointed out, this assumption is too extreme. For\nexample, suppose you heard the sentence, “John slept the guitar”, in which\nthe word guitar is totally inappropriate in the sentence context. However,\nit was nearly always accurately perceived reasonably rapidly (320 ms on\naverage). In the revised version, it is assumed context-inappropriate words\nare eliminated later in processing (see below).\nThree processing stages are identified within the cohort model\n(Marslen-Wilson, 1987):\nKEY TERM\nUniqueness point\nThe point in time in\nspoken word recognition\nat which the available\nperceptual information is\nconsistent with only one\nword.\nCreated from usyd on 2022-02-16 03:16:01.",
    "426\nLanguage\n(1) access stage during which a word cohort is activated;\n(2) selection stage during which one word is chosen from the cohort;\n(3) integration stage during which the word’s semantic and syntactic\n(grammatical) properties are integrated within the sentence.\nAccording to the model’s original version, context influences the selection\nprocess. In the revised version, in contrast, “Context plays no role in the\nprocesses of access and selection” (Marslen-Wilson, 1987, p. 71).\nThe assumptions of the revised model are more flexible than the orig-\ninal ones. As we will see shortly, they predict processes in spoken word\nrecognition more accurately.\nFinally, Gaskell and Marslen-Wilson (2002) proposed another variant\nof the cohort model. Its central assumption was that there is “continu-\nous integration” of information from the speech input and context. If the\nspeech input is degraded or the context is strongly predictive, top-down\nprocesses relating to prediction of the next word are likely to dominate\nwithin this continuous integration. In contrast, bottom-up processes\ntriggered by the speech signal are dominant within continuous integra-\ntion if the speech signal is unambiguous and there is no constraining\ncontext.\nFindings\nEvidence the initial phoneme of a spoken word is often especially impor-\ntant was reported by Allopenna et al. (1998; discussed earlier, p. 422). For\nexample, when listeners heard the word beaker, the competition from a\nword starting with the same phoneme (e.g., beetle) was greater than from a\nrhyming competitor having the same last phoneme (e.g., speaker). McQueen\nand Huettig (2012) replicated this finding.\nAccording to the original version of the model (Marslen-Wilson,\n1987), spoken words would not be recognised if their initial phoneme was\nunclear or ambiguous. Contrary evidence was reported by Frauenfelder\net  al. (2001). French-speaking listeners activated words even when the\ninitial phoneme of spoken words was distorted (e.g., hearing focabulaire\nactivated the word vocabulaire). However, the listeners took some time to\novercome the effects of the mismatch in the initial phoneme.\nWe now consider evidence that spoken words are identified when their\nuniqueness point (see p. 425) is reached. O’Rourke and Holcomb (2012)\npresented words with an early uniqueness point (mean of 427 ms after\nonset) and those with a late uniqueness point (mean of 533 ms after onset).\nThey used event-related potentials and focused on the N400 component.\nThe N400 (reflecting access to word meaning) occurred 100 ms earlier for\nwords having an early uniqueness point.\nKocagoncu et  al. (2017) used magneto-encephalography (MEG; see\nGlossary) while presenting spoken words with varying uniqueness points.\nAs predicted, each word’s uniqueness point was associated with increased\nsemantic processing of that word plus a marked reduction in lexical and\nsemantic processing of competitor words. The latter finding was predicted\nbecause all competitor words have been eliminated from the word cohort\nwhen the uniqueness point is reached.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n427\nAccess to word meaning sometimes occurs prior to the uniqueness\npoint if the preceding context is very constraining. Van Petten et al. (1999)\npresented listeners with sentence frames (e.g., Sir Lancelot spared the man’s\nlife when he begged for ____ ) followed by a contextually congruent (e.g.,\nmercy) or incongruent (e.g., mermaid) word. There were differences in the\nN400 to contextually congruent and incongruent words 200 ms before the\nuniqueness point. However, as Nieuwland (2019) pointed out, word rec-\nognition prior to the uniqueness point probably occurs only in those rare\nsituations where a spoken word is very predictable within its context.\nHow does context influence word-recognition processes? According to\nthe revised version of the model, context influences only the later stages\nof word recognition. Zwitserlood (1989) supported this assumption.\nListeners performed a lexical decision task (deciding whether visually pre-\nsented letter strings were words) immediately after hearing part of a word.\nWhen only cap ___ had been presented, it was consistent with captain and\ncapital. Lexical decisions were faster when the presented word was related\nin meaning to either word (e.g., ship; money).\nIn another condition, the part word was preceded by a biasing context\n(e.g., With dampened spirits the men stood around the grave. They mourned\nthe loss of their cap ___ ). As predicted, such context did not prevent acti-\nvation of the word capital even though it was inconsistent with the context.\nIn a similar study, Friedrich and Kotz (2007) presented sentences\nending with incomplete words (e.g. To light up the dark she needed her\ncan ___ ). Immediately afterwards, listeners saw a visual word matched to\nthe incomplete word in form and meaning (e.g., candle), in meaning only\n(e.g., lantern), in form only (e.g., candy) or in neither (e.g., number). As\npredicted by the cohort model, the word candy was activated even though\nit was inconsistent with the context.\nHowever, Weber and Crocker (2012) found context can sometimes\nexert a very early influence on speech processing. Listeners heard German\nsentences (e.g., The woman irons the ____. Bluse (German for blouse) is\na likely final word whereas the similar-sounding word Blume (meaning\nflower) is implausible. Weber and Crocker studied eye fixations to pictures\nof the target word (e.g., Bluse), a similar-sounding word (e.g., Blume), and\nan irrelevant distractor (e.g., Wolke meaning cloud).\nContext had a powerful effect. More fixations were directed at the\ntarget object than the other objects before the final word was presented and\nthis tendency increased during and after its presentation (see Figure 9.10).\nHowever, similar-sounding words were fixated more than irrelevant dis-\ntractors shortly after the final word in the sentence was presented. Thus, as\npredicted by the cohort model, words phonologically related to a spoken\nword were activated even when inconsistent with the context.\nFinally, we consider the notion of “continuous integration” (Gaskell\n& Marslen-Wilson, 2002). As predicted by this approach, context often\ninfluences the early stages of word processing via top-down processes (see\nabove, pp. 412–416). Theoretically, the extent of such contextual effects\nshould also depend in part on bottom-up influences from the to-be-\nrecognised word itself.\nSupporting evidence for the above predictions was reported by Strand\net  al. (2018). Participants received a grammatically constraining context\nCreated from usyd on 2022-02-16 03:16:01.",
    "428\nLanguage\nFigure 9.11\nA sample display showing\ntwo nouns (“bench” and\n“rug”) and two verbs\n(“pray” and “run”).\nFrom Strand et al. (2018).\n(e.g., “They thought about the ___) or an unconstraining context (e.g., “The\nword is ___) accompanied by a visual display (see Figure 9.11). Suppose the\ntarget word is rug. The constraining context implies the target should be a\nnoun. As predicted, top-down processes led to faster target fixation with a\nFigure 9.10\nFixation proportions to\nhigh-frequency target\nwords, high-frequency\ncompetitors that are\nphonologically similar to\ntarget words, and unrelated\ndistractor words during the\nfirst 1,000 ms after target\nonset.\nFrom Weber and Crocker\n(2012). With kind permission\nfrom Springer Science+Business\nMedia.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n429\nconstraining context. In addition, the phonologically similar distractor (i.e.,\nrun) was not fixated more than the phonologically dissimilar distractors\n(i.e., bench; pray). However, the word run was fixated more than other dis-\ntractors when pronounced to sound more similar to the target.\nWhat is the take-home message from the above findings? As predicted\nby Gaskell and Marslen-Wilson’s (2002) approach, “Listeners make use of\ncontextual constraints very early in word processing while remaining sen-\nsitive to bottom-up acoustic input as words unfold” (Strand et  al., 2018,\np. 969).\nEvaluation\nThe cohort model has several strengths. First, the assumption that accurate\nperception of a spoken word is typically accompanied by some processing\nof several competitor words is generally correct. Second, the processing of\nspoken words is sequential and changes considerably during the course of\ntheir presentation. Third, the uniqueness point is of great importance in\nspoken word recognition. Fourth, context effects often (but not always)\noccur during the integration stage following word identification as pre-\ndicted by the model. Fifth, the revised versions of the model are superior\nto the original version. For example, the assumption that membership of\nthe word cohort is a matter of degree rather than all-or-none is more in line\nwith the evidence.\nWhat are the model’s limitations? First, context sometimes influences\nword processing earlier than the integration stage. This is especially the\ncase when the context is strongly predictive (e.g., Grisoni et al., 2017; dis-\ncussed earlier, p. 415) or the speech input is degraded (e.g., Wild et  al.,\n2012; discussed earlier, p. 416). However, Gaskell and Marslen-Wilson’s\n(2002) more flexible approach based on continuous integration can accom-\nmodate these (and many other) findings.\nSecond, the revised cohort model de-emphasises the role of word\nmeaning in spoken word recognition. One aspect of word meaning is\nimageability (ease of forming an image of a word’s referent). When there\nare many words in the word cohort, high-imageability words are easier to\nrecognise than low-imageability ones (Tyler et al., 2000) and they are asso-\nciated with greater activation in brain areas involved in speech perception\n(Zhuang et al., 2011). Thus, word selection depends on semantic factors as\nwell as phonological ones.\nThird, mechanisms involved in spoken word recognition may differ\nfrom those emphasised within the model. More specifically, predictive\ncoding and enhanced processing of speech features inconsistent with\nprediction may be more important than assumed within the cohort\nmodel.\nCOGNITIVE NEUROPSYCHOLOGY\nSo far we have focused on the processes used by healthy listeners to rec-\nognise spoken words. Here we consider how research on brain-damaged\nCreated from usyd on 2022-02-16 03:16:01.",
    "430\nLanguage\npatients has clarified processes involved in speech perception. Our focus\nwill be on repeating spoken words immediately after hearing them.\nWe will use the theoretical framework proposed by Ellis and Young\n(1988; see Figure 9.12). There are five components:\n●\nThe auditory analysis system extracts phonemes or other sounds from\nthe speech wave.\n●\nThe auditory input lexicon contains information about spoken words\nknown to the listener but not about their meaning.\n●\nWord meanings are stored in the semantic system.\n●\nThe speech output lexicon provides the spoken form of words.\n●\nThe phoneme response buffer provides distinctive speech sounds.\nThe framework’s most striking assumption is that three different routes can\nbe used when saying spoken words. We will discuss these routes after con-\nsidering the auditory analysis system.\nAuditory analysis system\nConsider patients with damage only to the auditory analysis system causing\ndeficient phonemic processing. The expected consequences are found in\npatients with pure word deafness: “an inability to understand spoken lan-\nguage in the absence of any other linguistic disturbance . . . [they] are per-\nfectly capable of speaking, writing, and reading” (Kasselimis et al., 2017,\nFigure 9.12\nProcessing and repetition of\nspoken words according to\nthe three-route framework.\nAdapted from Ellis and Young\n(1988).\nKEY TERM\nPure word deafness\nA condition involving\nseverely impaired speech\nperception but intact\nspeech production,\nreading, writing, and\nperception of non-speech\nsounds.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n431\np. 11). Of importance, such patients should have intact perception for non-\nspeech sounds (e.g., whistles) not containing phonemes.\nMaffei et  al. (2017) studied a female patient (FO) with pure word\ndeafness. She had a selective impairment in auditory language processing\nbut intact processing of environmental sounds and music (e.g., identifying\nwhich musical instrument was being played). She also had intact speech,\nreading and writing. Unsurprisingly, FO had damage to regions of a brain\nnetwork dedicated to speech sound processing.\nSlevc et al. (2011) argued that speech perception differs from the per-\nception of most non-speech sounds because listeners must cope with rapid\nstimulus changes. They found NL, a patient with pure word deafness, had\ngreat difficulties discriminating sounds (speech or non-speech) differing in\nrapid temporal changes. Thus, the rapid stimulus changes in spoken words\nmay partially explain why patients with pure word deafness have severe\nspeech-perception problems.\nThree-route framework\nEllis and Young’s (1988) framework specifies three routes that can be\nused when individuals process and repeat words they have just heard (see\nFigure 9.12). All three routes involve the auditory analysis system and the\nphonemic response buffer. Route 1 also involves the other three components\n(auditory input lexicon; semantic system; speech output lexicon). Route 2\ninvolves two additional components (auditory input lexicon; speech output\nlexicon), and Route 3 involves an additional rule-based system converting\nacoustic information into words that can be spoken.\nAccording to the three-route framework, Routes 1 and 2 are used with\nunfamiliar words and non-words.\nFindings\nPatients using predominantly Route 2 should recognise familiar words but\nnot understand their meaning. Since they can use the input lexicon, they\nshould distinguish between words and non-words. Finally, they should\nhave problems saying unfamiliar words and non-words. Patients with word\nmeaning deafness fit the above description. For example, Dr O had rea-\nsonable use of the input lexicon as shown by his excellent ability to dis-\ntinguish between words and non-words (Franklin et al., 1996). O repeated\nwords much more successfully than non-words (80% vs 7%, respectively).\nHe had impaired auditory comprehension. However, he had intact written\nword comprehension indicating his semantic system was probably not\ndamaged.\nBB, a female patient with word meaning deafness, could distinguish\nbetween words and non-words. She was severely impaired in identifying\npictures matching spoken words but not when identifying pictures match-\ning written words (Bormann & Weiller, 2012). Thus, BB could not access\nthe meanings of spoken words although her semantic processing ability\nwas intact.\nPatients using only Route 3 could repeat spoken words and non-words\nbut would have very little comprehension of the words. Patients with\nKEY TERM\nWord meaning deafness\nA condition in which there\nis selective impairment of\nthe ability to understand\nspoken (but not written)\nlanguage.\nCreated from usyd on 2022-02-16 03:16:01.",
    "432\nLanguage\ntranscortical sensory aphasia exhibit this pattern. For example, Kim et al.\n(2009) studied a male patient. He repeated spoken words but had severely\nimpaired auditory and reading comprehension. These findings suggested\nhe had damage within the semantic system. Kwon et al. (2017) studied two\npatients with transcortical sensory aphasia. Their impaired auditory com-\nprehension appeared to be due to greatly decreased functional connectivity\nbetween language centres in the brain.\nPatients with deep dysphasia have extensive problems with speech\nperception and production. They make semantic errors when repeating\nspoken words by producing words related in meaning to those spoken\n(e.g., saying sky instead of cloud). They also have very impaired ability\nto repeat words and non-words. Ablinger et al. (2008) discussed findings\nfrom JR, a man with deep dysphasia. In spite of severely impaired speech\nperception, he was only slightly impaired at reading aloud words and\nnon-words.\nWe could explain deep dysphasia by arguing all three routes shown\nin Figure 9.12 are damaged. However, Jefferies et al. (2007) argued plau-\nsibly that the central problem in deep dysphasia is a general phonologi-\ncal impairment (i.e., impaired processing of word sounds). This produces\nsemantic errors because it increases patients’ reliance on word meanings\nwhen repeating spoken words.\nJefferies et  al. (2007) found deep dysphasics had poor phonological\nproduction when repeating words, reading aloud and naming pictures.\nAs predicted, they also performed very poorly on tasks involving manip-\nulating phonology such as the phoneme subtraction task (e.g., remove\nthe initial phoneme from cat). Furthermore, they showed speech percep-\ntion problems (e.g., impaired performance when deciding whether words\nrhymed).\nEvaluation\nThe three-route framework is along the right lines. Patients have various\nproblems with speech perception (and speech production) and evidence\nexists for all three routes. Conditions such as pure word deafness, word\nmeaning deafness and transcortical sensory aphasia can readily be related\nto the framework.\nWhat are the limitations with this theoretical approach? First, it pro-\nvides only a sketch map of the underlying mechanisms. For example,\nwhat detailed processes occur within the semantic or auditory analy-\nsis systems? Second, it is sometimes hard to relate patients’ symptoms\nto the framework. For example, it is debatable whether deep dyspha-\nsia involves impairments to all three routes or a general phonological\nimpairment.\nREADING: INTRODUCTION\nReading is a very important skill – adults lacking effective reading skills\nare severely disadvantaged. Thus, we need to understand the processes\ninvolved in reading. Reading requires several perceptual and other  cognitive\nprocesses plus a good knowledge of language and grammar.\nKEY TERMS\nTranscortical sensory\naphasia\nA condition in which\nspoken words can\nbe repeated but\ncomprehension of spoken\nand written language is\nseverely impaired.\nDeep dysphasia\nA condition involving\nsemantic errors when\ntrying to repeat spoken\nwords and a generally\npoor ability to repeat\nspoken words and\nnon-words.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n433\nFigure 9.13\nA general framework of the\nprocesses and structures\ninvolved in reading\ncomprehension. For details,\nrefer to text.\nFrom Perfetti and Stafura\n(2014).\nIn this chapter, we focus mostly on basic processes used in reading\nsingle words. Research and theory relating to reading sentences and com-\nplete texts are discussed in Chapter 10. An overview of what is involved\nin reading across all these levels is shown in Figure 9.13. Here are its key\nfeatures:\n(1) Reading requires various kinds of stored information: word meanings\nstored in a lexicon (mental dictionary); word spellings (orthographic\nknowledge); general knowledge about the world; and linguistic\nknowledge.\n(2) Readers use the above knowledge sources to produce word identifi-\ncation followed by text comprehension. Processes required for text\ncomprehension include working out the syntactical or grammatical\nstructure of each sentence (the parser), drawing inferences, and pro-\nducing a situation model (an integrated mental representation).\n(3) The order in which reading processes occur is flexible. This is indi-\ncated in Figure 9.13 by bidirectional arrows (e.g., between the lexicon\nand comprehension processes).\nYou may well feel (and you would be right!) that Figure 9.13 implies that\nreading involves many complex processes. However, the good news is that\nall aspects of the framework shown in that figure are discussed in detail in\nthis chapter and Chapter 10.\nAnglocentricities\nMost research on reading considers only the English language. Does this\nmatter? Share (2008) argued strongly the “anglocentricities” of reading\nresearch are important because the relationship between orthography\nGeneral knowledge (including text structure)\nOrthographic system\nmapping to phonology\nLinguistic system\nphonology, syntax,\nmorphology\nWord\nidentifcation\nMeaning and\nform selection\nVisual input\nLexicon\nMeaning\nmorphology\nsyntax\n– argument\nstructure\n– thematic\nroles\nComprehension\nprocesses\nOrthographic\nunits\nPhonological\nunits\nInferences\nParser\nText\nrepresentation\nSituation\nmodel\nLinguistic and writing system knowledge\nCreated from usyd on 2022-02-16 03:16:01.",
    "434\nLanguage\nFigure 9.14\nEstimated reading ability\nover a 30-month period\nwith initial testing at a\nmean age of 66 months for\nEnglish, Spanish and Czech\nchildren.\nFrom Caravolas et al. (2013).\nReprinted by permission of\nSAGE Publications.\n(spelling) and phonology (sound) is much less consistent in English than\nmost other languages. Caravolas et  al. (2013) found English children\nlearned to read more slowly than children learning more consistent lan-\nguages (e.g., Spanish or Czech; see Figure 9.14).\nResearch methods\nNumerous methods are available for studying reading. For example, con-\nsider ways of assessing the time taken for word identification or recognition\n(e.g., deciding a word is familiar; accessing its meaning). The lexical deci-\nsion task involves deciding rapidly whether a letter string forms a word.\nThe naming task involves saying a printed word out loud as rapidly as pos-\nsible. Both tasks have limitations. Normal reading times are disrupted by\nthe requirement to respond to task demands and it is hard to identify the\nunderlying processes.\nBalota et al. (1999) argued reading involves several kinds of process-\ning: orthography (the spelling of words); phonology (the sound of words);\nsemantics (word meaning); syntax or grammar; and higher-level discourse\nintegration. The naming task emphasises links between orthography and\nphonology, whereas the lexical decision task emphasises links between\northography and semantics. Normal reading also involves processing of\nsyntax and higher-level integration, processes irrelevant to naming or\nlexical decision.\nRecording eye movements provides an unobtrusive and detailed on-line\nrecord of attention-related processes. The main problem is deciding what\nprocessing occurs during each fixation (time period during which the eye\nremains still).\nNext there is priming (see Glossary) where a prime word is pre-\nsented shortly before the target word. This prime word is related to\nthe target word in spelling, meaning or sound. What is of interest is to\nobserve the effects of the prime on processing of (and response to) the\nKEY TERMS\nLexical decision task\nParticipants presented\nwith a string of letters or\nauditory stimulus decide\nrapidly whether it forms\na word.\nNaming task\nA task in which visually\npresented words are\npronounced aloud rapidly.\nOrthography\nThe study of letters and\nword spellings.\nPhonology\nThe study of the sounds\nof words and parts of\nwords.\nSemantics\nThe study of the meaning\nconveyed by words,\nphrases and sentences.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n435\ntarget word. For example, when reading clip, do you access information\nabout its pronunciation? The answer is “Yes”. A word preceded by a\nnon-word having identical pronunciation (klip) presented below the level\nof conscious awareness is processed faster (Rastle & Brysbaert, 2006; see\nbelow, p. 436).\nFinally, there has been a dramatic increase in reading research using\nevent-related potentials. ERPs provide a precise measure of the time taken\nfor certain processes to occur. For example, consider the N400, a nega-\ntive wave peaking at about 400 ms after word onset. It has been assumed\nto reflect the time taken to access word meaning. More specifically, a\nlarge N400 often indicates a change in the meaning assigned to a word\n(Rabovsky et al., 2018; see Chapter 10).\nPhonological processes\nYou are currently reading this sentence. Did you access the relevant sounds\nwhen identifying the words in it? More technically, did you engage in pho-\nnological processing of the words? We guess your answer is “Yes”, given\nthat most readers experience an “inner voice” or “inner speech” during\nreading. For example, readers reading a text said they had engaged in inner\nspeech immediately before being questioned on 59% of occasions (Moore &\nSchwitzgebel, 2018). However, subjective reports cannot demonstrate pho-\nnological processes play a causal role in the reading process.\nVarious answers to the above questions have been proposed\n(Leinenger, 2014). Van Orden (1987) argued phonological processing is\nnecessary very early in word reading because it plays a role in activating\nlexical entries (stored words). In contrast, Coltheart et  al. (2001) argued\nphonological processing is relatively slow, and mostly inessential for word\nidentification.\nWhy might we expect phonological processing to be important?\nChildren often learn to read using the phonics approach, which involves\nforming connections between letters or groups of letters and the sounds of\nspoken English (Share, 2008). Children’s early phonemic skills predict (and\nare probably causally related to) their future word-reading skills (Melby-\nLervåg et al., 2012).\nFindings\nMuch evidence supports the hypothesis that phonological processing is\nimportant in word reading. One approach involves the use of homophones\n(words with one pronunciation but two spellings). Van Orden (1987) found\nreaders made many more errors when asked, “Is it a flower? ROWS”, than\nwhen asked, “Is it a flower? ROBS. The errors occurred because readers\nengaged in phonological processing of the word ROWS which is homo-\nphonic with the flower name ROSE.\nJared and O’Donnell (2017) also used homophones. Eye movements\nwere recorded while skilled adult readers read sentences such as: (1) Last\nnight I made pasta for dinner; (2) Last night I maid pasta for dinner; and\n(3) Last night I mate pasta for dinner. Eye movements on incorrect sen-\ntences differed depending on whether the incorrect word was phonologically\nKEY TERM\nHomophones\nWords pronounced in the\nsame way but that differ in\ntheir spellings (e.g., pain/\npane; sale/sail).\nCase study:\nPhonological processes\nCreated from usyd on 2022-02-16 03:16:01.",
    "436\nLanguage\nidentical to the correct one (e.g., sentence 2) or not (e.g., sentence 3). Thus,\nthe readers used phonological processing.\nWe can use phonological priming (mentioned earlier, p. 434), to assess\nthe role of phonology in word processing. A word (e.g., clip) is immedi-\nately preceded by a phonologically identical non-word prime (e.g., klip)\npresented below the level of conscious awareness. Rastle and Brysbaert\n(2006) found in a meta-analytic review that words were processed faster\nwhen preceded by phonologically identical non-word primes than by unre-\nlated primes. This suggests phonological processing of visually presented\nwords occurs rapidly and automatically.\nAnother approach involves the notion of phonological neighbour-\nhood. Two words are phonological neighbours if they differ in only one\nphoneme (e.g., gate has bait and get as neighbours). If reading involves\nphonological processing, word recognition should be influenced by the\nnumber of its phonological neighbours. This is the case (Carrasco-Ortiz\net al., 2017).\nPhonological processing typically occurs during reading. However,\nsuch processing is not necessarily essential (e.g., it may occur after word\nrecognition has occurred) and may simply be a byproduct of reading.\nHowever, various types of research support the hypothesis that phonolog-\nical processing causally facilitates reading.\nFirst, phonological processing often starts within 80–100 ms of the first\nfixation on a word (Leinenger, 2014). That would be fast enough to influ-\nence word recognition. For example, Sliwinska et  al. (2012) found trans-\ncranial magnetic stimulation (TMS; see Glossary) to the supramarginal\ngyrus (an area associated with phonological processing) 80 ms after word\nonset impaired performance on a phonological task.\nSecond, we can study profoundly deaf adult readers who initially\nlearned a sign language (e.g., American Sign Language) and so did not\nlearn to read by reading aloud and sounding out the letters of words. They\noften make extensive use of phonological processing during the early stages\nof visual word recognition (Gutierrez-Sigut et al., 2017).\nSuggestive evidence that word meaning can be accessed without access\nto phonology was reported by Hanley and McDonnell (1997). Their patient,\nPS, could not gain access to the other meaning of homophones when he\nsaw one of the spellings (e.g., air) and could not pronounce written words\naccurately. However, PS provided accurate definitions of printed words\nsuggesting he had full access to the meanings of words for which he lacked\nthe appropriate phonology. Similar findings were obtained from a Chinese\nmale patient, YGA (Han & Bi, 2009).\nIn sum, phonological processing is typically involved in reading and\nmuch evidence suggests it plays a causal role. However, the findings from\npatients with severely impaired phonological processing suggest some\ncaution in assuming that is invariably the case.\nWORD RECOGNITION\nCollege students typically read at about 300 words per minute (200 ms per\nword). How long does word recognition take? It is hard to say because of\nimprecision about the meaning of the “word recognition”. The term can\nKEY TERM\nPhonological\nneighbourhood\nWords are phonological\nneighbours if they differ in\nonly one phoneme (e.g.\nwipe, pipe and tap are\nphonological neighbours\nof type).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n437\nrefer to deciding a word is familiar, accessing\na word’s name or accessing its meaning. As a\nresult, estimates of the time taken for word\nrecognition vary.\nInteractive activation model\nMcClelland and Rumelhart (1981) proposed\nan influential interactive activation model\nof visual word processing. It is a computa-\ntional model involving considerable parallel\nprocessing and based on the assumption that\nbottom-up and top-down processes interact\n(see Figure 9.15):\n●\nThere are recognition units at three\nlevels: the feature level at the bottom; the\nletter level in the middle; and the word\nlevel at the top.\n●\nWhen a feature in a letter is detected\n(e.g., vertical line at the right-hand side\nof a letter), activation goes to all letter\nunits containing that feature (e.g., H, M,\nN), and inhibition goes to all other letter\nunits.\n●\nLetters are identified at the letter level. When a letter within a word is\nidentified, activation is sent to the word level for all four-letter word\nunits containing that letter in that position within the word, and inhi-\nbition is sent to all other word units.\n●\nWords are recognised at the word level. Activated word units increase\nthe level of activation in the letter-level units for that word’s letters.\nFindings\nMuch research has used the following task. A letter string is presented\nvery briefly followed by a pattern mask and participants decide which of\ntwo letters was presented in a given position (e.g., the third letter). Task\nperformance is better when the letter string forms a word – the word\nsuperiority effect. This effect is explained by assuming there are top-down\nprocesses from the word to the letter level. Suppose the word SEAT is pre-\nsented and participants decide whether the third letter is A or N. If the\nword unit for SEAT is activated, this increases activation of A and inhibits\nactivation of N.\nSand et  al. (2016) obtained the word superiority effect when stimuli\nwere presented in central vision. However, the effect disappeared when\nstimuli were presented in peripheral vision. These findings suggest top-\ndown processes from the word level do not apply in peripheral vision.\nMuch research has considered orthographic neighbours (the words\nformed by changing one of a target word’s letters. For example, stem has\nFigure 9.15\nMcClelland and Rumelhart’s (1981) interactive activation model\nof visual word recognition.\nAdapted from Ellis (1984).\nKEY TERMS\nWord superiority effect\nA target letter is more\nreadily detected in a letter\nstring when the string\nforms a word than when it\ndoes not.\nOrthographic\nneighbours\nWith reference to a target\nword, the number of\nwords that can be formed\nby changing one of its\nletters.\nCreated from usyd on 2022-02-16 03:16:01.",
    "438\nLanguage\nseveral orthographic neighbours (e.g., seem, step, stew). When a word is\npresented, its orthographic neighbours are activated and influence its rec-\nognition time. Orthographic neighbours facilitate word recognition if they\nare less common than the word itself but have an inhibitory effect if they\nare more common. Chen and Mirman (2012) developed a computational\nmodel based on the interactive activation model’s assumptions (especially\nthat common words are activated more than uncommon ones) to predict\nthese findings.\nThe model assumes each letter within a word is rigidly assigned to\na specific position. As a consequence, “WROD is no more like WORD\nthan is WXYD” (Norris & Kinoshita, 2012, p. 517). It follows that readers\nshould have great problems reading the “Cambridge email:\nAoccrdnig to a rscheearch at Cmabrigde Uinervtisy it deosn’t mttaer\nin waht oredr the ltteers in a wrod are. The olny iprmoatnt tihng is\nthat the frist and lsat ltteer be at the rghit pclae. The rset can be a\ntoatl mses and you can still raed it wouthit porbelm. Tihs is bcusease\nthe huamn mnid deos not raed ervey lteter by istlef but the wrod as a\nwlohe.\nIn fact, most readers find it easy to read the Cambridge email even though\nnumerous letters are transposed (Norris & Kinoshita, 2012). In the original\nresearch on this topic, however, transpositions involving the ending letters\nof words slowed reading rate by 26% (Rayner et al., 2006).\nEvaluation\nThe interactive activation model was an early (and extremely influ-\nential) example of how a connectionist model (see Chapter 1) could\nexplain visual  word processing. There is considerable support for its\ncentral assumption that “Participants in language-processing tasks use\nall the available information and start to show sensitivity to it within a\nthird of a second” (McClelland et al., 2014, p. 1179). Within the model,\nthis involves readers simultaneously using top-down and bottom-up\nprocesses. The model accounts for the word superiority effect and a revised\nversion accounts for the effects of orthographic neighbours on word\nrecognition.\nWhat are the model’s limitations?\n(1) The model is narrow in that it ignores the role of meaning in visual\nword recognition. It also ignores “how recognition processes may be\ninfluenced by surrounding words and contexts” (Snell et  al., 2018,\np. 969).\n(2) Phonological processing is often involved in word recognition (e.g.,\nJared & O’Donnell, 2017; discussed earlier, pp. 435–436), but that is\nnot considered within the model.\n(3) The model exaggerates readers’ focus on the precise positions of\nletters within words. As Grainger (2018, p. 341) pointed out, “[Many]\nempirical findings . . . point to the need for a more flexible letter-\nposition coding scheme.” For example, readers should struggle\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n439\nto read the sentence howcanwereadwithoutspaces? because it lacks\nprecise information about where words start and end. In similar\nfashion, the model cannot explain why the Cambridge email is easy\nto read.\n(4) The model’s accounts for the processing of four-letter words and its\napplicability to word recognition for longer words is unclear.\nSemantic priming\nMany words within most sentences are related in meaning and this facili-\ntates word recognition. This often involves semantic priming – a word is\nrecognised or identified more rapidly if immediately preceded by a seman-\ntically related word. For example, we decide faster that “doctor” is a word\nwhen preceded by a semantically related priming word (e.g., “nurse”) than\nby a semantically unrelated word (e.g., “library”) (Meyer & Schvaneveldt,\n1971).\nWhy does semantic priming occur? Perhaps the priming word “auto-\nmatically” activates the stored representations of all words related to it due\nto massive previous learning. Alternatively, controlled processes may be\ninvolved, with a prime such as “nurse” leading readers to expect a seman-\ntically related word to follow.\nNeely (1977) showed both the above explanations are valid. The\npriming word was a category name (e.g., BIRD) followed by a letter\nstring at 250, 400, or 700 ms. Participants decided whether the letter string\n(target) formed a word (lexical decision task). Participants were instructed\nthe prime BIRD would mostly be followed by a type of bird, whereas the\nprime BODY would mostly be followed by part of a building. This gives\nus four conditions:\n(1) Expected, semantically related (e.g., BIRD–robin)\n(2) Expected, semantically unrelated (e.g., BODY–door)\n(3) Unexpected, semantically related (e.g., BODY–heart)\n(4) Unexpected, semantically unrelated (e.g., BIRD–arm)\nIt was assumed “automatic” facilitatory processes would be activated if the\ntarget were semantically related to the prime but not if it were semantically\nunrelated. In contrast, controlled processes might be involved if the target\nwere expected but not if it were unexpected.\nNeely (1977) obtained two priming or context effects (see Figure 9.16).\nFirst, there was a rapid, short-lived facilitatory effect based on semantic\nrelatedness. Second, there was a slower but more long-lasting effect based\non expectations, with expected target words showing facilitation and unex-\npected ones showing an inhibitory effect.\nAndrews et  al. (2017) reported additional support for “automatic”\nsemantic priming. Skilled readers showed semantic priming even when\nthe prime words were presented very briefly below the level of conscious\nawareness. However, there are issues concerning the interpretation of such\nfindings. It is hard to assess whether there is any conscious awareness of\nstimuli (see Chapter 2) and the notion of “automaticity” is imprecise (see\nChapter 5).\nKEY TERM\nSemantic priming\nThe finding that word\nrecognition is facilitated\nby the prior presentation\nof a semantically related\nword.\nCreated from usyd on 2022-02-16 03:16:01.",
    "440\nLanguage\nSentential context effects\nSentence context is used extensively during\nreading. Of particular importance is word\npredictability. This is typically assessed by a\nword’s Cloze Score (the proportion of par-\nticipants provided with the first few words\nof a sentence guessing it would be the next\nword). Readers consistently fixate for shorter\nperiods of time on predictable words and are\nmore likely to skip them (Staub, 2015). These\neffects occur in part because there is generally\nmore semantic priming of predictable than\nunpredictable words.\nWord predictability also influences event-\nrelated potentials. This is especially true\nof the N400 component (a negative wave\npeaking at about 400 ms), which is larger\nwhen a word is semantically unexpected. Van\nPetten and Luka (2012) reviewed the rel-\nevant ERP research and found the N400 is\nsmaller when a word’s predictability is high\nwithin the  sentence context. They concluded,\n“the N400 . . . reliably indexes the benefits of\nsemantic context” (p. 176).\nEarly or late effects?\nHow can we explain the effects of word pre-\ndictability? Perhaps anticipatory processing\ntriggered by sentence context allows readers to\nprocess predictable words faster than unpre-\ndictable ones. Alternatively, it may simply be easier to integrate predict able\nwords with the preceding context. According to this latter explanation,\nreaders would use contextual information only after accessing the word’s\nmeaning.\nEvidence suggesting readers can use anticipatory processing was\nreported by DeLong et al. (2005). Here is a sample sentence they used:\nThe day was breezy so the boy went outside to fly [a kite/an airplane]\nin the park.\nIn this sentence, a kite is highly predictable whereas an airplane is not. There\nwas a smaller N400 to the more predictable noun (e.g., kite) than the less\npredictable one (e.g., airplane). This finding was replicated in a large-scale\nstudy (Nieuwland et al., 2018).\nMore strikingly, DeLong et  al. (2005) reported a larger N400 to the\narticle an (preceding airplane) than to a (preceding kite). These effects on\nprocessing prior to the presentation of a predictable or unpredictable noun\nFigure 9.16\nThe time course of inhibitory and facilitatory effects of priming\nas a function of whether or not the target word was related\nsemantically to the prime, and of whether or not the target\nword belonged to the expected category.\nData from Neely (1977). © American Psychological Association.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n441\nsuggest readers predicted in advance the most likely subsequent noun.\nHowever, this finding was not replicated (Nieuwland et al., 2018).\nFreunberger and Roehm (2017) measured the N400 to more predicta-\nble and less predictable nouns presented in sentences as well as the N400 to\nthe immediately preceding adverbs. There were two key findings. First, the\nN400 to the noun was smaller when it was more predictable in the sentence\ncontext. More importantly, adverbs strongly predicting the following noun\nhad larger N400s than less predictive ones. This was because strongly pre-\ndictive adverbs led to increased activation of information relevant to the\nfollowing noun before it was presented.\nLexical prediction vs graded prediction\nLuke and Christianson (2016) distinguished between two types of predic-\ntion readers might use:\n(1) Lexical prediction: readers activate one specific word prior to its\npresentation.\n(2) Graded prediction: readers generate more partial and general predic-\ntions (e.g., the approximate meaning of the next word; whether the\nnext word is a noun, verb, or some other part of speech).\nLexical prediction involves “putting all your eggs in one basket” – if the actual\nword is not the one predicted, this would probably disrupt reading. Luke\nand Christianson (2016) analysed 55 text passages and discovered only 21%\nof content words (words having meaning) and 40% of function words (words\nclarifying grammatical structure) in these passages were the ones most com-\nmonly guessed. Thus, most lexical predictions would be wrong. However,\nword predictability speeded up reading time across the entire range from very\nlow to very high (consistent with the notion of graded prediction).\nFrisson et al. (2017) compared the reading time for an unpredictable\n(but plausible) word in a sentence when another word was (or was not)\nhighly predictable at that point. Reading times were comparable. Thus,\nthere was no prediction error cost when an incorrect word was far more\npredictable than the one actually presented.\nNieuwland (2019) reviewed relevant neuroimaging research. He con-\ncluded that the evidence for lexical prediction in reading is “weak and\ninconsistent” (p. 367).\nConclusions\nIn sum, processing can be influenced at an early stage by word predicta-\nbility (perhaps prior to the presentation of the target word). The evidence\nstrongly favours graded over lexical prediction. However, lexical prediction\nmay sometimes be used when a sentence context very strongly predicts a\ngiven word (see DeLong et al., 2005, above). The most convincing evidence\nfor graded prediction is that it has proved hard to identify any processing\ncosts associated with prediction errors.\nWhat is involved in graded prediction? Luke and Christianson (2016)\nfound readers could accurately predict general characteristics of the next\nCreated from usyd on 2022-02-16 03:16:01.",
    "442\nLanguage\nword (e.g., part of speech; whether a noun will be singular or plural). Most\nbeneficial effects of word predictability depend on predicting such general\ncharacteristics rather than predicting the word itself.\nREADING ALOUD\nRead aloud the following words and non-words (pronounceable non-words\nare pseudowords but we will generally use the term non-words):\nCAT  FOG  COMB PINT  MANTINESS  FASS\nYou probably regarded that as a simple task although it involves hidden\ncomplexities. For example, how do you know the b in comb is silent and\nthat pint does not rhyme with hint? Presumably you have specific informa-\ntion stored in long-term memory about how to pronounce these words.\nHowever, that does not explain your ability to pronounce non-words such\nas mantiness and fass. Perhaps non-words are pronounced by analogy with\nreal words (e.g., fass is pronounced to rhyme with mass). Alternatively, we\nmay use rules governing the translation of letter strings into sounds to gen-\nerate pronunciations for non-words.\nThe above description is incomplete. There are different reading disor-\nders in brain-damaged patients depending on which parts of the language\nsystem are damaged. We turn now to two major theoretical approaches\naddressing these issues. First, there is the dual-route cascaded model\n(Coltheart et  al., 2001). Second, there is the distributed connectionist\napproach or triangle model (Harm & Seidenberg, 2004; Plaut et al., 1996)\nextended to explain reading disorders (Patterson & Lambon Ralph, 1999).\nThe above theoretical approaches are both connectionist models\n(see Glossary). Why is this? The processes involved in skilled reading are\ncomplex and interactive, and computational models can handle such com-\nplexity. Of particular importance, computational models make it easier to\npredict what follows from various theoretical assumptions (Norris, 2013).\nThere are key differences between the above approaches. According to\nthe dual-route approach, reading words and non-words involves different\nprocesses. These processes are relatively neat and tidy and some are rule-\nbased. Alas, the dual-route approach has become less neat and tidy over\ntime!\nAccording to the connectionist triangle approach, reading processes\nare used more flexibly than within the dual-route model. Reading involves\ninteractive processes – all the relevant knowledge we possess about word\nsounds, word spellings and word meanings is used in parallel (at the same\ntime) whether reading words or non-words. Of importance, reading aloud\ninvolves more involvement of the semantic system within this model.\nThe most important difference between the two approaches concerns\nwhether the processes involved in reading are specific to reading or whether\nthey are more general. According to the triangle approach, “Reading is, in\nevolutionary terms, a recently developed skill . . . underpinned by the more\nmature primary systems of vision, phonology, and semantics” (Hoffman\net al., 2015, p. E3719). Thus, reading involves relatively general systems. In\ncontrast, the dual-route model focuses more on reading-specific processes.\nKEY TERM\nPseudowords\nNon-words consisting\nof strings of letters that\ncan be pronounced (e.g.,\nmantiness; fass).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n443\nWe first consider each model’s major assumptions plus relevant supporting\nevidence. After that, we directly compare the two models on controversial\nissues.\nDual-route cascaded model\nColtheart et al.’s (2001) dual-route cascaded model of reading (see Figure\n9.17) accounts for reading aloud and silent reading. There are two main\nroutes between printed words and speech, both starting with orthographic\nanalysis (used for identifying and grouping letters in words). There is a\nnon-lexical route using grapheme-phoneme rules to convert letters into\nsounds (see later discussion). The identification of these rules is somewhat\narbitrary and open to question (Eysenck & Brysbaert, 2018).\nThere is also a lexical route involving lexical or dictionary look-up. In\nFigure 9.17, the non-lexical route is Route 1 and the lexical route is divided\ninto two sub-routes (Routes 2 and 3) depending on whether the semantic\nsystem (meanings of words) is used.\nFigure 9.17\nBasic architecture of the\ndual-route cascaded model.\nAdapted from Coltheart et al.\n(2001).\nInteractive exercise:\nDual-route cascade model\nCreated from usyd on 2022-02-16 03:16:01.",
    "444\nLanguage\nHealthy individuals use both routes in parallel when reading aloud.\nHowever, naming visually presented words typically depends mostly on the\nlexical route because it operates faster.\nIt is a cascaded model because it involves cascade processing with\nactivation at one level being passed on to the next level prior to comple-\ntion of processing at the first level. Cascaded models differ from threshold\nmodels where activation at one level is only passed on to other levels after\na given threshold of activation is reached.\nEarlier we discussed the role of phonological processing in visual\nword identification. Coltheart et al. (2001) argued for a weak phonological\nmodel where word identification generally does not depend on phonologi-\ncal processing.\nColtheart et  al. (2001) produced a detailed computational model to\ntest their dual-route cascaded model. They started with 7,981 one-syllable\nwords and used McClelland and Rumelhart’s (1981) interactive activation\nmodel (discussed earlier, pp. 437–439), to provide the orthographic com-\nponent of their model. They predicted the pronunciation most activated\nby processing in the lexical and non-lexical routes would determine the\nnaming response.\nColtheart et  al. (2001) found 99% of words and one-syllable words\nwere read accurately.\nRoute 1 (grapheme–phoneme conversion)\nRoute 1 differs from the other routes in using grapheme–phoneme con-\nversion, which involves converting spelling (graphemes) into sound (pho-\nnemes). A grapheme is a basic unit of written language whereas a phoneme\nis a basic unit of spoken language. Examples of graphemes are the i in pig\nand the igh in high.\nIf a brain-damaged patient used only Route 1, what would we expect?\nUse of grapheme–phoneme conversion rules (converting each grapheme\ninto the phoneme most closely associated with it) should permit accu-\nrate pronunciations of words with regular spelling–sound correspondence.\nHowever, these rules would not permit accurate pronunciation of irregular\nwords not conforming to the conversion rules. For example, if the irregular\nword pint has grapheme–phoneme conversion rules applied to it, it would be\npronounced to rhyme with hint. This is regularisation. Finally, grapheme–\nphoneme conversion rules can provide pronunciations of non-words.\nSurface dyslexics are apparently largely reliant on Route 1. Surface\ndyslexia involves special problems in reading irregular words. For\nexample, KT, a surface dyslexic, read 81% of regular words and 100%\nof non-words accurately but only 41% of irregular words (McCarthy &\nWarrington, 1984). Over 70% of KT’s errors with irregular words involved\nregularisation.\nWe might not expect to find cases of surface dyslexia in languages (e.g.,\nGreek) lacking irregular words (i.e., all words follow grapheme–phoneme\nrules). However, Sotiropoulos and Hanley (2017) identified Greek individ-\nuals whose slow reading of Greek words suggested they might have surface\ndyslexia. When these individuals read English words and non-words, they\nshowed the classic pattern associated with surface dyslexia: high accuracy\nKEY TERMS\nCascade processing\nLater processing stages\nstart before earlier\nprocessing stages have\nbeen completed when\nperforming a task.\nGrapheme\nA small unit of written\nlanguage corresponding\nto a phoneme (e.g., the\nph in photo).\nPhonemes\nThe smallest units of\nsound that distinguish\none word from another\nand contribute to word\nmeaning; the number and\nnature of phonemes varies\nacross languages.\nSurface dyslexia\nA condition in which\nregular words and non-\nwords can be read but\nthere is impaired ability\nto read irregular or\nexception words.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n445\nwith regular words and non-words but severely impaired performance with\nirregular words.\nRoute 2 (lexicon + semantic knowledge) and Route 3\n(lexicon only)\nThe basic idea behind Route 2 is that representations of thousands of famil-\niar words are stored in an orthographic input lexicon. Visual presentation of\na word produces activation within this lexicon. This is followed by obtain-\ning its meaning from the semantic system, after which its sound pattern is\ngenerated by the phonological output lexicon. Route 3 also involves the\northographic input and phonological output lexicons but bypasses the\nsemantic system.\nWhat would we expect to find in patients using Route 2 or 3 but not\nRoute 1? Their intact orthographic input and phonological output lexicons\nmeans they could pronounce familiar words (regular or irregular). However,\ntheir inability to use grapheme-phoneme conversion rules means they should\nfind it very hard to pronounce unfamiliar words and non-words.\nPhonological dyslexics fit this predicted pattern fairly well. Phono-\nlogical dyslexia involves special problems with reading unfamiliar words\nand non-words. Caccappolo-van Vliet et al. (2004) studied two phonologi-\ncal  dyslexics – their performance on reading familiar regular and irregular\nwords exceeded 90% compared to under 60% with non-words. In a study\ndiscussed above, Sotiropoulos and Hanley (2017) identified two Greek\nindividuals with phonological dyslexia: they had problems with non-words\nin Greek and English but not words.\nDeep dyslexia\nDeep dyslexia involves problems in reading unfamiliar words and an ina-\nbility to read non-words. However, its most striking symptom consists of\nsemantic reading errors (e.g., ship read as boat). According to Coltheart\net al. (2001), deep dyslexics use a completely different reading system based\nin the right hemisphere (it is in the left hemisphere for 90% of people).\nAccordingly, they concluded deep dyslexia cannot be explained by the\ndual-route cascaded model. Most evidence is inconsistent with this right-\nhemisphere hypothesis.\nTwo routes?\nFindings from brain-damaged patients support the notion of two different\nroutes (lexical vs non-lexical) in reading words. However, neuroimaging\nstudies reveal individual differences. Jobard et al. (2011) found only indi-\nviduals with low working memory capacity (see Glossary) had activation\nin brain areas associated with grapheme–phoneme conversion. Fischer-\nBaum et al. (2018) found significant individual differences in the use of the\nnon-lexical route by skilled readers.\nAccording to the dual-route model, the non-lexical route to reading\ninvolves grapheme–phoneme conversion. This requires serial left-to-right\nprocessing and so the time taken to start saying non-words should depend\nKEY TERMS\nPhonological dyslexia\nA condition in which\nfamiliar words can be\nread but there is impaired\nability to read unfamiliar\nwords and non-words.\nDeep dyslexia\nA condition in which\nreading unfamiliar words\nand non-words is impaired\nand there are semantic\nerrors (e.g., reading\nmissile as rocket).\nCreated from usyd on 2022-02-16 03:16:01.",
    "446\nLanguage\non their length. In contrast, the lexical route involves parallel processing\nand so there should be minimal effects of length on the time taken to start\nsaying words.\nJuphard et al. (2011) found the time to start saying three-syllable non-\nwords was 26% longer than one-syllable ones, but for words this difference\nwas only 11%. Syllabic length of non-words (but not words) influenced\nthe duration of activity in brain areas associated with phonological pro-\ncessing. These findings suggest producing phonological representations of\nnon-words is a slow, serial process whereas it is fast and parallel for words.\nPreliminary evaluation\nThe dual-route cascaded model was the first systematic attempt to account\nfor basic reading processes in brain-damaged and healthy individuals. The\nnotion there are two routes in reading has been very influential and has\nattracted support from research on patients with various reading disorders\n(e.g., surface dyslexia; phonological dyslexia). The specific assumption there\nare separate lexical and non-lexical routes involving parallel and serial pro-\ncessing, respectively, has received behavioural and neuroimaging support\nfrom healthy individuals.\nWhat are the model’s limitations? First, it de-emphasises semantic\nprocesses in reading (discussed later, pp. 447–449). For example, Cattinelli\net  al. (2013) found in a meta-analytic review that reading was associated\nwith activation in brain areas (e.g., parts of the temporal lobe; the anterior\nfusiform region) associated with semantic processing.\nSecond, the model focuses on the reading of individual words.\nHowever, word reading in everyday life typically occurs within sentences.\nThird, the model does not exhibit learning and so cannot explain how\nchildren acquire grapheme–phoneme rules. However, Perry et  al. (2007)\ndeveloped a new connectionist dual-process model (the CDP+ model)\nbased on the dual-route cascaded model. This model learns and also elim-\ninates other problems with the dual-route model.\nFourth, the model assumes phonological processing of words typi-\ncally occurs relatively slowly and has little effect on word recognition and\nreading. In fact, however, phonological processing often occurs rapidly\nand automatically (Rastle & Brysbaert, 2006; discussed earlier, p. 436).\nFifth, Adelman et al. (2014) found the model did not provide an ade-\nquate account of individual differences in reading. In addition, its assump-\ntion that readers have perfect knowledge of letter positions within words\nis incorrect.\nSixth, it is desirable for computational models to have relatively few\nparameters (values free to change). The dual-route model has over 30\nparameters, so it is unsurprising it fits the data well.\nSeventh, there are issues concerning the model’s applicability to non-\nEnglish languages. For example, French orthography is unusual in that\nnumerous letters are silent and so lack a phonological representation.\nHowever, the CDP+ model accounts for reading in French (Perry et  al.,\n2014).\nEighth, the model only accounts for the reading of one-syllable words.\nHowever, Mousikou et al. (2017) found stress, pronunciation and naming\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n447\ntimes for two-syllable non-words were predicted by models incorporating\naspects of the dual-route model.\nConnectionist triangle model\nWithin the dual-route model, it is assumed different routes are used to pro-\nnounce irregular words and non-words. According to the connectionist tri-\nangle approach, in contrast,\nAll of the system’s knowledge of spelling-sound correspondences is\nbrought to bear in pronouncing all types of letter strings [words and\nnon-words]. Conflicts among possible alternative pronunciations of a\nletter string are resolved . . . by co-operative and competitive interac-\ntions based on how the letter string relates to all known words and\ntheir pronunciations.\n(Plaut et al., 1996, p. 58)\nThus, reading depends on a highly interactive system based on “all hands\nto the pump”.\nThe triangle model (which has been instantiated in distributed connec-\ntionist form) is shown in Figure 9.18. The three sides of the triangle are\northography (spelling), phonology (sound) and semantics (meaning). Of\nimportance, the triangle model learns to produce the correct output (i.e.,\nspoken word or non-word) from the input (i.e., written word or non-word)\nusing back-propagation (see Glossary) by comparing actual responses\nagainst correct ones.\nIf you compare Figure 9.18 with Figure 9.17, you can see semantics\nis more important in the triangle model. Note that this model (unlike the\ndual-route model) has no lexicons for orthographic or phonological words\nand lacks grapheme–phoneme rules.\nThere are two routes from spelling to sound in the triangle model: (1)\na direct pathway from orthography to phonology (O → P pathway); (2) an\nindirect pathway from orthography to phonology proceeding via seman-\ntics or word meanings (O → S → P pathway). The direct, non- semantic\npathway is typically used when reading high-frequency and regular or\nconsistent words, whereas the indirect, semantic pathway is mostly used\nwhen reading low-frequency and irregular or inconsistent words.\nHoffman et al. (2015) found brain areas associated with orthographic,\nphonological and semantic processing were all activated during word\nreading (see Figure 9.18). These findings are as predicted by the triangle\nmodel.\nAccording to the triangle model, words and non-words vary in\nconsistency  – the extent to which their pronunciation agrees with those\nof similarly spelled words (neighbours). Harley (2010) gives the exam-\nples of TAZE and TAVE. TAZE has consistent neighbours (gaze; laze;\nmaze), whereas TAVE does not (have as well as gave, rave, and save).\nThe prediction (discussed later, p. 451) is that consistent words and non-\nwords should be said faster than inconsistent ones. In contrast, the dual-\nroute model focuses on dividing words into regular ones (conforming\nCreated from usyd on 2022-02-16 03:16:01.",
    "448\nLanguage\nFigure 9.18\nThe three components\nof the triangle model\n(left) and their associated\nneural regions (right).\nO = orthography; P =\nphonology; S = semantics.\nOrthographic processing\ninvolves the ventral\noccipito-temporal cortex;\nphonological processing\ninvolves the precentral\ngyrus; semantic processing\ninvolves the anterior\ntemporal lobes.\nFrom Hoffman et al. (2015).\nto  grapheme-phoneme rules) and irregular (not conforming to those\nrules).\nHow does the triangle model account for the different dyslexias? It is\nassumed surface dyslexia mostly involves damage to the semantic system.\nPlaut et al. (1996) lesioned or damaged their connectionist model to reduce\nthe contribution of semantics. Its performance matched the pattern with\nsurface dyslexics: very good with all consistent words and non-words,\nworse on inconsistent high-frequency words, and worst on inconsistent\nlow-frequency words.\nThe model assumes that phonological dyslexia (involving problems in\nreading unfamiliar words and non-words) involves a general impairment of\nphonological processing. Relevant evidence is discussed later (see p. 450).\nFinally, there is deep dyslexia (involving problems in reading unfamiliar\nwords and non-words plus semantic errors). Within the triangle model,\ndeep dyslexia represents a serious form of phonological dyslexia with\nseverely impaired phonological processing, leading to increased reliance on\nsemantic processing.\nFindings\nPlaut et al. (1996) gave the model prolonged training with 2,998 words. Its\nperformance resembled that of adult readers in various ways:\n(1) Inconsistent words took longer to name than consistent ones.\n(2) Rare words took longer to name than common ones.\n(3) The effects of consistency were much greater for rare words than\ncommon ones.\n(4) The network pronounced over 90% of non-words “correctly” (com-\nparable to adult readers). This is impressive given the network\nreceived no direct training on non-words.\nThe triangle model assumes semantic processing (involving the O → S → P\npathway) is generally involved when inconsistent/irregular words are read.\nP\nS\nO\nS\nP\nS\nO\nP\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n449\nare  read. As predicted, Hoffman et  al. (2015) found greater activation\nwithin the  anterior temporal lobe (associated with semantic processing)\nwhen  participants read inconsistent/irregular words than when they read\nconsistent/regular ones.\nHoffman et al.’s (2015) findings do not show that semantic processing\nwithin the anterior temporal lobe plays a causal role. Ueno et  al. (2018)\nobtained more direct evidence. They administered transcranial magnetic\nstimulation (TMS; see Glossary) to the anterior temporal lobe to impair\nits functioning while participants read words. As predicted, TMS reduced\nreading accuracy when inconsistent/irregular words were read but not con-\nsistent/regular words.\nAccording to the triangle model, the O → P pathway should be used\nmostly when participants read regular/consistent words. As predicted,\nHoffman et  al. (2015) found functional connectivity between the brain\nareas involved in orthographic (ventral occipito-temporal cortex) and pho-\nnological processing (the precentral gyrus) was much greater with such\nwords than inconsistent/irregular words.\nPreliminary evaluation\nThe triangle model has several successes to its credit. First, there is much\nsupport for the two pathways assumed to be involved in reading aloud.\nSecond, and most important, semantic processing plays a major role in\nreading especially with inconsistent or irregular words. Third, the triangle\nmodel focuses on how we learn to pronounce words, unlike the original\ndual-route cascaded model. Fourth, the model provides important insights\ninto the mechanisms underlying the dyslexias (discussed below).\nWhat are the model’s limitations? First, the model “focused on the re cogni-\ntion of simple, often monosyllabic words” (Harley, 2013). Second, its emphasis\nis on explaining the reading of words presented in isolation, whereas words\nare typically read within a sentential context. Third, in its original version,\nas Plaut et al. (1996, p. 108) admitted, “The nature of processing within the\nsemantic pathway has been characterised in only the coarsest way”. However,\nHarm and Seidenberg (2004) improved the model by implementing its\nsemantic component to map orthography and phonology onto semantics.\nControversial topics\nWe turn now to controversial topics where the two models make different\npredictions. Note, however, that both models have evolved over time, and\nso some predictions have changed.\n1 Surface dyslexia\nSurface dyslexics have problems reading irregular or inconsistent words\nbut perform reasonably well with regular or consistent ones and with non-\nwords. According to the dual-route model, surface dyslexics have damage\nto Routes 2 and 3 and so rely heavily on Route 1 (grapheme–phoneme\nconversion). In contrast, the triangle model claims the major problem in\nsurface dyslexia is extensive damage to the semantic system.\nCreated from usyd on 2022-02-16 03:16:01.",
    "450\nLanguage\nWoollams et  al. (2007) studied 51 patients with semantic demen-\ntia (see Glossary), a condition involving severe loss of knowledge about\nword meanings. Surface dyslexia was present in 48 of the patients, and the\nremaining 3 patients became surface dyslexics as their semantic knowledge\ndeteriorated. Of crucial importance, there was a large negative correlation\nbetween the ability to read low-frequency irregular/inconsistent words and\nthe extent of patients’ semantic knowledge.\nIn sum, both models provide reasonable accounts of surface dyslexia.\nHowever, evidence that surface dyslexia is associated with severe prob-\nlems within the semantic system is easier to account for on the triangle\nmodel.\n2 Phonological dyslexia\nPhonological dyslexia involves severe difficulties in reading unfamiliar words\nand non-words. According to the dual-route model, phonological dyslexics\nhave an inability to use Route 1 (grapheme–phoneme conversion)  – their\nproblems are specific to reading. According to the triangle model, in con-\ntrast, phonological dyslexics have a more general phonological deficit.\nThe evidence is mixed. Support for the dual-route model was obtained\nby Caccappolo-van Vliet et al. (2004) (discussed earlier, p. 445). Their two\nphonological dyslexics showed essentially intact performance on various\nnon-reading phonological tasks. However, Woollams and Patterson (2012)\nstudied patients exhibiting symptoms of phonological dyslexia when\nreading aloud. The number of phonological errors these patients made in\npicture naming predicted their reading performance, indicating they had a\nrelatively general phonological deficit.\nHenry et al. (2012, 2016) found patients with symptoms of phonolog-\nical dyslexia had brain damage in areas associated with phonological pro-\ncessing. In addition, their performance when reading non-words depended\non phonological processes also involved in speech production and speech\nperception. These findings support the triangle model.\nIn sum, the available evidence indicates most (but not all) phonological\ndyslexics have fairly general phonological impairments. Thus, the  findings\nare mostly more supportive of the triangle model.\n3 Deep dyslexia\nDeep dyslexics make many semantic errors when reading aloud and have\nproblems in reading unfamiliar words and non-words. As discussed earlier,\nColtheart et al. (2001) (p. 445) argued that an account of deep dyslexia is\noutside the scope of the dual-route model because deep dyslexics predomi-\nnantly use the right (rather than left) hemisphere when reading. According\nto the triangle model, deep dyslexia and phonological dyslexia both involve\nsevere impairments in phonological processing.\nThe triangle model’s assumptions were supported by Jefferies et  al.\n(2007). Deep dyslexics performed poorly on various phonologically based\ntasks (e.g., phoneme addition; phoneme subtraction). They concluded deep\ndyslexics have a general phonological impairment as do phonological dys-\nlexics. Crisp et al. (2011) found deep dyslexics and phonological dyslexics\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n451\nhad substantially impaired ability to translate orthography (spelling) into\nphonology as predicted by the triangle model.\nIt is plausible the semantic errors made by deep dyslexics occur because\ntheir very severe problems with phonological processing force them to rely\nheavily on the semantic system. Ablinger and Radach (2016) studied a deep\ndyslexic, KJ, who relied excessively on semantic processing while reading\naloud. Therapy based on increasing the involvement of phonological pro-\ncessing enhanced his ability to read words aloud.\nIn sum, the triangle model provides a generally persuasive account of\ndeep dyslexia. However, it is probably not applicable to all deep dyslexics\n(Harley, 2013).\n4 Word regularity vs word consistency\nAccording to the dual-route model, regular words (those conforming to the\ngrapheme–phoneme rules in Route 1) can often be named faster than irregu-\nlar words. According to the triangle model, what matters is consistency. The\nletter patterns in consistent words are pronounced in the same way in all\nwords in which they appear and such words are predicted to be read faster\nthan inconsistent words. Since irregular words tend to be inconsistent, we\nneed careful experimentation to decide whether regularity or  consistency is\nmore important.\nJared (2002) presented words belonging to the four following categories:\n(1) Regular consistent (e.g., bean)\n(2) Regular inconsistent (e.g., beak)\n(3) Irregular consistent (e.g., both)\n(4) Irregular inconsistent (e.g., bear)\nThe findings were reasonably clear-cut: word\nnaming times were affected much more by\nconsistency than regularity (see Figure 9.19).\nLee et al. (2005) studied Chinese speakers\nnaming Chinese characters. Performance was\ninfluenced by character consistency and char-\nacter regularity with low-frequency characters\nbut only by consistency with high-frequency\ncharacters. Thus, consistency and regularity\nboth played a role.\nIn sum, research provides some support\nfor the dual-route and triangle models. How-\never, the findings provide stronger support\nfor the triangle model.\n5 Pronouncing non-words\nThe dual-route model assumes non-word\npronunciations depend on the application of\ngrapheme–phoneme rules and so are inflex-\nible. In contrast, the triangle model predicts\nFigure 9.19\nMean naming latencies for high-frequency (HF) and low-\nfrequency (LF) words that were irregular (exception words:\nEXC) or regular and inconsistent (RI). Mean naming latencies\nof regular consistent words matched with each of these word\ntypes are also shown. The differences between consistent and\ninconsistent words were much greater than those between\nregular and irregular words (EXC compared to RI).\nFrom Jared (2002). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-16 03:16:01.",
    "452\nLanguage\nflexibility because non-word pronunciations depend on an individual’s pre-\nvious reading experience. As predicted by the triangle model, Coltheart and\nUlicheva (2018) discovered considerable evidence of flexibility in the pro-\nnunciations of non-words.\nThe triangle model makes another prediction. Variability in pro-\nnunciation should be greater with inconsistent non-words than consis-\ntent ones because orthographically similar words provide more possible\npronunciations for the former. Zevin and Seidenberg (2006) studied the\npronunciations of consistent and inconsistent non-words. As predicted,\nthe pronunciations of inconsistent words were more variable. This finding\nis not predicted by the dual-route model, according to which grapheme–\nphoneme rules should typically generate only one pronunciation for all\nnon-words.\nBuetler et al. (2014) studied the influence of language context on pro-\nnunciation of non-words. German/French bilinguals read non-words pre-\nsented in a context of French or German words. Grapheme–phoneme rules\nwere used more often in the German context. Why was this? The relation-\nship between spelling and sound is much more consistent in German than\nFrench and so grapheme–phoneme conversion is easier to use in German.\n6 General vs language-specific processes?\nMore research supports the triangle model’s assumption that reading\ninvolves general processes than the dual-route’s assumption that it involves\nmostly reading-specific processes. Woollams et  al. (2018) studied stroke\npatients suffering from aphasia (severe language problems). They assessed\ngeneral phonological and semantic processing abilities in these patients\nusing tasks not involving reading. They then related individual differences\nin these abilities to reading performance.\nWhat did Woollams et  al. (2018) find? First, phonological process-\ning ability strongly predicted reading performance with both words and\nnon-words. Second, semantic processing ability strongly predicted reading\nperformance with words but only weakly predicted reading performance\nwith non-words. These findings are as predicted by the triangle model\nand strengthen the argument that poor reading performance often reflects\nimpaired general cognitive processes.\nMuch research on reading (and its disorders) has focused on the role\nof orthography (spelling; written form of words). However, poor readers\nmay also have general problems with complex visual processing rather than\nmore specific problems relating to correctly identifying letters and combi-\nnations of letters. Evidence that general visual processes may be involved\nwas reported by Sigurdardottir et al. (2018). Individuals who were poor at\nreading also tended to have difficulties with face matching.\nIn sum, the triangle approach suggests we should stop putting individ-\nuals with reading impairments into categories such as “phonological dys-\nlexia”, “surface dyslexia” and “deep dyslexia”. Instead, we should assess\ntheir general semantic, phonological and visual abilities so their underlying\ncognitive impairments can be interpreted within a three-dimensional space\nformed by those three abilities.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n453\nConclusions\nThe dual-route and triangle models share several impressive strengths and\nhave deservedly been highly influential. First, both models assume cor-\nrectly that reading words and non-words aloud is a complex achievement.\nSecond, both models provide plausible accounts of reading applicable to\ndyslexics and those with intact reading skills. Third, both models have been\nimplemented as computational models and so make precise predictions.\nWith respect to the above six controversial issues, the triangle model\nhas the edge (although this is less true of relatively recent theoretical devel-\nopments). Why is this so? It is assumed within the triangle model that\nreading is a skill that developed only recently in our evolutionary history.\nAs a result, reading depends heavily on general processes not specific to\nreading. In contrast, the dual-route model’s emphasis is on reading- specific\nprocesses and structures (e.g., grapheme–phoneme rule system). This\nemphasis may be misplaced if evolutionary development has not provided\nus with the relevant neural architecture.\nREADING: EYE-MOVEMENT RESEARCH\nSeveral theoretical approaches discussed earlier (e.g., interactive activation\nmodel; dual-route cascaded model; triangle model) focus on explaining\nthe processing of isolated words. In contrast, research on eye movements\nduring text reading has led to theories focusing on word reading within sen-\ntential contexts (Snell et al., 2018).\nBasic processes\nEye movements are crucial to reading. Most text information we process\nrelates to the word currently fixated. However, limited information from\nother words may also be processed.\nOur eyes move in rapid jerks (saccades). Saccades are ballistic (once\ninitiated their direction cannot be changed). Regressions (the eyes moving\nbackwards in the text) account for 10% of saccades. Saccades take 20–30\nms to complete and are separated by fixations lasting 200–250 ms. The\nlength of each saccade is about 8 letters or spaces. Information is extracted\nfrom text only during each fixation.\nThe amount of text from which useful information can be extracted\non each fixation has been assessed using the “moving window” technique\n(Rayner et  al., 2012). The text is mutilated except for an experimenter-\ndefined area or window surrounding fixation point. When readers move\ntheir eyes, different parts of the text are mutilated to permit normal reading\nonly within the window region. The perceptual span (effective field of\nview) extends 3 or 4 letters to left of fixation and up to 15 letters to the\nright in English and is affected by text difficulty.\nThe size of the perceptual span means information from the  parafovea\n(the area surrounding the fovea: see Glossary) is used during reading.\nConvincing evidence comes from the boundary technique. There is a\npreview word just to the right of fixation. When readers make a saccade to\nthis word, it changes into the target word. The fixation time on the target\nKEY TERMS\nSaccades\nRapid eye movements\nseparated by eye fixations\nlasting about 250 ms.\nPerceptual span\nThe effective field of view\nin reading (letters to the\nleft and right of fixation\nthat can be processed).\nParafovea\nThe area in the retina\nimmediately surrounding\nthe fovea.\nInteractive exercise:\nDual-route reading\nCreated from usyd on 2022-02-16 03:16:01.",
    "454\nLanguage\nword is less when it is the same as the preview word (Vasilev & Angele,\n2017).\nReaders fixate 80% of content words (nouns, verbs and adjectives) but\nonly 20% of function words (e.g., a, the, and, or). Words not fixated tend\nto be those easily processed (e.g., common, short or predictable). Finally,\na word’s fixation time is longer if preceded by a rare word (the spillover\neffect).\nThere are numerous theories of reading based on eye-movement data.\nWe will focus on the most influential one: the E-Z Reader model.\nE-Z Reader model\nThe original version of the E-Z Reader model was proposed by Reichle\net al. (1998) and has been followed by several other versions (Sheridan &\nReichle, 2016). The model assumes the mind and eyes are tightly coupled,\nand so patterns of eye movements provide potentially rich data concerning\nreaders’ processing strategies.\nThe most obvious model would assume we fixate a word until it is pro-\ncessed adequately, after which we immediately fixate the next word. Alas,\nthere are two major problems with this model. First, it takes 85–200 ms\nto execute an eye-movement programme and so readers would waste time\nwaiting for their eyes to move to the next word. Second, readers sometimes\nskip words. According to the model, readers know nothing about the next\nword until it is fixated. How, then, could they decide which words to skip?\nThe E-Z Reader model provides elegant solutions to the above prob-\nlems. A crucial assumption is that the next eye movement is programmed\nafter only partial processing of the current word (word n). This greatly\nreduces the time between completing processing of word n and an eye\nmovement to the next word (word n+1). There is typically less spare time\navailable with rare words than common ones – this accounts for the spill-\nover effect. If the processing of word n+1 is completed rapidly enough, it\nis skipped.\nAccording to the model, readers can attend to two words (words n and\nn+1) during a single fixation. However, it is a serial processing model – at\nany given moment, only one word is processed. Here are its main assump-\ntions (see Figure 9.20):\n(1) Readers check the familiarity of the word currently fixated (word n).\n(2) Completion of the familiarity check (the first stage of lexical access) is\nthe signal to initiate an eye-movement programme.\n(3) Readers then engage in the second stage of lexical access, which\ninvolves accessing word n’s semantic and phonological forms.\n(4) Familiarity checking and lexical access are completed faster for easily\nprocessed words (e.g., common; short; predictable).\n(5) Completion of lexical access to word n signals a shift of covert (inter-\nnal) attention to word n+1.\nSeveral findings support the model (Reingold et al., 2012). First, common\nwords are fixated for less time than rare ones. Second, a word following\na rare word is fixated longer than one following a common word (the\nKEY TERM\nSpillover effect\nAny given word is fixated\nlonger during reading\nwhen preceded by a\nrare word rather than a\ncommon one.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n455\nFigure 9.20\nKey assumptions of the\nE-Z Reader model. The\nx-axis shows the processing\ndifficulty of the word\ncurrently being fixated\n(word n). The preview time\n(shaded area) is the time\navailable for parafoveal\nprocessing of word n+1\n(covert attention) prior to\neye fixation on that word.\nFrom Sheridan & Reichle (2016).\nspillover effect) because it receives less parafoveal processing when word n\nis rare (Luke, 2018). Third, word n+1 is skipped when its lexical access has\nbeen completed during fixation on word n. This typically occurs when word\nn is common, short or predictable.\nThe E-Z Reader model (which emphasises serial processing) can be\ncontrasted with parallel processing models such as the SWIFT model\n(Saccade-Generation With Inhibition by Foveal Targets) model (e.g.,\nEngbert et  al., 2005; Schad & Engbert, 2012). This model assumes the\ndurations of eye fixations in reading are often influenced by parallel pro-\ncessing of the previous and next words as well as the current one.\nAttentional processes are of central importance to both models. The\nE-Z Reader model assumes an attentional spotlight moves from one word\nto the next. Within the SWIFT model, in contrast, attention is more like a\nzoom lens because its scope can change (see Chapter 5). Attention is widely\ndistributed when foveal processing is easy but more narrowly focused when\nit is hard.\nThe two models both account for most findings. However, they differ\nwith respect to lexical parafoveal-on-foveal effects. This sounds complicated\nbut simply means lexical properties of the next word (e.g., its frequency and/\nor predictability) influence the fixation duration on the current word. Such\neffects should not occur according to the serial processing E-Z Reader model,\nbut they can occur according to the parallel processing SWIFT model.\nFindings\nAccording to the E-Z Reader model, there are two stages of lexical pro-\ncessing for words: (1) checking word familiarity; (2) lexical access (access-\ning semantic and phonological information about the word). Sheridan and\nReingold (2013) argued that presenting words faintly disrupts stage (1) but\nnot stage (2). In contrast, case alternation (e.g., tAbLe) disrupts only stage\n(2). Their findings were as predicted, thus supporting the notion that lexical\nprocessing occurs in two stages.\nEyes fxate word n + 1\nFocus of attention on word n + 1\nLexical access of word n\nFamiliarity check on word n\nPreview time\nTime (ms)\nEasy\nDifficult\nWord n processing difficulty\nKEY TERM\nLexical parafoveal-on-\nfoveal effects\nThe finding that\nfixation duration on the\ncurrent word (word n)\nis influenced by lexical\nproperties of the next\nword (word n+1).\nCreated from usyd on 2022-02-16 03:16:01.",
    "456\nLanguage\nAccording to the E-Z Reader model, readers use parafoveal process-\ning to extract limited information from the next word (n+1) before it is\nfixated (this occurs during the preview time shown in Figure 9.20). As\na result, fixation time on word n+1 is reduced when parafoveal process-\ning is possible. Vasilev and Angele (2017) found in a meta-analysis that\nparafoveal review reduced gaze duration on word n+1 by an average of\n40 ms.\nWhat information is extracted from word n+1 during parafoveal\nreview? Schotter et al. (2012) found that orthographic (word spelling), pho-\nnological (word sound) and morphological (word structure) information\ncan all be processed parafoveally. As mentioned earlier, readers sometimes\nskip word n+1 (i.e., do not fixate it) when reading. This suggests a complete\nidentification of word n+1 can occur during parafoveal review. Consistent\nwith these findings, Angele et al. (2016) found evidence for two stages of\nparafoveal processing: (1) early orthography-based processing; and (2) late\nattentionally dependent lexical access.\nMost research has focused only on the English language. Rayner et al.\n(2007) studied eye movements in Chinese individuals reading Chinese text.\nChinese differs from English in that it is written without spaces between\ncharacters. Nevertheless, the pattern of eye movements resembled that\nfound in readers of English.\nWe turn now to lexical parafoveal-on-foveal effects where lexical\nproperties (e.g., frequency) of the next word influence the processing\nof the current word. Remember the SWIFT model predicts such effects\nwhereas the E-Z Reader model does not. There would be evidence for\nparafoveal-on-foveal effects if gaze duration on word n were greater when\nword n+1 was a low-frequency rather than high-frequency word.\nBrothers et  al. (2017) conducted a meta-analytic review of research\nwhere the frequency of word n+1 was manipulated. There was no evidence\nfor parafoveal-on-foveal effects across several languages (e.g., English;\nFinnish; Spanish; Chinese). Brothers et  al. reported a similar absence of\nlexical parafoveal-on-foveal effects in further meta-analyses focusing on\nother features of word n+1 related to lexical access (i.e., semantic plau-\nsibility; lexical predictability). Degno et  al. (2019) pointed out that most\nprevious research had used very artificial reading conditions. They used a\nmore natural reading task, but also failed to find any evidence of lexical\nparafoveal-on-foveal effects.\nEvaluation\nThe E-Z Reader model is very successful in several ways. First, there is\nample justification for its emphasis on eye-movement patterns, because “the\ncontrol of eye movements is part and parcel of the dynamics of informa-\ntion processing within the task of reading itself” (Radach & Kennedy, 2013,\np. 429). Second, it identifies several factors (e.g., word frequency; word pre-\ndictability) determining eye fixations in reading. Third, there is support for\nthe assumption lexical processing occurs in two separate stages (i.e., famili-\narity checking and lexical access).\nFourth, parafoveal preview of the next word typically facilitates its\nsubsequent processing when fixated. Fifth, the assumption there are close\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n457\nconnections between eye (fixations) and mind (cognitive processes) has\nreceived support (e.g., Bixler & D’Mello, 2016). Sixth, the absence of lexical\nparafoveal-on-fovea effects supports serial models (e.g., E-Z Reader) over\nparallel models (e.g., SWIFT).\nWhat are the model’s limitations?\n(1) The E-Z Reader and SWIFT models both explain where and when\nthe eyes move during reading. Such approaches have proceeded inde-\npendently of approaches (e.g., McClelland & Rumelhart’s, 1981, inter-\nactive activation model) designed to identify the processes involved\nin word recognition. However, Snell et  al. (2018) produced a com-\nputational model of reading (OB1-reader) integrating insights from\neye-movement and word-recognition models.\n(2) The role of higher-level processes is de-emphasised. For example, the\nprocesses involved in inference drawing, integration of information\nwithin sentences, and the use of schematic and other knowledge in\ntext comprehension are outside the model’s scope (see Chapter 10).\n(3) We do not know in detail how readers perform the familiarity check.\nReingold et al. (2015) argued it depends on the fluency of orthographic\nprocessing (processing the pattern of letters) but the evidence is\ninconclusive.\n(4) There may be more parallel processing during reading than acknow-\nledged by the E-Z model. For example, Snell et al.’s (2018) OB1-reader\nmodel (which assumes extensive parallel processing) successfully\naccounts for many aspects of reading behaviour.\nCHAPTER SUMMARY\n•\nSpeech (and music) perception: introduction. Speech and music\nperception both involve categorical perception. However, there\nare typically substantial differences in the brain areas activated\nduring speech and music perception. In addition, some patients\nhave selective impairment of speech or music perception. Speech\nperception involves various stages starting with selection of speech\nfrom the acoustic background and including word recognition and\nutterance interpretation. Speech perception is often more variable\nthan implied by the notion of sequential stages.\n•\nListening to speech. Among the problems faced by listeners\nare the speed of spoken language, the segmentation problem,\nco-articulation, individual differences in speech patterns, and\ndegraded speech. Listeners prefer to use lexical (e.g., syntax)\ninformation to achieve word segmentation but can also\nuse co-articulation, allophony and syllable stress. Listeners\noften cope with variations between speakers by forming a\nspeaker model. The McGurk effect shows listeners often make\nuse of visual information (i.e., lip-reading) during speech\nperception.\nCreated from usyd on 2022-02-16 03:16:01.",
    "458\nLanguage\n•\nContext effects. Context influences speech perception in several\nways (e.g., phonemic restoration effect; Ganong effect) There\nis much controversy concerning how context influences speech\nperception. The main divide is between those arguing such effects\noccur late in processing (autonomous position) and those arguing\nthey can also occur early in processing (interactionist position).\nThe interactionist position has received much support recently.\nHowever, it is more applicable when speech is degraded than\nwhen it is clear and unambiguous.\n•\nTheories of speech perception. Spoken word recognition is\noften influenced by orthography (word spellings). According to the\nmotor theory, motor processes can facilitate speech perception.\nIn support, brain areas involved in speech production are typically\ninvolved in speech perception. Impaired speech perception\nfollowing damage to speech-production systems also supports\nthe theory. However, many brain areas are involved in speech\nperception but not speech production.\nThe TRACE model assumes bottom-up and top-down processes\ninteract flexibly in spoken word recognition. The model accounts\nfor several phenomena (e.g., word superiority effect, the Ganong\neffect, categorical perception and the phonemic restoration effect).\nHowever, it has a narrow focus on word recognition, it exaggerates\nthe importance of top-down processes and it de-emphasises the\nrole of conceptual meaning.\nThe cohort model assumes spoken word recognition involves\nrejecting competitors in a sequential process. It also assumes\nthat context effects occur during the integration stage following\nword identification. However, context sometimes influences\nword processing prior to the integration stage. The model\nalso de-emphasises the role of word meanings in spoken word\nrecognition. There is support for the more recent assumption that\nthere is continuous integration of information from the speech\ninput and context.\n•\nCognitive neuropsychology. Brain-damaged patients exhibit\nvarious patterns of impairment in speech perception. Some of\nthese patterns can be explained by assuming the existence of\nthree routes between sound and speech. Support has been\nobtained by studying patients with pure word deafness, word\nmeaning deafness and transcranial sensory aphasia. The three-\nroute approach provides a sketch map rather than a detailed\ntheoretical account.\n•\nReading: introduction. It is harder to read English than most other\nlanguages because the relationship between spelling and sound is\nvery inconsistent. Lexical decision, naming and priming tasks are\nused to assess word identification. Studies of masked phonological\npriming suggest that visual word recognition typically depends on\nCreated from usyd on 2022-02-16 03:16:01.",
    "Speech perception and reading\n459\nprior phonological processing. The finding that word recognition\ndepends on the number of phonologically similar words also\nindicates the importance of phonological processing.\n•\nWord recognition. According to the interactive activation\nmodel,  bottom-up and top-down processes interact during word\nrecognition. The model accounts for the word-superiority effect\nand the effects of orthographic neighbours on word recognition\nbut not for the roles of meaning and sound. Semantic priming can\nfacilitate word recognition “automatically” or in a more controlled\nfashion. More generally, semantic priming reduces the amount of\nvisual information required for word recognition. Words predictable\nwithin the sentence context are processed faster than those less\npredictable. Readers’ predictions are typically general or graded\nrather than specific, which minimises prediction-error costs.\n•\nReading aloud. According to the dual-route model, reading\ninvolves lexical and non-lexical routes (the latter involving\ngrapheme–phoneme conversion rules). Surface dyslexics rely mainly\non the non-lexical route whereas phonological dyslexics use mostly\nthe lexical route.\nThe triangle model consists of orthographic, phonological and\nsemantic systems. The reading of regular or consistent words\ninvolves a pathway from orthography to phonology, whereas\nthe reading of irregular/inconsistent words involves a pathway\nfrom orthography to phonology via semantics. Surface dyslexia\nis attributed to damage within the semantic system, whereas\nphonological dyslexia stems from a general phonological\nimpairment. The triangle model emphasises general processes\nnot specific to reading whereas the dual-route model focuses on\nreading-specific processes. The triangle model provides a more\nadequate account (e.g., the importance it attaches to semantic\nprocessing is well supported).\n•\nReading: eye-movement research. According to the E-Z Reader\nmodel, the completion of familiarity checking of the current word\nis the signal to initiate an eye-movement programme, and the\ncompletion of lexical access is the signal to shift attention covertly\nto the next word. It is a serial processing model in contrast to\nparallel processing models (e.g., SWIFT). The absence of lexical\nparafoveal-on-foveal effects (lexical effects of the next word on\nprocessing of the current word) supports serial models. The E-Z\nReader model is limited because it de-emphasises the processes\ninvolved in word recognition and higher-level reading processes\n(e.g., use of knowledge in text comprehension).\nCreated from usyd on 2022-02-16 03:16:01.",
    "460\nLanguage\nFURTHER READING\nCai, Z.G. & Vigliocco, G. (2018). Word processing. In S. Thompson-Schill (ed.),\nStevens’ Handbook of Experimental Psychology and Cognitive Neuroscience,\nVol. 3: Language and Thought (4th edn; pp. 75–110). New York: Wiley. The\nprocesses involved in processing words presented in text and in speech are\ndiscussed in detail.\nEisner, F. & McQueen, J.M. (2018). Speech perception. In S. Thompson-Schill\n(ed.), Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience,\nVol. 3: Language and Thought (4th edn; pp. 1–46). New York: Wiley. This\nchapter contains a comprehensive account of basic processes involved in speech\nperception.\nGrainger, J. (2018). Orthographic processing: A “mid-level” vision of reading: The\n44th Sir Frederic Bartlett lecture. Quarterly Journal of Experimental Psychology,\n71, 335– 359. Basic processes involved in word recognition and reading are\ndiscussed in detail in this article by Jonathan Grainger.\nNieuwland, M.S. (2019). Do “early” brain responses reveal word form prediction\nduring language comprehension? A critical review. Neuroscience and\nBiobehavioral Reviews, 96, 367–400. Mante Nieuwland discusses how contextual\ninformation is used by readers and listeners.\nPickering, M.J. & Gambi, C. (2018). Predicting while comprehending language:\nA theory and review. Psychological Bulletin, 144, 1002–1044. Martin Pickering\nand Chiara Gambi provide a thorough discussion of research supporting the\ntheoretical assumption that listeners’ speech perception often depends on their\nspeech-production system.\nSchwanenflugel, P.J. & Knapp, N.F. (2016). The Psychology of Reading: Theory\nand Applications. New York: Guilford Press. Paula Schwanenflugel and Nancy\nKnapp provide a comprehensive account of theory and research on reading.\nSnell, J., van Leipsig, S., Grainger, J. & Meeter, M. (2018b). OB1-reader: A model\nof word recognition and eye movements in text reading. Psychological Review,\n125, 969–984. Joshua Snell and colleagues provide a theoretical model of reading\nbased on word-recognition and eye-movement research.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\nINTRODUCTION\nBasic processes involved in the identification of individual words during\nthe initial stages of reading and listening to speech were discussed in\nChapter  9. In this chapter, we discuss how phrases, sentences and entire\ntexts (e.g., stories) are processed and understood during reading and listen-\ning. Sentence comprehension is complex. Neural activity within the brain\nincreases steadily during the reading of a sentence but not with non-word\nlists or meaningless sentences (Fedorenko et  al., 2016). This progressive\nincrease “reflects the increasing complexity of the evolving representation\nof the meaning of the sentence” (Fedorenko et al., 2016, p. E6262).\nThe previous chapter dealt mainly with aspects of language processing\ndiffering between reading and listening to speech. In contrast, higher-level\ncomprehension processes are similar whether a story is listened to or read.\nThe research focus has been on comprehension processes in reading rather\nthan listening and so our emphasis will be on reading. However, what is\ntrue of reading is mostly also true of comprehending speech.\nWhat is the structure of this chapter? We start by considering com-\nprehension at the sentence level and finish by focusing on comprehension\nprocesses with larger language units (e.g., complete texts). More detail is\ngiven below.\nThere are two main levels of analysis in sentence comprehension. First,\nthere is an analysis of the syntactical structure of each sentence. Syntax\ninvolves a study of the rules of word order. Grammar is somewhat broader\nin meaning. It focuses on the structure of a language (especially syntax\nand inflections). Inflections involve modifying nouns or verbs to indicate\ngrammatical changes (e.g., adding -ed to a verb to indicate the past tense).\nSecond, there is an analysis of sentence meaning. The intended meaning\nof a sentence often differs from its literal meaning as in irony, sarcasm or\nmetaphor. For example, someone may say “Don’t overdo it!” when talking\nto a notoriously lazy colleague. The study of intended meaning is prag-\nmatics. The context in which a sentence is spoken can also influence its\nintended meaning. Issues concerning pragmatics are discussed immediately\nafter the section on parsing.\nIn the third section, we consider processes involved when  individuals\nare presented with a text or speech consisting of several or numerous\nChapter\n10\nKEY TERMS\nSyntax\nThe set of rules\nconcerning word order\nto create well-formed\nsentences.\nGrammar\nThe set of rules\ngoverning the structure\nof a language (especially\nsyntax and inflections).\nInflections\nGrammatical changes\nto nouns or verbs (e.g.,\nadding -s to a noun to\nindicate the plural; adding\n-ed to a verb to indicate\nthe past tense).\nCreated from usyd on 2022-02-16 03:16:01.",
    "462\nLanguage\nsentences. Our focus will mainly be on the inferences readers and listeners\ndraw during comprehension. The major theoretical issue is the following:\nwhat determines which inferences are (or are not) drawn during language\ncomprehension?\nIn the fourth section, we consider processing involving larger units\nof language. When we read a text, we typically try to integrate the infor-\nmation within it. Such integration often involves drawing inferences,\nidentifying the main themes in the text, and so on. These integrative pro-\ncesses (and theories put forward to explain them) are discussed in this\nsection.\nPARSING: OVERVIEW\nThis section is devoted to parsing (analysis of the syntactical or gram-\nmatical structure of sentences) plus the processes readers and listeners\nuse to comprehend sentences. Parsing allows readers and listeners “to\nsay who did what to whom (or how, when, and where)” (Traxler, 2014,\np. 605).\nMost parsing research has focused only on the English language. Does\nthis matter? The short answer is “Yes”. Information about grammar can\nbe provided by word order or by inflection (see Glossary). Many languages\n(e.g., Arabic; German; French) are more inflectional than English and thus\nhave a richer morphology (analysis of the morphemes or basic units of\nmeaning within words). Such languages permit greater flexibility of word\norder than English. As a consequence, it has proved easier to develop\ncomputational models of parsing for English than most other languages\n(Tsarfaty et al., 2013).\nSyntax and grammar\nWe can produce an infinite number of grammatically correct sentences in\nany language (this is known as productivity). Linguists (e.g., Chomsky,\n1957) have produced rules explaining the productivity and regularity of\nlanguage. A set of rules focusing on syntax or word order and inflections\nforms a grammar. Ideally, we can use a grammar to decide whether any\ngiven sentence is permissible or unacceptable.\nNumerous sentences are ambiguous. Some are globally ambiguous\nmeaning the entire sentence has two interpretations (e.g., “Kids make nutri-\ntious snacks”). Others are locally ambiguous – various interpretations are\npossible during parsing.\nWhy are so many sentences ambiguous? Language users apply a least\neffort principle because it would be very demanding for speakers and\nwriters to produce only unambiguous sentences (Solé & Seoane, 2015).\nPiantadosi et al. (2012) argued listeners and readers can usually deal with\nsome ambiguity. The context typically provides useful information about\nsentence meaning. In addition, it would be inefficient (and extremely boring\nfor listeners and readers!) if spoken or written language duplicated that\ninformation.\nWhy does much research on parsing use ambiguous sentences? Parsing\ngenerally occurs very rapidly, which makes it hard to study the processes\nKEY TERMS\nParsing\nAnalysing the syntactical\nor grammatical structure\nof sentences.\nMorphology\nThe study of words and\nhow they are formed from\nmorphemes.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n463\ninvolved. Assessing the problems encountered by listeners and readers\nstruggling with ambiguous sentences is revealing about parsing processes.\nProsodic cues\nOne way that listeners work out the syntactic or grammatical structure of\nspoken languages is by using prosodic cues (e.g., stress; intonation; rhythm;\nword duration). When each syllable is spoken in a monotone lacking prosodic\ncues, listeners struggle to understand the speaker (Duffy & Pisoni, 1992).\nThe use of prosodic cues by speakers and writers is discussed in Chapter 11.\nSuppose a spoken sentence contains a prosodic cue (pause) that occurs\nmisleadingly at a place conflicting with its syntactic structure. Pauker et al.\n(2011) found this made the sentence much harder to understand, thus\nshowing the impact of prosodic cues (this study is discussed in more detail\nlater, see p. 466).\nProsodic cues are most valuable with ambiguous spoken sentences.\nConsider the ambiguous sentence, “The old men and women sat on the bench”.\nIf the women are not old, the spoken duration of men will be relatively long\nand the stressed syllable in women will have a steep rise in pitch contour.\nListeners often use prosodic cues very rapidly to facilitate the under-\nstanding of ambiguous sentences. Holzgrefe et  al. (2013) presented word\nstrings such as Mona oder Lena und Lola [Mona or Lena and Lola] auditor-\nily with a pause and other prosodic cues occurring after the word Mona\n(early pause) or Lena (late pause). When the pause came after the word\nLena to indicate it was Mona or Lena as well as Lola, listeners immedi-\nately integrated the prosodic information into their parsing. In a similar\nstudy, Petrone et al. (2017) found parsing was more influenced by pauses\nat phrase boundaries than other prosodic cues (e.g., phrase-final lengthen-\ning: longer sound at the end of a phrase).\nAs Drury et al. (2016, p. 1) pointed out, “Unlike speech, written lan-\nguage does not provide the same wealth of prosodic information”. How\ndo readers cope? According to Fodor’s (1998) implicit prosody hypothesis,\nreaders activate prosodic patterns during silent reading using their “inner\nvoice”.\nSupport for Fodor’s (1998) hypothesis was reported by Steinhauer and\nFriederici (2001), who asked participants to listen to sentences containing\npauses and read sentences containing commas. Event-related potentials\n(ERPs; see Glossary) were similar in both cases suggesting participants\nused their “inner voice” while reading.\nIn a similar reading study, Drury et al. (2016) manipulated the plausi-\nbility of sentences via the presence or absence of commas (e.g., John, said\nMary, was the nicest boy at the party vs John said Mary was the nicest boy\nat the party). The impact of this manipulation on ERPs closely resembled\nthe impact of manipulating pauses with similar spoken sentences in previ-\nous research. These findings are also consistent with the implicit prosody\nhypothesis.\nDirect evidence implicit prosody benefits reading was reported by Calet\net al. (2017). Prosody training (reading with an emphasis on sensitivity to\nprosody) increased reading fluency and comprehension in primary-school\nchildren.\nCreated from usyd on 2022-02-16 03:16:01.",
    "464\nLanguage\nThe effects of prosody are more complex than indicated so far in three\nways. First, we must consider the overall pattern of prosodic phrasing\nwithin a sentence rather than simply what happens at one particular point.\nConsider the following ambiguous sentence:\nI met the daughter (#1) of the colonel (#2) who was on the balcony.\nFrazier et al. (2006) found the interpretation of this sentence depended on\nthe relationship between the phrase boundaries at #1 and #2. Listeners were\nmuch more likely to assume the colonel was on the balcony when the first\nboundary was greater than the second one than when the first boundary\nwas smaller than the second.\nSecond, there is much evidence that individual speakers differ con-\nsiderably in their production of prosody (Cole, 2015). This variability\nmakes it harder for listeners to understand what any given speaker is\nsaying.\nThird, Fodor (1998) assumed implicit prosody in reading (based on\ninner speech) is very similar to explicit or spoken prosody. Research find-\nings supporting this assumption were discussed earlier. However, it is not\nalways supported. Jun (2010) found systematic differences between prosody\ngenerated in silent reading and prosody generated in reading aloud when\nthe text had not been skimmed in advance. Thus, the implicit prosody\nhypothesis may have limited applicability.\nTHEORETICAL APPROACHES: PARSING AND\nPREDICTION\nAn important theoretical issue is to work out when different kinds of infor-\nmation are used during sentence comprehension. Much research on parsing\nconcerns the relationship between syntactic and semantic analysis. There\nare at least four major possibilities:\n(1) Syntactic analysis generally precedes (and influences) semantic\nanalysis.\n(2) Semantic analysis usually occurs prior to syntactic analysis.\n(3) Syntactic and semantic analysis occur at the same time.\n(4) Syntax and semantics are very closely associated and have a hand-in-\nglove relationship (Altmann, personal communication).\nAt the risk of oversimplification, early theories of parsing tended to favour\npossibility (1) above, whereas later ones focus more on the remaining possi-\nbilities (Traxler, 2014).\nThere are more models of parsing than you can shake a stick at.\nHowever, many belong to two categories: (1) two-stage, serial processing\ntheories; (2) one-stage, parallel processing models. The garden-path model\n(Frazier & Rayner, 1982) has been the most influential one in the first cate-\ngory. Its key assumption is that the initial attempt to parse a sentence uses\nonly syntactic information.\nMacDonald et al.’s (1994) constraint-based model has been the most\ninfluential example of a one-stage, parallel processing model. Its key\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n465\nassumption is that all information sources (syntactic; semantic; contextual)\nare used from the outset to construct a syntactic model of each sentence.\nWe initially consider the above two models. After that, we turn to\nalternative models. One of these is the unrestricted race model, which com-\nbines aspects of the garden-path and constraint-based models.\nWe will discover many apparent inconsistencies in research findings on\nparsing. Why is that? Most people are very sensitive to language subtleties.\nAs a result, sentence parsing often varies because of relatively minor differ-\nences in the sentences presented.\nIt has often been assumed in linguistics and cognitive psychology that\nnearly all adult native speakers have fully mastered the grammar of their\nlanguage (Chomsky, 1965), and this assumption is implicit in many theo-\nries and much research.\nIt follows from the above assumption that inaccurate sentence parsing\nreflects deficient processing rather than deficient grammatical knowledge\nand competence. In fact, non-verbal IQ correlates +.46 with grammatical\nknowledge, meaning that many individuals with low non-verbal IQ have\nseverely deficient grammatical knowledge (Dąbrowska, 2018). However,\nresearchers rarely consider deficient grammatical knowledge as a potential\nexplanation for poor parsing performance.\nGarden-path model\nFrazier and Rayner’s (1982) garden-path model was an early theory\nof parsing. It is so-called because readers (and listeners) can be misled\nor “led up the garden path” by ambiguous sentences. A famous (or\nnotorious!) example of such a sentence is “The horse raced past the\nbarn fell”. It is notorious because it is very hard to understand (partly\nbecause such sentences occur exceptionally rarely in naturally produced\nsentences).\nThe model incorporates the following assumptions:\n●\nOnly one syntactical structure is initially considered for any sentence.\n●\nMeaning is not involved in the selection of the initial syntactical\nstructure.\n●\nTwo general principles influence the initial syntactical structure:\nminimal attachment and late closure.\n●\nAccording to the principle of minimal attachment, the structure pro-\nducing the fewest nodes (major parts of a sentence such as noun phrase\nand verb phrase) is preferred.\n●\nThe principle of late closure is that new words encountered in a sen-\ntence are attached to the current phrase or clause if grammatically\npermissible.\n●\nConflict between the above two principles is resolved in favour of the\nminimal attachment principle.\n●\nIf the initial syntactic structure is incompatible with additional\ninformation (e.g., semantic), it is revised during a second processing\nstage.\nCreated from usyd on 2022-02-16 03:16:01.",
    "466\nLanguage\nWhy do readers use the minimal attachment and late closure principles?\nAccording to Clifton et al. (2016, p. 8): they arise “out of the pressure to\ninterpret a sentence as quickly as possible . . . relating new words to phrases\ncurrently in active memory is faster than building new or more complex\nstructures”.\nFindings\nThe relevance of the principle of minimal attachment was shown by Frazier\nand Rayner (1982). Consider the following sentences:\n(1) The girl knew the answer by heart.\n(2) The girl knew the answer was wrong.\nThe minimal attachment principle produces a grammatical structure in\nwhich the answer is treated as the direct object of the verb “knew”. This is\nappropriate only for the first sentence. As predicted, Frazier and Rayner\nfound eye fixations were longer with the second sentence.\nFrazier and Rayner (1982) also showed the importance of the principle\nof late closure. Consider the following sentences:\n(1) Since Jay always jogs a mile it seems like a short distance to him.\n(2) Since Jay always jogs a mile seems like a short distance to him.\nUse of the principle of late closure leads a mile to be included in the first\nclause as the object of jogs. This is appropriate only for the first sentence.\nReaders had very long fixations on the word seems in the second sen-\ntence when it became clear the principle of late closure was not applicable.\nHowever, the second sentence is much easier to read with a comma (a pro-\nsodic cue) after jogs (Rayner et al., 2012).\nAccording to the garden-path model, the syntactic structure of sen-\ntences can often be worked out in the almost complete absence of seman-\ntic information. Supporting evidence comes from patients with semantic\ndementia (a condition involving loss of word meanings; see Glossary and\nChapter 7). Such patients sometimes show essentially intact performance\non tasks involving grammaticality judgements (e.g., Garrard et al., 2004).\nIn a study mentioned earlier, Pauker et  al. (2011) presented listeners\nwith sentences such as the following including prosodic cues (pauses indi-\ncated by #):\n(1) When a bear is approaching the people # the dogs come running.\n(2) When a bear is approaching # the people # the dogs came running.\nAccording to the model, listeners should apply the principle of late closure\nand so find it easy to identify the correct syntactical structure. This was\nfound with sentences such as (1) where the pause’s location coincided with\nthe syntactic structure. In contrast, performance was very poor with sen-\ntences such as (2) because of the misleading pause (e.g. between approach-\ning and people). Thus, listeners’ adherence to the principle of late closure\ncan be greatly disrupted by misleading prosodic cues. Drury et al. (2016),\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n467\nin a study discussed earlier (p. 463), obtained similar findings when readers\nwere presented with ambiguous sentences and commas which indicated (or\nfailed to indicate) the appropriate syntactic structure.\nAccording to the garden-path model, the initial parsing of an ambig-\nuous sentence should be uninfluenced by visual context providing infor-\nmation relevant to the sentence’s interpretation. Coco and Keller (2015)\npresented listeners with ambiguous sentences and with relevant visual\ncontext. Ambiguity resolution within the sentence depended mostly on lin-\nguistic information, which is broadly consistent with the model. However,\nvisual context had more influence on sentence processing than expected by\nthe model.\nFinally, when readers initially construct an incorrect syntactic struc-\nture for a garden-path sentence, the model predicts they should revise it\nin the light of additional information and so typically produce the correct\nsyntactic structure. Findings reported by Qian et al. (2018) are inconsistent\nwith this prediction. Readers were presented with garden-path sentences\nsuch as the following:\nWhile the man hunted, the deer that was brown and graceful ran into\nthe woods.\nThis was followed by the question, Did the man hunt the deer? Readers pro-\nduced numerous incorrect “Yes” responses with such sentences (approxi-\nmately 50% errors). Thus, they often failed to work out the correct syntactic\nstructure.\nEvaluation\nThe model provides a simple and coherent account of parsing. The prin-\nciples of minimal attachment and late closure often influence the selec-\ntion of an initial syntactic structure for sentences. The model is plausible\nin that these two principles reduce processing demands on the reader or\nlistener.\nWhat are the model’s limitations? First, it assumes parsers who dis-\ncover that their initial preferred syntactic structure is incorrect go back to\nsquare one and form an alternative structure. As Kuperberg and Jaeger\n(2016) pointed out, this “all-or-nothing” assumption is simply incorrect.\nMore generally, the model mistakenly assumes initial attempts at parsing\nare inflexible (see below, pp. 468–470).\nSecond, opposed to the model’s assumptions, den Ouden et al. (2016)\nfound syntactic processing typically does not occur in the absence of other\nforms of processing. This conclusion was based on patterns of brain acti-\nvation during the processing of garden-path sentences. Behavioural evi-\ndence discussed shortly indicates that several factors (including misleading\nprosody and prior context) prevent readers and listeners from adhering to\nthe principles of minimal attachment and late closure.\nThird, the model assumes readers will ultimately generate a correct\nsyntactic structure even for complex sentences. However, this is often not\nthe case when sentences are complex and hard to comprehend (e.g., Qian\net al., 2018).\nCreated from usyd on 2022-02-16 03:16:01.",
    "468\nLanguage\nFourth, the model is hard to test. For example, evidence that non-\nsyntactic information is used early in sentence processing seems inconsist-\nent with the model. However, the second stage of parsing (following the\nfirst, syntactic stage) may simply start very rapidly.\nFifth, the model is more applicable to English than other languages.\nFor example, there is a preference for early (rather than late) closure in\nseveral languages (e.g., Spanish; Russian; French) (Harley, 2013). Mandarin\ndiffers from most European languages in having fewer reliable cues to syn-\ntactic structure and a more flexible word order (Huang et al., 2016). Thus,\nprinciples such as those of minimal attachment and late closure are not\ndirectly relevant to Mandarin.\nConstraint-based model\nAccording to MacDonald et  al.’s (1994) constraint-based model, initial\nsentence interpretation depends on multiple information sources (e.g., syn-\ntactic; semantic; general world knowledge) called constraints. These con-\nstraints limit (or constrain) the number of possible interpretations.\nThe model is based on a connectionist architecture (see Chapter 1)\nwhich exhibits learning through experience. It is assumed all relevant\nsources of information are immediately available to the parser. Competing\nanalyses of the current sentence are activated at the same time. The syn-\ntactic structure receiving most support from the various constraints is\nmore activated than other syntactic structures. Confusion occurs if the\ncorrect syntactic structure is less activated than one or more incorrect\nstructures.\nThe processing system uses four language characteristics to resolve sen-\ntence ambiguities:\n(1) Grammatical knowledge constrains possible sentence interpretations.\n(2) The various forms of information associated with any given word are\ntypically not independent of each other.\n(3) A word may be less ambiguous in some ways than in others (e.g.,\nambiguous tense but not grammatical category).\n(4) The various interpretations permissible according to grammatical\nrules generally differ considerably in frequency and probability based\non past experience. The syntactic interpretation most consistent with\nsuch experience is typically selected.\nMacDonald (2013) developed her constraint-based model. She started by\nassuming speakers use various strategies to reduce processing demands on\nthem (see also Chapter 11). Here is one strategy: the speaker can start with\ncommon words and syntactically simple phrases while planning the rest of\nthe utterance. Another strategy is for the speaker to re-use sentence plans –\nthat is, to favour practised and easy sentence plans.\nMacDonald’s (2013) key assumption is that listeners’ comprehension\nprocesses are sensitive to these strategies, which increases their ability to\npredict the speaker’s next utterance. In sum, “Rarer patterns [produced\nby speakers] are more difficult to comprehend than frequent patterns”\n(Momma & Phillips, 2018, p. 236). Momma and Phillips broadened this\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n469\napproach, arguing that a single mechanism is used in parsing by listeners\nand utterances produced by speakers.\nFindings\nAccording to the constraint-based model, several kinds of non-syntactic\ninformation are used very early in sentence processing. In contrast, this\noccurs only after an initial stage of syntactic processing within the garden-\npath model. Much research is more consistent with the constraint-based\nmodel. For example, researchers (e.g., Hagoort et  al., 2004) using event-\nrelated potentials have found sentence processing is influenced very rapidly\nby semantic factors (discussed further later, pp. 475–476).\nThe constraint-based model assumes sentence processing is paral-\nlel whereas the garden-path model assumes it is serial. Cai et  al. (2012)\ncompared the models’ predictions using ambiguous sentences such as the\nfollowing:\nBecause it was John that Ralph threatened the neighbour recorded\ntheir conversation.\nThis sentence is initially ambiguous because it is unclear whether the neigh-\nbour is the subject of the main clause (recorded their conversation: subject\nanalysis) or the object of the preceding verb (threatened: object analysis).\nReaders interpreted the sentence in line with the subject analysis.\nHowever, the object analysis disrupted sentence processing even though it\nwas not adopted. This finding suggests there was parallel processing of the\ntwo analyses as predicted by the constraint-based model.\nAccording to the model, verbs are an important constraint that often\nstrongly influence initial attempts at parsing. The focus has been especially\non verb bias – some verbs (e.g., read ) are associated with two different\nsyntactic structures (but more frequently with one). Consider the following\ntwo sentences:\n(1) The professor read the newspaper had been destroyed.\n(2) The professor read the newspaper during his break.\nThe second sentence is easier to understand because the verb read is gener-\nally followed by a direct object, as in (2). However, it can also be followed\nby an embedded clause, as in (1).\nAccording to the constraint-based model, readers should find it easier\nto resolve ambiguities (and identify the correct syntactic structure) when\nthe sentence structure is consistent with the verb bias. According to the\ngarden-path model, in contrast, verb bias should have no initial effect.\nWilson and Garnsey (2009) studied verb bias in ambiguous sentences.\nAs predicted by the constraint-based model, it took longer to resolve the\nambiguity when the sentence structure was inconsistent with the verb bias.\nThus, readers’ previous experience with verbs immediately influenced sen-\ntence processing.\nFine et  al. (2013) asked participants to read sentences such as the\nfollowing:\nKEY TERM\nVerb bias\nAn imbalance in the\nfrequency with which\na verb is associated\nwith different syntactic\nstructures.\nCreated from usyd on 2022-02-16 03:16:01.",
    "470\nLanguage\n(1) The experienced soldiers warned about the dangers before the mid-\nnight raid.\n(2) The experienced soldiers warned about the dangers conducted the\nmidnight raid.\nBoth sentences are temporarily ambiguous. However, verbs such as warned\nare far more likely to occur as a main verb, as in sentence (1), than as the\nverb in a relative clause, as in sentence (2). Accordingly, readers find it\nmuch easier to process sentences such as (1) than those such as (2).\nFine et al. (2013) used a condition in which 50% of sentences resem-\nbled sentence (1) and 50% resembled sentence (2). Readers rapidly adapted\ntheir syntactic expectations so they increasingly read sentences such as (2)\nwith relative ease. The take-home message is that the initial syntactic struc-\nture considered by readers is flexible and influenced by recent past experi-\nence. This flexibility is entirely consistent with the constraint-based model\nbut not the garden-path model.\nEvaluation\nWhat are the constraint-based model’s strengths? First, it seems efficient\nthat readers and listeners should use all relevant information from the\noutset when working out a sentence’s syntactic structure. As we have seen,\nnon-syntactic factors (e.g., word meaning; verb bias) are often used very\nrapidly.\nSecond, the model predicts much flexibility in parsing because it is\ninfluenced by our past linguistic experience. There is strong support for\nthis prediction (e.g., Fine et al., 2013). Brysbaert and Mitchell (1996) found\nsubstantial individual differences among Dutch readers in their parsing\ndecisions, providing further evidence of flexibility.\nWhat are the model’s limitations? First, its predictions are often impre-\ncise. As Rayner et al. (2012, p. 229) pointed out, “It is difficult . . . to falsify\nthe general claim that parsing is interactive and constraint-based . . . it\ndoes not by itself make any clear predictions about which things actually\nmatter, or how and when they have their influence.”\nSecond, much experimental support for the model consists of findings\nshowing that non-syntactic factors influence early sentence processing.\nSuch findings are clearly consistent with the model. However, some can\nbe accounted for by the garden-path model by assuming the second, non-\nsyntactic, stage of parsing starts very rapidly.\nUnrestricted race model\nVan Gompel et al. (2000) proposed the unrestricted race model combining\naspects of the garden-path and constraint-based models. Here are its main\nassumptions:\n(1) All information sources (semantic + syntactic) are used to identify a\nsyntactic structure (consistent with the constraint-based model).\n(2) All other syntactic structures are ignored unless the favoured syntac-\ntic structure is disconfirmed by subsequent information.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n471\n(3) If the initial syntactic structure is discarded, there is an extensive\nre-analysis to form a new one. This resembles the garden-path model\nin that parsing often involves two distinct stages.\nFindings\nVan Gompel et  al. (2001) compared the unrestricted race model against\nother models. Participants read three kinds of sentences (examples\nprovided):\n(1) Ambiguous sentences: The burglar stabbed only the guy with the\ndagger during the night. (It could be the burglar or the guy who had\nthe dagger).\n(2) Verb-phrase attachment: The burglar stabbed only the dog with\nthe dagger during the night. (Here the burglar stabbed with the\ndagger).\n(3) Noun-phrase attachment: The burglar stabbed only the dog with the\ncollar during the night.\nAccording to the garden-path model, the principle of minimal attach-\nment  means readers should always adopt the verb-phrase analysis. This\nproduces rapid processing of sentences such as (2) but slow process-\ning of sentences such as (3). Ambiguous sentences are processed rapidly\nbecause  the verb-phrase analysis is accept-\nable. According to the constraint-based\ntheory, sentences such as (2) and (3) are\nprocessed rapidly because the word mean-\nings support only the correct interpretation.\nHowever, there will be competition between\nthe two possible interpretations of sentence\n(1) and so processing will be slow.\nWhat actually happened? There was an\nambiguity advantage: ambiguous sentences\nwere processed faster than either of the other\nsentence types (see Figure 10.1). According to\nthe unrestricted race model, readers rapidly\nuse syntactic and semantic information in\nambiguous sentences to form a syntactic\nstructure, and no re-analysis is necessary. In\ncontrast, re-analysis is sometimes required\nwith noun-phrase and verb-phrase sentences.\nMohamed and Clifton (2011) com-\npared the same three models. Participants\nread temporarily ambiguous sentences (e.g.,\nThe second wife will claim the entire family\ninheritance for herself  ). This sentence has\nambiguous (the entire family inheritance) and\ndisambiguating (for herself  ) regions. The sen-\ntence was sometimes preceded by a context\nbiasing the incorrect syntactic structure.\nFigure 10.1\nTotal sentence processing time as a function of sentence\ntype (ambiguous; verb-phrase attachment; noun-phrase\nattachment).\nData from van Gompel et al. (2001). Reprinted with permission of\nElsevier.\nCreated from usyd on 2022-02-16 03:16:01.",
    "472\nLanguage\nWhat do the three models predict? Since the actual syntactic structure\nis the simplest possible, the garden-path model predicts readers will not\nbe slowed down in the ambiguous or disambiguating regions. According\nto the constraint-based theory, both syntactic structures are activated in\nthe ambiguous region, which slows down reading. Readers then select one\nsyntactic structure in the disambiguating region, which also slows reading\ntime. According to the unrestricted race model, reading is not slowed in\nthe ambiguous region because only one syntactic structure is produced.\nHowever, it will often be the incorrect syntactic structure, which slows\nreading in the disambiguating region.\nWhich model was the winner? Reading times in the ambiguous and\ndisambiguating regions were most consistent with the predictions of the\nunrestricted race model.\nAccording to the unrestricted race model, parsing terminates when a\npermissible syntactic structure is produced. Logačev and Vasishth (2016)\nargued that this assumption is too limited because it takes no account of\ntask demands. When they asked readers to construct all possible syntactic\nstructures, there was an ambiguity disadvantage (i.e., ambiguous sentences\nwere processed more slowly than unambiguous ones). This finding is con-\ntrary to the unrestricted race model’s prediction.\nEvaluation\nThe unrestricted race model combines successful features of the garden-path\nand constraint-based models. It is reasonable that all information sources\nare used from the outset, and that the initial syntactic structure is retained\nunless subsequent evidence is inconsistent with it. It differs from most other\nmodels in predicting the surprising finding there can be an ambiguity advan-\ntage in sentence processing.\nWhat are the model’s limitations? First, it assumes readers and listen-\ners typically identify a sentence’s correct syntactic structure. That is by no\nmeans always the case (see below). Second, the model assumes an ambi-\nguity advantage will typically be found. In fact, task conditions determine\nwhether there is an ambiguity advantage or disadvantage.\nGood-enough representations\nUntil recently, nearly all theories of sentence processing (including those\ndiscussed above) assumed the language processor “generates representa-\ntions of the linguistic input that are complete, detailed, and accurate”\n(Ferreira et al., 2002, p. 11). There are two reasons why this assumption is\nincorrect. First, as discussed earlier, many individuals with low non-verbal\nIQs have very limited grammatical knowledge (Dąbrowska, 2018). Second,\nthe good-enough processing approach “emphasises the tendency of the\ncomprehension system to perform superficial analyses of linguistic input,\nwhich sometimes result in inaccurate interpretations” (Ferreira & Lowder,\n2016, p. 218).\nKarimi and Ferreira (2016) proposed a model of comprehension based\non the notion of good-enough representations (see Figure 10.2). It assumes\ntwo routes are used in language processing, both starting at the same time.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n473\nFigure 10.2\nA model of language\nprocessing involving\nheuristic and algorithmic\nroutes.\nFrom Karimi & Ferreira (2016).\nFirst, the heuristic route uses simple, error-prone heuristics (rules of thumb)\nand typically produces a rapid output. This route is “quick and dirty”\nbut has the advantage of involving minimal effort. Second, the algorith-\nmic route is more demanding on resources – it uses strict and well-defined\nsyntactic rules “to compute precise representations for the given linguistic\ninput” (Karimi & Ferreira, 2016, p. 1014).\nWhat are the model’s implications? First, listeners and readers generally\naccept the output of the heuristic route as correct. Comprehenders empha-\nsise heuristic processing because they have limited cognitive resources and\nprocessing time is limited.\nSecond, if the output of the heuristic route is not accepted as correct\n(or listeners and readers strive for high levels of comprehension accuracy),\nalgorithmic processing continues and typically determines the outcome of\nthe comprehension process. Third, individuals with poor comprehension\nskills are less likely than those with good comprehension skills to make\neffective use of algorithmic processing.\nFindings\nAs predicted by the model, comprehension processes are often superficial\nand inaccurate. For example, consider the Moses illusion. When asked\n“How many animals of each sort did Moses put on the ark?”, approximately\n50% of people reply “Two”. In fact, the correct answer is “None” (think\nabout it!). The Moses illusion occurs because of superficial or heuristic\nprocessing. Successful avoidance of the Moses illusion requires more thor-\nough processing to inhibit the outcome of heuristic processing (Raposo &\nMarques, 2013).\nIn similar fashion, Ferreira (2003) found listeners who heard “The\nmouse was eaten by the cheese” sometimes misinterpreted it as meaning the\nmouse ate the cheese! Ferreira argued this was due to a common heuristic\n(the noun-verb-noun or NVN strategy). This involves the assumption that\nthe subject of a sentence is the agent of some action whereas the object is\nHeuristic route\nInterim output\nequilibrium\nAlgorithmic route\nInterim output refned\nif necessary\nTime\nFinal\noutput\nCreated from usyd on 2022-02-16 03:16:01.",
    "474\nLanguage\nthe recipient. We use this heuristic because most English sentences conform\nto this pattern.\nChristianson et al. (2010) argued that listeners in the Ferreira (2003)\nstudy faced a conflict between the syntactic structure of the passive\nsentences and their semantic knowledge of what is typically the case.\nThey found listeners hearing implausible passive sentences (e.g., “The\nangler was caught by the fish”) paid little attention to their syntactic\nstructure.\nSwets et al. (2008) argued readers would engage in increased algorith-\nmic processing if they anticipated detailed (rather than superficial) compre-\nhension questions. Participants read sentences more slowly in the former\ncase (see Figure 10.3). Ambiguous sentences were read more rapidly than\nunambiguous ones when superficial questions were asked (suggesting heu-\nristic processing). However, this ambiguity advantage disappeared when\nmore challenging comprehension questions were anticipated (suggesting\nmore algorithmic processing).\nReliance on heuristic processing can be so great that readers fail to\nrepair their preferred syntactic structure of a sentence even when inade-\nquate. Ferreira and Lowder (2016) discussed studies where readers received\nsentences such as “While Anna bathed the baby played in the crib”. Many\nreaders mistakenly understood this sentence to mean Anna bathed the baby\nand the baby played in the crib. What happened was many readers ini-\ntially assumed Anna bathed the baby and maintained this assumption even\nthough this structure breaks down when they reach the verb played which\nthen has no subject.\nFinally, we consider individual differences. Individuals high in working\nmemory capacity (high intelligence and attentional control; see Glossary)\nanswered comprehension questions about garden-path sentences 70%\nFigure 10.3\nSentence reading times\nas a function of the way\nin which comprehension\nwas assessed: detailed\n(relative clause) questions;\nsuperficial questions on\nall trials; or occasional\nsuperficial questions.\nSample sentence: The\nmaid of the princess who\nscratched herself in public\nwas terribly humiliated.\nFrom Swets et al. (2008). With\nkind permission from Springer\nScience+Business Media.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n475\nof the time. In contrast, the comparable figure for those low in working\nmemory capacity was 50% (chance performance) (MacDonald et al., 1992).\nEvaluation\nSentence comprehension can depend on precise algorithmic processes or\nimprecise heuristic ones. As predicted by the model, language processing\noften uses good-enough representations and so is error-prone. It follows\nfrom the model that language processing should be flexible. As predicted,\nthere is more evidence of algorithmic processing when readers or listen-\ners have high IQ or working memory capacity or when they are expecting\ndetailed comprehension questions.\nWhat are the model’s limitations? First, as Karimi and Ferreira (2016,\np. 1019) admitted, “The nature of the simple rules that guide heuristic pro-\ncessing is unclear”. Second, heuristic processing can involve very limited\nprocessing or top-down semantic processing (e.g., the Moses illusion). It\nis not clear all forms of heuristic processing (especially top-down semantic\nprocessing) are relatively effortless (Koornneef & Reuland, 2016).\nThird, it is often assumed theoretically that re-analysis of ambiguous\nsentences using precise or algorithmic processes reduces misinterpretations.\nAccording to this viewpoint, readers spending the most time processing the\ndisambiguating region of ambiguous sentences should be less likely to mis-\ninterpret them. However, Qian et al. (2018; discussed above, p. 467), found\nthat spending extra time processing the disambiguating region (and so pre-\nsumably engaging in re-analysis) was ineffective when events described in\nthe misinterpretation seemed highly probable.\nFourth, it is assumed within the model that misinterpretations of sen-\ntences such as “The mouse was eaten by the cheese” occur because heuristic\nprocessing produces incorrect syntactic representations. However, there is\nanother possibility. Perhaps listeners/readers typically form correct syntac-\ntic representations with misinterpretations due to memory limitations (i.e.,\nincomplete retrieval of relevant information) (Bader & Meng, 2018). The\ncrucial point is that misinterpretation errors may reflect processes (e.g.,\ninvolving memory) occurring after an initial correct sentence interpretation.\nCognitive neuroscience: event-related potentials\nCognitive neuroscience has enhanced our understanding of parsing and\nsentence comprehension. Since the precise timing of different processes is\nso important, much use has been made of event-related potentials (ERPs;\nsee Glossary). As we will see, semantic information of various kinds is\nactively processed very early on, which is broadly consistent with predic-\ntions from the constraint-based and unrestricted race models. The literature\nis reviewed by Beres (2017).\nThe N400 component in the ERP waveform is of special relevance.\nIt is a negative wave with an onset at 250 ms and peak at 400 ms. The\nN400 to a sentence word is smaller when its meaning matches the sentence\ncontext. Other factors influencing N400 during sentence processing mostly\nrelate to semantic processing. As a result, N400 has often been assumed to\nreflect difficulty with achieving semantic access. However, it is more likely\nCreated from usyd on 2022-02-16 03:16:01.",
    "476\nLanguage\nthat N400 reflects “the input-driven update of a representation of sentence\nmeaning” (Rabovsky et al., 2018, p. 693).\nAs we will see, research within cognitive neuroscience has provided\nevidence for top-down predictive processes in sentence processing. There is\nfurther discussion of such predictive processes with respect to reading and\nspeech perception in Chapter 9.\nFindings\nHow does meaning influence initial sentence processing? The traditional\nview was that initially we process only word meanings with aspects of\nmeaning going beyond the sentence itself (e.g., our world knowledge) pro-\ncessed subsequently. Hagoort et  al. (2004) reported contrary evidence.\nDutch participants read sentences such as the following (critical words are\nin italics):\n(1) The Dutch trains are yellow and very crowded. (This sentence is true).\n(2) The Dutch trains are sour and very crowded. (This sentence is false\nbecause of the meaning of the word “sour”).\n(3) The Dutch trains are white and very crowded. (This sentence is false\nbecause of world knowledge – Dutch trains are yellow).\nAccording to the traditional view, the semantic mismatch in a sentence such\nas (3) should have taken longer to detect than the mismatch in a sentence\nsuch as (2). However, the effects of these different kinds of semantic mis-\nmatch on N400 were very similar (see Figure 10.4).\nWhat do the above findings mean? First, “While reading a sentence,\nthe brain retrieves and integrates word meanings and world knowledge at\nthe same time” (Hagoort et  al., 2004, p. 440). Thus, the traditional view\nthat we process word meaning before information about world knowl-\nedge may be wrong. Second, word meaning and world knowledge are\nboth integrated into the reader’s sentence comprehension within about 400\nms. This suggests sentence processing involves making almost immediate\nFigure 10.4\nThe N400 response to the\ncritical word in a correct\nsentence (“The Dutch trains\nare yellow”: green line), a\nsentence incorrect on the\nbasis of world knowledge\n(“The Dutch trains are\nwhite”: orange line) and a\nsentence incorrect on the\nbasis of word meanings\n(“The Dutch trains are\nsour”: purple line). The\nN400 response was very\nsimilar with both incorrect\nsentences.\nFrom Hagoort et al. (2004).\nReprinted with permission from\nAAAS.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n477\nuse of all relevant information, consistent with MacDonald et al.’s (1994)\nconstraint-based theory.\nThe traditional view also assumed contextual information is processed\nafter information about word meanings. Contrary evidence was reported\nby Nieuwland and van Berkum (2006a, p. 1106) using scenarios such as\nthis one:\nA woman saw a dancing peanut who had a big smile on his face. The\npeanut was singing about a girl he had just met. And judging from\nthe song, the peanut was totally crazy about her. The woman thought\nit was really cute to see the peanut singing and dancing like that. The\npeanut was salted/in love, and by the sound of it, this was definitely\nmutual.\nSome listeners heard “salted ”, which was appropriate in terms of word\nmeanings but inappropriate within the story context. Others heard “in love”,\nwhich was appropriate within the story context but not word meanings. The\nN400 was greater for “salted ” than “in love” because it did not fit the story\ncontext. Thus, contextual information can have a very rapid major impact.\nVan den Brink et al. (2012) argued that listeners take rapid account of\nstereotyped inferences about the speaker. For example, suppose you heard\na woman say “I have a large tattoo on my back”. This would conflict with\nstereotypical views if she had an upper-class accent but not if she had a\nworking-class accent. As predicted, there was a larger N400 to the word\n“tattoo” when spoken in an upper-class accent.\nEvaluation\nBehavioural measures (e.g., time to read a sentence) provide only indirect\nevidence concerning the nature and timing of underlying language pro-\ncesses. In contrast, research using event-related potentials indicates listeners\nmake use of several kinds of information (e.g., context; world knowledge;\nknowledge of the speaker; syntax) very early in processing, before the end\nof each spoken word. Such findings are more supportive of constraint-based\ntheories than the garden-path model.\nHow can we explain the above findings? According to Hagoort (2017,\np. 200),\nVery likely, lexical, semantic and syntactic cues conspire to predict\ncharacteristics of the next anticipated word, including its syntactic and\nsemantic make-up. A mismatch between contextual prediction and the\noutput of bottom-up analysis results in an immediate brain response\nrecruiting additional processing resources for the sake of salvaging the\non-line interpretation process.\nMore research using event-related potentials to assess the extent to which\nreaders/listeners predict upcoming text is discussed in the section entitled\n“Discourse processes: inferences” (see pp. 490–498).\nWhat are the limitations of research in this area? First, most research\nis artificial because sentences are presented word-by-word to stop eye\nCreated from usyd on 2022-02-16 03:16:01.",
    "478\nLanguage\nmovements contaminating the ERPs. Findings are generally similar in\nword-by-word and free reading. However, comprehension is better in free\nreading because it permits regressions (eyes moving backwards in the text)\n(Metzner et al., 2017). These regressions are associated with a P600 effect\n(an ERP component produced by syntactic and semantic violations in the\ntext).\nSecond, much research differs from naturalistic language compre-\nhension in important ways. The latter more often involves processes not\nspecific to language (e.g., relating text to pre-existing knowledge and to\ncontext) whereas the former is generally concerned primarily with language\nprocessing (Hasson et al., 2018).\nThird, a small N400 to a predictable word in a sentence may indicate\nsuccessful prediction. Alternatively, however, it might also indicate easy\nintegration of that word into the developing sentence meaning.\nPRAGMATICS\nPragmatics is concerned with practical language use and comprehension.\nIt relates to the intended rather than literal meaning expressed by speak-\ners and understood by listeners and often involves drawing inferences. For\nexample, we assume someone who says “The weather’s really great!”, when\nit has been raining non-stop for several days, actually thinks the weather is\nterrible. Pragmatics is also important when readers comprehend text.\nPragmatics is “meaning minus semantics”. Suppose someone says\nsomething in an unfamiliar language. Using a dictionary would partly\nclarify what the speaker intended to communicate. Most of what the dic-\ntionary (plus knowledge of the language’s grammatical structure) fails to\ntell you about the speaker’s intended meaning lies within the field of prag-\nmatics. A full understanding of intended meaning generally requires taking\naccount of contextual information (e.g., the speaker’s tone; the speaker’s\nrelevant behaviour; the current environment).\nAn important area within pragmatics is figurative language (language\nnot intended to be taken literally). Metaphor is figurative language where\na word or phrase is used figuratively to mean something it resembles (e.g.,\n“Time is a thief”). There is also irony where the intended meaning differs\nsubstantially from the literal meaning. Here is an example from the film\nDr Strangelove: “Gentlemen, you can’t fight in here! This is the War Room.”\nThere are also idioms, which are common figurative expressions (e.g., “kick\nthe bucket”.\nBohrn et al. (2012) carried out a meta-analysis (see Glossary) compar-\ning brain activation with figurative and literal language processing. There\nwere two main findings:\n(1) Figurative language processing involves essentially the same brain\nnetwork as literal processing.\n(2) Several areas in (and close) to the inferior frontal gyrus (BA45/36/47/13)\n(especially in the left hemisphere) were more activated during figu-\nrative than literal language processing. Häuser et  al. (2016) applied\nrepetitive transcranial magnetic stimulation (rTMS; see Glossary)\nto part of this network (BA45), which they hypothesised provides\nKEY TERMS\nPragmatics\nThe study of the ways\nlanguage is used and\nunderstood in the\nreal world including\na consideration of its\nintended meaning; in\ngeneral, the impact of\ncontextual factors on\nmeaning.\nFigurative language\nLanguage that is not\nintended to be taken\nliterally; examples include\nmetaphor, irony and\nidiom.\nAutism spectrum\ndisorder (ASD)\nA disorder involving\ndifficulties in social\ninteraction and\ncommunication and\nrepetitive patterns of\nbehaviour and thinking.\nCentral coherence\nThe ability to make use of\nall the information when\ninterpreting an utterance\nor situation.\nAsperger syndrome\nAn autism spectrum\ndisorder involving\nproblems with social\ncommunication in spite\nof at least average\nintelligence and no delays\nin language development.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n479\ncognitive control to resolve semantic conflicts. As predicted, rTMS\nimpaired the processing of idioms involving maximal semantic con-\nflict between literal and idiomatic meanings.\nIN THE REAL WORLD: AUTISTIC SPECTRUM DISORDERS AND\nPRAGMATICS\nWe can see the importance of pragmatics by studying individuals who have difficulty in distin-\nguishing between literal and intended meanings. For example, individuals with autism spectrum\ndisorder (ASD) are poor at understanding others’ intentions and beliefs and so find social com-\nmunication very hard. They also have weak central coherence (the ability to integrate information\nfrom different sources). It follows that individuals with autism spectrum disorder should have severe\nproblems understanding the intended meanings of figurative language.\nMuch evidence has been obtained from individuals with Asperger syndrome (relatively mild\nASD). Children with Asperger’s often develop language normally but have impaired pragmatic\nlanguage comprehension (see Volden, 2017, for a review). For example, Kaland et al. (2005) found\nthey were deficient at drawing inferences when presented with jokes, white lies, figurative lan-\nguage or irony. Here is an example involving irony:\nAnn’s mother has spent a long time cooking Ann’s favourite meal: fish and chips. But when she\nbrings it to Ann, she is watching TV, and she doesn’t even say thank you. Ann’s mother is cross\nand says, “Well, that’s very nice, isn’t it! That is what I call politeness!”\nIndividuals with Asperger syndrome were less able than healthy controls to explain why Ann’s\nmother said what she did. This illustrates their general inability to understand what other people\nare thinking. Of importance, Asperger’s individuals were comparable to controls when drawing\ninferences not requiring social understanding.\nLoukusa et  al. (2018) extended the findings of Kaland et  al. (2005). Two factors were jointly\nresponsible for the impaired ability of children with ASD to draw correct pragmatic inferences\nduring comprehension. First, they had problems taking account of the context. Second, they found\nit hard to infer someone’s thoughts and feelings from what that person said. The deficit in correct\npragmatic inferences by ASD children went from 25% when only context was important to 48%\nwhen someone’s else thoughts and feeling were also important.\nAs mentioned already, deficient pragmatic language comprehension in individuals with Asperger\nsyndrome is partly due to weak central coherence. Zalla et al. (2014) asked participants to decide\nwhether a speaker’s compliments to another person were literal or ironic. Healthy controls correctly\nrecognised a speaker was being ironic if they had a sarcastic/ironic occupation (e.g., comedian;\nchat show host). In contrast, individuals with Asperger’s typically ignored information about the\nspeaker’s occupation.\nLanguage impairments in autism spectrum disorder are not always specific to pragmatic lan-\nguage. Whyte and Nelson (2015) found children with ASD also had poorer knowledge of syntax\nand vocabulary. These language deficits mostly explained their impaired pragmatic language\ncomprehension.\nIn sum, individuals with ASD have impaired pragmatic language comprehension especially when\nthey need to take account of context and someone else’s thoughts and feelings. Their great diffi-\nculty in inferring others’ intentions and motivations from what they say and how they behave plays\na significant role in restricting their social horizons.\nCreated from usyd on 2022-02-16 03:16:01.",
    "480\nLanguage\nFigurative language: metaphors\nThe central problem readers (and listeners) have with metaphors is that\nthey have separate literal and non-literal or metaphorical meanings. For\nexample, consider the unfamiliar metaphor “My mother says envy is rust”\n(George & Wiley, 2016). The reader (or listener) has to ignore the relatively\nmeaningless literal meaning and identify the metaphorical meaning (i.e.,\nenvy is like rust because it is corrosive). Olkoniemi et al. (2016) obtained\nevidence suggesting that metaphor comprehension can be relatively\ndemanding. Readers low in working memory capacity (associated with low\nintelligence; see Glossary) required more processing time to comprehend\nmetaphors.\nTheoretical approaches to metaphor comprehension are reviewed in\ndetail by Holyoak and Stamenković (2018). According to the traditional\nstandard pragmatic model (e.g., Grice, 1975), three sequential stages are\ninvolved in processing metaphorical and other figurative statements:\n(1) the literal meaning is accessed;\n(2) the reader or listener decides whether the literal meaning makes sense\nin the current context;\n(3) if the literal meaning is inadequate, there is a search for a suitable\nnon-literal meaning.\nThis model is oversimplified. Suppose we ask people to decide whether\nsentences are literally true or false. According to the model, they should\nnot access the figurative meanings of metaphors on this task and so should\nrespond rapidly. However, that is not the case. Chouinard et  al. (2018)\nfound participants took longer to decide whether metaphorical sentences\nwere literally true or false than when judging control sentences (literally\nfalse; scrambled metaphor, e.g., “Some cats are ribbons”; see Figure 10.5).\nThis is the metaphor interference effect.\nWhy is the metaphor interference effect important? As Chouinard\net al. (2018, p. 14) concluded, it shows “metaphorical and literal meanings\nare generated automatically and simultaneously during comprehension”.\n(a) 1550\n2280\n2260\n2240\n2220\n2200\n2180\n2160\n2140\n2120\n2100\n2080\n* ++\n1500\n1450\n1400\n1350\n1300\nLF\nSM\nSentence type\nMilliseconds\nMilliseconds\nM\n(b)\n*\n*\nLF\nSM\nSentence type\nM\nFigure 10.5\nResponse times for literally\nfalse (LF), scrambled\nmetaphor (SM) and\nmetaphor (M) sentences in\n(a) written and (b) spoken\nconditions.\nFrom Chouinard et al. (2018).\nKEY TERMS\nMetaphor interference\neffect\nThe finding that it takes\nlonger to judge whether\nmetaphorical sentences\nare literally true or false\nthan control sentences.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n481\nSeveral theorists (e.g., Barsalou, 2012) have argued that sensory experi-\nence is relevant to the processing of metaphors and other forms of  language\n(see Chapter 7). Lacey et  al. (2017) tested this viewpoint. Participants\nwere presented with metaphorical (e.g., “He had to foot the bill”) and literal\n(e.g., “He had to pay the bill”). All the metaphorical sentences referred to\nbody parts. The key finding was that brain areas responsive to images\nof body parts were activated only by the metaphorical sentences. These\nfindings indicate that comprehension of metaphors can be perceptually\ngrounded.\nPredication model\nKintsch (2000) proposed a predication model of metaphor comprehension\ninvolving two components:\n(1) The latent semantic analysis component: this represents word mean-\nings based on their relations with other words. Kintsch (2000) spec-\nulated that metaphor comprehension is facilitated when both nouns\nin a metaphor (e.g., “Lawyers are sharks”) have strong semantic rela-\ntionships to numerous other words because that facilitates the task of\nestablishing connections between them.\n(2) The construction-integration component: this uses information from the\nfirst component to construct interpretations of statements. Consider\nthe statement “Lawyers are sharks”. It has an argument (lawyers) and\na predicate or assertion (sharks). This component selects predicate\nfeatures relevant to the argument (e.g., vicious; aggressive) and inhibits\nirrelevant predicate features (e.g., have fins; swim).\nWolff and Gentner (2011) agreed with Kintsch (2000) that metaphors\ninvolve a directional process with information from the argument (e.g.,\nlawyers) being projected on to the predicate (e.g., sharks). However,\nthey also argued this directional process is preceded by a non-directional\nprocess identifying commonalities in meaning between the argument and\npredicate.\nFindings\nThe non-reversibility of metaphors is an important phenomenon. For\nexample, “My surgeon is a butcher” means something very different to “My\nbutcher is a surgeon”. Kintsch’s (2000) model explains non-reversibility by\nassuming only those features of the predicate (second noun) relevant to the\nargument (first noun) are selected. Thus, changing the argument changes\nthe features selected.\nSuppose we try to understand a metaphor such as “My lawyer was a\nshark”. According to Kintsch’s model, this should be harder to understand\nwhen literal properties of sharks (e.g., can swim) irrelevant to its metaphor-\nical meaning have recently been activated. McGlone and Manfredi (2001)\nfound (as predicted by the model) that the above metaphor took longer to\nunderstand when preceded by a contextual sentence emphasising the literal\nmeaning of shark (e.g., “Sharks can swim”).\nCreated from usyd on 2022-02-16 03:16:01.",
    "482\nLanguage\nFigure 10.6\nMean reaction times to\nverify metaphor-relevant\n(REL) and metaphor-\nirrelevant (IRR) properties.\nFrom Solomon & Thompson-\nSchill (2017). Reprinted with\npermission of Elsevier.\nAccording to the predication model, understanding metaphors\ninvolves inhibiting the semantic properties of the predicate irrelevant to the\nargument. Solomon and Thompson-Schill (2017) tested this assumption.\nParticipants saw metaphors (e.g., “The prisoners are sardines”) and literal\nsentences (e.g., “The fish are sardines”). After that, participants decided\nwhether a metaphor-relevant property (e.g., canned) or metaphor- irrelevant\nproperty (e.g., salty) was true of the last word in the sentence (e.g., sar-\ndines). Participants verified object properties more slowly following a met-\naphorical sentence (the MET condition in Figure 10.6) compared to a\nliteral one (the LIT condition in Figure 10.6). Thus, participants inhibited\nmetaphor- irrelevant information while reading metaphorical sentences.\nCarriedo et al. (2016) investigated the effects of individual differences\nin inhibitory processes on metaphor comprehension. As predicted, indi-\nviduals having superior inhibitory processes exhibit the best metaphor\ncomprehension.\nAccording to Kintsch (2000), metaphor comprehension should be\ngreater when both nouns in a metaphor are similar in meaning to numer-\nous other words. However, Al-Azary and Buchanan (2017) obtained the\nopposite findings. They speculated that the activation of numerous seman-\ntically similar words might make it harder to find shared meanings between\nthe two nouns.\nAccording to Wolff and Gentner (2011), initial processing of meta-\nphors involves a non-directional process focusing on finding overlapping\nmeanings between the argument and predicate. This process is the same\nwhether participants see forward metaphors (e.g., Some giraffes are sky-\nscrapers) or reversed metaphors (e.g., Some skyscrapers are giraffes). It\nfollows that rated comprehensibility should be the same for forward and\nreversed metaphors if participants must respond rapidly. In contrast, com-\nprehensibility rating should be much higher for forward than reversed met-\naphors if participants have sufficient time for thorough processing. The\npredicted findings were obtained (see Figure 10.7).\n1400\n1300\nProperty-verifcation RT (ms)\n1200\n1100\n1000\nLIT\nIRR\n**\nREL\nMET\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n483\nFigure 10.7\nMean proportion\nof statements rated\ncomprehensible with a\nresponse deadline of 500\nor 1,600 ms. There were\nfour statement types:\nliteral; forward metaphors;\nreversed metaphors; and\nscrambled metaphors.\nFrom Wolff and Gentner (2011).\nEvaluation\nWhat are the strengths of research in this area? First, it has been established\nthat metaphor processing depends on many factors, including the listener’s\nlanguage ability, the familiarity of the metaphor, and the listener’s goal\n(e.g., understanding a metaphor; judging its appropriateness in context)\n(Gibbs, 2013). Second, findings indicate that literal and metaphorical mean-\nings are processed simultaneously. Third, inhibitory processes play a key\nrole in diminishing the impact of irrelevant information. Fourth, metaphor\ncomprehension involves a non-directional process followed by a directional\none.\nWhat are the limitations of research in this area? First, insufficient\nattention has been paid to possible processing differences between different\ntypes of metaphors. For example, we can distinguish between “A is B”\nmetaphors and correlation metaphors (Gibbs, 2013). “Lawyers are sharks”\nis an example of the former whereas “My research is off to a great start” is\nan example of the latter. Kintsch’s (2000) prediction model is more appli-\ncable to the former type of metaphor than the latter.\nSecond, most research has not distinguished clearly between novel\nand familiar metaphors. George and Wiley (2016) found participants took\nlonger to think of interpretations of novel than familiar metaphors (7.6\nseconds vs 4.9 seconds, respectively). Of importance, inhibitory processes\nwere used less often with familiar metaphors, perhaps because overall\nprocessing demands were much less.\nCreated from usyd on 2022-02-16 03:16:01.",
    "484\nLanguage\nCommon ground\nGrice (1975) argued that speakers and listeners generally conform to the\ncooperative principle – they work together to ensure mutual understand-\ning. Of direct, relevance, speakers and listeners need to take account of the\ncommon ground, which “describes a body of information that people alleg-\nedly share” (Cowley and Harvey, 2016, p. 56). Listeners expect speakers to\nrefer mostly to information and knowledge that falls in the common ground\nand often experience difficulties if that is not the case. The extent to which\nthat expectation is correct is discussed in Chapter 11 (see pp.   544–547).\nNote that a major goal of conversation is to extend the common ground\nbetween those involved (Brown-Schmidt & Heller, 2014).\nKeysar et  al. (2000) accepted listeners would benefit from using the\ncommon ground existing between them and the speaker. However, this\ncan be very effortful for listeners, and so they generally resort to a rapid\nand non-effortful egocentric heuristic. The egocentric heuristic is “a ten-\ndency to consider as potential referents objects that are not in the common\nground, but are potential referents from one’s own perspective” (Keysar\net al., 2000, p. 32). Use of the egocentric heuristic will often cause listeners\nto misunderstand the speaker’s message. Accordingly, Keysar argued that\nlisteners sometimes follow use of the egocentric heuristic with an effortful\nprocess of trying to adopt the speaker’s perspective.\nSeveral theorists (e.g., Bezuidenhout, 2014) have disagreed that lis-\nteners typically make use of the egocentric heuristic. Instead, they argue\nlisteners generally take account of the common ground very early in pro-\ncessing. Heller et al. (2016) claimed it is simplistic to assume listeners adopt\na single perspective (egocentric or that of the common ground). Instead,\nlisteners use both perspectives simultaneously.\nFindings\nIn Keysar’s research (e.g., Keysar et al., 2000), listeners often used the ego-\ncentric heuristic and ignored the common ground. However, many studies\n(e.g., Heller et al., 2016, discussed shortly) have found the opposite. How\ncan we resolve these inconsistencies? Dębska and Rączaszek-Leonardi\n(2018) argued that Keysar’s approach was biased. Suppose listeners were\ninstructed to “Put the small candle . . .” from an array containing three\ncandles (big, medium and small). The candle hidden from the speaker was\nalways the smallest one. Thus, one reason why listeners used the egocentric\nheuristic by selecting the smallest candle was because it was the one best\ndescribed by the instructions.\nDębska and Rączaszek-Leonardi (2018) tested the above ideas by\nusing a set-up resembling that of Keysar. Listeners showed less evidence of\nthe egocentric heuristic when the object hidden from the speaker was not\nthe one best described by the instructions.\nHeller et  al. (2016) tested the various theories mentioned earlier.\nFigure  10.8 illustrates their four conditions viewing the display from the\nlistener’s perspective when the task was to move the big candle (inside the\nwhite oval). In the baseline conditions, all four objects were in common\nground. In the crucial privileged conditions, one object was visible only to\nKEY TERMS\nCommon ground\nShared knowledge\nand beliefs possessed\nby a speaker and a\nlistener; its use facilitates\ncommunication.\nEgocentric heuristic\nA strategy used by\nlisteners in which they\ninterpret what they hear\nbased on their own\nknowledge rather than\nknowledge shared with\nthe speaker.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n485\nFigure 10.8\nSample displays seen from\nthe listener’s perspective;\ninstructions were to “pick\nup the big candle”; the\ntarget is within the white\noval.\nFrom Heller et al. (2016).\nReprinted with permission of\nElsevier.\nthe listener. In the pairs conditions, two pairs of objects differed in size,\nand in the triplet conditions, three similar objects differed in size and there\nwas also a completely different object. Eye-tracking assessed listeners’\nattentional focus.\nWhat would we predict for the crucial privileged conditions? We start\nwith the privileged triplet condition. If listeners used the egocentric heuris-\ntic, they would mistakenly focus on the candle the speaker could not see\n(bottom left). If they used common ground information, in contrast, they\nwould focus on the larger of the two candles the speaker could see (bottom\nright). There was some evidence for the egocentric heuristic because listen-\ners focused to some extent on the candle the speaker could not see (privi-\nleged big candle; see Figure 10.9). However, common ground information\nwas also used – listeners consistently fixated the target rapidly and to a\nmuch greater extent than any other object.\nThe privileged triplet condition is biased to elicit the egocentric heuris-\ntic in that the object only the listener could see fitted the speaker’s instruc-\ntions better than the intended target. This is not the case in the privileged\npairs condition. In this condition, use of the egocentric heuristic would lead\nto equal fixations on the big funnel and the big candle (the target) when the\nspeaker has said “Pick up the big . . .”, but has not yet said “candle”. In con-\ntrast, use of the common ground would cause fixations to be allocated to\nthe big candle rather than the big funnel before the speaker says “candle”.\nIn the privileged pairs condition, listeners used the common ground –\nthey attended more to the big candle than the big funnel faster than in the\nCreated from usyd on 2022-02-16 03:16:01.",
    "486\nLanguage\nFigure 10.9\nProportion of fixation on\nthe four objects over time;\n0 ms = onset of adjective\n“big” and the shaded area\ncovers processing of the\nadjective.\nFrom Heller et al. (2016).\nReprinted with permission of\nElsevier.\nbaseline conditions (200 ms after the adjective “big” was presented versus\n350 ms). However, there was some evidence of the egocentric heuristic  –\nlisteners had some fixations on the object only they could see (i.e., the\nsmall funnel) and also on the irrelevant big funnel.\nIn sum, Heller et al.’s (2016) findings indicate that listeners rapidly use\ncommon ground. Of greatest importance, their findings are most consistent\nwith the theory that listeners make simultaneous use of an egocentric per-\nspective and common ground.\nSuppose listeners who were given a task resembling the privileged\ntriplet condition in Heller et  al.’s (2016) study performed a demanding\nsecond task at the same time. According to Keysar et al.’s (2000) theory,\nthis should increase their use of the egocentric heuristic (compared to a\ncontrol condition with an undemanding second task) because they would\nlack the processing resources to make use of the common ground. Lin et al.\n(2010) carried out a study along those lines and obtained the predicted\nfindings. Cane et al. (2018) obtained similar findings using the demanding\ntask of remembering a sequence of five digits.\nLuk et  al. (2012) studied cultural differences in use of the egocentric\nheuristic. Chinese–English bilinguals were primed to focus on the Chinese\nor American culture. Only 5% of those focusing on the Chinese culture\nused the egocentric heuristic on a listening task compared to 45% focusing\non the American culture. These findings are consistent with the common\nTriplet\n0.9\nBig candle (target)\nSmall candle\nSmall funnel\nBig funnel (competitor)\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nProportions of fxations\nBaseline\n–200\n–100\n100\n200\n300\n400\n500\nTime (ms) after ADJ onset\n600\n700\n800\n900\n1000\n1100\n1200\n0\nPairs\n0.9\nBig candle (target)\nMedium candle\nFunnel\nSmall candle\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nProportions of fxations\n–200\n–100\n100\n200\n300\n400\n500\nTime (ms) after ADJ onset\n600\n700\n800\n900\n1000\n1100\n1200\n0\n0.9\nBig candle (target)\nSmall candle\nSmall funnel (PRIVILEGED)\nBig funnel (competitor)\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nProportions of fxations\nPrivileged\n–200\n–100\n100\n200\n300\n400\n500\nTime (ms) after ADJ onset\n600\n700\n800\n900\n1000\n1100\n1200\n0\n0.9\nMedium candle (target)\nSmall candle\nFunnel\nPRIVILEGED big candle\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nProportions of fxations\n–200\n–100\n100\n200\n300\n400\n500\nTime (ms) after ADJ onset\n600\n700\n800\n900\n1000\n1100\n1200\n0\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n487\nassumption that Western cultures are more individualistic and self-focused\nthan Eastern cultures (which are more collectivistic and group-centred).\nMost research has focused only on whether specific pieces of infor-\nmation are in common ground. This ignores the potential richness of\ncommon ground representations, which can include cultural and commu-\nnity information shared by speaker and listener. Brown-Schmidt (2012)\nused a task where two individuals worked together to move various game\npieces. Their interactive discussions led to the formation and maintenance\nof rich common ground representations. Brown-Schmidt also found that\nthe assumption that a given piece of information is or is not in common\nground between a speaker and listener is oversimplified. In fact, a given\npiece of information can be in common ground to a greater or lesser\nextent.\nNearly all research in this area is limited because speakers and  listeners\nare strangers to each other. We might assume friends share more common\nground than strangers and so rely less on the egocentric heuristic. However,\nSavitsky et  al. (2011) obtained the opposite finding because friends over-\nestimated how well they communicated with each other.\nEvaluation\nThe evidence suggests listeners make simultaneous use of both their egocen-\ntric perspective and common ground. However, several factors influence\nthe relative importance of these two perspectives. First, the egocentric per-\nspective is used more often when the object hidden from the speaker is the\none best described by the instructions. Second, the egocentric perspective is\nmore frequent when listeners have limited processing resources avail able.\nSecond, it is used more often in Western cultures than in Eastern ones.\nThird, the egocentric perspective may be used more often by listeners when\nthe speaker is a friend of theirs rather than a stranger.\nWhat are the limitations of research in this area? First, most research\nhas focused on very specific aspects of common ground. Second, findings\nfrom listener–speaker pairs who are strangers may not generalise to pairs\nwho are friends. Third, many studies lack ecological validity (see Glossary):\nit is rare in everyday life for an object between two individuals to be visible\nto the listener but not to the speaker.\nFourth, in most research, the participants act only as listeners. In\ncontrast, real-life conversations involve rapid switching between listening\nand speaking. In such situations, it is often useful for listeners to focus on\ninformation available only to them (and thus not in the common ground)\nso they can communicate it to the other person (Mozuraitis et al., 2015).\nINDIVIDUAL DIFFERENCES: WORKING MEMORY\nCAPACITY\nThere are considerable individual differences in almost all complex cogni-\ntive activities. Accordingly, theories based on the assumption (explicit or\nimplicit) that everyone comprehends text similarly are oversimplified. What\nare the most important individual differences influencing reading perfor-\nmance? Just and Carpenter (1992) emphasised individual differences in\nCreated from usyd on 2022-02-16 03:16:01.",
    "488\nLanguage\nworking memory capacity (the ability to process and store information at\nthe same time) (see Glossary and Chapter 6).\nEngle and Kane (2004) proposed an influential theory according to\nwhich individuals with high working memory capacity have superior\nexecutive attention or attentional control than low-capacity individ-\nuals. This manifests itself in the superior monitoring of task goals and\nthe ability to resolve response competition. It follows that high-capacity\nindividuals should have less mind-wandering (task-unrelated thoughts)\nthan low-capacity ones while engaged in reading comprehension. As\npredicted, Unsworth and McMillan (2013) found high-capacity individ-\nuals had superior reading comprehension partly because of their reduced\nmind-wandering.\nThere are two key theoretical issues relating to the effects of working\nmemory capacity on reading comprehension. First, we can focus on rel-\natively specific individual differences in working memory capacity (e.g.,\nverbal working memory involving simultaneous processing and storage of\nverbal information). An example is reading span (see Glossary).\nAlternatively, we can focus on general individual differences in working\nmemory capacity (working memory involving simultaneous processing and\nstorage of different kinds of information). An example is operation span\nIN THE REAL WORLD: UNDERSTANDING NON-NATIVE SPEAKERS\nAs Ryskin et al. (2018, p. 141) pointed out, “Everyday language use occurs amid myriad sources of\nnoise”. For example, non-native speakers may make errors because of deficient knowledge of the\nlanguage including numerous mispronunciations when engaged in conversation (Levis & Barriuso,\n2011). In such circumstances, listeners have to infer the intended meaning from what is actually said.\nHow do we cope when trying to understand what a non-native speaker is saying? A crucial part\nof the answer was provided by Lev-Ari (2014) in a study where a native speaker of Mandarin or of\nEnglish gave instructions in English to native English speakers. Listeners to the non-native speaker\nincreased their reliance on top-down processes (e.g., predicting what the speaker would say next)\nand reduced their reliance on what the speaker said. This strategy is entirely appropriate given the\nlower language competence of the non-native speaker.\nGibson et al. (2017) also found listeners relied less on the actual words spoken by non-native\nspeakers and focused more on the intended meaning. Native and non-native speakers produced\nmany utterances, some of which were implausible (e.g., “The tax law benefitted from the busi-\nnessman”). Listeners were more likely to interpret such implausible utterances as plausible (e.g.,\n“The businessman benefited from the tax law”) when spoken by a non-native speaker. This makes\nsense given the assumption that non-native speakers are more likely to put words in the wrong\norder.\nSuppose a listener is exposed to the utterances of a non-native speaker whose errors consist\nmainly of deletions (e.g., “We had nice time at the beach”) or insertions (e.g., “The earthquake\nshattered from the house”). Listeners might simply assume in both cases that the speaker makes\nmany errors across the board. Alternatively, they might assume the speaker only has a high proba-\nbility of making specific speech errors (e.g., deletions or insertions). Ryskin et al. (2018) found that\nlisteners’ inferences about the speaker’s intended meaning were influenced by the specific errors\nthey had heard previously. Thus, listeners are sensitive to fine-grained information about the types\nof errors made by speakers.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n489\nwhich involves numerical processing and verbal storage (see Glossary). Are\nspecific or general aspects of working memory capacity more important in\npredicting reading comprehension?\nSecond, there are two possible types of explanation for positive cor-\nrelations between working memory capacity and reading comprehension.\nJust and Carpenter (1992) assumed there was a direct relationship: indi-\nviduals with low working memory capacity have more limited processing\nresources than high-capacity individuals and this directly impairs their\nreading comprehension. Alternatively, there may be an indirect relation-\nship: the effects of working memory capacity on reading comprehension\nmay occur because it correlates with other reading-relevant factors (e.g.,\nvocabulary; reading experience).\nWhy does it matter whether the relationship is direct or indirect? In\nessence, if the relationship between working memory capacity and reading\nis indirect, it implies factors other than working memory capacity itself are\nprimarily responsible for its effects on reading performance.\nFindings\nPeng et  al. (2018) reported a meta-analytic review based on 197 studies.\nOverall, they reported a correlation of +.29 between working memory\ncapacity and reading. Measures of general working memory capacity cor-\nrelated +.26 with reading comprehension. Among specific measures, the\ncorrelation between verbal working memory capacity and reading was\nsomewhat higher (+.32). Thus, general and specific individual differences\nin working memory capacity are both important predictors of reading\nperformance.\nPeng et  al. (2018) also addressed the issue whether the effects of\nworking memory capacity on reading comprehension are direct or indirect.\nMore specifically, two factors they considered were vocabulary size and\ndecoding (“the ability to translate written language into speech with accu-\nracy and/or fluency”, p. 52). They obtained evidence for indirect effects:\nworking memory capacity influenced reading comprehension via its effects\non vocabulary and decoding.\nFreed et al. (2017) also considered whether the effects on reading com-\nprehension of working memory capacity are direct or indirect. They dis-\ncovered the relationship between working memory capacity and reading\ncomprehension was indirect. It depended on two factors: language experi-\nence (e.g., reading habits) and general reasoning ability or fluid intelligence\n(see Glossary).\nEvaluation\nTheoretical approaches such as that of Just and Carpenter (1992) have the\nadvantage over most language theories in emphasising the importance of\nindividual differences. In contrast, as Kidd et al. (2018, p. 154) pointed out,\nmost theorists regard large individual differences in language comprehen-\nsion as “an inconvenient truth” which they ignore or de-emphasise.\nIndividual differences in working memory capacity correlate moder-\nately highly with measures of reading comprehension. This is so whether\nCreated from usyd on 2022-02-16 03:16:01.",
    "490\nLanguage\nworking memory capacity is assessed by relatively specific measures (e.g.,\nverbal working memory) or more general ones. Other research suggest-\ning the importance of working memory capacity is discussed in the next\nsection (see p. 494).\nWhat are the limitations of research in this area? First,\nWe have a huge literature . . . that has focused on the role of WMC\n[working memory capacity] in language processing, based on the\nassumption that WMC has a unique and direct effect on comprehen-\nsion. However, only one major study has found such an effect.\n(Freed et al., 2017, p. 137)\nSecond, and related to the first point, much more research is required to\nclarify the interrelationships between the numerous individual difference\nvariables correlating with reading comprehension. For example, Van Dyke\net  al. (2014) found IQ correlated +.61 with working memory capacity,\nand that much of the relationship between working memory capacity and\nreading comprehension depended on IQ.\nDISCOURSE PROCESSING: INFERENCES\nSo far we have focused primarily on comprehension of single sentences.\nIn real life, however, we mostly encounter connected discourse (speech\nor written speech at least several sentences long). Single sentences and dis-\ncourse differ in various ways. First, single sentences are more likely to be\nambiguous because they lack the context provided by previous sentences\nwithin discourse. Second, discourse processing typically requires inference\ndrawing for full comprehension.\nWe draw numerous inferences when exposed to discourse (even though\nwe are generally unaware of doing so). Why is so much inference drawing\nrequired? Readers and listeners would be bored to tears if writers and\nspeakers spelled everything out in incredible detail.\nTest your skill at inference drawing with this example taken from\nRumelhart and Ortony (1977):\nMary heard the ice-cream van coming.\nShe remembered the pocket money.\nShe rushed into the house.\nYou probably inferred that Mary wanted to buy some ice cream, that\nbuying ice cream costs money, that Mary had some pocket money in the\nhouse, and that Mary had only limited time to get hold of some money\nbefore the ice-cream van appeared. None of these inferences is explicitly\nstated.\nThere are several types of inference. First, logical inferences depend\nonly on the meanings of words. For example, we infer that a widow is\nfemale. Second, bridging inferences establish coherence between the\ncurrent part of the text and the preceding text and so are also known as\nbackward inferences.\nKEY TERMS\nDiscourse\nLanguage that is a\nminimum of several\nsentences in length; it\nincludes written text and\nconnected speech.\nLogical inferences\nInferences that follow\nnecessarily from the\nmeanings of word (e.g., a\nbachelor is a man who is\nunmarried).\nBridging inferences\nInferences or conclusions\ndrawn to increase\ncoherence between the\ncurrent and preceding\nparts of a text; also known\nas backward inferences.\nResearch activity:\nText comprehension\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n491\nThird, elaborative inferences embellish or add details to the text by\nusing world knowledge to expand on textual information. Predictive infer-\nences (or forward inferences) are an important form of elaborative infer-\nence. Predictive inferences “allow readers to generate expectations about\nwhat will happen next in a text” (Virtue et al., 2017, p. 456). It is hard to\nwork out how we typically access relevant information from our huge store\nof world knowledge when forming elaborative inferences.\nThe differences between bridging and elaborative inferences are\nnot  always clear-cut. Consider the following scenario (Kuperberg et  al.,\n2011):\nJill had very fair skin.\nShe forgot to put sunscreen on.\nShe had sunburn on Monday.\nWhen readers read the second sentence, they could draw the elaborative\ninference that Jill had sunburn. When they read the third sentence, they\ncould draw the bridging or backward inference that the sunburn has\nresulted from forgetting to put on sunscreen.\nTheoretical perspectives\nReaders (and listeners) typically draw logical and bridging inferences,\nwhich are generally required for full comprehension. However, the number\nand nature of elaborative inferences (including predictive inferences) drawn\nremain controversial.\nBransford et  al. (1972) in their constructionist approach argued\nreaders typically construct a fairly complete “mental model” of the situ-\nation described in a text. They assumed numerous elaborative inferences\nare drawn during reading even when not essential for comprehension.\nSeveral theories of discourse comprehension (including the construction-\nintegration model, the event-indexing model, and the event-segmentation\ntheory) involve very similar assumptions (see the later section entitled\n“Discourse comprehension: theoretical approaches”, pp. 498–510).\nMcKoon and Ratcliff’s (1992) minimalist hypothesis (developed by\nGerrig and O’Brien, 2005) assumes far fewer inferences are drawn than\ndoes Bransford et al.’s (1972) constructionist approach. This hypothesis is\nbased on the following assumptions:\n●\nInferences are automatic or strategic (goal-directed).\n●\nSome automatic inferences establish local coherence (two or three sen-\ntences making sense on their own or in combination with easily avail-\nable general knowledge). These inferences involve parts of the text in\nworking memory at the same time.\n●\nOther automatic inferences rely on information readily available\nbecause it is explicitly stated in the text.\n●\nStrategic inferences are formed in pursuit of the reader’s goals; they\nsometimes serve to produce local coherence.\n●\nMost elaborative inferences are made at recall rather than during\nreading.\nKEY TERMS\nElaborative inferences\nInferences based on our\nknowledge of the world\nthat involve adding details\nto a text that is being read\n(or speech being listened\nto).\nPredictive inferences\nExpectations concerning\nwhat will happen next\n(e.g., a new event) when\nreading text or listening\nto someone.\nMental model\nAn internal representation\nof some possible situation\nor event in the world\nhaving the same structure\nas that situation or event.\nResearch activity:\nInferences\nCreated from usyd on 2022-02-16 03:16:01.",
    "492\nLanguage\nFigure 10.10\nA theoretical framework\nfor reading comprehension\ninvolving interacting\npassive and reader-initiated\nprocesses.\nFrom van den Broek and Helder\n(2017).\nIn sum, memory-based theories (e.g., minimalist hypothesis) “rely on a\npassive and dumb [memory] activation mechanism” (Cook & O’Brien,\n2017, p. 2). In contrast, explanation-based theories (e.g., constructionist\napproach) “assume more interaction between basic memory mechanisms\nand reader goals and strategies” (Cook & O’Brien, 2017, p. 2).\nVan den Broek and Helder (2017) provided a theoretical framework\ncombining elements of previous theories (see Figure 10.10). First, there are\npassive “automatic” processes outside the reader’s conscious control which\nalways occur. These processes resemble those assumed within the minimal-\nist hypothesis.\nSecond, there are effortful reader-initiated processes. The extent of\nsuch processes depends on the reader’s standards of coherence: “the criteria\nthat a reader has for what constitutes adequate comprehension and coher-\nence in a particular reading situation” (p. 364). For example, if a reader’s\ngoal includes a search after meaning, they will use more reader-initiated\nprocesses and draw more inferences than if that goal is missing (Graesser\net al., 1994). These processes correspond to those assumed within the con-\nstructionist approach.\nThe central prediction from the above theoretical framework is as\nfollows:\nWhen the passive processes alone yield adequate comprehension by\nattaining the reader’s standards of coherence, then no further pro-\ncessing is necessary. However, if passive processes alone lead to com-\nprehension falling short of satisfying the reader’s standards, then\nreader-initiated, coherence-building processes are likely.\n(van den Broek & Helder, 2017, p. 364)\nResearch relevant to the various theoretical approaches discussed above is\ndiscussed later (pp. 494–497).\nPassive\nStandards\nof\ncoherence?\nMental representation\nof the text\nYes\nNo\nReader-initiated\nProcesses\nContinue\nreading\nProduct\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n493\nBridging inferences: anaphors\nAn anaphor is a word (e.g., pronoun) referring back to a person or object\npreviously mentioned in a text or speech. Anaphor resolution is a very\ncommon form of bridging inference. Here is an example:\nFred sold John his lawn mower, and then he sold him his garden hose.\nIt requires a bridging inference to realise the referent for “he” is Fred rather\nthan John.\nHow do readers/listeners draw appropriate anaphoric inferences?\nGender information can be very helpful. Compare ease of anaphor resolu-\ntion with the following sentence compared to the one above:\nJuliet sold John her lawn mower, and then she sold him her garden hose.\nAnaphor resolution is also facilitated by having pronouns in the expected\norder. Harley (2013) provided the following example:\n(1) Vlad sold Dirk his broomstick because he hated it.\n(2) Vlad sold Dirk his broomstick because he needed it.\nThe first sentence is easy to understand because “he” refers to the first-\nnamed man (i.e., Vlad). The second sentence is harder to understand\nbecause “he” refers to the second-named man (i.e., Dirk).\nAnother factor influencing anaphor resolution is working memory\ncapacity (see Glossary). Nieuwland and van Berkum (2006b) presented\nsentences containing pronouns whose referents were ambiguous. Readers\nhigh in working memory capacity were more likely to take account of both\npossible referents.\nWhen pronouns have only a single possible referent, it has often\nbeen assumed readers “automatically” identify the correct one. Love and\nMcKoon (2011) obtained support for this assumption only when readers\nwere highly engaged with the text.\nMost findings are consistent with Kaiser et al.’s (2009) assumption that\nanaphor resolution involves multiple constraints (e.g., gender; meaning)\noperating interactively in parallel. Itzhak and Baum (2015) studied one\nsuch constraint (i.e., verb bias) as in the following example:\n(1) John envied Bill because he was rich.\n(2) John envied Bill because he was poor.\nSentence (1) is easier to comprehend than sentence (2) because we expect\nthe pronoun he to refer to Bill.\nItzhak and Baum (2015) argued anaphor resolution would be easier\nwith sentence (2) if the referent of he (i.e., John) were emphasised when the\nsentence was spoken. That is what they found, thus showing an interaction\nbetween verb bias and noun emphasis.\nKEY TERM\nAnaphor\nA word or phrase that\nrefers back to a previous\nword or phrase (e.g., a\npronoun may refer back\nto a given individual\nmentioned earlier).\nCreated from usyd on 2022-02-16 03:16:01.",
    "494\nLanguage\nBridging inferences: more complex inferences\nCausal inferences are a common form of bridging inference. They require\nreaders to work out the causal relationship between the current sentence\nand a previous one. Consider the following two sentences:\nKen drove to London yesterday.\nThe car kept overheating.\nYou had no trouble (hopefully!) in linking these sentences based on the\nassumption that Ken drove to London in a car that kept overheating.\nThe above bridging inference may occur because the verb drove in\nthe first sentence activated concepts relating to driving (especially car).\nAlternatively, readers may form a representation of the situation described\nin the first sentence and then relate information in the second sentence to\nit. The crucial difference is that the sentential context is only relevant with\nthe second explanation.\nGarrod and Terras (2000) identified two stages in forming bridging\ninferences. The first stage is bonding, a low-level process involving the auto-\nmatic activation of words from the preceding sentence (explanation one).\nThe second stage is resolution, which ensures the overall interpretation is\nconsistent with the contextual information (explanation two). Resolution is\ninfluenced by context but bonding is not.\nAccording to the minimalist hypothesis and van den Broek and\nHelder’s (2017) theoretical framework, the reader’s goals influence which\ninferences are drawn. Calvo et al. (2006) gave some participants the goal\nof reading sentences for comprehension whereas others were explicitly told\nto anticipate what might happen next. Participants in the latter condition\ndrew more predictive inferences. Even when participants in the former con-\ndition drew predictive inferences, they did so more slowly than those in the\nanticipation condition.\nEarlier (see pp. 488–490), we discussed how individual differences in\nworking memory capacity influence language comprehension. Such indi-\nvidual differences also influence inference drawing. Barreyro et  al. (2012)\nfound readers with high working memory capacity drew more elaborative\ncausal inferences than did low-capacity readers. Of relevance, there is a\nmoderately high correlation between working memory capacity and IQ\n(intelligence). However, Christopher et al. (2012) found working memory\ncapacity still predicted comprehension performance after controlling for\nintelligence.\nMurray and Burke (2003) focused on predictive inferences (e.g., infer-\nring break when presented with a sentence such as The angry husband threw\nthe fragile vase against the wall. Only participants with high reading skill\ndrew such inferences “automatically’. In general, individuals with poor\nreading skills draw fewer inferences than those with good reading skills\nMcKoon & Ratcliff, 2017).\nIn sum, research on individual differences in inference drawing and\ncomprehension ability is important. Any adequate theory of language com-\nprehension (or inference drawing) must provide an explanation for such\nindividual differences.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n495\nFindings: underlying processes\nThe minimalist hypothesis and van den Broek and Helder’s (2017) theoreti-\ncal framework are consistent with the assumption that predictive inferences\ncan be drawn automatically. This issue was addressed by Gras et al. (2012)\nusing short texts such as the following:\nCharlotte was having her breakfast on the terrace when the bees\nstarted flying about the pot of jam. She made a movement to brush\nthem away but one of them succeeded in landing on her arm.\nThe predictive inference is that Charlotte felt a sting.\nGras et  al. (2012) followed the text with the word sting presented in\nblue, red or green 350, 750 or 1,000 milliseconds after the text with instruc-\ntions to name the colour. The speed of colour naming was slowed only at\nIN THE REAL WORLD: ANXIETY AND INFERENCE DRAWING\nSo far we have focused on factors determining whether readers draw inferences. It is also impor-\ntant (but relatively neglected) to consider which inferences are drawn when we read or listen to\ndiscourse. For example, suppose we present individuals high and low in trait anxiety (see Glossary)\nwith ambiguous sentences such as the following:\nWith hardly any visibility, the plane quickly approached the dangerous mountain and, at the\nsame time, the passengers began to shout in panic. The plane . . .\nWe might expect that high-anxious individuals would be more likely than low-anxious ones to be\nbiased towards the negative or threatening predictive inference (i.e., the plane crashed). Calvo\nand Castillo (2001) tested this expectation. After reading the sentence above, participants were\npresented with the word “crashed” or “swerved” and named it rapidly.\nWhat did Calvo and Castillo (2001) find? When the time interval between “The plane . . .” and\nthe word was 1,500 ms, high-anxious individuals named the word “crashed” faster than low-\nanxious ones and named the word “swerved” slower. Thus, high-anxious individuals were more\nlikely to draw the threatening inference and less likely to draw the non-threatening one. This\ngroup difference disappeared when the time interval was less than 1,500 ms, suggesting the bias\nin predictive inferencing shown by high-anxious individuals did not depend on rapid “automatic”\nprocesses.\nMoser et al. (2012) obtained similar findings among individuals meeting criteria for social anxiety\ndisorder (involving extreme fear and avoidance of social situations). They heard ambiguous sen-\ntence stems resolved by a negative or positive final word. Event-related potentials indicated that\nsocially anxious listeners expected (or predicted) the negative completion more than non-anxious\nlisteners.\nDo anxious individuals draw negative inferences from all ambiguous situations? Walsh et  al.\n(2015; see Chapter 15) addressed that issue using four kinds of ambiguous text scenarios: (1)\nsocial (potential threat of social embarrassment); (2) intellectual (potential threat of appearing unin-\ntelligent); (3) health (potential threat of severe illness; and (4) physical (potential threat of physical\ndanger). High-anxious individuals drew more negative inferences than low-anxious ones only with\nthe social and intellectual scenarios. This pattern of inference drawing indicates that high-anxious\nindividuals are especially sensitive to situations involving social evaluation.\nCreated from usyd on 2022-02-16 03:16:01.",
    "496\nLanguage\nFigure 10.11\nReaction times to name\ncolours when the word\npresented in colour was\npredictable from the\npreceding text compared to\na control condition (scores\nbelow 0 ms indicate a\nslowing effect of predictive\ninferences). Performance in\nthe explicit condition is not\nrelevant here.\nFrom Gras et al. (2012). ©\nAmerican Psychological\nAssociation.\n1,000 milliseconds (see Figure 10.11). This finding suggests it took approxi-\nmately 1 second for the predictive inference to be drawn. The fact that par-\nticipants could not prevent it from interfering with colour naming suggests\nit was drawn automatically.\nKuperberg et al. (2011) also investigated the “automaticity” of infer-\nence drawing using short scenarios such as one discussed earlier:\nJill had very fair skin.\nShe forgot to put sunscreen on.\nShe had sunburn on Monday.\nKuperberg et  al. recorded event-related potentials to assess readers’ pro-\ncessing of these scenarios. Of particular interest was the N400 component\nwhich is larger when the meaning of the word currently being processed\ndoes not match its context.\nWhat did Kuperberg et  al. (2011) find? Consider the above scenario\nwhere the word sunburn in the third sentence is highly causally related\nto its context. There was only a small N400 to this word. Thus, process-\ning of the causal inference explaining Jill’s sunburn in terms of her fair\nskin and failure to use sunscreen started very rapidly and probably fairly\n“automatically”.\nKuperberg et  al. (2011) also focused on complex causal inferences\nusing short scenarios such as the following:\nJill had very fair skin.\nShe usually remembered to wear sunscreen.\nShe had sunburn on Monday.\nThere was a small N400 to the word sunburn, but it was not as small\nas in the previous case. Thus, some inference processing is initiated\nvery rapidly (and probably “automatically’) even with complex causal\ninferences.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n497\nIn spite of the above findings, there are circumstances where few\ninferences are drawn via “automatic” or passive processes. For example,\nCollins and Daniel (2018) studied trained speed readers whose reading rate\nwas 35% faster than that of untrained readers. These speed readers did not\nappear to draw bridging or predictive inferences even when such inferences\nwere strongly implied by the text.\nFinally, listeners’ stereotypical inferences about the speaker can influ-\nence sentence processing. For example, there was a large N400 when the\nsentence “I have a large tattoo on my back” was spoken in an upper-class\naccent (Van den Brink et al., 2012; discussed earlier, p. 477). Thus, listen-\ners rapidly draw inferences about the kinds of statement a given speaker is\nlikely (or unlikely) to make.\nOverall evaluation\nThere is an increasing consensus on several issues:\n(1) Readers (and listeners) typically form bridging inferences (including\ncausal inferences) to make coherent sense of text or speech.\n(2) Readers and listeners rapidly use contextual information and their\nworld knowledge to draw inferences.\n(3) Many inferences (including causal and predictive ones) are often\ndrawn relatively “automatically”. However, the extent to which this\nhappens depends on various factors (e.g., working memory capacity;\nengagement with the text; reading speed).\n(4) Readers’ goals influence whether predictive inferences are drawn.\n(5) Readers with superior reading skills (including those having high\nworking memory capacity) draw more inferences than other readers.\n(6) The major theories contribute to our understanding of inference\ndrawing:\nThe minimalist hypothesis is probably correct when the reader\nis very quickly reading the text, when the text lacks global\ncoherence, and when the reader has very little background\nknowledge. The constructionist theory is on the mark when\nthe reader is attempting to comprehend the text for enjoyment\nor mastery at a more leisurely pace.\n(Graesser et al., 1997, p. 183)\nThus, inference drawing is very flexible. This flexibility is captured by\nvan den Broek and Helder’s (2017) theoretical framework allowing\nfor both passive and reader-initiated processes.\nWhat are the limitations of theory and research in this area? First, it is\noften hard to predict which inferences will be drawn because inference\ndrawing depends on several interacting factors (e.g., readers’ goals and\nreading ability). Second, it is also hard to predict which inferences will be\ndrawn because of theoretical imprecision. For example, it is assumed within\nthe minimalist hypothesis that automatic inferences are drawn if the nec-\nessary information is “readily available”. How do we establish the precise\ndegree of availability of some piece of information? Third, the notion that\nCreated from usyd on 2022-02-16 03:16:01.",
    "498\nLanguage\ninference drawing depends on two processes (passive and reader-initiated:\nvan den Broek & Helder, 2017) is oversimplified. Fourth, we need more\nresearch on individual differences in which inferences are drawn with ambig-\nuous material.\nDISCOURSE COMPREHENSION: THEORETICAL\nAPPROACHES\nIf someone asks us to describe a story or book we have read recently, we\ndiscuss the main events and themes omitting the minor details. Thus, our\ndescription is highly selective based on the meaning extracted from the story\nwhile reading it and on selective processes operating at retrieval. Imagine\nour questioner’s reaction if our description was not selective but simply\ninvolved recalling random sentences from the story!\nGomulicki (1956) demonstrated the selectivity of story comprehension\nand memory. Some participants wrote a précis (summary) of a story visible\nin front of them whereas others recalled the story from memory. Still other\nparticipants, who were provided only with each précis and recall, had great\ndifficulty in telling them apart. Thus, story memory resembles a précis in\nfocusing primarily on important information.\nSeveral factors determine the importance of story information. For\nexample, statements causally connected to several other statements are judged\nas more important than those lacking such causal connections (Trabasso &\nSperry, 1985). Other factors are discussed later.\nNearly all comprehension research has presented readers with paper-\nbased texts. In the real world, however, readers increase use e-readers or\ncomputers (e.g., when accessing information from the internet). Margolin\net al. (2013) found comprehension was comparable for paper, e-reader, and\ncomputer presentation for both narrative (telling a story) and expository\ntexts (conveying facts and information).\nHowever, comprehension and learning are often reduced when texts\nare presented on a computer screen rather than on paper (Sidi et al., 2016).\nWhy is this? First, readers engage in more multi-tasking and discontinuous\nreading on screen. Second, screen readers tend to be more confident than\npaper readers about their levels of comprehension and learning. Third, in\nspite of this overconfidence, screen readers perform comparably to paper\nreaders in conditions emphasising the importance of deep processing (e.g.,\nhigh perceived task importance) (Sidi et al., 2017).\nBelow we discuss several theories or models of discourse comprehen-\nsion starting with Bartlett’s (1932) influential schema-based approach.\nNumerous theories have been put proposed over the past 35 years or so\n(see McNamara and Magliano, 2009, for a review) and a few of the most\nprominent ones will be considered.\nSchema theory: Bartlett\nOur processing of texts involves relating textual information to relevant\nstructured knowledge stored in long-term memory. What we process in\ntexts, how we process textual information, and what we remember about\ntexts we have read all depend heavily on such previously stored information.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n499\nMuch stored knowledge consists of schemas (well-integrated packets\nof knowledge about the world, events, people and actions; see Chapter\n7). Schemas include scripts and frames. Scripts (see Glossary) deal with\nknowledge about events and consequences of events whereas frames are\nknowledge structures referring to some aspect of the world (e.g., buildings).\nGhosh and Gilboa (2014) argued schemas possess four necessary and\nsufficient features:\n(1) associative structure: schemas consist of interconnected units;\n(2) basis in multiple episodes: schemas consist of integrated information\nbased on several similar events;\n(3) lack of unit detail: this follows from the variability of events from\nwhich any given schema is formed;\n(4) adaptability: schemas change and adapt as they are updated in the\nlight of new information.\nSeveral definitions of “schema” have been proposed. For example, Bartlett\n(1932) attached great importance to adaptability. Of interest, this is prob-\nably the feature least often found in recent definitions.\nWhy are schemas important? First, they contain relevant information\nneeded to understand what we hear and read. Second, schemas allow us to\nform expectations (e.g., of the sequence of events in a restaurant) that are\ngenerally confirmed, which makes the world relatively predictable. Third,\nschemas contain higher-level information (based on commonalities across\nevents) making it easier to disregard trivial details during comprehension.\nBartlett (1932) claimed persuasively that schemas strongly influence\nhow we remember texts. More specifically, comprehension of (and memory\nfor) texts depends on top-down processes triggered by schemas. He tested\nthis hypothesis by presenting people with stories from a different culture to\nproduce a conflict between the story itself and their prior knowledge. He\nfound that what was remembered might be inaccurate because it included\nschematic knowledge not included in the story. Bartlett identified three\nmain error types:\n(1)\nrationalisation (making recall more consistent with the reader’s cul-\ntural expectations);\n(2) levelling (omitting unfamiliar details);\n(3) sharpening (elaborating on certain details).\nThe above errors might result from processes occurring during comprehen-\nsion or retrieval. Bartlett (1932) favoured the latter explanation but others\n(e.g., Bransford & Johnson, 1972) emphasise comprehension processes.\nNote that Henderson (1903) anticipated many of Bartlett’s theoretical ideas\n(Davis, 2018).\nFindings\nBartlett (1932) used stories (e.g., “The War of the Ghosts”) from the North\nAmerican Indian culture. Unfortunately, his studies were poorly controlled\n(Roediger, 2010). For example, he did not provide specific instructions:\nKEY TERM\nRationalisation\nIn Bartlett’s theory, errors\nin story recall that conform\nto the rememberer’s\ncultural expectations.\nCase study:\nBartlett\nCreated from usyd on 2022-02-16 03:16:01.",
    "500\nLanguage\n“I thought it best . . . to try to influence the subjects’ procedure as little\nas possible” (Bartlett, 1932, p. 78). As a result, many distortions observed\nby Bartlett were due to conscious guessing rather than deficient memory.\nGauld and Stephenson (1967) found instructions stressing the need for\naccurate recall (designed to reduce deliberate guessing) eliminated almost\nhalf the errors obtained using Bartlett’s original instructions.\nBartlett (1932) claimed discourse or text information shows more\nrapid forgetting than schematic knowledge. Thus, the tendency for sche-\nmatic knowledge to produce memory distortions should increase over time.\nSulin and Dooling (1974) obtained support for this prediction. Participants\nreceived a story about a ruthless dictator identified as Gerald Martin or\nAdolf Hitler. It was assumed those told it concerned Hitler would activate\ntheir schematic knowledge of him. There was a recognition memory test\nat a short- or long-retention interval including the sentence “He hated the\nJews particularly and so persecuted them”. As predicted, participants told\nthe story was about Hitler were much more likely to falsely recognise the\nabove Hitler-relevant sentence at the long- rather than the short retention\ninterval.\nStrong evidence that memory distortions increase over time was\nreported by Bergman and Roediger (1999). Their participants read “The\nWar of the Ghosts” and then recalled it three times. The proportion of\nrecall involving major distortions increased from 27% at the shortest reten-\ntion interval (15 minutes) to 59% at the longest (6 months).\nBartlett (1932) argued that schemas influence retrieval as well as com-\nprehension. Supporting evidence was reported by Anderson and Pichert\n(1978). Participants read a story from the perspective of a burglar or a\npotential homebuyer. After story recall, they recalled the story again from\nthe alternative perspective (or schema). This time, participants recalled\nmore information important only to the second perspective than on the\nfirst recall. Anderson et  al. (1983) found that manipulating the reader’s\nperspective while reading selectively enhanced encoding and comprehen-\nsion of schema-relevant story information.\nBransford and Johnson (1972) also found schemas influence story\ncomprehension. Here is part of the story they used:\nThe procedure is quite simple. First, you arrange items into different\ngroups. Of course one pile may be sufficient depending on how much\nthere is to do. If you have to go somewhere else due to lack of facilities\nthat is the next step; otherwise, you are pretty well set. It is important\nnot to overdo things. That is, it is better to do too few things at once\nthan too many.\nWhat on earth was that all about? Listeners hearing the passage in the\nabsence of a title rated it as incomprehensible and recalled only 2.8 idea\nunits on average. However, listeners supplied beforehand with the title\n“Washing clothes” found it easy to understand and recalled 5.8 idea units on\naverage. Having relevant schema information (i.e., the title) helped passage\ncomprehension rather than simply acting as a retrieval cue –  participants\nreceiving the title after hearing the passage but before recall recalled only\n2.6 idea units on average.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n501\nResearch in cognitive neuroscience has established that the ventro-\nmedial prefrontal cortex plays a key role in schema processing (Gilboa\n& Marlatte, 2017; see Chapter 7). Van Kesteren et  al. (2010) studied the\ninvolvement of the ventromedial prefrontal cortex during comprehen-\nsion. Viewers watched a film with the first half providing a schema for\nthe second half. Activation in the ventromedial prefrontal cortex during\nviewing of the second half depended on whether the first half was pre-\nsented in the typical sequential order (providing a strong schema) or out of\norder (providing a weak schema). Activation was greater when there was\na weak schema because it was harder to integrate new information with\nschematic information.\nEvaluation\nSchematic knowledge assists text comprehension and memory. In addition,\nmany distortions in memory for stories and other texts reflect the influ-\nence of schematic information. More generally, schema theory emphasises\nthe role of top-down processes in discourse comprehension and memory\n(Wagoner, 2013).\nWhat are the limitations of schema theories? First, “schema” has many\ndefinitions (Ghosh & Gilboa, 2014) and it is hard to ascertain the precise\ninformation contained within any given schema. Second, schema-based\nexplanations require independent evidence of the existence of relevant\nschemas, but this is usually lacking. As Harley (2013) pointed out, “The\nprimary accusation against schema and script-based approaches is that\nthey are nothing more than re-descriptions of the data.”\nThird, it is unclear when a given schema will be activated. Theoretically,\nschemas facilitate inference drawing during text comprehension, but many\ninferences are not drawn. In contrast, the phrase “the five-hour journey from\nLondon to New York” activates the “plane flight schema” even though no\nwords in the phrase have strong associations with flying by plane (Harley,\n2013).\nFourth, schema theories exaggerate how error prone we are in every-\nday life. For example, Wynn and Logie (1998) found students recalled\n“real-life” events experienced during their first week at university reason-\nably accurately up to six months later.\nFifth, Bartlett (1932) argued that schemas exert their influence at\nretrieval rather than during comprehension. In fact, schemas often also\ninfluence comprehension processes.\nKintsch’s construction-integration model\nKintsch’s views on language comprehension have been very influential.\nIn his well-known construction-integration model, Kintsch (1988, 1998)\ncombined elements of schema-based theories and Johnson-Laird’s mental\nmodel approach (see Chapter 14). Here are the model’s main assumptions\n(see Figure 10.12):\n(1) Readers turn text sentences in the text into propositions (true or false\nstatements) representing their meaning.\nKEY TERM\nProposition\nA statement making an\nassertion or denial which\ncan be true or false.\nCreated from usyd on 2022-02-16 03:16:01.",
    "502\nLanguage\n(2) The propositions constructed from the text are stored briefly along\nwith associatively related propositions (e.g., inferences). At this stage,\nmany irrelevant propositions are stored.\n(3) Spreading activation (see Glossary) selects propositions for the text\nrepresentation. In this integration process, clusters of highly inter-\nconnected propositions attract most activation and have the great-\nest probability of inclusion in the text representation. Within the text\nrepresentation, it is hard to distinguish between propositions based\ndirectly on the text and those based on inferences.\n(4) As a result of the above processes, three levels of text representation\ncan be constructed:\n(i)    surface representation (the text itself);\n(ii)      propositional representation or textbase (propositions formed\nfrom the text);\n(iii)  situation representation (a mental model describing the situ-\nation referred to in the text) – this is the only representation\ndepending mostly on the integration process.\nThe construction-integration model sounds rather (very?) complex.\nHowever, its major assumptions are straightforward. The initial construc-\ntion of many propositions involves relatively inefficient processes with\nmany irrelevant propositions being included. At this stage, context pro-\nvided by the overall theme of the text is ignored. After that, the integration\nprocess uses contextual information from the text to weed out irrelevant\npropositions.\nWhat is the relationship between schemas (as proposed by Bartlett,\n1932) and situation models? Schemas are abstract and very general whereas\nsituation models are more specific. However, schemas are often used as the\nbuilding blocks from which situation models are formed.\nFigure 10.12\nThe construction-integration\nmodel.\nAdapted from Kintsch (1992).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n503\nFigure 10.13\nForgetting functions for\nsituation, proposition and\nsurface information over a\n4-day period.\nAdapted from Kintsch et al.\n(1990).\nHow does the construction-integration model differ from schema\ntheory? Schema theory emphasises top-down processes in discourse com-\nprehension and memory. This differs substantially from the construction-\nintegration model: “During the construction phase, the text input launches\na dumb bottom-up process in the reader’s knowledge base . . . top-down\nfactors, such as reading perspective or reading goal, exert their influence at\nthe integration phase” (Kaakinen & Hyönä, 2007, p. 1323).\nFindings\nKintsch et  al. (1990) tested the assumption that text processing produces\nthree levels of representation. Participants read brief descriptions of various\nsituations and their recognition memory was tested immediately or at times\nranging up to four days later. As predicted, forgetting was fastest for the\nleast complete representation (i.e., the surface representation) and there\nwas no forgetting for the most complete representation (i.e., the situation\nmodel).\nMore evidence for the existence of three levels of representation was\nreported by Karlsson et  al. (2018). They asked children aged 9 to 11 to\nthink aloud while reading texts. Some children (literal readers) stayed close\nto the text and produced a surface level understanding. Other children\n(paraphrasing readers) focused on the meaning of the text and produced a\ntextbase understanding. Finally, some children (elaborating readers) made\nuse of background knowledge and produced a situation model of the text.\nAs predicted, comprehension ability was greatest in elaborating readers\nand least in literal readers.\nNguyen and McDaniel (2016) increased the extent to which some\nreaders formed a situation model from a text by given them instructions to\nreduce gaps in their situation model. Readers given those instructions had\nhigher comprehension levels than those not given them.\nAnother prediction is that readers should often find it hard to discrim-\ninate between text information and inferences drawn from the text. As we\nsaw earlier, that prediction has received much support.\nCreated from usyd on 2022-02-16 03:16:01.",
    "504\nLanguage\nKaakinen and Hyönä (2007) disputed the model’s assumption that\nthe reader’s goal in reading influences the integration stage rather than the\nconstruction stage. In their study, participants read a text discussing four\nrare diseases. They were asked to assume a close friend had been diagnosed\nwith one of them and they had to inform the friends they had in common\nabout that disease. These instructions influenced the construction stage of\ncomprehension – readers focused primarily on sentences relating to their\nfriend’s disease.\nAccording to the model, text information is linked with general world\nor semantic knowledge before contextual information from the rest of the\ntext. Cook and Myers (2004) tested this assumption using various passages.\nHere is an excerpt from one passage:\nThe movie was a small independent film with a low budget and small\nstaff, so everyone involved had to take on extra jobs and responsibilities.\nOn the first day of filming “Action!” was called by the actress so that\nshooting could begin . . .\nThe model predicts that readers’ knowledge that actresses do not direct\nfilms should have caused them to fixate the word actress for a long time. In\nfact, however, that word was not fixated for long because readers immedi-\nately used the contextual justification for someone other than the director\nbeing in charge (in italics). Thus, in opposition to the model, contextual\ninformation can be accessed before general world knowledge.\nThe precise processes involved in integration and leading to a situation\nmodel are not spelled out within the model. However, it is probable that\nvarious executive functions (see Glossary) are involved such as inhibitory\nprocesses (suppressing irrelevant propositions), attention shifting (cogni-\ntive flexibility), updating information in working memory, and planning.\nFollmer (2018) reported in a meta-analysis that individuals high in each of\nthese executive functions had superior comprehension ability to those low\nin these functions.\nEvaluation\nThe key notion that propositions for the text representation are selected\nby spreading activation operating on propositions drawn from the text\nand stored knowledge is plausible and consistent with most of the evi-\ndence. There is also reasonable evidence for the model’s three levels of\nrepresentation. The model predicts accurately that readers often find it hard\nto discriminate between text information and related inferences. The model\nhas influenced the development of several subsequent theories (especially\nthe RI-Val model below).\nWhat are the model’s limitations?\n(1) The model is less applicable when texts are easy to process (McNamara\n& Magliano, 2009). With easy texts, there is often no need to generate\na situation model.\n(2) The assumption that only bottom-up processes are used during the\nconstruction phase of text processing is dubious. The finding that\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n505\nreaders’ goals can lead them to allocate attention selectively very early\nin text processing (Kaakinen & Hyönä, 2007) suggests text processing\nis more flexible than assumed theoretically.\n(3) It is assumed only general world and semantic knowledge is used in\naddition to text information during the construction phase. In fact,\nother sources of information (e.g., context) can also be used during\nthis phase (e.g., Cook & Myers, 2004).\n(4) The model is oversimplified. For example, O’Brien and Cook (2016)\nargued persuasively that language comprehension involves a valida-\ntion stage continuing after the completion of the integration stage (see\nbelow).\n(5) The cognitive processes involved in the integration stage of text com-\nprehension are not specified clearly in the model. As we have seen,\ninhibitory processes, attention shifting, updating and planning are all\ninvolved (Follmer, 2018).\n(6) The model accounts for the relatively “automatic” inferences drawn\nduring reading but not more effortful ones (Reichle, 2015).\n(7) Individual differences (e.g., in working memory capacity) are\nde-emphasised.\n(8) There is an exaggerated emphasis on the role played by abstract\npropositions in forming situation models. More recent theories (e.g.,\nthe event-indexing model discussed shortly) assume situation models\ninclude more concrete information (e.g., perceptual details).\nRI-Val model\nO’Brien and Cook (2016) developed Kintsch’s construction- integration\nmodel. Their model assumes there are three stages in language\ncomprehension:\n(1) The activation or resonance (R) stage: there is a “dumb and unre-\nstricted process” (p. 329) in which any discourse-relevant infor-\nmation in long-term memory can be activated and influence initial\ncomprehension.\n(2) The integration (I) stage: activated concepts are linked to (or inte-\ngrated with) the contents of working memory. Integration is based\non conceptual overlap, making it possible that it results in “the con-\nnection of related, but contradictory pieces of information” (Williams\net al., 2018, p. 1415).\n(3) The validation (Val) stage: linkages formed during the integration\nstage are validated against relevant information (e.g., general knowl-\nedge) stored in long-term memory.\nO’Brien and Cook’s (2016) RI-Val model is shown in Figure 10.14. The\nthree processing stages overlap in time but start in the order described\nabove. It is assumed all three processes are passive (i.e., relatively auto-\nmatic) and always continue to completion. At some point in processing, the\nreader (or listener) decides on the basis of the validation process that they\nhave an adequate comprehension of the discourse: the coherence threshold\nhas been reached.\nCreated from usyd on 2022-02-16 03:16:01.",
    "506\nLanguage\nFigure 10.14\nThis is the RI-Val model\nshowing the effects\non comprehension of\nresonance, integration\nand validation over time.\nNote that these processes\ncontinue even after the\ncoherence threshold has\nbeen reached.\nFrom O’Brien and Cook (2016).\nHow does the RI-Val model compare with Kintsch’s construction-\nintegration model? The two models are broadly similar: the resonance\nand integration states resemble the construction stage in Kintsch’s model.\nHowever, there are two important differences:\n(1) The RI-Val model explicitly identifies separate integration and val-\nidation processes whereas validation is only implicitly incorporated\nwithin the construction-integration model.\n(2) In contrast to other models, it is assumed within the RI-Val model\nthat the validation process often continues even after the readers (or\nlisteners) have understood the discourse (see Figure 10.14). As a con-\nsequence, they may detect an inconsistency in what they are reading\nor hearing after reaching the coherence threshold.\nCook and O’Brien (2014) obtained support for the above prediction.\nParticipants read a passage about Mary who had been a strict vegetarian\nfor many years. The crucial (target) sentence in the passage was either,\nMary decided to order a cheeseburger, or, Mary decided to order a tuna\nsalad. The pattern of eye movements indicated that participants rapidly\ndetected the inconsistency between Mary being a vegetarian and ordering a\ncheeseburger. However, the inconsistency is less obvious when Mary orders\na tuna salad. With that inconsistency, it was only on the sentence following\nthe target one that the participants’ eye movements were disrupted.\nWilliams et al. (2018) obtained similar findings. Readers often detected\nthat sentences such as, Moses brought two animals of each kind on the ark,\nwere incorrect when reading the sentence following the incorrect one.\nIn sum, it makes sense to divide Kintsch’s integration stage into\nsomewhat separate integration and validation stages. The prediction that\ndetection of an inconsistency in discourse can be delayed when it is not\nimmediately obvious based on participants’ general knowledge has been\nreported (Cook & O’Brien, 2014; Williams et al., 2018).\nWhat are the model’s limitations? First, it does not explicitly consider\nthe effects of individual differences (e.g., in working memory capacity) on\nTime\nThreshold\nCoherence\nthreshold\nDegree of infuence on comprehension\nResonance\nIntegration\nValidation\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n507\nthe three major processes involved in language comprehension and on\nsetting the coherence threshold. Second, the model focuses too much on\npassive or automatic processes and has very little to say about active stra-\ntegic processes (discussed later).\nEvent-indexing model and event-segmentation theory\nKintsch’s construction-integration model is a leading example of a situa-\ntion model. As Zwaan (2016, p. 1028) pointed out, “The basic idea behind\nsituation models is that comprehension of a stretch of discourse involves\nthe construction of the state of affairs denoted by the text rather than only\na mental representation of the text itself.” In this section, we consider two\nmore situation models representing developments of Kintsch’s approach.\nThe theoretical discussed here both emphasise the importance of\nevents. According to Radvansky and Zacks (2011, p. 608), “Events are\nfundamental to human experience. They [are] the elements that constitute\nthe stream of experience.”\nOne theoretical approach we will discuss is the event-indexing model\n(Zwaan et al., 1995). The other is event-segmentation theory (Zacks et al.,\n2007) which represents a development and extension of the event- indexing\nmodel. They are both situation models, but they differ from Kintsch’s\nmodel in the nature of the representations formed during discourse com-\nprehension. He argued that mental models consist of abstract propositions.\nIn contrast, the event-indexing and event-segmentation theories assume rep-\nresentations are often grounded in perception and action (Zwaan, 2014).\nZwaan (2016, p. 1029) used the sentence “The egg is in the carton”\nto illustrate the difference between these theoretical approaches. A con-\ncrete representation of the sentence might include the shape of a whole egg\nwhereas an abstract representation would not.\nThe event-indexing model (Zwaan et al., 1995) focuses on comprehen-\nsion processes when someone reads a narrative text (e.g., a story or novel).\nThus, its scope differs from that of the construction-integration model\nwhere the emphasis is on comprehension of expository texts designed to\ndescribe and/or inform. However, there are some similarities (e.g., the\nemphasis on constructing situation models during reading).\nAs McNamara and Magliano (2009, p. 321) pointed out, a fundamen-\ntal assumption of the event-indexing model is that “The cognitive system\nis more attuned to perceive dynamic events (changes in states) rather\nthan static information”. According to the event-indexing model, readers\nmonitor five situational aspects to decide whether their situation model\nrequires updating:\n(1) protagonist: the central character or actor in the present event com-\npared to the previous one;\n(2) temporality: the relationship between the times at which the present\nand previous events occurred;\n(3) causality: the causal relationship of the current event to the previous\none;\n(4) spatiality: the relationship between the spatial setting of the current\nand previous events;\nInteractive exercise:\nConstruction-integration\nmodel\nCreated from usyd on 2022-02-16 03:16:01.",
    "508\nLanguage\n(5) intentionality: the relationship between the character’s goals and the\npresent event.\nWhat happens to outdated information when we update a situation model?\nThere are two possibilities (Zwaan & Madden, 2004). First, such informa-\ntion continues to influence the comprehension process (resonance view).\nSecond, outdated information is mostly or totally discarded in favour of\nnew information in the text (here-and-now view).\nAccording to event-segmentation theory (Zacks et al., 2007), updating\nof a situation model can take two main forms:\n(1) incremental updating of individual situational dimensions (the “brick-\nby-brick” approach emphasised with the event-indexing model);\n(2) global updating in which the current situational model is replaced\nby a new one (the “from scratch” approach emphasised by event-\nsegmentation theory); such updating is most likely to occur when we\nreach the boundary between one event and the next.\nWhen do readers engage in global updating? It is assumed we try to predict\nthe near future when reading a text or observing a scene. Such predictions\nbecome harder to make as we approach the boundary between one event\nand the next, which can trigger construction of a new model.\nFindings\nAccording to the event-indexing model, updating is effortful and incurs a\nprocessing load. As predicted, Swets and Kurby (2016) found reading time\n(indexed by eye movements) was greater when updating was required at the\nboundary between the end of one event and the start of the next. If each\naspect of the situation model is processed independently or separately, we\nwould predict updating time to be greater when two aspects require updat-\ning rather than only one. Curiel and Radvansky (2014) obtained the pre-\ndicted finding.\nThe probability of updating occurring varies across the situational\naspects. Readers generally update information on intentionality, time and\nprotagonist, but are less likely to do so with spatial information (Smith &\nO’Brien, 2012).\nMost research has involved only short texts. McNerney et  al. (2011)\nstudied reading times while participants read a novel. In contrast to find-\nings with short texts, reading times were reduced when spatial or tem poral\ninformation required updating. Perhaps readers’ engagement with the\nnovel facilitated the task of updating such information.\nAs discussed earlier, the theoretical approach discussed here assumes\nsituation models often contain concrete perceptual and/or motor infor-\nmation. As Kaup et al. (2007, p. 978) argued, “Comprehension is tied to\nthe creation of representations . . . similar in nature to the representations\ncreated when directly experiencing or re-experiencing the respective situa-\ntions and events.”\nEvidence supporting the above theoretical assumption has been\nobtained using the sentence-picture verification task. Zwaan et  al. (2002)\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n509\nasked participants to read sentences such as the following: The ranger saw\nan eagle in the sky or, The ranger saw an eagle in the nest. They were then\npresented with a picture and decided rapidly whether the object in the\npicture had been mentioned in the preceding sentence. Verification times\nwere faster when the object’s shape in the picture (e.g., an eagle with out-\nstretched or folded wings) matched the shape implied in the sentence indi-\ncating readers’ use of perceptual information.\nZwaan and Pecher (2012) also used the sentence–picture verification\ntask in several experiments. Verification times were faster to pictures\nmatching the implied orientation, shape or colour of sentence objects than\nto non-matching pictures.\nMoore and Schwitgebel (2018) reported evidence consistent with the\nabove assumptions and research. Participants read various kinds of text\n(e.g., stage dialogue; poems; descriptive text). When they heard a beep, they\nindicated whether they had just been engaged in visual imagery. Across the\ndifferent kinds of text, readers reported visual imagery 70% of the time.\nIs it cognitively demanding for readers to create detailed visual sim-\nulations of objects referred to in texts? Gao and Jiang (2018) increased\nprocessing demands by presenting text in a hard-to-read font. However,\nthis did not impair readers’ ability to infer the physical shapes of objects\nreferred to in texts. The implication is that relatively little processing\ncapacity is required for readers to create visual simulations while compre-\nhending texts.\nDoes outdated information disrupt current text processing and forma-\ntion of a situation model? Kendeou et al. (2013) argued it would be disad-\nvantageous if outdated information was always disrupting. They discovered\nthe provision of causal explanations supporting the updating process elim-\ninated disruption. One story involved Mary, who had been a vegetarian\nfor 10 years. This sentence was presented late in the story: Mary ordered a\ncheeseburger and fries. There was no disruption from outdated information\nfor readers giving a causal explanation why Mary was no longer vegetarian\n(she had insufficient vitamins and so her doctor told her to eat meat).\nIs situation-model updating incremental (as claimed within the event-\nindexing model) or global (as claimed within event-segmentation theory)?\nKurby and Zacks (2012) asked readers to think aloud while reading an\nextended narrative. They showed incremental updating by increased men-\ntions of the character, object, space, time and goal when the relevant situa-\ntional aspect changed. They also showed global updating – the presence of\nan event boundary was associated with increased mentions of the charac-\nter, cause, goal, and time. Huff et al. (2018) found that updating was also\nincremental when listeners were presented with an audio drama.\nEvaluation\nThe greatest strength of the event-indexing model and event- segmentation\ntheory is that they identify key aspects of situation models that were\nde-emphasised within other theoretical approaches. For example, they\nfocus on gradual and global updating of situation models in response\nto changes within and between events. The assumption that situation\nmodels are not limited to abstract propositions (as assumed within the\nCreated from usyd on 2022-02-16 03:16:01.",
    "510\nLanguage\nconstruction-integration model) but can include perceptual and other con-\ncrete types of information has received much empirical support.\nWhat are the limitations of this theoretical approach? First, it is fully\napplicable only to narrative texts describing event sequences and is of little\nrelevance to expository texts providing information and/or explanations.\nEven with narrative texts, situation models are less likely to be formed\nwhen the text is complicated. For example, most readers failed to form\na situation model when reading a complex account of a murder scene\n(Zwaan & van Oostendorp, 1993).\nSecond, the theoretical approach de-emphasises important deter-\nminants of comprehension (e.g., the reader’s goals and reading skills;\nMcNamara & Magliano, 2009). Reasonable reading skills and adequate\nmotivation for successful monitoring the five different dimensions of pro-\ntagonist, temporality, causality, spatial relationships and intentionality.\nThird, relatively little is known about the underlying mechanisms\nleading text comprehension to produce representations containing percep-\ntual and/or motor information (Dijkstra & Post, 2015). We also lack a\ndetailed understanding of how such concrete information and the abstract\npropositional information emphasised by Kintsch are combined during\ntext comprehension.\nFourth, most research has involved relatively short texts. However,\npreliminary evidence suggests some comprehension processes may differ\nbetween long and short texts (McNerney et al., 2011).\nCHAPTER SUMMARY\n•\nParsing: overview. Listeners often make use of prosodic cues (e.g.\npauses) provided by the speaker to interpret sentences (especially\nambiguous ones). There is much evidence readers use their\n“inner voice” to produce implicit prosody that closely resembles\nthe prosody found in spoken sentences. Readers’ use of implicit\nprosody is greatly aided by the presence of commas in text.\n•\nTheoretical approaches: parsing and prediction. The garden-\npath model is a two-stage model where only syntactic information\nis used at the first stage. In fact, various kinds of non-syntactic\ninformation are sometimes used earlier in sentence processing\nthan the model predicts. The model erroneously predicts that most\nreaders will ultimately generate a correct syntactic structure even\nfor complex sentences.\nAccording to the constraint-based model, all sources of\ninformation (e.g., context) are available immediately to someone\nprocessing a sentence. Competing sentence analyses are activated\nin parallel, with several language characteristics (e.g., verb bias)\nbeing used to resolve ambiguities. There is much support for this\nmodel. However, its predictions are sometimes imprecise.\nAccording to the unrestricted race model, all information\nsources are used to identify a single syntactic structure for a\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n511\nsentence. If this structure is disconfirmed, there is extensive\nre-analysis. This model de-emphasises the importance of task\ndemands in influencing parsing.\nAccording to the good-enough language processing account,\nwe often process sentences rather superficially using various\nheuristics and so are prone to error. It is not clear how readers\ndecide a proposed sentence structure is good enough.\nERP studies indicate several sources of information (including\nword meanings and context) influence sentence processing at an\nearly stage. Top-down processes generate predictions as to what\nwill be read next.\n•\nPragmatics. Pragmatics is concerned with intended rather\nthan literal meanings. Understanding figurative language (e.g.,\nmetaphor; irony) is often relatively complex because it involves\nsimultaneous processing of metaphorical and literal meanings.\nUnderstanding metaphors involves selecting predicate features\nrelevant to the argument and inhibiting irrelevant predicate\nfeatures. There are processing differences between different types\nof metaphors and between novel and familiar metaphors.\nListeners generally understand better what speakers are saying\nif they make use of the common ground (shared knowledge and\nbeliefs). When it is effortful to use the common ground, listeners\noften rely on the egocentric heuristic. Sometimes listeners make\nsimultaneous use of an egocentric perspective and common\nground.\n•\nIndividual differences: working memory capacity. Individuals\nhigh in working memory capacity outperform low-capacity\nindividuals with respect to language comprehension. This\nsuperiority depends on both specific individual differences (e.g.,\nverbal working memory) and more general ones. It has generally\nbeen assumed theoretically that there is a direct relationship\nbetween working memory capacity and reading comprehension.\nHowever, there is increasing evidence that the relationship is\nindirect and depends on factors such as vocabulary size, language\nexperience and general reasoning ability.\n•\nDiscourse processing: inferences. Readers typically make logical\nand bridging inferences (e.g., anaphor resolution) but the extent\nto which they make elaborative inferences is variable. Inference\ndrawing depends on two types of processes: (1) passive or\n“automatic” processes; (2) effortful reader-initiated processes.\nReader-initiated processes are most likely to be used when\nrequired for readers to attain adequate comprehension and\ncoherence while reading a text. Anaphor resolution is a very\ncommon form of bridging inference. It involves multiple constraints\noperating interactively in parallel. Most research focuses on\nCreated from usyd on 2022-02-16 03:16:01.",
    "512\nLanguage\nwhether inferences are drawn rather than which inferences are\ndrawn. However, there is evidence that anxious individuals are\nmore likely than non-anxious ones to draw threatening predictive\ninferences.\n•\nDiscourse comprehension: theoretical approaches. According\nto schema theory, schemas or organised packets of knowledge\ninfluence our comprehension of (and memory for) discourse in\na top-down fashion. The theory lacks explanatory power, and\ncomprehension and memory are less error-prone than assumed\ntheoretically. According to Kintsch’s construction-integration model,\nthree levels of text representation are constructed. It is assumed\nbottom-up processes (construction stage) are followed by top-down\nprocesses (integration stage). However, top-down processes occur\nearlier than assumed theoretically. The model is less applicable\nwhen texts are easily processed. According to the RI-Val model (a\ndevelopment of the construction-integration model), a long-lasting\nvalidation process can detect inconsistencies in a text even after\nreaders believe they have adequate text comprehension.\nThe event-indexing model and event-segmentation theory\nfocus on how readers update their situation models in response to\nchanges within and between events. This general approach works\nwell with simple narrative texts but is less applicable to complex\nand/or expository texts. The approach de-emphasises the role\nplayed by the reader’s goals and reading skills.\nFURTHER READING\nCarreiras, M., Armstrong, B.C. & Duñabeitia, J.A. (2018). Reading. In S.L.\nThompson-Schill (ed.), Stevens’ Handbook of Experimental Psychology and\nCognitive Neuroscience, Vol. 3: Language and Thought (4th edn; pp. 207–244).\nNew York: Wiley. Manuel Carreiras and colleagues provide a thorough account\nof comprehension processes in reading.\nCook, A.E. & O’Brien, E.J. (2017). Fundamentals of inferencing during reading.\nLanguage and Linguistics Compass, 11 (Article e12246). This article evaluates\nseveral major theoretical approaches to inference drawing while comprehending\ntext.\nGarnham, A. (2018). Pragmatics and inference. In S.-A. Rueschemeyer and M.G.\nGaskell (eds), The Oxford Handbook of Psycholinguistics (2nd edn). Oxford:\nOxford University Press. Alan Garnham provides a thorough review of theory\nand research on pragmatics.\nKarimi, H. & Ferreira, F. (2016). Good-enough linguistic representations and\nonline cognitive equilibrium in language processing. Quarterly Journal of\nExperimental Psychology, 69, 1013–1040. Hossein Karimi and Fernanda Ferreira\npropose an interesting theoretical model of language comprehension based on\nthe good-enough processing approach.\nKim, A.E. (2018). Sentence processing. In S.L. Thompson-Schill (ed.), Stevens’\nHandbook of Experimental Psychology and Cognitive Neuroscience, Vol. 3:\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language comprehension\n513\nLanguage and Thought (4th edn; pp. 111–148). New York: Wiley. The many\nprocesses involved in understanding sentences are discussed in detail in this\nchapter.\nPeng, P., Barnes, M., Wang, C., Wang, W., Li, S., Swanson, H.L. et al. (2018).\nA meta-analysis on the relation between reading and working memory.\nPsychological Bulletin, 144, 48–76. This article provides a detailed account of\nhow reading performance is related to individual differences in working memory.\nPickering, M.J. & Gambi, C. (2018). Predicting while comprehending language.\nPsychological Bulletin, 144, 1002–1044. Martin Pickering and Chiara Gambi\ndiscuss how listeners’ and readers’ language comprehension is enhanced by\npredictive processes.\nZwaan, R.A. (2016). Situation models, mental simulations, and abstract concepts\nin discourse comprehension. Psychonomic Bulletin and Review, 23, 1028–1034.\nRolf Zwaan discusses key theoretical issues relating to approaches to language\ncomprehension based on situation models (e.g., Kintsch’s construction-\nintegration model; event-indexing model; event-segmentation theory).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\nINTRODUCTION\nWe know much more about language comprehension than language pro-\nduction. Why is this? We can easily control material to be comprehended,\nbut it is harder to constrain an individual’s language production. In addi-\ntion, to account for language production, we need more than simply a\ntheory of language. Language production is basically a goal-directed activ-\nity having communication as its main goal. People speak and write to impart\ninformation, to be friendly and so on. Thus, motivational and social factors\nmust be considered in addition to purely linguistic ones.\nThis chapter focuses on speech production and writing (including\nthe effects of brain damage on these language processes). More is known\nabout speech production than about writing and nearly everyone spends\nmore time talking than writing. Thus, it is more important to understand\nthe processes involved in talking. Nevertheless, writing is an important\nskill.\nHow similar are the processes involved in spoken and written lan-\nguage? Both have as their central function the communication of informa-\ntion about the writer or speaker, other people and the world. In addition,\nboth depend on the same knowledge base. However, children (and nearly\nall adults) find writing much harder than speaking which suggests there are\nimportant differences between them. The main similarities and differences\nare discussed below.\nSimilarities\nThe view that speaking and writing are similar receives support from theo-\nretical approaches to these language activities. For example, it is assumed\nboth start with planning, in order to decide on the overall meaning to be\ncommunicated (e.g., Dell et al., 1997, on speech production; Hayes, 2012,\non writing). At this stage, the actual words to be spoken or written are not\nconsidered. The planning stage is followed by language production (often\non a clause-by-clause basis).\nMiozzo et  al. (2018) identified several other similarities. First, chil-\ndren typically only learn how to write after they have developed good\nspoken-language skills. Second, the teaching of writing often focuses on\nChapter\n11\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n515\nknowledge of spoken language (e.g., emphasising speech–print correspond-\nences). Third, adults’ word spellings are influenced to some extent by word\npronunciation.\nSome forms of written communication closely resemble spoken forms.\nFor example, consider instant messaging involving a rapid exchange of\ntyped messages. Choe (2018) studied five Korean friends exchanging\ninstant messages. The messages were mostly typed in a spontaneous and\ninformal fashion resembling casual speech. Those receiving these messages\noften replied with simplified messages (e.g. yeah) or indicated their involve-\nment by responding with “machine-gun” questions (produced very rapidly\nwithout hesitation). In sum, the exchanges of typed messages were very\nsimilar to spoken conversation.\nDifferences\nThere are several important differences between speaking and writing.\nWritten language typically uses longer and more complex constructions\nas well as longer words and a larger vocabulary. Writers make more use\nthan speakers of words or phrases signalling what comes next (e.g., but; on\nthe other hand). This helps to compensate for the fact that there is a rela-\ntive lack of prosody (rhythm; intonation, and so on; discussed shortly) in\nwriting compared to speech.\nHere are five major differences between speaking and writing (Crystal,\n2005):\n(1) Speech is time-bound and transient whereas writing is space-bound\nand permanent.\n(2) Speakers typically have much less time available for planning than\nwriters and so spoken sentences are typically shorter.\n(3) Speakers mostly receive immediate verbal and non-verbal feedback\n(e.g., expressions of bewilderment) from their listeners.\n(4) Speech is well suited to social functions (e.g., casual chatting), whereas\nwriting is well suited to communicating facts and ideas.\n(5) Writers have direct access to what they have produced so far whereas\nspeakers do not.\nWhat are the consequences of the above differences? Speech is often infor-\nmal and simple in structure whereas writing is more formal and complex.\nWriters need to write clearly because they do not receive immediate\nfeedback.\nSome brain-damaged patients have largely intact writing skills despite\nan almost total inability to speak and a lack of inner speech (e.g., EB,\nstudied by Levine et  al., 1982). Other brain-damaged patients can speak\nfluently but find writing very hard (Ellis & Young, 1988). Rapp et al. (2015)\nstudied patients following a left-hemisphere stroke. Aspects of grammar\nwere impaired in writing but not speech for some patients whereas others\nshowed the opposite pattern. These findings suggest partial independence\nof the processes underlying writing and speech. However, the higher-level\nprocesses of language production (e.g., planning; use of knowledge) are\nprobably very similar in speech and writing.\nCreated from usyd on 2022-02-16 03:16:01.",
    "516\nLanguage\nWe must not exaggerate the differences between speech and writing.\nAs Crystal (2005, p. 8) noted, “There are few . . . absolute differences\nbetween speech and writing, and there is no single parameter of linguistic\nvariation which can distinguish all spoken from all written genres.” For\nexample, emails often contain features associated with speech (e.g., infor-\nmality; rapid feedback).\nBASIC ASPECTS OF SPEECH PRODUCTION\nWe start by introducing broad issues of direct relevance to speech pro-\nduction. First, there is the important (but complex) issue of the extent to\nwhich speech production utilises processes involved in speech compre-\nhension. Second, we argue speech production is much harder than it may\nappear subjectively. Strategies used by speakers to cope with the complex-\nities of speech production are discussed. Third, we provide a preliminary\naccount of the notion that speech production involves a series of process-\ning stages.\nSpeech production vs speech comprehension\nWe saw in Chapter 9 that speech perception (especially under difficult lis-\ntening conditions) often involves brain regions associated with speech pro-\nduction (e.g., Adank, 2012). In similar fashion, it is increasingly argued\nthat speech production often involves processes and brain regions asso-\nciated with speech perception. For example, Chater et  al. (2016, p. 244)\nargued that “Language comprehension and production are facets of a\nunitary skill”. They discussed their computational model (the Chunk-\nBased Learner) which simulates aspects of children’s language acquisition\nand is equally applicable to production and comprehension (see discussion\nlater).\nStrong evidence that speech production involves processes overlap-\nping with those used in speech perception was reported by Silbert et  al.\n(2014). They identified the brain areas activated as speakers produced a\n15-minute narrative, and also those activated as listeners comprehended\nthe  same  narrative. They argued there are two possible reasons why a\ngiven brain area is activated during both speech comprehension and\nproduction:\n(1) The same processes are occurring in both cases.\n(2) Different processes occur in comprehension and production within\nthe same brain area.\nIn their analyses, they assumed (1) was the case only when there were\nsimilar patterns over time during comprehension and production: they\ncalled this comprehension-production coupling.\nSilbert et al.’s (2014) findings are shown in Figure 11.1. Several brain\nareas exhibited comprehension-production coupling (in blue). Thus,\nspeech production shares several processes with speech comprehension.\nUnsurprisingly, other brain areas were specifically associated with speech\ncomprehension or speech production. In approximate terms, the findings\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n517\nFigure 11.1\nAreas activated (and\ncoupled) during speech\ncomprehension and\nproduction are in blue (STG\n= superior temporal gyrus;\nMTG = medial temporal\ngyrus; AG = angular gyrus;\nRPJ = temporal-parietal\njunction; IFG = inferior\nfrontal gyrus); areas\nactivated (not coupled)\nduring comprehension and\nproduction are in orange;\nareas activated only during\nproduction are in red;\nareas activated only during\ncomprehension are in\nyellow.\nFrom Silbert et al. (2014).\noverall suggested high-level language processing is more likely than low-\nlevel processing to be shared between comprehension and production.\nPickering and Gambi (2018, p. 1002) focused on the use of speech-\nproduction processes in speech comprehension: “[Comprehenders] cov-\nertly imitate the linguistic form of the speaker’s utterance and construct\na representation of the underlying communicative intention . . . [they] run\nthis intention through their own production system to prepare the pre-\ndicted utterance.” This hypothesis has much support (see Chapter 10). For\nexample, the average gap between turns during a conversation between\ntwo individuals is only 250 ms (Stivers et  al., 2009) even though it takes\nabout 600 ms to produce a single word (Pickering & Gambi, 2018).\nHow easy is speech production?\nOn the face of it (by the sound of it?), speech production seems straight-\nforward. Indeed, it seems almost effortless when we chat with friends and\nacquaintances. We typically speak at 2–3 words per second or about 150\nwords a minute and this rapid speech rate suggests that speaking requires\nrelatively few processing resources.\nThe reality of speech production is very different from what is\nimplied above. Consider Christiansen and Chater’s (2016) theoreti-\ncal approach (discussed in Chapter 10 and in more detail later, p. 535).\nAccording to this approach, our short-term memory has very limited\ncapacity and new information rapidly eliminates old information. As a\nresult, “Once detailed [language] production information has been assem-\nbled, it must be executed straight away, before it is obliterated by the\non-coming stream of later low-level decisions” (Christiansen & Chater,\n2016, p. 5).\nEvidence speech production is often more cognitively demanding than\nspeech comprehension was reported by Boiteau et al. (2014). Participants\ntracked a moving target while engaged in speech production or comprehen-\nsion. Speech production (especially speech planning) was associated with a\ngreater impairment of tracking performance than speech comprehension.\nThese findings suggest speech production is more attentionally demanding\nthan comprehension.\nSchematic summary\nLeft hemisphere\nRight hemisphere\nMedial\nProduction\nComprehension\nIPS\nAG\nSTG\nMC\nIFG\nPM\nSPM\nrpPFC\nPCC\nRS\nprecuneus\nMTG\nTP\nIT\nTP\nIFG\nIT\nMTG\nSTG\nAG\nTPJ\nTPJ\nMC\nPM\nIPS\nCaudala\nPutarnen\nT\nh\na\nl\ns\nm\nu\ns\nOverlap without coupling\nComprehension-production\ncoupling (CPC)\nTPJ\nTPJ\nCreated from usyd on 2022-02-16 03:16:01.",
    "518\nLanguage\nHow do speakers cope with the cognitive demands of producing\nspeech? One way is by re-using aspects of what they have just heard. An\nimportant example is syntactic priming in which speakers re-use a given\nsyntactic structure. If, for example, you have just heard a passive sentence\n(e.g., “The man was bitten by the dog”), this increases the probability you\nwill produce a passive sentence. Convincing evidence for syntactic priming\nwas reported in a meta-analysis (see Glossary) by Mahowald et al. (2016).\nThis priming effect was especially strong when speakers used the same (or\nsimilar) words to those they had heard.\nAnother way speakers reduce processing demands is via  preformulation,\nwhich involves producing phrases used before. Approximately 70% of\nour speech consists of word combinations we use repeatedly (Altenberg,\n1990;  Liu, 2014). Horseracing commentators (who speak very rapidly)\nmake extensive use of preformulations (e.g., “They are off and racing\nnow”).\nAnother\nstrategy\nused\nto\nfacilitate\nspeech\nproduction\nis\nunderspecification, which involves using simplified expressions where the\nfull meaning is not explicit. Underspecification and preformulation often\ngo together. “Or something” and “and things like that” are examples.\nKEY TERMS\nSyntactic priming\nThe tendency for a\nspeaker’s utterances to\nhave the same syntactic\nstructure as those they\nhave heard shortly\nbeforehand.\nPreformulation\nThe production by\nspeakers of phrases used\nfrequently before; it\nreduces the demands of\nspeech production\nUnderspecification\nA strategy used to\nreduce processing costs\nin speech production\nby using simplified\nexpressions.\nIN THE REAL WORLD: MILD COGNITIVE IMPAIRMENT\nIt is cognitively demanding to produce coherent spontaneous speech. Unsurprisingly, patients with\nAlzheimer’s disease exhibit clear signs of impaired spontaneous speech. Alzheimer’s disease is\noften preceded by mild cognitive impairment, a condition involving minor problems with memory\nand thinking. Here we consider which aspects of speech production are impaired in individuals\nwith mild cognitive impairment.\nBerisha et  al. (2015) compared the press conferences of two American presidents: Ronald\nReagan and George Herbert Walker Bush. Reagan was diagnosed with Alzheimer’s disease six\nyears after leaving office. He showed a substantial reduction in the use of unique words during his\ntime as president, coupled with a large increase in conversational fillers (e.g., “well”; “um”; “ah”)\nand non-specific nouns (e.g., “something”; “anything”). Thus, his speech became simpler and less\ninformative due to mild cognitive impairment. In contrast, President Bush showed no systematic\nchanges in vocabulary use over time.\nMueller et  al. (2018) studied individuals with early mild cognitive impairment (subtle cognitive\ndeficits not meeting the criteria for mild cognitive impairment). Over a two-year period, these\nindividuals showed greater decline than cognitively healthy controls in two aspects of speech: (1)\nfluency (e.g., few filled pauses; few false starts); (2) semantic content (proportion of words provid-\ning meaningful content). These findings resemble those found with President Reagan.\nIn sum, reductions in speech-production quality are found even during the early stages of mild\ncognitive impairment, suggesting that “normal” quality of speech production requires intact cog-\nnitive processes. Such findings also suggest that speech-production deficits may serve as an “early\nwarning” of future, more severe, cognitive impairment.\nOf relevance, Berisha et al. (2017) found professional American football players had lower spoken\nlanguage complexity (e.g., low ratio of content words (e.g., nouns; verbs) to total words spoken)\nthan controls. In addition, those football players who had been tackled the most had the lowest\nspoken language complexity. It might be a useful precaution to carry out more detailed cognitive\ntesting on those American football players with the least spoken language complexity.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n519\nStages in speech production\nSpeech production involves several general stages or processes. Dell (1986),\nin his spreading-activation theory (discussed later, pp. 526–530), argued\nspeech production consists of four levels:\n●\nsemantic level: the meaning of what is to be said (or the message to be\ncommunicated); this is the planning level;\n●\nsyntactic level: the grammatical structure of the words in the planned\nutterance;\n●\nmorphological level: the morphemes (basic units of meaning);\n●\nphonological level: the phonemes (basic units of sound).\nIt makes sense to assume the above four levels or stages occur in the order\ndescribed. Thus, we engage in planning, followed by working out the gram-\nmatical structure of the sentence and the basic units of meaning, and finally\nwork out the sounds to be produced. In fact, speech production is much\nless neat and tidy: “later” processes can occur at the same time as (or even\nahead of) “earlier” processes.\nSPEECH PLANNING\nWe typically plan what we are going to say before speaking (the first stage\nin speech production). In other words, we engage our brain before speaking.\nIs speech planning influenced by the syntactic structure of planned\nutterances? Supporting evidence was reported by Lee et al. (2013). Consider\nthe following sentence:\nThe student of the teacher who is raising her hand.\nThis sentence is ambiguous. Is the person raising their hand the teacher\n(simpler syntactic structure) or the student (more complex structure).\nThe time to initiate speech was longer when speakers produced the more\ncomplex syntactic structure indicating that speech planning included aspects\nof syntactic structure.\nWhat is the scope of speakers’ planning? Planning might occur at the\nlevel of the clause (a part of a sentence containing a subject and a verb).\nAlternatively, it might occur at the level of the phrase (a group of words\nexpressing a single idea). In the sentence “Failing the exam was a major\ndisappointment to him”, the first three words form a phrase.\nHolmes (1988) found speakers talking spontaneously about various\ntopics had hesitations and pauses immediately before the start of a clause.\nThis suggests they were planning the forthcoming clause. Martin et  al.\n(2004) found speakers describing moving pictures took longer to initiate\nspeech when the initial phrase was complex rather than simple. This sug-\ngests they planned the initial phrase before speaking.\nThe extent of advance speech planning often differs at the semantic,\nsyntactic and phonological levels. Garrett (1980) analysed various types\nof speech errors (discussed further later, pp. 521–523). Word-exchange\nerrors (e.g., “My chair seems empty without my room”) often involved\nKEY TERMS\nAlzheimer’s disease\nA disease in which general\ndeterioration of the brain\nleads to progressive\nmental deterioration.\nMorphemes\nThe basic units of\nmeaning; words consist of\none or more morphemes.\nClause\nA group of words within a\nsentence that contains a\nsubject and a verb.\nPhrase\nA group of words within\na sentence expressing a\nsingle idea.\nCreated from usyd on 2022-02-16 03:16:01.",
    "520\nLanguage\nwords belonging to the same syntactic or grammatical category and gen-\nerally spanned different phrases. These errors occur during grammatical\nencoding.\nIn contrast, sound-exchange errors (e.g., burst of beaden instead of\nbeast of burden) typically involved nearby elements within a phrase. These\nerrors occur during phonological encoding. Garrett concluded that gram-\nmatical or syntactic planning occurs over greater distances within a sen-\ntence than does phonological planning.\nRecent research reveals a more complex picture. In a review, Klaus\net  al. (2017) concluded planning at the syntactic and phonological levels\ncan both extend “beyond the initial phrase and may even span over a\nwhole simple sentence” (p. 813). In their own research, Klaus et al. found\nadvance planning was comparable at the syntactic and phonological levels\nwhen speakers performed a visuo-spatial task at the same time. However,\nperforming a verbal task (remembering digits) at the same time only\nreduced the extent of phonological planning, suggesting the verbal task\nand phonological planning required the same processing resources. More\ngenerally, the findings suggest that the scope of planning at any given level\n(e.g., syntactic; phonological) depends on the precise demands of any non-\ntask processing occurring at the same time.\nFlexibility\nHow can we account for the variable findings discussed above? Speakers\ngenerally want to start communicating rapidly (implying little forward plan-\nning). However, they also want to talk fluently (implying much forward\nplanning). Speakers resolve conflict flexibly depending on their immediate\ngoals and the situational demands.\nFerreira and Swets (2002) reported evidence that speakers’ planning\nvaries flexibly. Speakers answered mathematical problems. When there\nwas no time pressure, speakers planned their responses before starting to\nspeak and so the time taken to start speaking was influenced by task dif-\nficulty. When there was time pressure, speakers engaged in limited plan-\nning before starting to speak, with additional planning occurring during\nspeaking. Thus, they did as much forward planning as was feasible before\nspeaking.\nWagner et al. (2010) agreed speech planning is flexible and identified\nseveral factors influencing advance planning. First, individuals speaking\nslowly engaged in more planning than fast speakers. Second, there was\nmore planning before speakers produced simple rather than complex sen-\ntences. Third, speakers showed more planning when under low (rather\nthan high) cognitive load.\nHow can we explain speakers’ flexible advance planning? As men-\ntioned earlier, they face a trade-off between communicating effectively\nand avoiding errors on the one hand and cognitive demands on the other\nhand. If they focus on avoiding errors, the cognitive demands are substan-\ntial. However, if they try to minimise cognitive demands, their speech will\ncontain many errors. In practice, speakers mostly engage in extensive plan-\nning only when it is relatively undemanding. In sum, “Speech planning\nprocesses flexibly adapt to external task goals” (Swets et al., 2013, p. 23).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n521\nThere is a final important point. Since speakers’ advance planning is\ngenerally limited in scope, it would seem that they must often engage in\nincremental planning. In other words, speakers plan only part of the next\nsentence or utterance and gradually extend and change their plan over\ntime. Brown-Schmidt and Konopka (2015) obtained evidence of incremen-\ntal planning when participants were required to add new information to\ntheir spoken utterance after they had started to speak. Brown-Schmidt and\nKonopka also found that speakers’ fluency was not impaired by adding\nnew information, suggesting that their initial plan was so flexible it could\neasily accommodate message revisions.\nSPEECH ERRORS\nOur speech is generally accurate and coherent. However, we all make occa-\nsional speech errors. There are several kinds of speech errors which can\noccur at any stage of speech production. Human limitations in process-\ning capacity (e.g., short-term memory) might suggest speech errors would\nbe frequent (Christiansen & Chater, 2016). However, the average person\nmakes a speech error only once every 500 sentences.\nIn spite of their rarity, speech errors are important because they\nprovide insights into the mechanisms underlying speech production. This\nwould not be so if speech errors were random and thus unpredictable. In\nfact, speech errors are predominantly systematic. The speech errors even\nof brain-damaged patients are generally similar to the correct words (Dell\net al., 2014). As Dell et al. concluded, “Slips [speech errors] are more right\nthan wrong.”\nHistorically, speech errors were typically written down by researchers\nimmediately after being heard. This is limited because many speech errors\nare undetected (Ferber, 1995). More recently, research has focused on\nspeech errors produced deliberately under laboratory conditions.\nError types\nThere are several types of error additional to those mentioned earlier. One\nexample is the spoonerism which occurs when the initial letter(s) of two\nwords are switched. It was named after the Reverend William Spooner who\nis credited with several memorable examples (e.g., “You have hissed all my\nmystery lectures”). Alas, most of his gems resulted from painstaking effort.\nThe Freudian slip is a famous type of error allegedly revealing the\nspeaker’s true sexual desires. In a study by Motley (1980), male partici-\npants said out loud pairs of items such as goxi furl and bine foddy. For\nsome participants, the experimenter was a female who was “attractive, per-\nsonable, very provocatively attired, and seductive in behaviour” (Motley,\n1980, p. 140). More spoonerisms (e.g., goxi furl turning into foxy girl) were\nproduced when the participants’ passions were inflamed by this female\nexperimenter.\nSemantic substitution errors occur when the correct word is replaced by\none of similar meaning (e.g., “Where is my tennis bat?” instead of “Where\nis my tennis racquet?”). In 99% of cases, the substituted and correct words\nbelong to the same part of speech (e.g., nouns), suggesting speakers plan\nKEY TERMS\nSpoonerism\nA speech error in which\nthe initial letter or letters\nof two words (typically\nclose together) are\nswitched to form two\ndifferent words.\nFreudian slip\nA speech error that\nreveals the speaker’s\n(often unconscious) sexual\ndesires.\nCreated from usyd on 2022-02-16 03:16:01.",
    "522\nLanguage\nthe grammatical structure of their next utterance before finding the precise\nwords to insert into it.\nMorpheme-exchange errors involve inflections or suffixes (e.g., -ed)\nbeing attached to the wrong word (e.g., “He has already trunked two\npacks”). Such errors imply that the positioning of inflections is dealt with\nby a different process from the one responsible for positioning word stems\n(e.g., trunk; pack). The word stems are worked out before the inflections\nare added because the spoken inflections or suffixes are generally altered to\nfit with the new word stems. For example, the “s” sound in “the forks of a\nprong” is pronounced in a way appropriate within the word forks but not\nthe original word prongs.\nFinally, we consider subject-verb agreement errors, in which sin-\ngular verbs are mistakenly used with plural subjects or vice versa (e.g.,\n“The government have made a mess of things”). Why do we make such\nerrors? McDonald (2008) argued that considerable processing resources\nare required to avoid subject-verb agreement errors. As predicted, speak-\ners made more such errors when there was an externally imposed load on\nworking memory.\nOther factors associated with use of singular or plural verbs have been\nidentified. When speakers had recently encountered phrases (e.g., a trio of\nviolinists) paired with plural verbs, they were more likely to produce plural\nverbs with other, similar phrases (e.g., a class of children) (Haskell et al.,\n2010).\nMirković and MacDonald (2013) found semantic factors are important.\nParticipants received verbs plus phrases (in Serbian) such as the following:\n(1) Many wolves . . . (to jump)\n(2) Several wolves . . . (to jump)\nIn each case, they had to decide whether to say jump or jumps (both gram-\nmatically acceptable in Serbian). Mirković and MacDonald argued that\nmany is more suggestive than several of a single mass or collection. As pre-\ndicted, speakers used plural verbs less often following phrases containing\nmany rather than several.\nIt has generally been assumed most speech errors involve sound sub-\nstitutions. Goldrick et  al. (2016) showed the limitations of this assump-\ntion. Speakers said tongue twisters repeatedly. The sounds associated with\nspeech errors varied considerably – some resembled direct substitutions but\nmost did not. This variability occurred because speech errors were due to\na combination of two factors: (1) planning processes relating to the targets\nof articulation; and (2) articulatory processes specifying the motor move-\nments required to execute this plan. This study is important because it indi-\ncates speech errors are multiply determined and so require more complex\nexplanations than those proposed in the past.\nIn sum, speakers make several types of speech errors. We will shortly\ndiscuss other types of speech errors within the context of Dell’s (1986)\nspreading-activation theory, which provides an explanation of most types\nof speech errors. Before turning to that theory, however, we discuss two\nprominent theories of how speakers monitor their own speech to prevent\n(or correct) speech errors. These theories have general importance because\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n523\nthey identify mechanisms that serve to minimise the number of errors made\nby speakers and thus enhance communication (Nozari & Novick, 2017).\nPerceptual loop theory\nSpeakers often detect and rapidly correct their own speech errors. Levelt\n(1983) proposed a perceptual loop theory to explain such error detection.\nAccording to this theory, speakers detect their own speech errors by moni-\ntoring their utterances and discovering that what they say sometimes differs\nfrom what they intended.\nOf importance, this monitoring occurs at two levels: inner speech and\novert speech. With overt speech, speakers make use of auditory feedback.\nIn essence, speakers use the comprehension system to detect their own\nspeech errors in ways resembling those used to detect errors in other peo-\nple’s speech. Monitoring of inner speech should typically occur faster than\nmonitoring of overt speech.\nStrong evidence that monitoring for speech errors occurs at the two\nstages of inner and overt speech was reported by Nooteboom and Quené\n(2017). Speakers were given a task designed to produce errors. For\nexample, the word pair BIN DOG was presented visually and had to be\nspoken aloud. When they had previously been presented with word pairs\nsuch as DOVE BALL; DEER BACK; and DIM BOMB, they sometimes\nincorrectly said DIN BOG. Nooteboom and Quené recorded two meas-\nures: (1) error-to-cut-off times (time between an error and the speaker stop-\nping speaking); and (2) error-to-repair times (time between an error and\nthe speaker correcting it).\nWhat did Nooteboom and Quené (2017) find? First, the error-to-cut-\noff times showed two peaks (139 ms and 637 ms). The fast times reflect\nmonitoring of inner speech whereas the slow times reflect monitoring of\novert speech. Second, the error-to-repair times also showed two peaks (253\nms and 970 ms): repairing or correcting an error was more time-consuming\nwhen detected in overt speech rather than inner speech.\nIt is assumed within perceptual loop theory that speakers often use\nauditory feedback to monitor their own speech for errors. This assumption\nhas been supported by research showing speakers are worse at detecting\nerrors when auditory masking is used to prevent them from hearing them-\nselves speak. However, Nooteboom and Quené (2017) discovered that loud\nmasking noise had no effect on the detection of speech errors. Auditory\nfeedback is probably more important in monitoring when speakers produce\nfairly long and complex utterances than when they simply produce two\nwords as in Nooteboom and Quené’s study.\nConflict-based monitoring theory\nNozari et  al. (2011) proposed a conflict-based monitoring theory. They\nargued error detection depends on information generated by the speech-\nproduction system rather than the comprehension system. Their theory\nassumes speakers engage in conflict monitoring during competition among\nvarious possible words at the time of response selection. Cognitive control\nmechanisms are used to resolve conflicts between response options.\nCreated from usyd on 2022-02-16 03:16:01.",
    "524\nLanguage\nThe two theories make different predictions. First, the perceptual\nloop theory predicts speakers’ success at detecting their own speech\nerrors depends mostly on their comprehension ability. In contrast, Nozari\net  al.’s (2011) conflict-based account predicts speakers’ ability to detect\ntheir speech errors depends on the quality of their speech-production\nsystem.\nSecond, speakers should detect errors rapidly if error detection\ndepends on detecting conflict prior to producing an error (the conflict-based\naccount). According to the perceptual loop theory, in contrast, error detec-\ntion can be fast or slow depending on whether it is based on monitoring\ninner or overt speech.\nFigure 11.2\nCorrelations between aphasic patients’ speech-production abilities and their ability to detect their own speech-\nproduction errors. Top row: ability to avoid semantic errors when speaking (s weight) was positively correlated with\nability to detect their own semantic errors (left) but not with ability to detect their own phonological errors. Bottom row:\nability to avoid phonological errors when speaking (p weight) was not positively correlated with ability to detect their\nown semantic errors (left) but was positively correlated with ability to detect their own phonological errors (right).\nFrom Nozari et al. (2011). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n525\nFindings\nNozari et  al. (2011) tested patients with aphasia (various language prob-\nlems; see Glossary) to decide whether their ability to detect their own speech\nerrors depends more on their comprehension or their speech-production\nability. There was practically no correlation between comprehension ability\nand error-detection performance. However, speech-production ability pre-\ndicted error detection (see Figure 11.2). Patients making many semantic\nspeech errors were much worse than other patients at detecting their own\nsemantic errors (r = –.59). Those making many phonological speech errors\nwere poorer at detecting their own phonological errors (r = –.43).\nBlackmer and Mitton (1991) assessed speed of error detection among\ncallers to a radio chat show. Many errors were detected very rapidly (e.g.,\n19% of overt corrections of what a caller had just said occurred immedi-\nately). For example, one caller said “willfiddily” and without any pause\nadded “fully”. In the study by Noteboom and Quené (2017) discussed\nearlier, 72% of the error-to-cut-off times were fast, which is consistent with\nconflict-based monitoring theory.\nGauvin et  al. (2016) studied the brain regions associated with error\ndetection in speech production and speech perception. Error detection in\nspeech production generally involved brain regions mostly independent\nof speech-perception systems. In addition, detection of speech-production\nerrors involved a cognitive control mechanism resolving conflict centred on\nthe anterior  cingulate cortex.\nOverall evaluation\nThere is support for the assumption of perceptual loop theory that speak-\ners monitor inner and overt speech. Its further assumption that monitor-\ning of overt speech is based on auditory feedback has also received some\nsupport. However, auditory feedback is used less often than implied by the\ntheory. Finally, the assumption that speech monitoring involves compre-\nhension-like processes appears mostly incorrect.\nSeveral findings support conflict-based monitoring theory. First, the\nsuccess of brain-damaged patients in detecting their own speech errors\ndepends largely on their speech-production ability. Second, the finding that\nspeakers often detect speech errors very rapidly suggests speech monitoring\noccurs within the speech-production system. Third, the brain regions asso-\nciated with the detection of speech errors are closer to those predicted by\nthis theory than by perceptual loop theory (Gauvin et al., 2016). However,\nthe theory is limited because it de-emphasises the role sometimes played by\nspeech-perception mechanisms in detecting speech-production errors.\nTHEORIES OF SPEECH PRODUCTION\nEarlier we mentioned four levels or stages of processing involved in speech\nproduction: semantic; syntactic; morphological; and phonological. There is\ncontroversy concerning the relationships between these levels or stages of\nprocessing in speech production. Two highly influential theories of speech\nproduction are Dell’s (1986) spreading-activation theory and Levelt et al.’s\nCreated from usyd on 2022-02-16 03:16:01.",
    "526\nLanguage\n(1999) WEAVER++ model (discussed in detail shortly, pp. 530–534).\nBelow we provide a brief preview of key differences between them.\nAccording to Dell’s (1986, 2013) spreading-activation theory, process-\ning can occur in parallel (at the same time) at different levels (e.g., seman-\ntic; syntactic). More specifically, it is assumed theoretically that processing\nis interactive. That means there can be cascade processing (see Glossary)\nwith the initiation of later processing stages occurring prior to the com-\npletion of processing at earlier stages. It also means processing can involve\nbottom-up feedback in addition to the top-down processing characteristic\nof speech production.\nIn contrast, Levelt et al. (1999) argued serial processing (one process at\na time) plays a major role in speech production. They also assumed within\ntheir WEAVER++ model that speech production involves a feedforward\nsystem with processing occurring in a strictly forward direction (i.e., from\nmeaning to sound). That assumption seems reasonable – it is plausible that\nspeakers decide the meaning they want to communicate before deciding on\nthe appropriate sounds to articulate.\nIn sum, the main assumptions of spreading-activation theory imply\nspeech-production processes are (if not chaotic) then at least very flexible.\nIn contrast, the main assumptions of WEAVER++ imply the processes\ninvolved in speech production are regimented and structured. However,\nthe actual theoretical differences are less extreme. Dell (1986) accepted\nprocessing at any given point in time is generally more advanced at some\nlevels (e.g., semantic) than others (e.g., phonological). Thus, the notions\nthat initial processing is mainly at the semantic and phonological levels\nwhereas later processing is mostly at the morphological and phonological\nlevels are common to both theories.\nWe will make two final preliminary points about the two theories.\nFirst, Goldrick (2006) proposed the compromise position that there is\n“limited interaction” in speech production. This makes sense – too much\ninteraction would lead to numerous speech errors whereas too little inter-\naction would inhibit speakers’ ability to produce interesting new sentences\nand new ideas.\nSecond, spreading-activation theory was initially based largely on evi-\ndence from speech errors. In contrast, WEAVER++ was based mostly on\nlaboratory studies of the time taken to speak words accurately in different\ncontexts. It is arguable (Goldrick, 2006) that interactive effects are more\nprevalent in speech-error data than response-time data. Speculatively, the\nspeech-production system may be most efficient when there is minimal\ndistraction and interference and so it operates approximately in line with\nthe assumptions of WEAVER++.\nFinally, speech production does not depend only on language- specific\nprocesses. Some more general processes (e.g., attention; short-term memory)\nare also important. We discuss relevant theory and research based on this\napproach at the end of this section (see pp. 535–536).\nSpreading-activation theory\nUnsurprisingly, the notion of spreading activation is central to Dell’s\n(1986) spreading-activation theory. It is assumed the nodes within a\nKEY TERMS\nSpreading activation\nActivation of a node\n(corresponding to a word\nor concept) in the brain\ncauses some activation to\nspread to several related\nnodes or words.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n527\nnetwork (nodes correspond to words or concepts) vary in activation or\nenergy. When a node or word is activated, activation or energy spreads\nfrom it to other related nodes or words. For example, strong activation of\nthe node corresponding to “tree” may cause some activation of the node\ncorresponding to “plant”. According to the theory, spreading activation\noccurs for sounds as well as words.\nThe theory assumes there are categorical rules at the semantic, syn-\ntactic, morphological and phonological levels of speech production. These\nrules impose constraints on acceptable categories of items and combina-\ntions of categories. The rules define categories appropriate at each level.\nFor example, the categorical rules at the syntactic level specify the syntac-\ntic categories of items within a sentence.\nThere is also a lexicon (dictionary) in the form of a connectionist\nnetwork. It contains nodes for concepts, words, morphemes and phonemes.\nWhen a node is activated, it sends activated to all the nodes connected to\nit (see Chapter 1).\nInsertion rules select items for inclusion in the representation of the\nto-be-spoken sentence according to the following criterion: the most acti-\nvated node belonging to the appropriate category is selected. For example,\nif the categorical rules at the syntactic level dictate a verb is required at a\ngiven point in the sentence, then the verb whose node is most activated will\nbe selected. After selection, the node’s activation level immediately reduces\nto zero to prevent it from being selected repeatedly.\nDell et al. (2008) focused on why we replace a noun with a noun and\na verb with a verb when making speech errors. They argued we possess a\n“syntactic traffic cop” that monitors what we intend to say and inhibits\nwords outside the appropriate syntactical category.\nAccording to the spreading-activation theory, speech errors occur\nbecause an incorrect item is sometimes more activated than the correct one.\nThe existence of spreading activation means several nodes are activated at\nthe same time, which increases the likelihood of speech errors. Dell et al.\n(2014) discuss the processes responsible for the occurrence of several major\nspeech errors (e.g., anticipatory errors; exchange errors).\nFindings\nWhat errors are predicted by spreading-activation theory? First, and of\nspecial importance, there is the mixed-error effect, which occurs when\nan incorrect spoken word is semantically and phonemically related to the\ncorrect word. The existence of this effect suggests semantic and phono-\nlogical factors can both influence word selection at the same time – this is\nconsistent with the notion the various levels of processing interact flexibly.\nAlternatively, a monitoring system may inhibit the production of words\nphonologically dissimilar to the intended word (Levelt et al., 1999).\nConvincing evidence for the mixed-error effect was provided by Ferreira\nand Griffin (2003). Participants read incomplete sentences (e.g., “I thought\nthat there would still be some cookies left, but there were . . .”) followed by\npicture naming (e.g., of a priest). In this example, participants tended to\nproduce the wrong word none due to the semantic similarity between priest\nand nun combining with the phonological identity of nun and none.\nKEY TERMS\nMixed-error effect\nA form of speech error in\nwhich the incorrect word\nspoken is related to the\ncorrect one in terms of\nboth meaning and sound.\nCreated from usyd on 2022-02-16 03:16:01.",
    "528\nLanguage\nSecond, speech errors typically consist of actual words rather than non-\nwords (the lexical bias effect). According to the theory, this effect occurs\nbecause it is easier for words than non-words to become activated because\nthey have representations in the lexicon (see Glossary). Alternatively,\nspeakers may monitor their inner speech and edit out non-words (monitor-\ning of inner speech was discussed earlier).\nThere is support for both explanations (Dell et al., 2014). Nooteboom\nand Quené (2008) found evidence for self-monitoring – speakers often cor-\nrected themselves just before producing an incorrect word (e.g., SAYING\nD . . . BARN DOOR when seeing BARN-DOOR).\nCorley et  al. (2011) asked people to say tongue twisters rapidly. In\none condition, all the stimuli were real words compared to only half in the\nsecond condition. There was the typical lexical bias effect in the all-word\ncondition, but the effect disappeared in the second condition. How can we\nexplain these findings? Since half the stimuli in the second condition were\nnon-words, speakers did not edit out non-words before speaking.\nThird, spreading-activation theory predicts speakers should make anti-\ncipatory errors in which a speech sound is made too early (e.g., “a Tanadian\nfrom Toronto” instead of “a Canadian from Toronto”). This prediction has\nbeen confirmed (e.g., Nooteboom & Quené, 2013). Anticipatory errors\noccur because many sentence words become activated during speech plan-\nning and sometimes a later word is more activated than the one that should\nbe spoken.\nFourth, many errors should be exchange errors in which two words\nwithin a sentence are swapped (e.g., “I must send a wife to my email”).\nThat is, indeed, the case (Nooteboom & Quené, 2013). Remember the acti-\nvation level of a selected word immediately reduces to zero. If “wife” is\nselected too early, it is unlikely to be selected in its correct place in the sen-\ntence. This allows a previously unselected but highly activated word such\nas “email” to be spoken in the wrong place.\nFifth, anticipation and exchange errors generally involve words moving\nonly a relatively short distance within the sentence. Those words relevant\nto the part of the sentence under current consideration are generally more\nactivated than those relevant to more distant parts of the sentence. Thus,\nthe findings accord with the predictions of spreading-activation theory.\nEvaluation\nSpreading-activation theory has several strengths:\n(1) The mixed-error and lexical bias effects indicate processing during\nspeech production can be highly interactive as predicted theoretically.\n(2) The theory can also explain several other speech errors (e.g., exchange\nerrors; anticipatory errors).\n(3) The theory’s emphasis on spreading activation provides links between\nspeech production and other cognitive activities (e.g., word recogni-\ntion: McClelland & Rumelhart, 1981).\n(4) Our ability to produce novel sentences may depend in part on the\nflexibility resulting from widespread activation between processing\nlevels assume by the theory.\nKEY TERM\nLexical bias effect\nThe tendency for speech\nerrors to form words\nrather than non-words.\nLexicon\nAn individual’s internal\ndictionary containing\ninformation about word\nmeanings.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n529\n(5) Dell’s (1986) original theory was vulnerable to the charge that it\npredicted too many speech errors. However, Nozari et al. (2011; dis-\ncussed earlier, pp. 523–525) improved the theory by adding mecha-\nnisms for monitoring and editing out errors early in processing.\nWhat are the theory’s limitations?\n(1) It de-emphasises processes involved in the construction of a message\n(including its intended meaning). It also fails to consider audience\ndesign (how speakers respond to the needs of their audience; dis-\ncussed later, pp. 544–547).\n(2) It does not predict the time taken to produce correct and incorrect\nspoken words.\n(3) The interactive processes emphasised by the theory are less apparent\nin error-free than speech-error data (Goldrick, 2006). For example, the\nprocesses involved in correct versus incorrect picture naming differ.\nPrincipe et al. (2017) found brain activity within large regions of the\nparietal and temporal cortex differed between correct and incorrect\nnaming within approximately 100 ms of picture presentation.\n(4) There is insufficient emphasis in the theory on factors influencing\nthe extent of interactive processes in speech production. There is less\ninteractive processing when overall processing demands are high than\nwhen they are low (Mädebach et al., 2011; discussed shortly, p. 533).\nAnticipatory and perseveration errors\nDell et al. (1997) developed spreading-activation theory. They argued most\nspeech errors belong to two categories:\n(1) Anticipatory: as discussed earlier, sounds or words spoken ahead of\ntheir time (e.g., “caff of coffee” instead of “cup of coffee”). These\nerrors mainly reflect inexpert planning.\n(2) Perseveratory: sounds of words are spoken later than they should have\nbeen (e.g., “beef needle” instead of “beef noodle”). These errors reflect\nplanning failure or a failure to monitor what one is about to say.\nSuppose we compare speakers engaging in much forward planning with\nthose doing much less forward planning. According to Dell et al. (1997),\nthose planning ahead should make more anticipatory errors. They\nfocused on the anticipatory proportion (the proportion of total errors\n[anticipation + perseveration] that is anticipatory) and argued this should\ncorrelate positively with speakers’ tendency to plan ahead.\nFindings\nDell et al. (1997) gave speakers extensive practice at saying tongue twisters\n(e.g., five frantic fat frogs; thirty-three throbbing thumbs). They argued prac-\ntice would lead to more forward planning and so increase the anticipatory\nproportion. As predicted, the anticipatory proportion increased from .37\nearly in practice to .59 at the end of practice.\nCreated from usyd on 2022-02-16 03:16:01.",
    "530\nLanguage\nDell et al. (1997) also argued that requiring participants to speak more\nrapidly would reduce forward planning and so decrease the anticipatory\nproportion. This prediction was supported by Vousden and Maylor (2006)\nin a study in which children and young adults said tongue twisters slowly\nor fast. Wutzler et al. (2013) assessed the anticipatory proportion in elderly\nindividuals. Those with cognitive impairment had a significantly lower\nanticipatory proportion than those without, presumably because they were\nless able to plan their utterances.\nFossett et al. (2016) asked speakers to say tongue twisters at three dif-\nferent rates: typical; fast; or faster. The anticipatory proportion was small-\nest at the typical speaking rate – this is opposite to theoretical prediction.\nHow can we explain the above unexpected finding? Dell et al. (1997)\nargued the anticipatory proportion will be greatest at a slow speaking rate\nbecause it permits much forward planning. This prediction involves the\nassumption that words later in the sentence remain activated long enough\nto produce anticipatory errors. If word activation decays rapidly, then the\nfindings of Fossett et al. (2016) can be explained.\nLevelt’s theoretical approach and WEAVER++\nLevelt et al. (1999) put forward a computational model called WEAVER++\n(WEAVER stands for Word-form Encoding by Activation and\nVERification). The model focuses on the processes involved in producing\nindividual spoken words and makes the following assumptions:\n●\nThere is a feedforward activation-spreading network meaning that\nactivation proceeds forwards through the network but not backwards.\nOf particular importance, processing proceeds from meaning to sound.\n●\nThere are three main levels within the network:\n(i)\nAt the highest level are nodes representing lexical concepts.\n(ii)\nAt the second level are nodes representing lemmas from the\nmental lexicon. Lemmas are word representations that “are\nspecified syntactically and semantically but not phonologically”\n(Harley, 2013). Thus, if you know the meaning of a word you\nare about to say and that is a noun, but you do not know its\npronunciation, you have accessed its lemma.\n(iii)  At the lowest level are nodes representing word forms in terms\nof morphemes (basic units of meaning) and their phonemic\nsegments.\n●\nLexical (word) selection depends on a competitive process based on the\nnumber of lexical units activated.\n●\nSpeech production following lexical selection involves various process-\ning states following each other in serial fashion (one at a time).\n●\nSpeech errors are avoided by means of a checking mechanism based\non the speaker monitoring what they say (discussed earlier, see\npp. 523–525).\nIt is easy to get lost in the model’s complexities (agreed?). In essence,\nhowever, the model shows how word production proceeds from meaning\n(lexical concepts and lemmas) to sound (e.g., phonological words). There is\nKEY TERM\nLemmas\nAbstract words possessing\nsyntactic and semantic\nfeatures but not\nphonological ones.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n531\na stage of lexical selection at which a lemma (representing word meaning +\nsyntax) is selected. A given lemma is generally selected because it is more\nactivated than other lemmas.\nThen there is morphological encoding during which the basic word\nform of the selected lemma is activated. This is followed by phonologi-\ncal encoding – the word’s syllables are computed. What happens is known\nas lexicalisation, “the process in speech production whereby we turn the\nthoughts underlying words into sounds” (Harley, 2013).\nThe most important development of Levelt et  al.’s (1999) approach\ninvolved identifying the brain regions associated with the various processes\nwithin the model (Indefrey & Levelt, 2004). This development means neu-\nroimaging techniques can be used to test the model’s predictions.\nIn sum, WEAVER++ is a discrete, feedforward model. Processing\nis discrete (separate), because the speech-production system identifies the\ncorrect lemma or abstract word before starting to work out the sound\nof the selected word. It is feedforward, because processing proceeds in a\nstrictly forward (from meaning to sound) direction.\nFindings\nAccording to the model, speakers process syntactic (e.g., a noun’s gender)\nand phonological information sequentially. Bürki et  al. (2016) tested this\nassumption using event-related potentials (ERPs; see Glossary). As pre-\ndicted, the evidence from ERPs suggested syntactic and phonological pro-\ncessing occurred at different times. Van Turennout et al. (1998) used ERPs\nwith Dutch participants and found syntactic information about a noun’s\ngender was available 40 ms before its initial phoneme. This is consistent\nwith Levelt’s theoretical approach.\nIndefrey (2011) carried out a meta-analysis of studies using ERPs\nand other techniques to assess brain activation during speech production.\nThe right column of Figure 11.3 provides approximate timings for major\nspeech-production processes. Conceptual preparation takes about 200 ms.\nAfter that, lemma retrieval takes 75 ms, and phonological code retrieval\ntakes 20 ms per phoneme and 50–55 ms per syllable. Finally, phonetic\nencoding with articulation typically starts about 600 ms after the initiation\nof processing. The left-hand side of Figure 11.3 is colour coded to indi-\ncate the various brain regions in the left hemisphere associated with each\nprocess.\nThere are limitations with Indefrey’s (2011) meta-analysis. First, most\nresearch involved picture naming meaning the focus of the meta-analysis is\nnarrow. Second, the timings are with respect to stimulus presentation. Since\nspeech production is more concerned with action than perception, it would\nbe preferable to focus on how long a given process occurs prior to speech\nonset. Third, the neat-and-tidy impression created by Figure 11.3 is mis-\nleading (see below, p. 532). Recent cognitive neuroscience research relevant\nto Dell’s and Levelt’s theoretical approaches is discussed in the next section.\nWe can see the distinction between a lemma and the word itself in\nthe tip-of-the-tongue state. The tip-of-the-tongue state occurs when we\nhave a concept or idea in mind (i.e., we have activated the correct lemma\nor abstract word) but cannot find the appropriate word (i.e., phonological\nKEY TERMS\nLexicalisation\nThe process of translating\na word’s meaning into\nits sound representation\nduring speech production.\nTip-of-the-tongue state\nThe frustrating experience\nof being unable to find\nthe correct word to\ndescribe a given concept\nor idea.\nCreated from usyd on 2022-02-16 03:16:01.",
    "532\nLanguage\nprocessing is unsuccessful). Harley and Bown (1998) found the tip-of-the-\ntongue state was especially frequent for words sounding unlike nearly all\nother words (e.g., apron; vineyard ) – their unusual phonological forms\nmake them hard to retrieve.\nLevelt et  al. (1999) claimed the lemma includes syntactic as well as\nsemantic information. Accordingly, individuals in the tip-of-the-tongue\nstate should have access to syntactic information. In many languages (e.g.,\nItalian; German), grammatical gender (e.g., masculine; feminine) is part\nof the syntactic information relating to nouns. As predicted, Italian par-\nticipants in the tip-of-the-tongue state for nouns guessed the grammatical\ngender correctly 85% of the time (Vigliocco et al., 1997).\nBiedermann et  al. (2008) reported less supportive findings. German\nspeakers guessed the grammatical gender and initial phoneme of nouns\nwhen in a tip-of-the-tongue state. Theoretically, access to grammatical\ngender precedes access to phonological information and so participants\nshould have guessed the first phoneme more often when they had access to\naccurate gender information. However, that was not the case.\nResnik et  al. (2014) used magneto-encephalography (MEG; see\nGlossary) while individuals were in the tip-of-the-tongue state when trying\nFigure 11.3\nThe right side of the figure indicates the sequence of processes (and their timings) for picture naming. Identical colours\non the left side of the figure indicate the brain regions associated with each process (the numbers within regions are the\nmedian peak activation times in msec after picture onset).\nFrom Indefrey (2011).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n533\nto identify pictures of celebrities. They predicted brain areas associated with\nsemantic and syntactic processing (i.e., lemma selection) should be activated\nshortly after picture presentation. In contrast, brain areas associated with\nmotor programming and articulation should be activated shortly before\nthe correct word was produced. The predicted brain areas were activated.\nHowever, semantic and motor areas were activated during both time periods\nsuggesting processing was more interactive than assumed within the model.\nAccording to WEAVER++, abstract word or lemma selection is com-\npleted before phonological information about the word is accessed. In con-\ntrast, Dell’s spreading-activation theory assumes phonological processing\ncan start before lemma or word selection is completed. Most evidence is\ninconsistent with WEAVER++’s prediction. Meyer and Damian (2007)\nrequired participants to name target pictures while ignoring distractor\npictures. According to WEAVER++, the phonological features of distrac-\ntor names should not have been activated. However, target pictures were\nnamed more slowly when accompanied by phonological related distractors\n(e.g., wall when ball was the target). In similar fashion, Roux and Bonin\n(2016) found naming times for a coloured target object (e.g., banana)\nslowed when a distractor was phonologically related to the target’s colour\n(e.g., yellow).\nMädebach et al. (2011) found picture naming was slowed in the pres-\nence of a phonologically similar distractor word only when the overall pro-\ncessing demands were relatively low. What do these findings mean? Serial\nprocessing (as predicted by Levelt) occurred when processing demands\nwere high. In contrast, processing was more interactive (as predicted by\nDell) when processing demands were low.\nEvaluation\nWEAVER++ has various successes to its credit. First, the assumption\nword production involves a series of stages moving from lexical selection\nto morphological encoding to phonological encoding is reasonably accurate\n(Indefrey, 2011; however, see next section, pp. 534–535). Second, Levelt’s\ntheoretical approach was important in shifting the balance of research away\nfrom speech errors (which are relatively rare) towards precise timing of\naccurate word-production processes. Third, WEAVER++ is a simple and\nelegant model making many testable predictions. It is arguably easier to\ntest WEAVER++ than more interactive theories such as Dell’s spreading-\nactivation theory. Fourth, lexical or word selection often involves a com-\npetitive process as assumed theoretically.\nWhat are the limitations with WEAVER++?\n(1) It focuses narrowly on processes involved in the production of single\nwords and so several processes involved in planning and producing\nsentences are de-emphasised.\n(2) There are many more interactions between different processing levels\nthan assumed within WEAVER++ (see next section, pp. 534–535).\nAs Melinger et al. (2014, p. 676) argued, “It is a plausible hypothesis\nthat the language production system is fundamentally parallel in its\noperation.”\nInteractive exercise:\nWEAVER++\nCreated from usyd on 2022-02-16 03:16:01.",
    "534\nLanguage\n(3) The evidence from speech errors (e.g., the mixed-error effect, the\nlexical bias effect, word-exchange errors, and sound-exchange errors)\nindicates more parallel processing than predicted by WEAVER++.\n(4) As Harley (2013) pointed out, “The need for lemmas is [not] strongly\nmotivated by the data. Most of the evidence really only demands a\ndistinction between the semantic and the phonological levels.”\nCognitive neuroscience\nEarlier we discussed Indefrey’s (2011) meta-analysis of ERP and other\nstudies that provided strong support for WEAVER++. Munding et  al.\n(2016) reported a similar meta-analysis to Indefrey (2011) based on simple\nspeech-production tasks (e.g., picture naming; reading aloud). However,\nthey included only studies using magneto-encephalography (whereas\nIndefrey (2011) focused mostly on ERP studies. This is important because\nMEG has superior spatial resolution.\nMunding et al.’s (2016) findings are shown in Figure 11.4. First, Levelt\net al.’s (1999) assumption that cognitive functions near the top of the figure\noccur earlier than those further down was supported. Second, as Munding\net  al. concluded, “There is a great deal of overlap in diverse functions’\nactive periods, and substantial numbers of reports of theoretically ‘late’\nfunctions being implicated early” (p. 452). For example, several studies\nfound evidence of articulatory processing approximately 300–500 ms before\nthe appropriate response is produced.\nDubarry et al. (2017) assessed brain activity during a picture naming\ntask. They replicated Munding et  al.’s (2016) findings when using the\ntypical procedure of averaging data across trials. However, they argued\nthe averaging approach can provide “a blurred view of the underlying pro-\ncesses” (p. 415). When they focused at the level of single trials, there was\nmuch less evidence of parallel processing. Thus, findings based on averaged\ndata may exaggerate the extent of parallel processing in speech production.\nIn sum, evidence obtained using the techniques of cognitive neuro-\nscience provides a complex picture. What conclusions can we draw? First,\nFigure 11.4\nThe timing of activation\nassociated with different\ncognitive functions (colour\nindicates the number of\nstudies reporting activity\nrelated to a given function).\nFrom Munding et al. 2016.\nNumber of activations\nCognitive function\n7\n6\n5\n4\n3\n2\n1\n0\n500\n600\nTime (ms)\n400\n200\n0\nVis. Processing\nConceptual prep.\nLemma sel.\nPhon. code ret’l\nSyllabifcation\nArticulation\nSelf monitoring\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n535\nas Riès (2016, p. 476) noted, “Areas associated with lemma selection are\ngenerally active before those involved in phonological code retrieval, which\nare themselves generally active before those associated with articulation.”\nSuch findings support Levelt et al.’s (1999) theoretical approach.\nSecond, brain areas associated with supposedly “late” processes (e.g.,\nphonological processes) are often active much earlier than predicted by\nLevelt et al. Perhaps top-down processes anticipate or predict the processes\nnecessary later in speech production.\nSpeech production: general cognitive processes\nFifty years ago, it was often assumed humans possessed “language genes”\nand that language involves processes very different from those used in other\ncognitive tasks. Those assumptions have been increasingly rejected. It is\nnow recognised that general processes (e.g., short-term memory; attention;\ncognitive control) play an important role in language processing (including\nspeech production). Here we will briefly consider some relevant research.\nAs mentioned earlier, Christiansen and Chater (2016) argued the very\nlimited capacity of short-term memory means speakers (and listeners to\nspeech) have to deal with a “now-or-never” bottleneck: “If linguistic infor-\nmation is not processed rapidly, that information is lost for good” (p. 3).\nHow do speakers cope with this bottleneck? According to Christiansen\nand Chater (2016), children learn to form chunks (see Glossary) in which\nfrequently encountered words are grouped together in long-term memory.\nAs a result, an ever-increasing number of chunks is stored in a “chunka-\ntory”. This reduces processing demands by allowing speakers to focus on\nretrieving entire phrases (rather than single words) from long-term memory.\nMacDonald (2016) argued that there are important similarities\nbetween utterance planning (transient memory of what is to be spoken)\nand verbal memory (e.g., immediate serial recall of a word list). Here\nare some examples: (1) words close to each other are most likely to be\nexchanged; (2) similar words interfere with each other; (3) there are more\nerrors in long lists/sentences than short ones. These findings suggest the\nprocesses involved in speech planning closely resemble those involved in\nverbal short-term memory.\nProficient bilinguals rarely allow words from their unintended lan-\nguage to intrude into their speech. Top-down inhibitory processes play an\nimportant role in this achievement (Kroll & Navarro-Torres, 2018). For\nexample, consider a Friulian-Italian bilingual patient (LI) with damage\nto the frontal cortex and anterior cingulate (brain areas associated with\ntop-down control). He switched into Italian 40% of the time when he was\nmeant to be speaking Friulian and into Friulian 43% of the time when\nItalian was required (Fabbro et al., 2000).\nOn the picture naming task, participants show interference when a\nword distractor is presented together with each picture. Inhibitory pro-\ncesses are required to minimise such interference. Patients with damage to\nthe lateral prefrontal cortex (involved in inhibition) have larger interfer-\nence effects than healthy controls (Piai et al., 2016).\nJongman et al. (2017) studied the relationship between sustained atten-\ntion and picture naming. Individuals with superior levels of sustained\nCreated from usyd on 2022-02-16 03:16:01.",
    "536\nLanguage\nattention had better picture naming performance than those with low\nlevels. McClain and Goldrick (2018) discussed other research indicating\nthe importance of attentional processes in speech production.\nIn sum, general processes (e.g., attention; short-term memory; inhi-\nbition), de-emphasised in spreading-activation theory and WEAVER++,\nstrongly influence speech production. For example, speakers’ use of inhibi-\ntory and other general processes may explain why the interactive processes\nemphasised within spreading-activation theory do not lead to numerous\nspeech errors. In future, it will be important to develop theories indicating\nhow general and language-specific processes combine in speech production.\nCOGNITIVE NEUROPSYCHOLOGY: SPEECH\nPRODUCTION\nThe cognitive neuropsychological approach to language started in the nine-\nteenth century. Its focus was on brain-damaged patients with aphasia, a\ncondition involving severe impairments in language comprehension and/or\nproduction.\nEarly researchers distinguished between Broca’s and Wernicke’s\naphasia. Patients with Broca’s aphasia have slow, non-fluent speech. They\nalso have a poor ability to produce syntactically correct sentences, but\ntheir sentence comprehension is relatively intact. Broca’s aphasia is gener-\nally assumed to involve BA44 and BA45 in the inferior frontal gyrus (see\nFigure 11.5).\nIn contrast, patients with Wernicke’s aphasia have fluent and appar-\nently grammatical speech that often lacks meaning. They also have severe\nproblems with speech comprehension. Wernicke’s aphasia is generally\nassumed to involve the posterior part of BA22 in the superior temporal\ngyrus (see Figure 11.5). In sum, the traditional approach assumed impaired\nlanguage production was of central importance in Broca’s aphasia whereas\nimpaired language comprehension was central to Wernicke’s aphasia.\nDronkers et al. (2017) reviewed the relevant evidence and reported very\nlimited support for the traditional approach. That approach was much\nKEY TERMS\nAphasia\nSevere problems in the\ncomprehension and/or\nproduction of language\ncaused by brain damage.\nWernicke’s aphasia\nA form of aphasia\ninvolving fluent speech\nwith many content words\nmissing and impaired\ncomprehension.\nBroca’s aphasia\nA form of aphasia\ninvolving non-fluent\nspeech and grammatical\nerrors.\nFigure 11.5\nLanguage-related regions and their connections in the left hemisphere. PMC, premotor\ncortex; STC, superior temporal cortex; p, posterior.\nBerwick et al. (2013). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n537\noversimplified in several ways. First, there is no consensus concerning the\nscope of Broca’s area or Wernicke’s area! Tremblay and Dick (2016) found\nthe most popular definition of Wernicke’s area by experts was “the poste-\nrior part of the superior temporal gyrus and including part of the supramar-\nginal gyrus” (p. 63) endorsed by 26% of respondents. The other respondents\nendorsed smaller or larger areas. The most popular definition of Broca’s\narea (endorsed by 50%) was that it consisted of the pars triangularis and\npars opercularis with the remaining 50% identifying a smaller or larger area.\nSecond, most aphasic patients have extensive brain damage (Flinker &\nKnight, 2018). As a result, the role played by Wernicke’s area of Broca’s\narea (however defined) is hard to establish. However, Flinker et al. (2015)\nfound, by using precisely targeted electrical stimulation of the cortex, that\nBroca’s area supports articulatory planning but is not directly involved in\nproduction of spoken words.\nThird, “The areas of the brain that support language are far more\nextensive than Broca or Wernicke could ever have imagined” (Dronkers\net al., 2017, p. 750). As we saw earlier, speech production involves general\nprocesses (e.g., attention; cognitive control) as well as language-specific\nprocesses (McClain & Goldrick, 2018). Language comprehension also\ninvolves similar general processes within a “multiple demand” network\nincluding several prefrontal areas (Blank & Fedorenko, 2017).\nFourth, the finding that Broca’s patients find it much harder than\nWernicke’s patients to speak grammatically is more common in English-\nspeaking than German- or Italian-speaking patients. English is less inflected\nthan German or Italian (with inflected languages, grammatical changes to\nnouns and verbs are indicated by changes to the words themselves). As\na result, the grammatical limitations of English-speaking patients with\nWernicke’s aphasia are less obvious (Dick et al., 2001).\nFifth, aphasic patients may have general problems relating to attention\nand memory in addition to specific language impairments (McNeil et al.,\n2010). For example, healthy individuals naming pictures rapidly make\nerrors resembling those of stroke aphasics with semantic impairments\n(Hodgson & Lambon Ralph, 2008). Thus, picture naming errors by apha-\nsics may partly reflect reduced processing resources or semantic control.\nIn sum, the traditional approach is very limited. Accordingly, the\nemphasis has shifted towards systematic attempts to understand relatively\nspecific cognitive impairments (see below).\nAnomia\nNearly all aphasics (regardless of the type of aphasia) suffer from anomia\n(an impaired ability to name objects). Within Levelt et  al.’s (1999)\nWEAVER++ model, there are two reasons aphasics might have problems\nwith lexicalisation (translating a word’s meaning into its sound):\n(1) There could be problems at the semantic level (i.e., selecting the\nappropriate lemma or abstract word). In that case, naming errors\nwould resemble the correct word in meaning.\n(2) There could be problems at the phonological level, in which case\npatients would be unable to find the appropriate form of the word.\nKEY TERM\nAnomia\nA condition caused by\nbrain damage in which\nthere is an impaired ability\nto name objects.\nCreated from usyd on 2022-02-16 03:16:01.",
    "538\nLanguage\nFindings\nLaganaro et al. (2009) divided aphasic patients into semantic and phono-\nlogical groups based on their main cognitive impairment on various tasks.\nBoth groups were then given a picture naming task and event-related poten-\ntials were recorded to assess the time course of processing. The semantic\ngroup had ERP abnormalities early (100–250 ms after picture onset). In\ncontrast, the phonological group only had later abnormalities (300–450 ms\nafter picture onset). Thus, anomia can result from an early semantic stage\n(finding the correct word) or a later phonological stage (generating the\nword’s phonological form).\nPatients with anomia having problems at the phonological (but not\nthe semantic) level often resemble healthy individuals in a tip-of-the-tongue\nstate (discussed earlier, see pp. 531–532). As a result, we might expect such\npatients to experience the tip-of-the-tongue state very frequently. Patients\nfitting this pattern (and having particular problems in producing low-\nfrequency names) have been identified (Funnell et al., 1996).\nGvion and Friedmann (2016) clarified the mechanisms involved in\npatients with anomia who have phonological problems. They focused on\nthe phonological output lexicon, which contains the representation of a\nword’s spoken form (e.g., number of syllables; consonants; vowels). It is\norganised by word frequency so high-frequency words are more accessi-\nble than low-frequency ones. Gvion and Friedmann found several patients\nwith anomia had an impaired phonological output lexicon. However, these\npatients performed well on a word-comprehension task suggesting their\nsemantic processing was reasonably intact.\nNardo et al. (2018) studied 18 aphasic patients whose comprehension\nof spoken words was good. They used a treatment programme focusing\non patients’ phonological problems: on a picture naming task, phonemic\ncues (e.g., initial phoneme of the word) were presented. This treatment\nproduced short-term and long-term improvements in naming ability.\nDiscovering anomia can result from difficulties at the semantic and/\nor phonological levels is consistent with serial models (e.g., Levelt et al.’s\nWEAVER++). However, it does not rule out interactive models (e.g., Dell’s\nspreading-activation theory). Soni et  al. (2009) compared these models\nusing a picture naming task in three conditions differing in the cues accom-\npanying each picture: (1) correct cues (e.g., lion + the cue l ); (2) incorrect\ncues (e.g., lion + the cue t which misleadingly suggests tiger): (3) no cue.\nAccording to Levelt’s model, speakers determine the lemma (abstract\nword) appropriate to the object before using phonological information gen-\nerated by the cues. Thus, an incorrect phonological cue should not impair\nperformance. Interactive models make the opposite prediction. Word selec-\ntion can be influenced by phonological activation and this can enhance (or\nimpair) performance depending on whether the cue is correct or incorrect.\nThe findings supported interactive models over serial ones.\nSoni et  al. (2011) extended their research. Aphasics viewed pictures\naccompanied by a sound and named the picture. There were four condi-\ntions determined by the relationship between picture and sound. Suppose\nthe picture showed a candle. The sound could be l (related category –\nsuggests lamp), w (associate word – suggests wax), or neutral (g). Naming\nKEY TERM\nPhonological output\nlexicon\nIt contains information\nabout the spoken form\nof words (e.g., number\nof syllables) and is used\nin object naming and\nreading aloud.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n539\nperformance was worse in these conditions than when the sound was k\n(suggesting the correct answer). These findings suggest (contrary to Levelt\net  al., 1999) that semantic processing is not necessarily complete before\nphonological processing starts.\nEvaluation\nMuch research on anomia is consistent with Levelt et al.’s (1999) notion that\nproblems with word retrieval can occur at two different stages: (1) abstract\nword (lemma) selection; and (2) accessing the phonological form of the\nword. However, there is a potential problem with that explanation. There\nis suggestive evidence (Soni et al., 2009, 2011) for more interaction between\nsemantic and phonological processing than assumed by Levelt et al. (1999).\nAgrammatism\nIt is often assumed (e.g., Dell, 1986) that speaking involves separate stages\nof working out the syntax or grammatical structure of utterances and\nthen producing content words to fit that grammatical structure. Patients\nwho apparently can find the appropriate words but not order them gram-\nmatically suffer from agrammatism (literally “without grammar”). Such\npatients produce short sentences containing content words (e.g., nouns;\nverbs) but lacking function words (e.g., the, in, and) and inflections (see\nGlossary). These omissions are important. For example, function words\nplay a key role in producing a grammatical structure for sentences. As we\nwill see, the agrammatic patients’ problems with syntactic processing often\nextend to language comprehension as well as speech.\nUse of the term “agrammatism” implies it forms a syndrome with all\nagrammatic patients having the same symptoms and with the same brain\nareas involved in most (or all) cases. It is the case that most agrammatic\npatients have damage to Broca’s area (BA44/45; see Figure 11.5) (Cappa,\n2012). However, agrammatism is not a syndrome – many patients possess\nonly some symptoms typical of agrammatism (Harley, 2013).\nFindings\nEngel et al. (2018) studied language comprehension in patients with agram-\nmatic aphasia presented with sentences such as:\n(1) The grandma said that the baker cleaned herself with a clean\nwashcloth.\n(2) The grandma said that the baker cleaned her with a clean washcloth.\nThe above sentences differ only in that the pronoun in (1) is reflexive (i.e.,\nherself  ) whereas the pronoun in (2) (i.e., her) is not. Healthy controls had\naccurate comprehension of both types of sentences on over 90% of trials. In\ncontrast, agrammatic patients performed much worse on sentences such as\n(2) (63% vs 90%, respectively).\nWhat do the above findings mean? Sentences such as (2) are slightly\nmore complex grammatically. Agrammatic patients were  considerably\nKEY TERM\nAgrammatism\nLiterally, “without\ngrammar”; a condition in\nwhich speech production\nlacks grammatical\nstructure and many\nfunction words and word\nendings are omitted;\nthere are often also\nproblems with language\ncomprehension.\nCreated from usyd on 2022-02-16 03:16:01.",
    "540\nLanguage\nmore  affected by this increased complexity than healthy controls, which\nmay reflect reduced computational resources in agrammatic individuals.\nFaroqui-Shah and Friedman (2015) considered verb tense impairment.\nIt involves a failure to change the forms of verbs to reflect whether the\nreference is to the past, the present, or the future (e.g., omitting -ed when\nusing a verb in the past tense). Agrammatic individuals had greater verb\ntense impairment when the task was more demanding (e.g., picture descrip-\ntion) than when it was less demanding (e.g., grammaticality judgement).\nThey argued that these findings suggest that agrammatic individuals have\nreduced computational resources.\nBeeke et  al. (2007) studied an agrammatic patient in the laboratory\n(using artificial tasks) and while conversing at home. His speech was more\ngrammatical in the latter situation. Rhys et al. (2013) studied an  agrammatic\npatient who used prosodic cues (e.g., stress; intonation) to communicate\nmeanings and grammatical structures despite very limited speech.\nChristiansen et  al. (2010) also considered whether the deficits of\nagrammatic patients are specific to language or whether they are more\ngeneral. They found agrammatic patients with damage to Broca’s area\n(BA44/45) showed impaired sequence learning as well as grammaticality,\nindicating their deficits extend beyond language. How can we explain these\nfindings? It seems reasonable that a deficit in sequence learning could lead\nto the production of ungrammatical sentences given the great dependence\nof grammaticality on appropriate word order. Uddén et  al. (2017) pro-\nduced further evidence for the role of Broca’s area in sequence learning.\nTranscranial magnetic stimulation (TMS; see Glossary) applied to that\narea indicated it plays a causal role in sequence learning.\nGriffiths et al. (2013) shed light on brain pathways involved in syntac-\ntic processing. They studied patients with damage to a dorsal pathway con-\nnecting part of Broca’s area (BA44) with part of Wernicke’s area (middle\ntemporal gyrus) and/or a ventral pathway connecting another part of\nBroca’s area (BA45) with Wernicke’s area. Participants listened to sentences\n(e.g., “The woman is hugged by the man”) and then selected a drawing: (1)\nFigure 11.6\nSemantic errors (left) and syntactic (right) errors made by: healthy controls and patients with no damage to the dorsal (D)\nor ventral (V) pathway, damage to the ventral pathway only, damage to the dorsal pathway only and damage to both\npathways.\nFrom Griffiths et al. (2013). By permission of Oxford University Press.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n541\nthe correct one; (2) a syntactic distractor (e.g., a woman hugging a man); or\n(3) a semantic distractor (e.g., a man painting a woman).\nWhat did Griffiths et al. (2013) find? Patients with damage to either or\nboth pathways made many more syntactic errors than controls or patients\nwith damage to neither pathway (see Figure 11.6). However, very few\nsemantic errors were made by any of the patient groups and the same was\ntrue on other semantic comprehension tasks.\nEvaluation\nResearch on agrammatism can be related to Dell’s (1986) identification of\nfour levels (semantic; syntactic; morphological; and phonological) of speech\nproduction. More specifically, agrammatics primarily have problems at the\nsyntactic level at which the grammatical structure of a sentence is formed\n(Dell, 1986). Of theoretical importance, there is accumulating evidence that\nagrammatic individuals have general deficits as well as language-specific\nones. For example, they have impaired sequence learning and reduced pro-\ncessing or computational resources.\nWhat are the limitations of research on agrammatism? First, the symp-\ntoms of agrammatic patients are too diverse for it to form a syndrome.\nSecond, agrammatic patients may possess more grammatical competence\nthan generally assumed. Third, more research is required to establish the\nextent to which agrammatism involves language-specific deficits versus\nmore general ones.\nJargon aphasia\nJargon aphasia “is an extreme form of fluent aphasia in which syntax is\nprimarily intact, but speech is marked by gross word-finding difficulties”\n(Harley, 2013). This pattern is superficially the opposite to that of patients\nwith agrammatism, who can find the correct content words but cannot\nproduce grammatically correct sentences. Jargon aphasics often produce\njargon (including neologisms, which are made-up words, and real words\nunrelated phonologically to the target word). Finally, jargon aphasics have\ndeficient self-monitoring – they are generally unaware their speech con-\ntains numerous errors and become irritated when others fail to understand\nthem.\nHere is how a jargon aphasic described a picture (Sampson & Faroqui-\nShah, 2011):\nIt’s not a large house, it’s small, unless an awful lot of it goes back\nbehind the hose. They are whiking what they are doing in the front\npart which must be peeving . . . leeling . . . weeding . . . there is a nico-\nverit spotole for the changer.\nFindings\nHow grammatical is the speech of jargon aphasics? If they engage in syn-\ntactic processing, their neologisms or made-up words might possess appro-\npriate prefixes or suffixes to fit the structure of the sentences in which they\nKEY TERMS\nJargon aphasia\nA brain-damaged\ncondition in which speech\nis reasonably correct\ngrammatically but there\nare severe problems in\naccessing the appropriate\nwords.\nNeologisms\nMade-up words produced\nby patients suffering from\njargon aphasia.\nCreated from usyd on 2022-02-16 03:16:01.",
    "542\nLanguage\nappear. Jargon aphasics generally modify their neologisms in this way\n(Butterworth, 1985).\nWhat factors determine the specific form of jargon aphasics’ neologisms?\nFirst, and of most importance, they exhibit a failure of phoneme selection\neven when the appropriate target word is initially selected. For example,\nOlson et  al. (2015) studied three jargon aphasic patients who performed\nnaming, repetition, and reading tasks. More specifically, the phonemes from\ntarget words were often only weakly activated and so were outcompeted\nby non-target phonemes. These non-target phonemes were often phonologi-\ncally related to target phonemes or were phonemes used recently.\nPilkington et  al. (2017) analysed the neologisms produced by 25\npatients with jargon aphasia. Those produced by 23 of these patients were\nrelated phonologically to the target (intended) word. These findings also\nindicate a major role for deficient phonological encoding in the production\nof neologisms.\nIf impaired phoneme selection is responsible for patients’ impaired\nspeech production, therapy designed to enhance phonemic processing\nmight prove beneficial. Bose (2013) found that therapy focused on gener-\nating and analysing phonological features of words reduced the number of\nneologisms produced by FF, a man with jargon aphasia.\nSecond, deficient self-monitoring plays a major role in jargon aphasia.\nSampson and Faroqui-Shah (2008) obtained a negative correlation between\nself-monitoring and the production of jargon in jargon aphasics. Eaton\net al. (2011) studied a male jargon aphasic (TK) over a 21-month period.\nHis improved word naming performance over time correlated highly with\nincreased self-monitoring suggesting inadequate self-monitoring played a\nrole in TK’s initially poor performance.\nThird, the production of jargon by jargon aphasics is sometimes influ-\nenced by impaired general cognitive abilities. For example, Robinson et al.\n(2015) studied a male jargon aphasic (JA) who produced almost mean-\ningless sentences. He had impaired cognitive control and so he had no\n“brake” inhibiting production of meaningless phrases.\nEvaluation\nSeveral factors responsible for jargon aphasics’ production of neologisms\nand other jargon have been identified. Impaired phoneme selection is typ-\nically of most importance. Some evidence indicates that jargon aphasics\noften have impaired cognitive or inhibitory control (linked to deficient\nself-monitoring) as well as more language-specific deficits.\nA limitation of much research is that insufficient attention has been\npaid to possible semantic deficits in addition to problems with phoneme\nselection (Harley, 2013). More research is also needed to assess more\nprecisely the grammaticality (or otherwise) of jargon aphasics’ spoken\nutterances.\nConclusions\nMost theories of speech production are based on the assumption, “There are\nindependent levels of representation/processing that encode word meaning\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n543\n(semantics), word form (phonology), and grammatical structure (syntax)”\n(McClain & Goldrick, 2018, p. 398). The evidence based on brain-damaged\npatients provides support for this overarching assumption.\nIn this section, we have focused on the patterns of language impair-\nment in patients categorised as suffering from anomia, agrammatism or\njargon aphasia. Such categorisations mistakenly imply all patients assigned\nto a given category have very similar language impairments. Mirman et al.\n(2015) avoided the use of categories. They used several tasks to assess\nvarious aspects of word recognition and production in 99 aphasic patients\nand also assessed the brain areas damaged in those patients.\nMirman et  al. (2015) used a statistical technique known as factor\nanalysis to identify the major components underlying patients’ patterns\nof impaired language performance. There was a major division between\nsemantic and phonological processing and each form of processing was\nsubdivided into language perception and language production. In future,\nthis approach could potentially allow us to move away from an overreli-\nance on categories or syndromes to a focus on similarities and differences\namong aphasic.\nAnother general conclusion is that the speech-production problems of\nmany aphasics (e.g., agrammatic individuals; jargon aphasics) depend in\npart on general cognitive processes as well as on language-specific ones.\nEvidence that general cognitive processes are important in the speech pro-\nduction of healthy individuals was reported by Zhang et  al. (2018) using\na picture naming task. Their key finding was that successfully coping with\nincreased task difficulty involved additional activation in language- specific\nbrain areas and general cognitive control (e.g., inhibition) areas. The role\nof general processes in language processing is discussed further in the intro-\nductory section entitled Part III: Language.\nSPEECH AS COMMUNICATION\nMost theories and research discussed so far focus on monologue. In the\nreal world, however, our speech nearly always occurs as conversation in a\nsocial context. Dialogue involves various complexities: “Both interlocutors\n[individuals involved in a conversation] must simultaneously produce their\nown contributions and comprehend the other’s contribution” (Pickering &\nGarrod, 2013, p. 330). Thus, as discussed earlier, speech production and\nspeech comprehension are interwoven (Meyer et al., 2016).\nGrice (e.g., 1975) considered the requirements of successful commu-\nnication in his cooperative principle: “Make your conversational contri-\nbution such as is required . . . by the accepted purpose or direction of the\ntalk exchange in which you are engaged” (Grice, 1989, p. 88). Grice’s use\nof the term “cooperation” was narrower than its common usage (Davies,\n2007). It should be seen in the context of his four maxims speakers should\nheed:\n●\nMaxim of relevance: the speaker should say things relevant to the\nsituation.\n●\nMaxim of quantity: the speaker should be as informative as necessary.\n●\nMaxim of quality: the speaker should be truthful.\nCreated from usyd on 2022-02-16 03:16:01.",
    "544\nLanguage\nFigure 11.7\nA sample array with six\ndifferent garments coloured\nblue or green.\nFrom Tarenskeen et al. (2015).\n●\nMaxim of manner: the speaker should make their contribution easy to\nunderstand.\nThere are two issues with Grice’s approach. First, is unclear we need four\nmaxims – the other three maxims are implied by the maxim of relevance.\nSecond, in the real world, many individuals (e.g., secondhand car salesper-\nsons; politicians) ignore one or more of the maxims out of self-interest. For\nexample, an analysis of Donald Trump’s statements during 2015 revealed\nthat he lied (failed to adhere to the maxim of quality) 76% of the time\n(Holan, 2015).\nSpeakers (even when not guided by self-interest) often fail to adhere to\nGrice’s four maxims. Suppose a speaker tries to provide enough informa-\ntion so a listener can identify the target item of clothing from an array (see\nFigure 11.7). Speakers included colour in their statements on 79% of trials\neven though it was unnecessary and so represented overspecification not\nadhering to the maxim of quantity (Tarenskeen et al., 2015).\nTarenskeen et al. (2015) carried out another experiment that included\nmany trials where it was necessary for speakers to include colour, pattern\nor size in their statements. As a result, each attribute was included in their\nstatements on 70% or more of trials when it was not necessary. This wide-\nspread overspecification was probably due to the speakers’ desire to be\nconsistent in their statements.\nIn sum, speakers often fail to adhere to Grice’s maxims. However,\noverspecification (unlike underspecification) typically has no negative\neffects on listeners’ comprehension and so is essentially harmless.\nAudience design\nThere has been a dramatic increase in research focusing on what speakers\nsay and how they say it when addressing one or more listeners. Much of\nthis research focuses on audience design, which “refers to the situation\nin which speakers fashion their utterances so as to cater to the needs of\ntheir addressees” (Ferreira, 2019). For example, communication can be\nfacilitated by establishing and extending common ground (see Chapter 9).\nKEY TERM\nAudience design\nThis involves speakers\ntailoring what they say\nto the specific needs\nand knowledge of their\naudience.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n545\nCommon ground consists of “knowledge that is shared with a communica-\ntion partner, and that the communication partners know each other know”\n(Brown-Schmidt & Duff, 2016, pp. 722–723). Common ground can include\nseveral kinds of information (e.g., objects or events visible to both partners;\nshared cultural values; shared experiences).\nFerreira (2019) identified two broad forms of audience design. First,\nthere is a simple form based on general characteristics of the listener. For\nexample, a speaker will typically plan shorter and simpler sentences when\ntalking to a child rather than an adult: this is child-directed speech (see\nGlossary). This form of audience design typically makes modest demands\non processing effort.\nSecond, there is a more complex form based on idiosyncratic charac-\nteristics of the listener and/or the context. This can involve considerable\nprocessing effort (e.g., taking full account of common ground) and altera-\ntions to planned utterances (e.g., you are talking to someone and they start\nlooking at their mobile phone).\nTheories\nHorton and Keysar (1996) proposed their monitoring and adjustment\nmodel to account for speakers’ successful (and unsuccessful) use of common\nground. Speakers initially plan their utterances using information available\nto them without considering the listener’s perspective or knowledge. These\nplans are then monitored and corrected to incorporate common ground.\nHowever, it is often computationally hard for speakers to focus on the lis-\ntener’s perspective while planning what to say. Accordingly, they often ego-\ncentrically focus on their own perspective and ignore the common ground.\nFerreira (2019) developed the above ideas in his forward modelling\napproach (see Figure 11.8). Speakers use their communicative intention\n(i.e., what they want to say) to generate utterances (left-hand side of the\nfigure). They also often produce a forward model (including a model of\naudience comprehension) to predict the likely effect on the audience of gen-\nerating those utterances. Of crucial importance, if the predictive commu-\nnicative effect mismatches the speaker’s intent, their message is changed to\nreduce the mismatch. This entire process is typically cognitively demanding\nand so speakers sometimes lack sufficient resources to produce a forward\nmodel plus a model of audience comprehension.\nMemory plays an important role in audience design. For example,\nHorton and Gerrig (2016) argued that memory limitations mean speakers\nsometimes assume less common ground than is actually the case. Suppose\nyou have told very few friends about a recent event. As a result, you mis-\ntakenly assume the friend you are talking to does not share that common\nground. The opposite can also happen: you have told nearly all your\nfriends about an event and mistakenly assume the one with whom you are\ncurrently talking was among them.\nFindings\nEffective use of common ground occurs most often when the listener’s\nknowledge and needs are readily accessible. Achim et  al. (2017) asked\nCreated from usyd on 2022-02-16 03:16:01.",
    "546\nLanguage\nspeakers to introduce and subsequently reintroduce movie characters likely\n(e.g., Harry Potter) or unlikely (Martin Riggs) to be known to the listener.\nSpeakers used each character’s name much more often when introduc-\ning and reintroducing known characters. They thus made effective use of\ncommon ground because it was easy.\nCraycraft and Brown-Schmidt (2018) tested the hypothesis that speak-\ners only assume they have formed common ground with listeners when\nthose listeners appear to be attentive. As predicted, speakers who had com-\nmunicated information to an inattentive listener (e.g., glancing repeatedly\naround the room; pulling out their mobile phone) did not subsequently\nassume they shared common ground with their listener. Thus, speakers are\noften responsive to the listener’s attentional state.\nIn contrast, Fukumura and van Gompel (2012) found speakers often\nignored listeners’ knowledge. Speakers typically use a noun phrase (e.g.,\n“the red desk”) the first time an object is mentioned but a pronoun (e.g.,\n“it”) in the next sentence. However, it is only appropriate to use a pronoun\nin the second sentence provided the listener has heard the previous sen-\ntence. In fact, speakers generally used a pronoun in the second sentence\neven when the listener had not heard the previous sentence, thus ignoring\naudience design.\nAccording to the monitoring and adjustment model and Ferreira’s\n(2019) forward modelling approach, it is often cognitively demanding to\ntake account of the listener’s perspective. Accordingly, we might expect\nspeakers with superior cognitive abilities to make more use of common\nground. As predicted, Long et  al. (2018) found that speakers high in\nthe executive functions of inhibition and switching (see Chapter 6) used\ncommon ground more often than low scorers.\nFigure 11.8\nArchitecture of the forward\nmodelling approach to\nexplaining audience design\neffects (blue rectangles =\nrepresentations; orange\novals = processes).\nFrom Ferreira (2019).\nModel of audience\ncomprehension\nForward model\nMessage\nencoding\nGrammatical\nencoding\nPhonetic\nencoding\nExecutive control\nEvaluator\nPre-articulatory\nutterance\nWords,\nstructures\nCommunicatively\nrelevant linguistic\nfeatures\nPredicted\ncommunicative\nefect\nCommunicative\nintention\nMessage\nRepresentations\nProcesses\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n547\nFurther evidence that cognitive demands are important in determin-\ning whether speakers take account of the common ground they share with\ntheir listener was reported by Horton and Keysar (1996). Speakers took\nless account of common ground when they spoke under time pressure than\nwhen they had as much time available as they wanted.\nAccording to Horton and Gerrig (2016; mentioned earlier, p. 545),\nspeakers’ memory failures often cause errors in the use of common ground.\nEmpirical support was obtained previously by Horton and Gerrig (2005),\nwho analysed numerous spontaneous telephone conversations. Here is an\nexample of a speaker assuming too little common ground:\nA:\nThis one guy with- who was like a a fresh br- breeze blown through\nthe factory uh uh uh twenty-four twenty-five-year-old guy\nB:\nOh, yeah you mentioned him. [p. 19]\nHere is an example of a speaker assuming too much common ground:\nA:\nYeah okay. I told you about the shampoo did I tell you?\nB:\nWhat shampoo no. [p. 19]\nThis example is especially interesting because it suggests the speaker\nwas  monitoring the accuracy of their memory and begins to doubt its\naccuracy.\nRubin et  al. (2011) obtained strong evidence of the importance of\nmemory. Amnesic patients with severely impaired episodic memory (see\nGlossary) made far less use of information about common ground than\nhealthy controls. However, amnesic patients made reasonably effective use\nof common ground when the relevant information was readily available.\nFurther evidence that amnesic speakers can often communicate effec-\ntively despite their memory problems was reported by Yoon et al. (2017).\nAmnesic speakers provided shorter descriptions of objects to listeners to\nwhom they had previously described those objects than to new listeners.\nThus, they were sensitive to the presence or absence of common ground\nwith their listener. This happened because the amnesic speakers could iden-\ntify the listener as new or old.\nFinally, speakers use various simple and relatively effortless strategies\nto facilitate communication. One example is syntactic priming (copying a\npreviously heard syntactic structure; see p. 518). Jaeger and Snider (2013)\nfound speakers were most likely to show syntactic priming when the last\nsentence they heard contained an unexpected syntactic structure. Speakers\nstrive to “get on the same wavelength” as the person with whom they are\nspeaking and this helps to achieve that goal.\nGesture\nMost speakers use gestures. It is generally assumed they do this because\nthey believe it increases their ability to communicate with their listener(s).\nThis belief is correct (see Chapter 9).\nHuman communication probably depended on gestures in our ances-\ntral past and it was only much later that vocalisation emerged. The fact\nCreated from usyd on 2022-02-16 03:16:01.",
    "548\nLanguage\nthat primate gestures resemble human language much more closely than\ndo primate vocalisations supports that viewpoint (Cartmill et al., 2012).\nIt seems reasonable to assume speakers use gestures more often\nwhen they can see the person to whom they are speaking. Surprisingly,\nthis finding has been obtained in only 50% of studies (Bavelas & Healing,\n2013). Why do speakers use gestures that cannot be seen by their listeners?\nGestures make it easier for speakers to communicate effectively. Frick-\nHorbury and Guttentag (1998) presented participants with the definitions\nof relatively uncommon words (e.g., tambourine) and asked them to say the\nword defined. When it was hard to use gestures, speakers produced 21%\nfewer words than when they were free to use gestures.\nGerwing and Allison (2011) asked speakers to describe an elaborate\ndress to a visible or non-visible listener. The number of gestures was com-\nparable in both conditions. However, speakers’ gestures were much more\ninformative in the face-to-face situation. In that situation, 74% of the\ninformation communicated was via gestures and only 26% via speech. In\ncontrast, only 27% of the information communicated in the telephone sit-\nuation was gestural.\nGestures are often modified to take account of the common ground\nbetween speakers and listeners. Hilliard and Cook (2016) used a task\nwhere speakers communicated information about how to solve a complex\nproblem. When the common ground between speakers and listeners was\nlimited, speakers used more informative gestures than when the common\nground was more extensive. However, speakers’ spoken language was not\ninfluenced by the extent of common ground. Gesture and speech provide\na unified system for communication and so either gesture or speech can be\nmodified to take account of common ground.\nHow responsive are speakers to listeners’ feedback? Holler and Wilkin\n(2011) compared speakers’ gestures before and after listener feedback.\nThere were two main findings:\n(1) The number of gestures reduced when the listener indicated under-\nstanding of what had been said.\n(2) Feedback encouraging clarification, elaboration or correction was\nfollowed by more precise, larger or more visually prominent gestures.\nIn sum, gestures are an important accompaniment to speech. Speakers use\ngestures because they make it easier to work out what they want to say, In\naddition, the fact that speakers are responsive to listeners’ needs (includ-\ning the feedback they provide) means gestures facilitate communication (see\nChapter 9).\nProsodic cues\nSome information communicated by speakers to listeners does not depend\ndirectly on the words themselves but rather on how those words are uttered.\nThis is prosody, which describes “systematic modifications to the way that\nspeakers utter words in order to specify or disambiguate the meaning of an\nutterance” (Cvejic et al., 2012, p. 442).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n549\nProsodic cues include rhythm, stress and intonation. For example, in\nthe ambiguous sentence, “The old men and women sat on the bench”, the\nwomen may be or may not be old. If the women are not old, the spoken\nduration of the word “men” should be relatively long and the stressed syl-\nlable in “women” will have a steep rise in pitch contour. Neither prosodic\nfeature will be present if the sentence means the women are old. Evidence\nthat listeners’ comprehension of speech is enhanced by prosodic cues is\ndiscussed in Chapter 9.\nGueliaï et  al. (2014) found gestures accompanying speech carry pro-\nsodic information. When listeners heard ambiguous sentences with a mis-\nmatch between the prosodic cues in the speech and the gestures, listeners\nmore often understood these sentences in line with the gestural information.\nDiscourse markers\nSpeakers can also enhance listener comprehension by using discourse\nmarkers. Discourse markers are words or phrases assisting communica-\ntion even though they are only indirectly relevant to the speaker’s message.\nAmong the ways they do this are by expressing the speaker’s attitude and\nfacilitating turn-taking in conversations (Hata, 2016). Speakers use the dis-\ncourse marker you know, for example, to check whether listeners under-\nstand them and to connect with them.\nWe are often unaware of the reasons why we use various discourse\nmarkers. For example, what determines whether you say oh or so when\nmoving on to a new conversational topic? Bolden (2006) found oh was\nused 98.5% of the time when the new topic directly concerned the speaker.\nIn contrast, so was used 96% of the time when the new topic was of most\nrelevance to the listener.\nIn sum, discourse markers often make it easier for listeners to under-\nstand speakers’ intended meanings. However, we can also consider discourse\nmarkers in the context of disfluencies (e.g., pauses; repetitions). Crible\n(2017) analysed 15 hours of speech containing a total of 161,700 words\nand found frequent clusters including disfluencies and discourse markers.\nShe concluded that discourse markers are often simply disfluencies.\nWRITING: THE MAIN PROCESSES\nWriting is an important topic in its own right (no pun intended!). However,\nit is not separate from other cognitive activities. As Kellogg and Whiteford\n(2012, p. 111) pointed out,\nComposing extended texts is . . . a severe test of memory, language,\nand thinking ability. It depends on the rapid retrieval of domain-\nspecific knowledge about the topic from long-term memory. It depends\non a high degree of verbal ability . . . It depends on the ability to think\nclearly.\nUnsurprisingly, writing ability is positively correlated with several aspects\nof cognitive ability (e.g., fluid reasoning ability) (Cormier et al., 2016).\nKEY TERMS\nProsodic cues\nFeatures of spoken\nlanguage such as stress,\nintonation, pauses and\nduration making it easier\nfor listeners to work out\ngrammatical structure\nand meaning; similar\ncues are often present\nin texts (e.g., commas;\nsemi-colons).\nDiscourse markers\nSpoken words and\nphrases that do not\ncontribute directly to the\ncontent of what is being\nsaid but still serve various\nfunctions (e.g., clarifying\nthe speaker’s intentions).\nResearch activity:\nDiscourse markers\nCreated from usyd on 2022-02-16 03:16:01.",
    "550\nLanguage\nIN THE REAL WORLD: EFFECTS OF\nALZHEIMER’S DISEASE ON NOVEL\nWRITING\nWe saw earlier that mild cognitive impairment\n(often a precursor to Alzheimer’s disease – see\nGlossary) is associated with various problems\nin speech production. In view of the cognitive\ncomplexities of effective writing, it seems proba-\nble mild cognitive impairment would also impair\nwriting performance.\nResearch has been carried out on Iris Murdoch\n(1919–1999), the renowned Irish novelist who\nwas\ndiagnosed\nwith\nAlzheimer’s\ndisease.\nGarrard et  al. (2005) compared her first pub-\nlished work, a novel written during her prime,\nand her final novel. Iris Murdoch’s vocabulary\nbecame less sophisticated (e.g., smaller vocab-\nulary; more common words) across these three\nworks but changes in syntax were less clear-\ncut. Subsequent research by Pakhomov et  al.\n(2011) showed the syntactic complexity of Iris\nMurdoch’s writing decreased over time. Thus, aspects of Iris Murdoch’s writing were adversely\naffected several years before she was diagnosed with Alzheimer’s disease during a period in which\nshe probably had mild cognitive impairment.\nLe et al. (2011) carried out a detailed longitudinal analysis of the writings of Iris Murdoch, Agatha\nChristie (suspected of having Alzheimer’s disease towards the end of her life) and P.D. James (a\nnovelist with no signs of cognitive impairment or Alzheimer’s disease). They confirmed previous\nfindings that there were signs of impairment in Iris Murdoch’s writing a considerable time before\nshe was diagnosed with Alzheimer’s disease.\nLe et al. (2011) claimed Agatha Christie’s last novels indicated she probably suffered the onset\nof Alzheimer’s disease. The writing impairments of Agatha Christie and Iris Murdoch both involved\nvocabulary much more than syntax. More specifically, they both showed a sharp decrease in vocab-\nulary size, increased repetition of phrases, and irrelevant filler words or phrases. Van Velzen et al.\n(2014) reported a detailed comparison of the writings of Iris Murdoch and Agatha Christie focusing\non their lexical diversity (richness of vocabulary). Iris Murdoch had a much earlier and more sudden\nreduction in lexical diversity than Agatha Christie. They concluded Agatha Christie did not have\nAlzheimer’s disease but rather some other neurodegenerative condition. In contrast, P.D.  James\nshowed only marginal writing impairments in old age due to normal ageing.\nIn sum, there are detectable impairments in the writing of novelists probably suffering from\nmild cognitive impairment. These impairments can provide an early indication of Alzheimer’s\ndisease  (or other neurodegenerative diseases), and probably reflect in part the cognitive com-\nplexity of writing. However, even the onset of Alzheimer’s disease has only modest effects on\nsyntax. Thus, cognitive impairment affects the content of what is written more than its grammat-\nical structure.\nIris Murdoch, the Irish novelist.\nUlf Andersen/Getty Images.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n551\nKey processes\nWriting extended texts involves several processes. In spite of minor disa-\ngreements about the number and nature of these processes, most theorists\nagree with Hayes and Flower (1986) that writing involves the following\nthree processes:\n(1) A planning process which involves producing ideas and organising\nthem to satisfy the writer’s goals.\n(2) A sentence-generation process which involves turning the writing plan\ninto the actual production of sentences.\n(3) A revision process which involves evaluating what has been written or\nword processed so far and changing it when necessary.\nChenoweth and Hayes (2003) developed the above approach. Their model\nidentifies four processes:\n(1) Proposer: it proposes ideas for expression and is engaged in  higher-level\nplanning processes.\n(2) Translator: it converts the message formed by the proposer into word\nstrings (e.g., sentences).\n(3) Transcriber: it converts the word strings into written or word pro-\ncessed text.\n(4) Evaluator/reviser: it monitors and evaluates what has been produced\nand engages in revision of deficiencies.\nThe main difference between the two approaches described above is that\nChenoweth and Hayes (2003) added a transcriber. Why did they do that?\nHayes and Flower assumed transcribing (writing sentences already com-\nposed) requires minimal processing resources and so had no impact on\nother writing processes. However, that assumption is incorrect. Hayes and\nChenoweth (2006) asked participants to transcribe or copy texts from one\ncomputer window to another. They transcribed more slowly when per-\nforming a very simple task (saying tap repeatedly) at the same time. Tindle\nand Longstaff (2016) found the task of writing down heard words utilised\nworking-memory resources.\nThe latest version of the above writing model (Hayes, 2012; shown\nin Figure 11.9) incorporates the four writing processes identified by\nChenoweth and Hayes (2003). However, it is more comprehensive because\nthe process level has been expanded to include the task environment and\nthere are additional control and resource levels. Of importance, the current\nversion includes motivation as a factor. Writing effectively is so demanding\n(as the authors of this book know to their cost!) that high motivation is\nrequired to engage in prolonged evaluation and revision of what has been\nwritten.\nThere is a final point. The “natural” sequence of the four main writing\nprocesses is as follows: proposer; translator; transcriber; and evaluator. As\nwe will see, however, writers surprisingly often deviate from this sequence,\nswitching rapidly between processes.\nCreated from usyd on 2022-02-16 03:16:01.",
    "552\nLanguage\nFindings\nPauses account for over half of writing time. Medimorec and Risko (2017)\nanalysed the pause data of students writing narrative essays (about a mem-\norable day) and argumentative essays (about mobile-phone use in schools).\nPauses occurred most often at paragraph boundaries, followed by sentence\nboundaries, suggesting they often indicate planning processes.\nLimpo and Alves (2018) studied key aspects of writing dynamics\nusing the triple-task technique. Participants engaged in writing an argu-\nmentative text (about controversial university initiation rites) were asked\nto respond as rapidly as possible to occasional auditory beeps. After\nthey had responded, they indicated which writing process they had just\nbeen using: planning, translating or revising. This is known as directed\nretrospection.\nWhat did Limpo and Alves (2018) find? First, time spent on plan-\nning reduced during the course of writing (see Figure 11.10). Second, the\ntime spent on the revising process increased over time. Third, all three\nwriting processes (i.e., planning, translating and revising) occurred during\nall phases of the writing process. Fourth, reaction times to the occasional\nbeeps were slowed most during revising and least during translating. These\nfindings indicate that revising was the most cognitively demanding process,\nfollowed by planning and translating in that order.\nBeauvais et  al. (2011) found writers switched rapidly between differ-\nent processes: 8 times a minute with narrative texts (telling a story) and 6\ntimes a minute with argumentative texts (discussing ideas). Each episode\nof translating lasted on average 16 seconds (narrative text) or 17 seconds\n(argumentative text), planning 8 seconds (narrative text) or 12 seconds\n(argumentative text), and revision (4 seconds for both texts). Thus, as Levy\nand Ransdell (1995) found, episodes of planning and revising were shorter\nthan translating or text generation.\nFigure 11.9\nHayes’ (2012) writing\nmodel. It consists of three\nlevels: (1) control level\n(including motivation and\ngoal setting); (2) writing\nprocess level (including\nproposer, evaluator,\ntranslator and transcriber);\nand (3) resource level\n(including working memory,\nattention and long-term\nmemory).\nFrom Hayes (2012). Reprinted\nby permission of SAGE\nPublications.\nKEY TERM\nDirected retrospection\nA technique in which\nindividuals (e.g.,\nwriters) categorise their\nimmediately preceding\nthoughts.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n553\nHow do writers make decisions about switching processes? Hayes and\nFlower (1980) argued writers have a monitor (closely resembling the central\nexecutive component of the working memory model: see Chapter 6) con-\ntrolling their processing activities. Two functions of the central executive\nare to switch attention between tasks and to inhibit unwanted responses.\nIf the monitor requires working memory resources, it should be less\nlikely to trigger a switch in the current task when current processing\ndemands are high. Quinlan et  al. (2012) tested this assumption. Writers\nchose whether to complete a sentence before correcting an error or to\ninterrupt sentence composing to focus on the error. Nearly all participants\ncompleted the sentence first (especially when total processing demands\nwere high).\nEvaluation\nProcesses such as planning, sentence generation and revision are all crucial\nin writing. However, they cannot be neatly separated because writers typi-\ncally move rapidly between them. Writers probably possess a monitor initi-\nating processing shifts when overall processing demands are relatively low.\nWhat are the limitations of research in this area? First, the factors\ndetermining when writers shift processes are mostly unknown. Second,\nthe social aspect of writing (i.e., taking account of the intended reader-\nship of written texts) is often de-emphasised (see below). Third, the ways\nwriting processes interact are not specified with precision. For example,\nHayes (2012; Figure 11.8) failed to indicate how the four resources relate\nto writing processes.\nIndividual differences in writing: development of expertise\nWhy are some writers more skilful than others? As with any complex cog-\nnitive skill, extensive deliberate practice is essential (see Chapter 12). In\nthe next section, we will see the working memory system (see Chapter 6)\nFigure 11.10\nThe frequency of three\nmajor writing processes\n(planning, translating and\nrevising) across the three\nphases (thirds) of writing.\nFrom Limpo and Alves (2018).\nReprinted with permission of\nElsevier.\n9\n8\n7\n6\n5\n4\n3\n2\n1\nPhase 1\nPhase 2\nWriting phase\nPhase 3\nNumber of occurrences\nNo planning\nPlanning\nTranslating\nRevising\nCreated from usyd on 2022-02-16 03:16:01.",
    "554\nLanguage\nFigure 11.11\nKellogg’s three-stage\ntheory of the development\nof writing skill.\nFrom Kellogg (2008). Reprinted\nwith permission of the Journal\nof Writing Research www.jowr.\norg.\nis very important. All its components have limited capacity. However, the\ndemands of writing on these components decrease with practice, which pro-\nvides experienced writers with spare processing capacity to enhance their\nwriting quality.\nWriting expertise often depends on reading ability. Berninger and\nAbbott (2010) assessed the four main language skills in children. Overall,\nwriting performance was predicted best by reading comprehension, fol-\nlowed by speech production and then speech comprehension. Kent and\nWanzek (2016) conducted a meta-analysis, also finding reading com-\nprehension predicted writing quality better than did speech-production\nability.\nHow can we explain the above findings? Reading allows writers\nto learn much about the structure and style of good writing; it also\nenhances their  vocabulary and knowledge. However, most evidence is\ncorrelational  and so does not prove writing ability is caused by reading\ncomprehension. For example, writing expertise may enhance reading com-\nprehension skills.\nBereiter and Scardamalia (1987) identified two major strategies writers\nuse. First, there is the knowledge-telling strategy: writers simply write\ndown all they know about a topic with minimal planning. Second, the\nmore complex knowledge-transforming strategy involves working out how\nto achieve the writing goals and how to decide on the specific information\nto write down. Optimal use of this strategy involves moving backwards\nand forwards between these two aims.\nKellogg and Whiteford (2012) developed the above approach (see\nFigure 11.11). They argued that really expert writers move beyond the\nknowledge-transforming strategy by using a knowledge-crafting strategy.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n555\nWith this strategy “The writer shapes what to say and how to say it with\nthe potential reader fully in mind. The writer tries to anticipate different\nways that the reader might interpret the text and takes these into account\nin revising it” (Kellogg & Whiteford, 2012, p. 116).\nOne reason why knowledge crafting is important is because of the\nknowledge effect – writers often assume other people share the knowl-\nedge they possess. Hayes and Bajzek (2008) found individuals familiar with\ntechnical terms greatly overestimated other people’s knowledge of these\nterms (are the authors of this book guilty of this?).\nFindings\nThe knowledge-transforming strategy is effective for various reasons.\nWriters using this strategy produce more high-level main points capturing\nimportant themes (Bereiter et al., 1988) and show more extensive interac-\ntions between planning, language generation and reviewing. This strategy\nis used more effectively if writers enhance their relevant knowledge prior to\nwriting an essay (Chuy et al., 2012). The resultant essays were more coher-\nent and easier to read.\nExpert writers spend more time revising than non-expert ones. Levy\nand Ransdell (1995) found writers producing the best essays spent 40%\nmore time reviewing and revising their essays than those producing the\nworst essays. In addition, expert writers detect many more problems in a\ntext than non-experts (Hayes et al., 1985).\nEvidence that knowledge-crafting skills are important was reported by\nKarlen (2017). Students were required to write an academic paper. Those\npossessing the most knowledge about how to craft texts made greatest use\nof knowledge-crafting strategies while writing and this in turn enhanced\nthe quality of their writing.\nKnowledge-crafting skills can be trained. For example, responsiveness\nto the reader’s needs can be improved by providing writers with feedback\nfrom readers about comprehension problems they had experienced (Sato\n& Matshushima, 2006). Wischgoll (2016) found students developing their\nknowledge-crafting skills by a meta-cognitive strategy (e.g., “Can I com-\nprehend my text if I read it from the reader’s perspective?”, p. 7) showed\ngreater enhancement of their writing skills than those using other strategies.\nFinally, the requirements of expert writing depend on the type of text\n(e.g., an advanced textbook vs a children’s story). Beauvais et  al. (2011)\nfound moderately expert writers engaged in more knowledge-telling when\nproducing narrative rather than argumentative texts. However, the oppo-\nsite was the case for knowledge-transforming. In other words, the writers\ntailored their writing behaviour to the requirements of the type of text they\nwere producing.\nWorking memory\nMost people find writing difficult and effortful because it involves several\ndifferent cognitive processes (e.g., attention; thinking; memory). Several\ntheorists have argued writers make extensive use of working memory to\ndeal with these complexities. This argument was supported by Tindle and\nKEY TERM\nKnowledge effect\nThe tendency to assume\nothers possess the same\nknowledge as us.\nResearch activity:\nKnowledge telling\nCreated from usyd on 2022-02-16 03:16:01.",
    "556\nLanguage\nLongstaff (2015). They found writing made more demands on working\nmemory than reading or listening.\nWorking memory is used when a task requires temporary storage of\nsome information while other information is processed (see Chapter 6).\nThat is clearly the case with writing – writers have to remember what they\nhave just written while planning what they are going to write next.\nThe key component of the working memory system is the central exec-\nutive (see Glossary), an attention-like process involved in organising and\ncoordinating cognitive activities. Other components of the working memory\nsystem are the visuo-spatial sketchpad (involved in visual and spatial pro-\ncessing) and the phonological loop (involved in verbal rehearsal). All these\ncomponents have limited capacity. This can easily cause problems with the\nwriting process, which is often very cognitively demanding.\nAll components of working memory are involved in writing. Kellogg\n(2001) linked these components to five processes involved in writing (see\nTable 11.1). These processes overlap with those identified by Chenoweth\nand Hayes (2003; described earlier, pp. 551–552). Planning corresponds\nto the proposer, translating to the translator, programming is part of the\ntranscriber, and reading and editing together relate to the evaluator/reviser\n(reading involves going back over what has been written so far).\nKellogg et  al. (2013) reconsidered the information contained in\nTable  11.1 and decided the phonological loop is actually involved in the\nediting process. Research by Hayes and Chenoweth (2006; discussed earlier,\np. 551) showed error correction while copying text was slowed down when\nthe phonological loop was required for another task.\nFindings\nAs you can see in Table 11.1, Kellogg (2001) assumed writing performance\ndepends more on the central executive than any other working memory\ncomponent. We can assess its involvement by measuring reaction times to\nauditory beeps presented in isolation (control condition) or while people are\nengaged in writing. If writing uses much of the central executive’s capacity,\nreaction times should be longer during writing. In a study discussed earlier\n(Limpo & Alves, 2018), planning, translating and revising all slowed reac-\ntion times (especially planning).\nTABLE 11.1 INVOLVEMENT OF WORKING MEMORY COMPONENTS IN VARIOUS\nWRITING PROCESSES\nProcess\nVisuo-spatial\nsketchpad\nCentral\nexecutive\nPhonological\nloop\nPlanning\nyes\nyes\n–\nTranslating\n–\nyes\nyes\nProgramming\n–\nyes\n–\nReading\n–\nyes\nyes\nEditing\nyes\n–\n–\nSource: Based on Kellogg (2001).\nCase study:\nWorking memory\ncomponents\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n557\nThe role of the central executive can also be assessed using an indi-\nvidual differences approach. Vanderberg and Swanson (2007) adopted\nthis approach. Students wrote stories and their performance was divided\ninto general skills (e.g., planning, translating, revision) and specific skills\n(e.g., grammar, punctuation). Individuals having the most effective central\nexecutive functioning exhibited the greatest general and specific skills.\nIn contrast, individual differences in the functioning of the visuo-spatial\nsketchpad and phonological loop did not influence performance.\nGuan et  al. (2014) studied the effects of individual differences in\nworking memory capacity (an approximate measure of central executive\nfunctioning; see Glossary). Essay-writing quality was predicted by working\nmemory capacity. In similar fashion, Van der Steen et  al. (2017) found\nstudents high in working memory capacity produced more complex essays\nthan low-capacity individuals.\nAnother approach is to study brain-damaged individuals with impaired\ncentral executive functioning suffering from dysexecutive syndrome (see\nGlossary; and Chapter 6). Many patients with dysexecutive syndrome have\ndifficulties planning and organising their ideas on writing tasks and in\nmaintaining attention (Ardila & Surloff, 2006). Ardila and Surloff coined\nthe term dysexecutive agraphia to refer to such patients. Sitek et  al.\n(2014) studied four patients with dysexecutive agraphia who had demen-\ntia causing severe cognitive impairment. Progressive deterioration in their\nwriting skills was closely linked to more general cognitive impairment.\nWhat role does the phonological loop play in writing? We can address\nthis question using an articulatory suppression task (e.g., saying the the the\nrepeatedly) while individuals are engaged in a writing task. Articulatory\nsuppression tasks use the resources of the phonological loop and so impair\nperformance on other concurrent tasks requiring the phonological loop.\nArticulation suppression causes writers to produce shorter sequences\nof words (suggesting it suppresses their “inner voice”; Chenoweth &\nHayes, 2003); it also slows down transcribing or copying texts (Hayes\n& Chenoweth, 2006). Finally, Colombo et  al. (2009) found articulatory\nsuppression impaired writers’ ability to produce the component parts of\nmulti-syllable words in the correct serial order.\nThe above findings strongly suggest the phonological loop is\noften  used  during writing. However, we must not exaggerate its impor-\ntance. Some patients with a severely damaged phonological loop neverthe-\nless have essentially intact written language (Gathercole & Baddeley, 1993).\nWhat role does the visuo-spatial sketchpad play in writing? Relevant\nresearch was reviewed by Olive and Passerault (2012). Bourke et al. (2014)\nfound individual differences in visuo-spatial working memory predicted\nchildren’s spelling and writing ability. Kellogg et al. (2007) asked students\nto write descriptions of concrete (e.g., house) and abstract (e.g., freedom)\nnouns while detecting visual stimuli. The writing task slowed detection times\nonly when concrete words were being described, indicating the visuo-spatial\nsketchpad is more involved when writers think about concrete objects.\nSomewhat separate visual and spatial processes occur within the\nvisuo-spatial sketchpad (see Chapter 6). Are both processes involved in\nwriting? Olive et al. (2008) asked students to write a text while performing\na visual or spatial task and discovered the answer is “Yes”.\nKEY TERM\nDysexecutive agraphia\nSeverely impaired writing\nabilities in individuals with\ndamage to the frontal\nlobes whose central\nexecutive functioning is\ngenerally impaired.\nCreated from usyd on 2022-02-16 03:16:01.",
    "558\nLanguage\nEvaluation\nThe main writing processes are very demanding and effortful and impose\nsubstantial demands on working memory (see Olive, 2012, for a review).\nIndividuals with high working memory capacity have good general and spe-\ncific writing skills. The central executive is heavily involved in most writing\nprocesses. There is also convincing evidence the visuo-spatial sketchpad\nand phonological loop are both involved in the writing process. The visuo-\nspatial sketchpad is involved in planning and editing, and the phonological\nloop seems to be of relevance to various writing processes.\nWhat are the limitations of theory and research on working memory in\nwriting? First, we do not know precisely why planning, sentence generation\nand revising are so demanding of processing resources. Second, there is\nlittle understanding of the role of working memory in influencing when and\nwhy writers shift from one writing process to another. However, switching\nof processes may be less likely when total working memory demands are\nhigh (Quinlan et al., 2012).\nThird, working memory (and other) processes are used flexibly and\nin parallel (i.e., at the same time) in writing (Olive, 2014). However, the\nfactors determining when and how these processes are used in parallel (and\nhow they interact with each other) remain unclear.\nFourth, most research has been based on Baddeley’s working memory\nmodel with other approaches (e.g., theories based on working memory\ncapacity; see Chapter 6) receiving little attention. These other approaches\ncould potentially enhance our understanding of the processes underlying\nwriting performance.\nWord processing\nGoldberg et al. (2003) carried out meta-analyses to compare writing per-\nformance when students used word processors or wrote in longhand. They\nconcluded as follows: “Students who use computers when learning to write\nare not only more engaged in their writing but they produce work that is of\ngreater length and higher quality” (Goldberg et al., 2003, p. 1).\nVan der Steen et al. (2017) found students wrote faster and produced\nessays of higher quality when using word processing rather than writing by\nhand. Why was this? Students spent more time pausing in the word process-\ning condition, and pausing was associated with more revision and thinking.\nAre there any disadvantages associated with word processing? Kellogg\nand Mueller (1993) found word processing involves more effortful planning\nand revision (but not sentence generation) than writing in longhand. Those\nusing word processors were much less likely to make notes (12% vs 69%,\nrespectively), which may explain the findings.\nSPELLING\nSpelling is an important aspect of writing. Brain areas involved in spelling\nwere identified by Planton et al. (2013; see Figure 11.12) in a meta-analytic\nreview. Three main areas were consistently activated during handwriting\ntasks:\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n559\n(1) Intraparietal sulcus and superior parietal lobule in the left hemi-\nsphere: this area is involved in the selection and/or representation of\nletter shapes.\n(2) Superior frontal sulcus in the left hemisphere: this area seems to be\nthe interface between abstract letter combinations and the generation\nof motor commands.\n(3) Posterior cerebellum in the right hemisphere: this area is probably\nmost involved in motor activity.\nPlanton et  al. (2017) discovered most of these areas were also activated\nwhen participants drew shapes or spelled out object names orally. Thus,\nthey are not specialised for writing.\nDual-route theory\nSeveral theorists (e.g., Hepner et al., 2017) have proposed versions of the\ndual-route theory for understanding the processes involved in spelling (see\nFigure 11.13(b)):\n●\nThe most important assumption is that there are two main routes\nbetween hearing a word and spelling it:\n(1) the lexical route (left-hand side of the figure);\n(2) the non-lexical route (right-hand side of the figure).\n●\nThe lexical route involves accessing word sounds in phonologi-\ncal long-term memory followed by accessing word meanings in the\nlexical semantic system and word spellings in orthographic long-term\nmemory. It is the main route we use with familiar words regardless\nof whether the relationship between sounds (phonemes) and spellings\n(orthography) is regular (e.g., cat) or irregular (e.g., yacht).\n●\nThe non-lexical route does not involve gaining access to detailed\ninformation about the sound, meaning and spelling of heard words.\nInstead, it uses rules to convert sounds or phonemes into groups of\nFigure 11.12\nBrain areas activated during handwriting tasks, controlling for verbal or linguistic input\n(red) or motor output (green). The areas in yellow are controlled for both and so provide\nan indication of handwriting-specific brain regions. IPS, intraparietal sulcus; SPL, superior\nparietal lobe; SFS, superior frontal sulcus; post CB, posterior cerebellum.\nFrom Planton et al. (2013). Reprinted with permission from Elsevier.\nCase study:\nDifferences in spelling\nability\nCreated from usyd on 2022-02-16 03:16:01.",
    "560\nLanguage\nletters or words. This route is used when spelling unfamiliar words or\nnon-words. It produces correct spellings when the relationship between\nsounds and spellings is regular or common but spelling errors when the\nrelationship is irregular or uncommon.\n●\nBoth routes converge on orthographic working memory (also known\nas the graphemic buffer). This briefly holds information about the\nletters within a word and the ordering of those letters before they are\nwritten or typed.\n●\nThe processes and structures involved in spelling (Figure 11.13(b)) are\nvery similar to those involved in reading (Figure 11.13(a)), but are used\nin the opposite direction. Spelling goes from hearing a word to writing\nit whereas reading goes from the written word to saying it.\nFindings\nWhat would happen if brain-damaged patients could not use the non-lexical\nroute but the lexical route was essentially intact? They would spell familiar\nwords accurately (whether they were regular or irregular) because the spell-\nings would be available in orthographic long-term memory. However, they\nwould have great problems with unfamiliar words and non-words having\nno relevant information stored in long-term memory. Such patients have\nphonological dysgraphia.\nShelton and Weinrich (1997) studied a male patient (EA) with pho-\nnological dysgraphia. He spelled 50% of regular words and 45% of irreg-\nular words correctly to dictation but 0% of non-words. Sotiropoulos and\nHanley (2017) found phonological dysgraphics had normal performance\nwhen spelling regular and irregular words.\nIt seems likely phonological dysgraphics have severe problems with\nphonological processing (processing involving word sounds). Accordingly,\nFigure 11.13\nThe cognitive architectures\nfor (a) reading and (b)\nspelling.\nFrom Hepner et al., 2017).\n(a)\n(b)\nLetter identification\nprocesses\nOrthographic working\nmemory\nPhonological working\nmemory\nOrthographic long-\nterm memory\nSpelling-to-sound\nconversion system\nLexical semantic\nsystem\nLexical route\nSublexical route\nPhonological long-\nterm memory\nAuditory/speech\nprocessing\nPhonological\nworking memory\nOrthographic\nworking memory\nGraphic motor\nplan selection\nLetter name\nselection\nPhonological long-\nterm memory\nSound-to-spelling\nconversion system\nLexical semantic\nsystem\nLexical route\nSublexical route\nOrthographic long-\nterm memory\nKEY TERMS\nOrthographic working\nmemory (also known as\nthe graphemic buffer)\nA store in which\ninformation about the\nindividual letters in a word\n(and their ordering) is\nheld immediately prior to\nspelling the word.\nGraphemic buffer\n(also known as the\nOrthographic working\nmemory)\nA store in which\ngraphemic information\nabout the individual\nletters in a word is held\nimmediately prior to\nspelling the word.\nPhonological dysgraphia\nA condition caused by\nbrain damage in which\nfamiliar words can be\nspelled reasonably well\nbut unfamiliar words and\nnon-words cannot.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n561\nthey should perform poorly on any task requiring phonological process-\ning. As predicted, Cholewa et al. (2010) found children with phonological\ndysgraphia performed poorly on various tests of phonological processing\n(e.g., deciding whether two spoken non-words sounded the same) as well\nas spelling non-words.\nWhat would happen if patients had damage to the lexical route and\nso relied mostly on the non-lexical route (converting sounds into groups\nof letters)? Such patients would be more accurate at spelling regular or\nconsistent words and non-words (because the spelling can be worked out\nfrom the sound) than irregular or inconsistent words. Such patients suffer\nfrom surface dysgraphia.\nMacoir and Bernier (2002) studied a patient, MK, who spelled 92%\nof regular words correctly but only 52% of irregular words. Cholewa et al.\n(2010) in a study discussed earlier (pp. 560–561) found children with surface\ndysgraphia spelled 56% of irregular words incorrectly but only 19% of non-\nwords. According to the dual-route theory, surface dysgraphics should not\nhave severe problems with phonological processing. Cholewa et al. obtained\npartial support for this prediction – surface dysgraphics had impaired on\nsome phonological tasks but on fewer tasks than phonological dysgraphics.\nSome research findings indicate the dual-route theory is oversimplified.\nFirst, Treiman and Kessler (2016) asked participants to spell monosyllabic\nnon-words. Whether a final /f/ sound in these non-words was spelt f or ff\ndid not depend solely on sound-to-spelling rules as predicted by the theory.\nSpellings were also influenced by context – the spelling ff was more likely\nto be used when the preceding vowel in the non-word was spelt with one\nletter rather than two.\nSecond, Rapp et al. (2002) found greater interaction between the lexical\nand non-lexical routes during word spelling than assumed by the theory.\nThey studied LAT, a patient with Alzheimer’s disease. He spelled bouquet\nas BOUKET and knowledge as KNOLIGE. These spellings suggest some\nuse of the non-lexical route. In addition, however, he could only have\nknown that bouquet ends in t and that knowledge starts with k by using\ninformation in orthographic long-term memory.\nThird, according to the theory, the spelling of non-words should\ninvolve only the non-lexical route. Suppose you heard the non-word /vi:m/\nand wrote it down. Would you write VEAM or VEME? Most spellers write\nVEAM if dream has just been presented auditorily but VEME if preceded\nby theme (Martin & Barry, 2012). This shows an influence of the lexical\nroute on non-word spellings.\nEvaluation\nEvidence from phonological dysgraphics and surface dysgraphics provides\nreasonable evidence spelling can involve a lexical or non-lexical route.\nThere is also evidence for interactions between the two routes.\nWhat are the limitations of the two-route theory?\n(1) The theory assumes phonological dysgraphics have a specific problem\nturning sounds into groups of letters. In fact, they often have a more\ngeneral problem with phonological processing.\nKEY TERM\nSurface dysgraphia\nA condition caused by\nbrain damage in which\nthere is impaired spelling\nof irregular words but\nreasonably accurate\nspelling of regular words\nand non-words.\nCreated from usyd on 2022-02-16 03:16:01.",
    "562\nLanguage\n(2) There are more interactions between the two spelling routes than\nassumed by the theory. This has been found with respect to the spell-\ning of words and non-words.\n(3) The theory is oversimplified because we use more sources of infor-\nmation in spelling than identified theoretically. As Treiman (2017,\np. 84) pointed out, “English spelling includes more regularities than\nis often  thought.” For example, double consonants are common\nbefore a final (e.g., haddock; paddock) but uncommon before a final\n(e.g., tannic vs panic, magic, tragic). Treiman discussed research\nshowing we use such information to increase the accuracy of our\nword spellings.\nOne or two orthographic lexicons?\nLook back to Figure 11.13 and you will see many similarities between\nreading and spelling. Of most relevance here, knowledge of word spell-\nings (orthography) is important in reading and writing. The simplest (and\nmost plausible) assumption is that there is a single orthographic lexicon\nwithin orthographic long-term memory used for reading and spelling.\nAlternatively, an input orthographic lexicon is used in reading and a separ-\nate output orthographic lexicon is used in spelling.\nFindings\nRelevant evidence has come from studies on brain-damaged patients.\nPatients with a reading impairment (dyslexia) generally also have impaired\nwriting and spelling (dysgraphia). In many cases, such patients have prob-\nlems with the same specific words in reading and writing.\nThe above findings suggest there is a single orthographical lexicon.\nHowever, some brain-damaged patients have greater problems with\nreading than spelling, or vice versa. Such evidence suggests there are\ntwo  orthographic lexicons. However, those with greater reading prob-\nlems generally have damage to brain areas associated with visual percep-\ntion (e.g.,  BA17/18), whereas those with greater spelling problems have\ndamage to premotor areas (e.g., BA6) (Rapp & Lipka, 2011). These\nfindings reflect the greater role of perception in reading and of motor\nprocesses in spelling and so they do not indicate whether there are two\northographic lexicons.\nHepner et  al. (2017) studied PJT (an 8-year-old boy with dysgraphia)\nand obtained the following findings: “We found no evidence of any reading\nimpairment . . . indicating a striking dissociation between impaired spelling\nand superior reading.” Hanley and Sotiropoulos (2018) obtained similar\nfindings with NR. He had no problems in reading words with atypical\nsound–letter associations but performed very poorly when required to spell\nsuch words.\nThe above findings may suggest there are two orthographic lexicons,\nwith the one associated with spelling being severely impaired in PJT and\nNR. However, this interpretation is implausible. It is more likely PJT has\none orthographic lexicon but finds it hard to access the information in it\nvia phonological long-term memory (as is required during spelling).\nKEY TERMS\nOrthographic lexicon\nPart of long-term memory\nin which learned word\nspellings are stored.\nDyslexia\nImpaired ability to read\nnot attributable to low\nintelligence.\nDysgraphia\nImpaired ability to write\n(including spelling).\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n563\nJames (2017) reviewed findings consistent with the dual-route theory\nand the notion there is a single orthographic lexicon. In essence, she found\nthat the brain areas associated with writing correspond closely to those\ninvolved in reading and in letter perception (see Figure 11.14).\nPurcell et  al. (2017) assessed activation in areas associated with\northographic processing (the ventral occipito-temporal cortex and infe-\nrior frontal gyrus) while participants read visually presented words or\nspelled spoken words. These areas were involved in both reading and\nspelling. When the same word was read on one trial and then spelled on\nthe next trial (or vice versa), there was reduced activation in brain areas\ninvolved in orthographic processing These findings provide strong evi-\ndence there is a single orthographic lexicon used on reading and spelling\ntasks.\nEvaluation\nThe issue of one vs two orthographic lexicons has not been fully resolved.\nHowever, most evidence from brain-damaged patients and from neuro-\nimaging studies on healthy individuals favours the notion of a single\northographic lexicon.\nWhat are the limitations of research in this area? First, much evidence\nis inconclusive. For example, individuals such as PJT and NR have severely\nimpaired spelling ability. This may occur because they have a deficient\northographic lexicon for spelling or because they have problems accessing\nthe orthographic lexicon when presented with word sounds. Second, the\nfact that children are often taught reading and spelling as separate skills\nsuggests some caution before rejecting the notion of two orthographic\nlexicons.\nFigure 11.14\nBrain areas in the left\nhemisphere associated with\nreading, letter perception\nand writing.\nFrom James (2017).\nSuperior temporal/\nsupramarginal gyri\nFusiform gyrus\nLeft hemisphere\nInferior frontal gyrus\nMiddle frontal gyrus\nPrecentral gyrus\nReading system\nLetter perception system\nWriting system\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-16 03:16:01.",
    "564\nLanguage\nCHAPTER SUMMARY\n•\nIntroduction. Speaking and writing rely on the same knowledge\nbase and involve similar planning skills. However, spoken language\nis simpler and less formal than written language because speakers\nhave less time for planning than writers, and because speech fulfils\na social function.\n•\nBasic aspects of speech production. Speech production involves\nseveral brain areas (and cognitive processes) overlapping with\nthose involved in speech perception. The finding that individuals\nwith mild cognitive impairment have poor speech quality indicates\nthat speech production is demanding. It is demanding in part\nbecause limited short-term memory means speakers have to make\nrapid decisions while planning and producing utterances. Speech\nproduction involves four stages: semantic; syntactic; morphological;\nand phonological.\n•\nSpeech planning. Speech planning can extend over a phrase\nor over a clause. The extent of advance speech planning often\ndiffers at the semantic, syntactic and phonological levels. Forward\nplanning is generally more extensive when speakers have no time\npressure, when they speak slowly and when they are under low\ncognitive load. Overall, speakers can choose flexibly whether to\nfocus on effective and error-free communication or on minimising\ncognitive demands.\n•\nSpeech errors. The study of speech errors can provide\ninsights into the processes (e.g., planning) underlying speech\nproduction. Speech errors including spoonerisms, Freudian\nslips, semantic substitutions, exchange errors and subject-verb\nagreement errors. Perceptual loop theory argues that speakers\nuse the comprehension system to monitor their inner and overt\nspeech for errors. In contrast, conflict-based monitoring theory\nargues that error detection depends primarily on the speech-\nproduction system combined with cognitive control processes.\nSpeakers monitor their inner and overt speech. Most such\nmonitoring probably involves the speech-production system and\ncognitive control processes rather than the comprehension system.\n•\nTheories of speech production. According to Dell’s spreading-\nactivation theory, the processing associated with speech\nproduction is parallel and interactive. The theory accounts for\nmost speech errors but may exaggerate processing interactivity.\nWEAVER++ is a discrete, feedforward model based on the\nassumption of serial processing. Patterns of brain activation\nprovide some support for this model, as does some research on\nthe tip-of-the-tongue state. However, speech production often\ninvolves more interactive and parallel processing than assumed\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n565\nwithin WEAVER++. In addition, the model exaggerates the\nrole of comprehension processes in the detection of one’s own\nspeech errors. Various theorists (e.g., Christiansen & Chater,\n2016) argue (with supporting evidence) that general cognitive\nprocesses (e.g., short-term memory; cognitive control) play\na major role in speech production. These general processes\nare de-emphasised within spreading-activation theory and\nWEAVER++.\n•\nCognitive neuropsychology: speech production. There\nis a traditional distinction between Broca’s aphasia (slow,\nungrammatical and non-fluent speech) and Wernicke’s aphasia\n(fluent speech often lacking meaning) involving damage to\ndifferent brain areas. The anatomical definitions of Broca’s and\nWernicke’s areas are unclear, and numerous other brain areas\nare also crucial in language processing. Anomia (impaired\nnaming ability) can involve semantic impairments or phonological\nimpairments, but interactions are sometimes found between\nsemantic and phonological processing. Patients with agrammatism\nproduce sentences lacking grammatical structure and with few\nfunction words. They have impaired processing resources, and\ngeneral problems with sequence learning. The speech of jargon\naphasics is reasonably grammatical. However, they produce many\nneologisms mostly due to deficient phonological processing.\nJargon aphasics’ production of jargon occurs in part because they\nhave deficient self-monitoring of their own speech. We can avoid\nan overreliance on categories such as anomia, agrammatism and\njargon aphasia by focusing on empirical similarities and differences\nin patterns of language impairments among aphasic patients.\n•\nSpeech as communication. The key purpose of speech is\ncommunication, and speakers are often sensitive to the needs of\ntheir listener. They also often make use of the common ground\nshared with the listener, but its use is subject to speakers’ memory\nlimitations as well as their processing limitations. Speakers use\ngestures in flexible ways that are generally responsive to the\nlistener. However, speakers make gestures even when the listener\ncannot see those gestures, because the use of gestures facilitates\nspeakers when planning what to say. Other ways speakers facilitate\ncommunication are by using prosodic cues (e.g., rhythm; stress)\nand discourse markers (words or phrases indirectly assisting the\nlistener’s comprehension).\n•\nWriting: the main processes. Writing involves proposing or\nplanning, translating, transcribing, and evaluating and revising\nthe text that has been produced. Shifts from one writing process\nto another depend on a monitor or control system. Good writers\nuse a knowledge-transforming rather than knowledge-telling\nstrategy and devote more time to revision. Expert writers attain\nCreated from usyd on 2022-02-16 03:16:01.",
    "566\nLanguage\na knowledge-crafting stage emphasising the reader’s needs. The\nworking memory system (especially the central executive) is heavily\ninvolved in the writing process. Word processing often enhances\nwriting quality, probably by encouraging revision and thinking\nprocesses.\n•\nSpelling. According to the two-route theory, there are separate\nlexical and non-lexical routes in spelling, with the former used\nto spell familiar words and the latter unfamiliar words and non-\nwords. Phonological dysgraphics have damage to the lexical route\nwhereas surface dysgraphics have damage to the non-lexical route.\nThe theory is oversimplified: phonological dysgraphics often have\ngeneral problems with phonological processing and the two routes\noften interact. Reading and spelling probably both involve a single\northographic lexicon. However, the evidence is complex and hard\nto interpret.\nFURTHER READING\nChater, N., McCauley, S.M. & Christiansen, M.H. (2016). Language as skill:\nIntertwining comprehension and production. Journal of Memory and Language,\n89, 244–254. Nick Chater and colleagues stress the strong links between speech\nproduction and comprehension and emphasise the role played by general\nprocesses (e.g., short-term memory; basic learning) in their development.\nDronkers, N.F., Ivanova, M.V. & Baldo, J.V. (2017). What do language disorders\nreveal about brain-language relationships? From classic models to network\napproaches. Journal of the International Neuropsychological Society, 23, 741–754.\nThis article by Nina Dronkers and colleagues contains a historical account\nshowing how cognitive neuropsychology has enhanced our understanding of the\nprocesses underlying language comprehension and production.\nFerreira, V.S. (2019). A mechanistic framework for explaining audience design in\nlanguage production. Annual Review of Psychology, 70, 29–51. Victor Ferreira\ndiscusses the processes used by speakers when attempting to be responsive to\nlisteners’ needs.\nHepner, C., McCloskey, M. & Rapp, B. (2017). Do reading and spelling share\northographic representations? Evidence from developmental dysgraphia.\nCognitive Neuropsychology, 34, 119–143. Christopher Hepner and colleagues\ndiscuss a recent version of the influential two-route theory of spelling.\nKellogg, R.T., Turner, C.E., Whiteford, A.P. & Mertens, A. (2016). The role\nof working memory in planning and generating written sentences. Journal of\nWriting Research, 7, 397–416. Ronald Kellogg and his colleagues provide a\ncomprehensive account of the various ways working memory contributes to the\nwriting process.\nMcClain, R. & Goldrick, M. (2018). The neurocognitive mechanisms of speech\nproduction. In S.L. Thompson-Schill (ed.), Stevens’ Handbook of Experimental\nPsychology and Cognitive Neuroscience, Vol. 3: Language and Thought (4th edn;\npp. 319–356). New York: Wiley. The major processes (including attention) that\nare involved in speech production are discussed in this chapter.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Language production\n567\nNozari, N. & Novick, J. (2017). Monitoring and control in language production.\nCurrent Directions in Psychological Science, 26, 403–410. This article provides\nan overview of the mechanisms used by speakers to avoid or correct production\nerrors.\nCreated from usyd on 2022-02-16 03:16:01.",
    "Created from usyd on 2022-02-16 03:16:01.",
    "569\nThinking and reasoning\nOur ability to reflect in complex ways on our lives (e.g., to plan and solve\nour daily problems) is the bedrock of thinking behaviour. The ways we think\n(and reason and make decisions) are very varied. They range from solving\nnewspaper crossword puzzles, to troubleshooting (or not!) if our car breaks\ndown, to developing a new theory of the universe. Below we consider two\nexamples of the activities to which we apply the term “thinking”.\nFirst, a fragment of Molly Bloom’s sleeping thoughts in James Joyce’s\nUlysses (1922/1960, pp. 871–872):\nGod help the world if all women in the world were her sort down on\nbathingsuits and lownecks of course nobody wanted her to wear I\nsuppose she was pious because no man would look at her twice I hope\nI’ll never be like her a wonder she didn’t want us to cover our faces but\nshe was a well educated woman certainly and her gabby talk about\nMr Riordan here and Mr Riordan there I suppose he was glad to get shut\nof her.\nSecond, here is the first author struggling to use PowerPoint:\nWhy has the Artwork put the title in the wrong part of the slide? Suppose\nI try to put a frame around it so I can drag it up to where I want it? Ah ha,\nnow if I just summon up the arrows I can move the top bit up, and then I\ndo the same with the bottom bit. If I move the bottom bit up more than\nthe top bit, then the title will fit in okay.\nThese two examples illustrate several general aspects of thinking. First,\nthey both involve individuals being conscious of their thoughts. Thinking\ntypically involves conscious awareness. There is an ongoing controversy\nconcerning the extent to which higher-level cognitive processes such as\nthinking can be unconscious (see Chapter 16). Hassin (2013) claimed uncon-\nscious processes can perform all the functions of conscious processes.\nHowever, the evidence suggests unconscious processes are much more\nPART IV\nCreated from usyd on 2022-02-17 03:28:25.",
    "570\nThinking and reasoning\n570\nThinking and reasoning\nlimited than conscious ones (especially with respect to thinking and reason-\ning) when stringent criteria are used to identify processes as “unconscious”\n(Hesselmann & Moors, 2015).\nNote also that we tend to be aware of the products of thinking rather than\nprocesses themselves (see Chapter 16). Furthermore, even when we can\nintrospect on our thoughts, our recollections of them are often inaccurate.\nJoyce reconstructs well the nature of idle, associative thought in Molly\nBloom’s internal monologue. However, if we asked her to tell us her thoughts\nfrom the previous five minutes, she would probably recall very little of it.\nSecond, thinking varies in the extent to which it is directed and controlled.\nIt can be relatively undirected as in the case of Molly Bloom letting one\nthought slide into another as she is on the point of slipping into a dream. In\nthe other example, the goal is much clearer and better defined.\nThird, the amount and nature of the knowledge used in different thinking\ntasks vary enormously. The knowledge required in the PowerPoint example\nis relatively limited (even though it took the first author much time to\nacquire it!). In contrast, Molly Bloom is making use of her vast knowledge of\npeople and of life.\nThe next three chapters (Chapters 12–14) are concerned with the higher-\nlevel cognitive processes involved in thinking and reasoning (see the Box,\nForms of thinking, on the facing page). Of importance, we use the same\ncognitive system to deal with all these types of thinking and reasoning. As a\nresult, many distinctions between different forms of thinking and reasoning\nare somewhat arbitrary and camouflage similarities in underlying cognitive\nprocesses.\nFrom the above viewpoint, it is unsurprising that similar brain areas are\ntypically involved in most problem-solving and reasoning tasks (see\nChapter  14). It is also worth mentioning there has recently been a major\nshift in research from deductive reasoning to informal reasoning because\nthe latter is of considerably more relevance in everyday life. Informal rea-\nsoning is closer than deductive reasoning to research on judgement and\ndecision-making because it makes much more use of an individual’s know-\nledge and experience.\nWe will briefly describe the structure of this section. Chapter 12 is concerned\nprimarily with the processes involved in problem solving. We discuss various\ntypes of problems (e.g., those involving insight) and there is an emphasis\non the reasons why most people find it very difficult to solve certain prob-\nlems. There is also an emphasis on the factors involved in the development\nof expertise in various areas (e.g., chess playing; medical expertise).\nChapter 13 deals with judgement and decision-making with an emphasis on\nthe errors and biases that are often involved. A central theme is that most\npeople make extensive use of heuristics (rules of thumb) that are simple to\nCreated from usyd on 2022-02-17 03:28:25.",
    "use but prone to error. Complex decision-making is also considered, as well\nas the role of emotional factors in decision-making.\nChapter 14 deals with the major forms of reasoning (inductive, deductive\nand informal) and the errors to which they are prone. There is also dis-\ncussion of the key (but very tricky!) question, “Are humans rational?”. As\nyou might expect, many psychologists answer that question “Yes and no”,\nrather than a definite “Yes” or “No”!\nFORMS OF THINKING\nProblem solving\nCognitive activity that involves moving from\nthe recognition that there is a problem through\na series of steps to the solution. Most other\nforms of thinking involve some problem solving.\nProblem solving differs from decision-making\nin that individuals have to generate their own\nsolutions.\nDecision-making\nSelecting one out of a number of presented\noptions or possibilities, with the decision having\npersonal consequences (e.g., winning or losing\nmoney).\nJudgement\nA component of decision-making that involves\ncalculating the likelihood of various possible\nevents; the emphasis is on accuracy.\nDeductive reasoning  Deciding what conclusions necessarily follow\nprovided various statements are assumed to be\ntrue; most deductive-reasoning tasks are based\non formal logic; however, most individuals use\ninformal reasoning (see below) rather than logic\nwith such tasks (see Evans et al., 2015).\nInformal reasoning\nEvaluating the strength of arguments by taking\naccount of one’s relevant knowledge and\nexperience.\nInductive reasoning\nDeciding\nwhether\ncertain\nstatements\nor\nhypotheses are true on the basis of the\navailable information. It is used by scientists and\ndetectives but is not guaranteed to produce\nvalid conclusions.\nThinking and reasoning\n571\nCreated from usyd on 2022-02-17 03:28:25.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving\nand expertise\nINTRODUCTION\nLife presents us with many problems, although thankfully most are fairly\ntrivial. Here are three examples. First, you have an urgent meeting in\nanother city. However, the trains generally run late, your car is old and\nunreliable, and the buses are slow. Second, you are struggling to work out\nthe correct sequence of operations on your computer to perform a given\ntask. You try to remember what you needed to do with your previous com-\nputer. Third, you are an expert chess player competing against a strong\nopponent. The time clock is ticking, and you must rapidly decide on your\nmove in a complicated position.\nThe above examples relate to the three main topics of this chapter. The\nfirst is problem solving, which involves the following (Goel, 2010, p. 613):\n“(1) there are two states of affairs; (2) the agent [problem solver] is in one\nstate and wants to be in the other state; (3) it is not apparent to the agent\nhow the gap between the two states is to be bridged; and (4) bridging\nthe gap is a consciously guided multi-step process.” One reason problem\nsolving is very important is because it is “a crossroads, where many dif-\nferent processes come together in the service of the needs and goals of an\nindividual” (Weisberg, 2018, p. 607).\nThe second topic is analogical problem solving. In our everyday lives,\nwe constantly use past experience and knowledge to assist us in our current\ntask. Often we detect (and make effective use of) analogies or similarities\nbetween a current problem and ones solved in the past.\nThe third topic is expertise. Individuals possessing expertise have\nconsiderable specialist knowledge in one area or domain. There is much\noverlap between expertise and problem solving in that experts are very effi-\ncient at solving numerous problems in their area of expertise. However,\nthere are also important differences. Knowledge is typically more impor-\ntant in research on expertise than problem solving. In addition, there is\nmore focus on individual differences in expertise research. Indeed, a central\nissue in expertise is to identify the main differences (e.g., in knowledge; in\nstrategic processing) between experts and novices.\nChapter\n12\nCreated from usyd on 2022-02-17 03:28:25.",
    "574\nThinking and reasoning\nPROBLEM SOLVING: INTRODUCTION\nThere are three major aspects to problem solving:\n(1) It is purposeful (i.e., goal-directed).\n(2) It involves controlled processes and is not totally reliant on “auto-\nmatic” processes.\n(3) A problem exists when someone lacks the relevant knowledge to\nproduce an immediate solution. Thus, for example, a task involving\nmathematical calculation may be a problem for most individuals but\nnot a professional mathematician.\nThe above three aspects are typically found during problem solving.\nHowever, as we will see, problem solving sometimes depends on non-\nconscious processes as well as (or instead of) the conscious deliberate pro-\ncesses implied by aspects (1) and (2).\nThere are major differences among problems. Well-defined problems\nare ones where all problem aspects are clearly specified, including the initial\nstate or situation, the range of possible moves or strategies, and the goal\nor solution. The goal is well specified because it is clear when it has been\nreached (e.g., the centre of a maze). Chess is a well-defined problem: there\nis a standard initial state, the rules specify all legitimate moves and the goal\nis to achieve checkmate. However, chess is in some ways ill- defined – the\nnature of the problem faced by a chess player varies constantly during a\ngame.\nIll-defined problems are underspecified. Suppose you set yourself the\ngoal of becoming happier. There are endless strategies you could adopt,\nand it is very hard to anticipate which would be most effective. Since hap-\npiness varies over time and is hard to define, how are you going to decide\nwhether you have solved the problem of becoming happier?\nMost everyday problems are ill-defined. However, psychologists have\nfocused mostly on well-defined problems. Why is this? With well-defined\nproblems, the researcher knows the correct answer and often also knows\nthe optimal strategy for their solution. As a result, they can easily identify\nthe errors and deficiencies in problem solvers’ strategies.\nGoel and Grafman (2000) studied PF, a man with brain damage to the\nright prefrontal cortex. He had a high IQ (128) and performed successfully\non well-defined laboratory tasks. However, he performed very poorly with\neveryday ill-defined problems because he produced inadequate preliminary\nplans. In similar fashion, Goel et al. (2013) found patients with damage to\nthe right prefrontal cortex made premature commitments when planning\na trip to Italy. In contrast, planning is more straightforward with most\nwell-defined problems.\nWe can also distinguish between knowledge-rich and knowledge-lean\nproblems. Knowledge-rich problems (e.g., chess problems) can only be\nsolved by those having much relevant specific knowledge. In contrast,\nknowledge-lean problems do not require such knowledge because the\ninformation needed to solve the problem is contained in the initial problem\nstatement. Historically, most research involved knowledge-lean problems\nbecause they minimise individual differences in relevant knowledge.\nKEY TERMS\nWell-defined problems\nProblems in which the\ninitial state, the goal and\nthe methods available for\nsolving them are clearly\nlaid out.\nIll-defined problems\nProblems in which the\nproblem is imprecisely\nspecified; for example, the\ninitial state, the goal state\nand the methods available\nto solve the problem may\nbe unclear.\nKnowledge-rich\nproblems\nProblems that can only be\nsolved by those having\nconsiderable relevant\nbackground knowledge.\nKnowledge-lean\nproblems\nProblems that can be\nsolved by individuals in\nthe absence of specific\nrelevant prior knowledge.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n575\nIN THE REAL WORLD: MONTY HALL PROBLEM\nWe can illustrate key issues in problem solving by considering the\nnotorious Monty Hall problem that formed an important part of\nMonty Hall’s show on American television:\nSuppose you’re on a game show and you’re given the choice of\nthree doors. Behind one door is a car, behind the others, goats.\nYou pick a door, say, Number 1, and the host, who knows what’s\nbehind the doors, opens another door, say Number 3, which has\na goat. He then says to you, “Do you want to switch to door\nNumber 2?” Is it to your advantage to switch your choice?\nIf you stayed with your first choice, you are in good company since\napproximately 85% of people make that decision. Unfortunately, it\nis wrong! There is actually a two-thirds chance of being correct if\nyou switch.\nMost people (including you?) furiously dispute the above answer.\nLet’s work it through. There are only three possible scenarios with\nthe Monty Hall problem (Krauss & Wang, 2003; see Figure 12.1).\nWith scenarios 1 and 2, your first choice is incorrect, and so Monty Hall opens the only remaining\ndoor with a goat behind it. As a result, switching is certain to succeed. With scenario 3, your first\nchoice is correct, and you would win by refusing to switch. Overall, switching succeeds two-thirds\nof the time.\nMonty Hall, the game-show host.\nMonty Hall. ZUMA Press, Inc./Alamy.\nFigure 12.1\nExplanation of the\nsolution to the Monty\nHall problem: in two out\nof three possible car/\ngoat arrangements, the\ncontestant would win by\nswitching; therefore she\nshould switch.\nFrom Krauss and Wang\n(2003). © 2003 American\nPsychological Association.\nCreated from usyd on 2022-02-17 03:28:25.",
    "576\nThinking and reasoning\nResearchers have studied problem solving using literally thousands of\ndifferent problems. This raises the issue as to whether there is some com-\nmonality in the processes used to solve these diverse problems. Bartley\net al. (2018) addressed this issue in a meta-analysis (see Glossary) of neuro-\nimaging studies involving mathematical, verbal and visuo-spatial problems.\nBartley et al. (2018) identified what they called “a core problem solving\nnetwork” (p. 318) that was common to all three types of problem (see\nFigure 12.2(d)). More specifically, there was a fronto-parietal network (e.g.,\nthe dorsolateral prefrontal cortex; the cingulate gyrus involved in processes\nsuch as attention, monitoring and working memory). In addition, there\nwere brain areas specific to mathematical, verbal and visuo-spatial prob-\nlems (see Figure 12.2).\nGESTALT APPROACH AND BEYOND: INSIGHT\nAND ROLE OF EXPERIENCE\nEarly research on problem solving was dominated by the gestaltists,\nGerman psychologists flourishing between the 1920s and 1940s. They dis-\ntinguished between reproductive and productive thinking. Reproductive\nthinking involves the systematic re-use of previous experiences (e.g., in\nHuman performance on the Monty Hall problem is very poor. Indeed, Herbranson and Schroeder\n(2010) found it was much worse than that of pigeons! After extensive practice, humans switched\non 66% of trials (the optimal response) whereas pigeons switched on 96% of trials. The pigeons\nperformed well because they simply maximised the reward they received whereas humans used\nmore complex strategies.\nWhy do humans perform so poorly on this problem? First, people typically use a heuristic (rule\nof thumb) known as the equiprobability bias (assuming all available options are equally likely even\nwhen they are not; Tubau et al., 2015). In addition, people experience more regret when losing by\nswitching than when losing by staying (Tubau et al.). These two factors lead most people to stay,\nmistakenly.\nSecond, the problem places substantial demands on the central executive (an attention-like\nsystem; see Glossary). Performance on the Monty Hall problem was much worse if participants per-\nformed a demanding task involving the central executive at the same time (8% vs 22%; De Neys\n& Verschueren, 2006).\nThird, many people mistakenly believe the host’s actions are random. Burns and Wieth (2004)\nmade the causal structure of the problem clearer. There are three boxers, one of whom is so good\nhe is certain to win any bout. You select one boxer and then the other two fight each other. The\nwinner of this bout then fights the boxer you selected initially. You win if you choose the winner\nof this second bout. With this version of the problem, 51% correctly decided to switch versus only\n15% with the standard three-door problem. This occurred because it is easy to see that the boxer\nwho won the first bout did so because of skill rather than any random factor.\nFourth, it is very hard to understand the problem. Saenen et al. (2015) found 16% of university\nstudents produced the optimal answer (i.e., switching) but only half understood the underlying\nprobabilities. For example, the probabilities of winning-when-staying and winning-when-switching\nmust equal 1 but several participants produced probabilities that did not sum to 1! Thus, it is\npossible to “solve” the Monty Hall problem without full understanding. When participants are pro-\nvided with relevant information about the underlying probabilities, over 80% of them decided to\nswitch compared to only 40% when that information was not provided (James et al., 2018).\nKEY TERM\nHeuristic\nRule of thumb that is\ncognitively undemanding\nand often produces\napproximately accurate\nanswers; see algorithm.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n577\nmathematical problems) and is mostly required on well-defined problems.\nProductive thinking involves novel problem restructuring and is mostly\nrequired on ill-defined problems. In what follows, our main focus will be on\ntheorising and research influenced by the Gestalt approach with only occa-\nsional mentions of the gestaltists’ original research.\nInsight\nThe gestaltists argued problems requiring pro-\nductive thinking are often solved using insight.\nInsight involves a sudden problem restructur-\ning, often accompanied by an “Aha! experi-\nence”. More technically, insight is “any sudden\ncomprehension, realisation, or problem solu-\ntion that involves a reorganisation of the ele-\nments of a person’s mental representation\nof a stimulus, situation, or event to yield a\nnon-obvious or non-dominant  interpretation”\n(Kounios & Beeman, 2014, p. 74).\nThe mutilated draughtboard (or chequer-\nboard) problem (see Figure 12.3) is an insight\nproblem. The board is initially covered by 32\ndominoes occupying two squares each. Then\ntwo squares are removed from diagonally\nKEY TERM\nInsight\nThe experience of\nsuddenly realising how\nto solve a problem;\nsometimes referred\nto as the “the Aha!\nexperience”.\nFigure 12.2\nBrain areas (a) involved in mathematical problem solving; (b) verbal problem solving;\n(c) visuo-spatial problem solving; and (d) areas common to all three problem types\n(conjunction).\nFrom Bartley et al. (2018). Reprinted with permission of Elsevier.\nFigure 12.3\nThe mutilated draughtboard problem.\nCreated from usyd on 2022-02-17 03:28:25.",
    "578\nThinking and reasoning\nopposite corners. Can the remaining 62 squares be filled by 31 dominoes?\nWhat is your answer?\nNearly everyone starts by mentally covering squares with dominoes.\nAlas, this strategy is ineffective because there are 758,148 possible permu-\ntations! You may well rapidly solve the problem using insight if we tell\nyou something you already know – each domino covers one white and one\nblack square. If that does not work, note that the two removed squares\nmust have the same colour. Thus, the 31 dominoes cannot cover the muti-\nlated board.\nThere is theoretical controversy concerning insight. Some (including\nthe gestaltists) claim it is very different from other cognitive processes (the\nspecial-process viewpoint). However, others claim very similar processes\nare used in insight and non-insight problems (the business-as-usual view-\npoint) (Zander et al., 2016). Below we discuss this controversy.\nFindings\nResearchers often use participants’ reports of the Aha! experience to indi-\ncate insight. Ideally, the Aha! experience should be reported predominantly\non “insight problems” rather than “non-insight problems” and should be\nassociated with correct solutions.\nThe evidence partially supports these predictions. Webb et al. (2016a)\nfound Aha! experiences were reported more often with insight than non-\ninsight or problems. However, insight problems were sometimes solved\nwithout any Aha! experiences and the solution of non-insight problems\nwas sometimes accompanied by Aha! experiences.\nThe gestaltists apparently assumed insight always produces correct\nsolutions. Danek and Wiley (2017) reported contrary evidence using insight\nproblems. Many incorrect solutions (especially those produced rapidly)\nwere associated with Aha! experiences.\nMuch research has considered whether insight is associated with a spe-\ncific pattern of brain activity (Kounios & Beeman, 2014). The findings are\nvariable. Bowden et al. (2005) used the Remote Associates Test: three\nwords were presented (e.g., fence; card; master) and participants thought\nof a word (e.g., post) going with each one to form compound words.\nThe anterior superior temporal gyrus was activated only when solutions\ninvolved insight. This is a brain area associated with processing distant\nsemantic relations between words as well as reinterpretation and semantic\nintegration. Other areas associated with insight are the anterior cingulate\ncortex (involved in the detection of cognitive conflict and the breaking of a\nmindset) and the prefrontal cortex (involved in higher cognitive processes\n(Kounios & Beeman, 2014).\nMetcalfe and Wiebe (1987) assessed participants’ feelings of “warmth”\n(closeness to solution) during insight and non-insight problems. Warmth\nincreased progressively during non-insight problems (as expected because\nthey involve several processes). With insight problems, warmth ratings\nremained low until suddenly increasing dramatically just before problem\nsolution (consistent with the Aha! experience). Kizilirmak et al. (2018)\nreported similar findings using the Remote Associates Test (discussed\nabove). Feelings of warmth increased much more abruptly for problems\nKEY TERM\nRemote Associates Test\nThis involves finding a\nword that is related to\nthree given words (e.g.,\nopera, hand and dish are\nall related to soap).\nCase study:\nBrain areas involved in\ninsight\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n579\nwhose solution was accompanied by an Aha! experience than those solved\nwith such experience.\nSubjectively, insight occurs suddenly and unexpectedly. However,\nthis is not necessarily true of the underlying processes. Ellis et al. (2011)\nrecorded eye movements while participants solved four-letter anagrams\n(five letters were presented but one was a distractor). On insight trials, par-\nticipants reported suddenly finding the solution to the problem. However,\nparticipants had decreasing fixations on the distractor letter ahead of the\nsolution indicating they were gradually, but unconsciously, accumulating\nrelevant knowledge.\nIn sum, insight is a process differing from other, more controlled\nprocesses. However, there are issues with respect to the measurement of\ninsight. For example, Laukkonen and Tangen (2018) found problem solvers\noften report the Aha! experience in the absence of a sudden increase in\nwarmth ratings and vice versa. The Aha! experience is a preferable measure\nof insight because it is more consistently associated with various objective\nmeasures (e.g., problem-solving strategies; performance accuracy on insight\nproblems) (see Laukkonen & Tangen). Of relevance, the Aha! experience is\nassociated with increased autonomic arousal (Shen et al., 2018) indicating\nan emotional reaction to insightful problem solving.\nRepresentational change theory\nOhlsson (1992, 2011) developed the gestaltist approach in his representa-\ntional change theory. According to this theory, the initial stage of problem\nsolving involves forming a mental representation of the problem. After\nthat, we access various mental operators that might be applied to this\nrepresentation, only one of which is selected and used at any given time.\nMore specifically, the current mental representation causes activation to\nspread to mental operators related to it in meaning via an unconscious\nprocess and the mental operator most strongly activated is retrieved.\nWe often encounter an impasse (feeling blocked and unsure how to\nproceed) when solving a problem because our mental representation of it\nis incorrect. Theoretically, we must change (or restructure) the problem\nrepresentation for insight to occur. This can happen in three ways:\n(1) Constraint relaxation: inhibitions on what is regarded as permissible\nare removed.\n(2) Re-encoding: some aspect of the problem representation  is  re inter -\npreted.\n(3) Elaboration: new problem information is added to the representation.\nŐllinger et al. (2014) developed representational change theory (see Figure\n12.4). What is new is the assumption that a search process may be neces-\nsary even after an impasse has been overcome by insight. For example,\nconsider the nine-dot problem which requires four straight lines that go\nthrough all nine dots (see Figure 12.5). Most people initially assume the\nline must remain within the confines of the square formed by the dots.\nEven when this constraint is relaxed by explicitly instructing participants\nthat they can draw lines outside the square, performance is still poor.\nKEY TERM\nImpasse\nThe experience of being\nblocked and not knowing\nhow to proceed when\nengaged in problem\nsolving.\nCreated from usyd on 2022-02-17 03:28:25.",
    "580\nThinking and reasoning\nThus, the processes involved can be more\ncomplex than envisaged within representa-\ntional change theory.\nFindings\nEarlier we discussed the mutilated chessboard\nproblem on which nearly everyone starts\nwith an incorrect problem representation.\nSolving it requires representing each domino\nas an object covering one white and one black\nsquare ( re-encoding) and representing the\nchessboard as having lost two black (or white)\nsquares (elaboration).\nKnoblich et al. (1999) showed the importance of constraint relaxation\nusing matchstick problems involving Roman numerals (see Figure  12.6).\nThe solution to each problem requiring moving a single stick to produce\na true statement to replace the initial false one. Some problems (Type A)\nonly required changing two values in the equation (e.g., VI = VII + I [6\n= 7 + 1] becomes VII = VI + I [7 = 6 + 1]). In contrast, Type B  problems\ninvolved a less obvious change in the  representation of the equation (e.g.,\nIV = III – I [4 = 3 – 1] becomes IV – III = I [4 – 3 = 1]).\nAccording to Knoblich et al. (1999), we have learned that many opera-\ntions change the values (numbers) in an equation (as in Type A  problems). In\ncontrast, relatively few operations change the operators (i.e., +, – and =)\nas required in Type B problems. As predicted, participants found it much\nharder to relax the normal constraints of arithmetic (and so show insight)\nwith Type B problems. Knoblich et al. (2001) reported further evidence that\nparticipants’ initial representation is based on the assumption that values\nmust be changed. Participants initially spent much more time fixating the\nvalues than the operators with both types of problems.\nFigure 12.4\nFlow chart of insight\nproblem solving. Initially,\na problem representation\nis established using prior\nknowledge and perceptual\nprocesses. The problem\nrepresentation is searched\nby heuristics (rules of\nthumb). If this proves\nunsuccessful, an impasse\nis encountered. This leads\nto a change in the problem\nrepresentation and this\nnew representation is also\nsearched by heuristics. This\nprocess is continued until\na solution is found or the\nproblem is abandoned.\nFigure 12.5\n(a) The nine-dot problem and (b) its solution.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n581\nFigure 12.6\nTwo of the matchstick\nproblems used by Knoblich\net al. (1999) and the\ncumulative solution rates\nproduced for these types of\nproblems in their study.\n© American Psychological\nAssociation.\nReverberi et al. (2005) argued that processing constraints on insight\nproblems involve the lateral prefrontal cortex. Patients with damage to\nthat area should not impose artificial constraints when solving insight\nproblems and so might perform better than healthy controls. As predicted,\nbrain-damaged patients solved 82% of the hardest matchstick arithmetic\nproblems compared to only 43% of controls.\nAccording to representational change theory, solution hints should be\nmost useful when individuals have just reached an impasse or block. At\nthat point, they have formed an incorrect problem representation but have\nnot become excessively fixated on it. Moss et al. (2011) obtained findings\nconsistent with this prediction.\nFleck and Weisberg (2013) asked participants to think aloud while\nsolving insight problems. There were large individual differences in their\nstrategies. Evidence of impasse and restructuring (of crucial importance\naccording to representational change theory) was obtained on only 25% of\nproblem attempts. Other successful strategies included direct applications\nof knowledge with no representational change and use of simple heuris-\ntics or rules of thumb (e.g., hill climbing, see Glossary). Overall, there was\nmuch less evidence of impasse and restructuring when solutions were pro-\nduced rapidly rather than slowly.\nFedor et al. (2015) reported various findings inconsistent with rep-\nresentational change theory in a study on solving an insight problem.\nFirst, less than 50% of problem solvers followed the theoretically predicted\nsequence of constrained search, impasse, insight, extended search and\nsolution. Most used more complex processing sequences with search and\nimpasse occurring several times. Second, Fedor et al. compared reported\nexperiences of impasse with behaviourally defined measures (i.e., repeti-\ntious behaviour; inactivity). Problem solvers were no more likely to report\nexperiencing an impasse during a behaviourally defined impasse than at\nother stages of processing.\nIn sum representational change theory provides a more explicit and\ntestable account than the original Gestalt theory. However, it is  increasingly\nclear that problem solving on insight problems is significantly more flexible\nand variable than assumed by that theory.\nCreated from usyd on 2022-02-17 03:28:25.",
    "582\nThinking and reasoning\nEvaluation\nRepresentational change theory extended the Gestalt approach by specify-\ning the mechanisms underlying restructuring and insight. More generally, it\ninvolves a fruitful combination of Gestalt ideas with cognitive psychology.\nÖllinger et al.’s (2014) extension of this theory has improved it by empha-\nsising that efficient search processes are often needed after as well as before\nan impasse leading to insight.\nWhat are the theory’s limitations? First, the theory provides an ideal-\nised account of the processes involved in insight problems. There are\nsubstantial individual differences in problem processing, and processing\nsequences are often more complex and flexible than assumed theoretically.\nSecond, we often cannot predict when (or why) problem solvers change a\nproblem’s representation.\nThird, there is often surprisingly little evidence of restructuring or\nimpasse when individuals solve insight problems. Fourth, the strategies\nused to solve insight problems include some (e.g., direct application of\nknowledge; heuristics) not included within the theory. Fifth, the original\nIN THE REAL WORLD: MAGIC TRICKS\nMany magic tricks persuade spectators to focus on a\nstrong (but incorrect) problem representation (Danek et\nal., 2014). For example, a magician pours water from a\nglass into an empty mug. He then turns the mug upside\ndown and a large ice cube drops out (see YouTube:\nhttp://www.youtube.com/watch?v=3B6ZxNROuNw).\nThis trick works because most people assume the mug\nis empty. In fact, there is a white napkin glued to the\nbottom of the mug and the ice cube. The water is fully\nabsorbed by the napkin and so only the ice cube falls\nout. Participants given a verbal cue to relax the incor-\nrect assumption that the mug was empty had improved\nperformance.\nSpectators often cannot change their initial incorrect problem representation into the correct\none. Our perceptual system rapidly and unconsciously extrapolates from the visible parts of objects\nto complete them (the Gestalt law of closure shown in Figure 3.4) (Ekroll et al., 2017). For example,\nconsider the Chinese linking rings trick in which solid metal rings appear to link and unlink by\npassing through each other. One ring has a small gap in it, but spectators assume all the rings are\ncomplete.\nThe multiplying billiard balls trick also depends on visual completion (see Figure 12.7). The con-\njuror starts with a single ball and then progressively adds balls until they have four: the initial ball\nis a hollow shell initially having a complete ball hidden in it. When that second ball is revealed, the\nconjuror inserts another complete ball in the hollow shell and so on.\nWhen observers viewed a hollow shell balanced on the tip of their finger, they perceived a\ncomplete ball despite strong evidence it was hollow (Ekroll et al., 2016). They even perceived their\nown finger as shorter than usual! These findings are directly relevant to representational change\ntheory  – observers often cannot correct their incorrect problem representation because their\nassumption the initial ball is complete is based on powerful perceptual processes.\nFigure 12.7\nThe multiplying billiard balls trick. (a) This is the\nend of the trick when the initial one ball has\nbecome four balls; (b) the secret of this trick is\nthat the initial ball is an empty semi-spherical\nshell that can contain another ball.\nFrom Ekroll et al. (2017).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n583\ntheory mistakenly implied that constraint relaxation is typically sufficient\nto solve insight problems (Őllinger et al., 2014).\nFacilitating insight: hints and incubation\nWe can facilitate insight by providing subtle hints. Consider Maier’s\n(1931) pendulum problem. Participants enter a room containing various\nobjects (e.g., poles, pliers, extension cords) plus two hanging strings (see\nFigure  12.8). The task involves tying the strings together, but they are\ntoo far apart for participants to reach one string while holding the other.\nThe solution involves tying the pliers to one string and swinging it like a\npendulum.\nThomas and Lleras (2009) used the pendulum problem with occa-\nsional exercise breaks in which participants swung or stretched their arms.\nThose moving their arms in a solution-relevant way (i.e., swinging) were\nmore likely to solve the problem even though unaware of the relationship\nbetween their arm movements and the task.\nWallas (1926) claimed problem solving can benefit from incubation,\nwhich “arises when the solution . . . comes to mind after a temporary\nshift of attention to another domain” (Sio & Ormerod, 2015, p. 113).\nResearch typically involves comparing an experimental group having an\nincubation period away from an unsolved problem with a control group\nworking continuously. Sio and Ormerod (2009) reported three findings in\na meta-analysis:\n(1) Incubation effects (generally fairly small) were reported in 73% of the\nstudies.\n(2) Incubation effects were stronger with creative problems having mul-\ntiple solutions than linguistic and verbal problems having a single\nFigure 12.8\nThe two-string problem\nin which it is not possible\nto reach one string while\nholding the other.\nKEY TERM\nIncubation\nA stage of problem\nsolving in which the\nproblem is put to one\nside for some time; it\nis claimed to facilitate\nproblem solving.\nCreated from usyd on 2022-02-17 03:28:25.",
    "584\nThinking and reasoning\nsolution. Incubation often widens the search for knowledge, which\nmay be more useful with multiple-solution problems.\n(3) The effects were larger when there was a fairly long preparation time\nprior to incubation. This may have occurred because an impasse or\nblock in thinking is more likely to develop when preparation time is\nlong.\nWhy is incubation beneficial? Simon (1966) argued control information\nrelating to the strategies used by problem solvers is forgotten during incu-\nbation. This forgetting facilitates problem solvers adopting a new approach\nafter the incubation period. Penaloza and Calvillo (2012) found solving\ninsight problems was only facilitated by a 2-minute break when this allowed\nmisleading information to be forgotten.\nGilhooly (2018) focused on “unconscious work”: “Incubation effects\ninvolve active although unconscious processing of the problem materials.”\nHis approach is supported by research on insight problems using two con-\nditions: (1) the task instructions immediately precede each problem; (2) a\ntotally irrelevant task is performed between instructions and the problem.\nPerformance is typically better in condition (2) than condition (1). This\ncan be explained by unconscious work but not forgetting previously used\nstrategies or information.\nPast experience: mental set\nPast experience generally increases our ability to solve problems. However,\nthe gestaltists argued persuasively we sometimes fail to solve problems\nbecause we are misled by our past experience. For example, mental set\n(Einstellung in German) involves continuing to use a previously successful\nproblem-solving strategy even when inappropriate or suboptimal. However,\nmental set is often useful – it allows successive problems of the same type to\nbe solved rapidly, with few processing demands.\nLuchins (1942) investigated mental set using problems that involved\nthree water jars of varying capacity. Here is a sample problem. Jar A can\nhold 28 quarts of water, Jar B 76 quarts and Jar C 3 quarts. You must end\nup with exactly 25 quarts in one of the jars. The solution is easy: Jar A is\nfilled, and then Jar C is filled from it, leaving 25 quarts in Jar A. Of partic-\nipants previously given similar problems, 95% solved it. Other participants\nhad previously been trained on problems all having the same complex\nthree-jar solution (fill Jar B and use the contents to fill Jar C twice and\nJar A once). Of these participants, only 36% solved the easy final problem!\nVallée-Tourangeau et al. (2011) found the damaging effects of mental\nset on Luchins’ water-jar problems were reduced when actual water jars\nwere used rather than presenting the problems on paper (as in the original\nresearch). According to Vallee-Tourangeau et al., the actual water jars pro-\nvided a “rich and dynamic . . . perceptual input” (p. 1894).\nThomas and Didierjean (2016) showed some powerful effects of mental\nset. Participants saw a central card surrounded by six cards (all face down).\nA magician asked them to select one of the six cards, which was then\nrevealed to match the central card. Participants were asked to identify\nthe trick’s secret (all the cards are the same). When the magician did not\nKEY TERM\nMental set\nThe tendency to use a\nfamiliar problem-solving\nstrategy that has proved\nsuccessful in the past\neven when it is no longer\nappropriate; also known\nas Einstellung.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n585\nsuggest a solution, 83% of participants solved the trick. However, when he\nclaimed he could influence participants’ choice by a specific hand move,\nonly 13% of participants solved the trick! Thus, mental set is so strong that\na single exposure to an implausible solution can inhibit finding the actual\n(and more obvious) solution.\nWe might assume experts given a problem in their area of expertise\nwould be relatively unaffected by mental set. Bilalić et al. (2008a) tested\nthis assumption with chess experts. Most failed to identify the shortest way\nto win a chess game, using instead a longer solution based on a familiar\nstrategy. However, the most skilful players were least likely to be impaired\nby mental set.\nWhy are chess experts susceptible to the damaging effects of mental\nset? Bilalić et al. (2008b) studied chess experts who had found the familiar\nsolution but were seeking a better one. They still fixated features of the\nchessboard position related to the familiar solution. Thus, their attention\nwas still partly controlled by processes producing the initial familiar solu-\ntion even though they were unaware this was the case.\nIn sum, mental set often impairs problem solving. Gobet (2016) argued\nthat its negative effects are very widespread. For example, mental set can\nlead scientists to ignore findings inconsistent with their favourite theory (see\nChapter 14). It is also relevant to myside bias (see Glossary) which involves\npeople disregarding arguments disproving their beliefs (see Chapter 14).\nPast experience: functional fixedness\nWe turn now to a specific form of mental set: functional fixedness.\nFunctional fixedness occurs when we mistakenly assume any given object\nhas only a limited number of familiar uses.\nDuncker (1945) carried out a classic study on functional fixedness.\nParticipants were given a candle, a book of matches, tacks in a box and\nseveral other objects (see Figure 12.9). Their task was to attach the candle\nto a wall by the table, so that it did not drip onto the table below. Most\nparticipants tried to nail the candle directly to the wall or glue it to the wall\nby melting it. Only a few produced the correct answer – use the inside of\nthe tack box as a candle holder and then nail\nit to the wall with tacks.\nAccording to Duncker (1945), his partic-\nipants “fixated” on the tack box’s function\nas a container rather than a platform. More\ncorrect solutions were produced when the box\ncontaining the tacks was empty at the start of\nthe experiment because it appeared less like a\ncontainer.\nMore direct evidence that past experi-\nence can produce functional fixedness was\nreported by Ye et al. (2009). Participants\ndecided whether objects could be used for a\nspecific function (e.g., packable with – usable\nas packing material to pack an egg in a box).\nImmediately afterwards, they decided whether\nKEY TERM\nFunctional fixedness\nThe inflexible focus on\nthe usual function(s) of an\nobject in problem solving.\nFigure 12.9\nSome of the materials provided for participants instructed\nto mount a candle on a vertical wall in the study by Duncker\n(1945).\nCreated from usyd on 2022-02-17 03:28:25.",
    "586\nThinking and reasoning\nthe same objects could be used for a different function (e.g., play catch\nwith, over a distance of 15 feet). Some objects (e.g., ski cap; pillow) could\nbe used for both functions. Deciding an object possessed the first function\nreduced the probability of detecting it also possessed the second function:\nthis is functional fixedness.\nIt is often assumed we are inflexible in our perceived uses of objects.\nWagman et al. (2016) disputed this assumption. Rods with several added\nplastic pieces were regarded as more suitable for striking than poking an\nobject. However, such rods were not regarded as suitable for striking with\nprecision although they were suitable for striking with power.\nHow can we overcome functional fixedness? Challoner (2009) studied\n1,001 important inventions and solutions to insight problems. Two steps\nwere typically involved:\n(1) Focus on an infrequently noticed or new feature.\n(2) Form a solution based on that obscure feature.\nMcCaffrey (2012) argued crucial obscure features are ignored because\npeople focus on the typical functions of objects based on their shape, size,\nmaterial they were made of, and so on. This functional fixedness can be\nreduced by the generic-parts technique: (1) generate function-free descrip-\ntions of all object parts; (2) decide whether each description implies a use.\nMcCaffrey gave some participants training in the generic-parts technique.\nThese participants solved 83% of insight problems (e.g., Duncker’s candle\nproblem) compared to only 49% in the control group.\nCognitive control: its role in insight, functional fixedness\nand mental set\nCognitive control refers to “the ability to limit attention to goal- relevant\ninformation and inhibit, or suppress, irrelevant distraction” (Amer et al.,\n2016b, p. 905). It is greater in individuals high in working memory capacity\n(which is related to attentional control; see Glossary). We might expect a\nhigh level of cognitive control to be advantageous on tasks involving insight,\nfunctional fixedness or mental set. However, that is not always the case.\nCognitive control is associated with a narrow focus of attention on\ngoal-relevant information and specific task strategies coupled with an inhi-\nbition of processing of other information sources (Amer et al., 2016b).\nThus, high cognitive control can impair performance when a broad focus\nof attention would be beneficial.\nFindings\nPope et al. (2015) compared the ability to break a mental set in human\nadults, children and baboons. The original task was as follows: (1) pres-\nentation of two red squares followed by participants touching the locations\npreviously occupied by those red squares: (2) if this was done correctly, a\nblue triangle was presented and had to be touched for reward. After partic-\nipants had established a mental set, the task changed slightly – the blue tri-\nangle was present throughout. All participants needed to do was touch the\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n587\nblue triangle for reward (thus breaking the mental set) although they could\nkeep using the original strategy.\nPope et al. (2015) found 100% of baboons successfully broke the\nmental set, as did 45% of children but only 12% of adults! Thus, the ability\nto break the mental set was inversely related to intelligence (and cognitive\ncontrol). Baboons probably broke the mental set because that involved\nmuch less processing capacity than the original strategy. Human adults did\nnot break the set because they found it hard to believe the task could be as\neasy as simply touching the blue triangle.\nDeCaro et al. (2016) compared the performance of individuals who\nwere high and low in working memory capacity (resembling attentional\ncontrol) on Knoblich et al.’s (1999) matchstick arithmetic problems. Some\nrequired insight (e.g., the Type B problem shown in Figure 12.6) whereas\nothers did not (e.g., the Type A problem shown in Figure 12.6). Participants\nhigh in working memory capacity performed better than those low in\nworking memory capacity scorers on problems not requiring insight (see\nFigure 12.10). However, the opposite was the case with insight problems.\nHow can we explain the above findings? Individuals high in working\nmemory capacity tend to consider complex problem solutions even when\nsimple ones are required (DeCaro et al., 2016, 2017). This disadvantages\nhigh-capacity individuals on many insight problems. However, high-\ncapacity individuals are often better than low-capacity ones at forming\nan initial problem representation and this facilitates their performance of\nmany non-insight problems.\nJarosz et al. (2012) considered the effects of alcohol intoxication on\nan insight task (Remote Associates Test; see Glossary). Intoxicated partic-\nipants solved 58% of the problems compared to only 42% for sober par-\nticipants. Alcohol intoxication broadened participants’ attentional focus\nbeyond strong (but incorrect) associates of the three words presented on\neach trial.\n100%\n90%\n80%\n70%\n60%\n50%\n40%\nProblem success (probability)\nWorking memory capacity\nLow (–1 SD)\nHigh (+1 SD)\nIncremental\nInsight\n30%\n30%\n10%\n0%\nFigure 12.10\nMean percentages of\ncorrect solutions as a\nfunction of problem type\n(incremental, not requiring\ninsight, vs insight) and\nworking memory capacity\n(low vs high).\nFrom DeCaro et al. (2016).\nCreated from usyd on 2022-02-17 03:28:25.",
    "588\nThinking and reasoning\nChrysikou et al. (2013) assessed the role of cognitive control in func-\ntional fixedness when participants generated common or uncommon uses for\nobjects. When transcranial magnetic stimulation (TMS; see Glossary) was\napplied to the left prefrontal cortex to reduce cognitive control, this facil-\nitated performance when uncommon uses for objects had to be produced.\nConclusions\nHigh cognitive control can impair performance on certain tasks, especially\nthose “that are aided by the use of previously irrelevant information, or\non tasks that generally benefit from drawing on diverse bits of information\nfrom various sources” (Amer et al., 2016b, p. 906). However, high cognitive\ncontrol is advantageous on tasks requiring working memory and/or selec-\ntive attention, and when distracting stimuli must be ignored. It remains for\nthe future to establish precisely which tasks benefit from (or are impaired\nby) high cognitive control and to obtain a detailed understanding of the\nunderlying mechanisms.\nPROBLEM-SOLVING STRATEGIES\nMajor landmarks in problem-solving research were an article by Newell\net al. (1958) followed in 1972 by Newell and Simon’s book, Human Problem\nSolving. Their central insight was that the strategies we use when tackling\ncomplex problems reflect our limited ability to process and store informa-\ntion. More specifically, we have very limited short-term memory capacity\nand so complex information processing is typically serial (one process at\na time). These assumptions were included in their General Problem Solver\n(a computer program designed to solve well-defined problems).\nGobet and Lane (2015) evaluated this theoretical approach. On the pos-\nitive side, the General Problem Solver was one of the first  problem-solving\nprograms and led to Newell and Simon being identified as “the founding\nfathers of artificial intelligence” (Gobet & Lane, 2015, p. 141). In addition,\nNewell and Simon (1972) identified several important problem- solving\nstrategies (discussed below). Limitations include exaggerating the role of\nserial processing in problem solving and the reliance on rather abstract and\nartificial problems.\nNewell and Simon (1972) used various well-defined, knowledge-lean\nproblems (e.g., the Tower of Hanoi; see Figure 12.11). The initial problem\nstate consists of up to five discs piled in decreasing size on the first of three\npegs. When they are on placed in the same order\non the last peg, the problem has been solved. Only\none disc can be moved at a time and a larger disc\ncannot be placed on top of a smaller one.\nNewell and Simon (1972) identified a\nproblem space for each problem. A problem\nspace consists of the initial problem state, the\ngoal state, all possible mental operators (e.g.,\nmoves) that can be applied to any state to\nchange it into a different state, and all the inter-\nmediate problem states.\nFigure 12.11\nThe initial state of the five-disc version of the Tower of\nHanoi problem.\nKEY TERM\nProblem space\nAn abstract description of\nall the possible states that\ncan occur within a given\nproblem.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n589\nHow do we solve well-defined problems with our limited process-\ning capacity? According to Newell and Simon (1972), we rely heavily on\nheuristics (see Glossary) – rules of thumb that are easy to use and often\nproduce reasonably accurate answers. Heuristics can be contrasted with\nalgorithms (computational methods guaranteed to produce a problem\nsolution). Algorithms are often too complex to be used by most people.\nIn this section, we consider some heuristics identified by Newell and\nSimon (1972). We also discuss other heuristics and strategies for problem\nsolving.\nHill climbing\nNewell and Simon (1972) identified the hill-climbing heuristic. Hill climbing\nis a very simple strategy which involves changing the present problem state\ninto one closer to the goal. It is mostly used when the problem solver has no\nclear understanding of the problem structure and so focuses on very short-\nterm goals. Use of hill climbing resembles a climber who tried to reach the\nhighest mountain peak in the area by using the strategy of always moving\nupwards. This may work. However, the climber will probably find himself/\nherself trapped on a hill several valleys away from the highest peak.\nMeans–ends analysis\nAccording to Newell and Simon (1972), the most important heuristic\nmethod is means–ends analysis. It resembles hill climbing but the problem\nsolver has greater awareness of how to break the problem down into\nsub-problems. Here is the essence of means–ends analysis:\n●\nNote the difference between the current problem state and the goal state.\n●\nForm a subgoal to reduce the difference between the current and goal\nstates.\n●\nSelect a mental operator (e.g., move or moves) that permits attainment\nof the subgoal.\nMeans–ends analysis typically assists problem solution. However, Sweller\nand Levine (1982) found it can severely impair performance. Participants\ntried to solve an apparently simple maze, most of which was not visible.\nSome participants could see the goal state (goal-information group)\nwhereas others could not. Use of means–ends analysis requires knowledge\nof goal location and so only the goal-information group could use that\nheuristic. However, the problem was designed so that means–ends analysis\nwould not be useful – every correct move involved turning away from the\ngoal. Only 10% of participants in this group solved the problem in 298\nmoves whereas those in the other group solved the problem in an average\n38 moves.\nMeta-reasoning\nAckerman and Thompson (2017) emphasised the importance of meta-\nreasoning (processes that monitor our progress during problem solving\nKEY TERMS\nAlgorithm\nA computational\nprocedure providing a\nspecified set of steps to\nproblem solution; see\nheuristic.\nHill climbing\nA simple heuristic used\nby problem solvers in\nwhich they focus on\nmaking moves that will\napparently put them\ncloser to the goal.\nMeans–ends analysis\nA heuristic method for\nsolving problems based\non creating a subgoal\nto reduce the difference\nbetween the current state\nand the goal state.\nMeta-reasoning\nMonitoring processes\nthat influence the time,\neffort and strategies used\nduring reasoning and\nproblem solving.\nCreated from usyd on 2022-02-17 03:28:25.",
    "590\nThinking and reasoning\nand reasoning and influence the strategies we adopt). One example is\nprogress monitoring. Problem solvers assess their rate of progress towards\nthe goal. If progress is too slow to solve the problem within the maximum\nnumber of moves allowed, they change their strategy. MacGregor et al.\n(2001) gave participants the nine-dot problem (see Figure 12.5) with one\nline of the solution to help them. Performance was worse when partici-\npants had the illusion of making progress (and so were slow to switch\nstrategies).\nPayne and Duggan (2011) also studied progress monitoring.\nParticipants received an unsolvable water-jar problem with a small or\nlarge number of possible problem states. When the problem had a small\nnumber of problem states, participants more rapidly abandoned the\nproblem because it was easier to perceive progress towards a solution was\nimpossible.\nAckerman and Thompson (2017) discussed other aspects of meta-\ncognition related to progress monitoring. These include judgements of\nsolvability, and feelings of rightness or error when problem solvers produce\nan answer to any given problem, all of which influence the decision as to\nwhether to remain engaged in problem solving.\nPlanning\nIt is generally assumed individuals presented with a complex problem\nengage in preliminary planning and that this planning involves prefrontal\nareas associated with planning. Supportive evidence comes from patients\nwith damage to prefrontal areas, who typically have impaired planning and\nproblem solving (Szczepanski & Knight, 2014).\nGoel and Grafman (1995) found patients with prefrontal damage\nperformed worse than healthy controls on the Tower of Hanoi task (see\nFigure 12.11). The patients were especially disadvantaged on a diffi-\ncult move involving moving away from the\ngoal because they found it harder to plan\nahead.\nColvin et al. (2001) reported similar\nfindings using water-jar problems. Patients\nwith prefrontal damage and healthy controls\nused the hill-climbing strategy. However, the\npatients performed worse because their defi-\ncient planning made it harder for them to\nmake moves conflicting with that strategy.\nAs discussed earlier, prefrontal damage\ncan produce planning problems in everyday\nlife. For example, Goel et al. (2013) found\npatients with right prefrontal damage per-\nformed poorly on a real-world travel plan-\nning task because their planning was too\npiecemeal and insufficiently comprehensive.\nDagher et al. (1999) used the Tower of\nLondon task in which coloured discs must\nbe moved one by one from an initial state to\nFigure 12.12\nTower of London task (two-move and five-move problems).\nThe balls in the bottom half must be rearranged to match the\narrangement in the top half.\nFrom Dagher et al. (1999). By permission of Oxford University Press.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n591\nmatch the goal state (see Figure 12.12). There was increased activation of\nthe dorsolateral prefrontal cortex when participants solved complex ver-\nsions of this task.\nIn sum, the prefrontal cortex is important in planning on many prob-\nlem-solving tasks. However, many other brain areas are also involved\n(Szczepanski & Knight, 2014).\nSequential processing stages\nTasks such as the Tower of Hanoi and Tower of London require planning\na sequence of moves. However, we can distinguish between plan produc-\ntion and plan execution. With complex tasks, only some moves are typically\nplanned, so executing the initial plan is followed by generating a further\nplan and then its execution.\nCrescentini et al. (2012) supported the distinction between plan pro-\nduction and plan execution using simple versions of the Tower of Hanoi\ntask. The dorsolateral prefrontal cortex was more active during initial\nplanning than plan execution. In contrast, posterior temporal areas, infe-\nrior frontal regions and dorsolateral premotor cortex were more activated\nduring plan execution.\nNitschke et al. (2012) obtained support for the assumption that Tower\nof London problems require participants to engage in problem representa-\ntion followed by planning. On problems placing high demands on forming\na problem representation, participants alternated their gaze more often\nbetween the start and goal state. On problems imposing high demands\non planning, in contrast, the last fixation of the start state was unusually\nprolonged.\nHow much planning?\nNewell and Simon (1972) assumed problem solvers typically engage in\nlimited planning because of the constraints of short-term memory capac-\nity. Patsenko and Altmann (2010) obtained strong support using Tower\nof Hanoi problems. Sometimes they added, deleted or moved discs during\nparticipants’ eye movements so they were not directly aware of the change.\nThese changes only minimally disrupted performance, strongly suggesting\nthat the participants’ next move was triggered by the current state of the\nproblem rather than a preformed plan.\nThere are substantial individual differences in planning for prob-\nlem-solving tasks. Koppenol-Gonzalez et al. (2010) found with the Tower\nof London task that some participants engaged in efficient planning (con-\nsiderable preplanning of moves and high performance). In contrast, other\nparticipants showed very little evidence of effective planning (short period\nof preplanning and numerous errors). Most individual differences in per-\nformance on this task can be explained by the single factor of planning\nability (Debelak et al., 2016).\nThe amount of planning is very flexible. Delaney et al. (2004) found\nlittle evidence of planning on water-jar problems when participants chose\ntheir preferred strategy. However, instructions to generate the com-\nplete solution before making any moves led to detailed planning and\nCreated from usyd on 2022-02-17 03:28:25.",
    "592\nThinking and reasoning\nKEY TERMS\nCognitive miser\nSomeone who is\neconomical with their\ntime and effort when\nperforming a thinking\ntask.\nCognitive Reflection\nTest\nA test assessing\nindividuals’ tendencies\nto override intuitive (but\nincorrect) answers to\nproblems.\nfaster problem solution. Morgan and Patrick (2013) argued that increas-\ning the cost of accessing important task-relevant information (the goal\nstate) on the Tower of Hanoi task would lead to more planning. It pro-\nduced increased planning and also led to problems being solved in fewer\nmoves.\nIf planning involves deliberate processes, we would expect problem\nsolvers to be consciously aware of it. Evidence suggesting important\nproblem-solving processes occur below the level of conscious awareness\nwas reported by Paynter et al. (2010) using event-related potentials (ERPs;\nsee Glossary). They observed clear differences in the ERPs associated with\ncorrect and incorrect moves early in the problem when no behavioural evi-\ndence indicated participants were making progress.\nCognitive miserliness\nMany theorists have proposed dual-process theories to account for perfor-\nmance on cognitive tasks such as judgement, decision-making and reason-\ning. Evans and Stanovich (2013; see Chapter 14) reviewed these theories\nand identified various commonalities among them. Of particular impor-\ntance, the theories distinguish two processes: (1) Type 1 intuitive processes\nare fast and relatively effortless; and (2) Type 2 reflective processes are slow\nand controlled.\nMost dual-process theorists argue that many individuals are cogni-\ntive misers. A cognitive miser is someone typically economical with their\ntime and effort on tasks requiring thinking. Cognitive misers would often\nrespond rapidly (but sometimes incorrectly) to problems using Type 1 pro-\ncesses without checking their answer using Type 2 processes.\nThe Cognitive Reflection Test (Frederick, 2005), which assesses the\nextent to which people are cognitive misers, involves a conflict between\nType 1 and Type 2 processes. Why don’t you take this very short test and\nthen see how many of your answers are correct?\nIN THE REAL WORLD: COGNITIVE REFLECTION TEST\n(1)\nA bat and a ball cost $1.10 in total. The bat costs $1.00 more\nthan the ball. How much does the ball cost? ___ cents.\n(2)\nIf it takes 5 machines 5 minutes to make 5 widgets, how long\nwould it take 100 machines to make 100 widgets? ___ minutes.\n(3)\nIn a lake, there is a patch of lily pads. Every day, the patch doubles\nin size. If it takes 48 days for the patch to cover the entire lake,\nhow long would it take for the patch to cover half the lake? ___\ndays.\nThe correct answers are 5 cents (problem 1), 5 minutes (problem 2)\nand 47 days (problem 3). Do not worry if you did not get them all right –\nonly about 25% of highly intelligent individuals answer all the items cor-\nrectly. Most incorrect answers (10 cents; 100 minutes; and 24 days) are\nintuitive responses produced rapidly by individuals using Type 1  processes.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n593\nHowever, individuals producing incorrect answers often experience a feeling\nof error (Gangemi et al., 2015), suggesting some awareness of conflict.\nLow scorers on the Cognitive Reflection Test also perform relatively\npoorly on many other judgement and reasoning tasks (Toplak et al., 2014).\nThis occurs in part because performance on the Cognitive Reflection Test\ncorrelates positively with intelligence. However, scores on the Cognitive\nReflection Test predicted performance on several other tasks after the\neffects of intelligence were removed statistically. This finding suggests cog-\nnitive miserliness is found on many tasks.\nTravers et al. (2016) found participants ultimately giving the incorrect\nintuitive answer were not drawn to the correct answer at any point. This\nsuggests they did not use Type 2 reflective processes. In contrast, partic-\nipants ultimately producing the correct answer were nevertheless initially\ndrawn to the incorrect intuitive answer suggesting they inhibited the incor-\nrect intuitive answer.\nThere is overlap between the notion of cognitive miser and Newell\nand Simon’s (1972) focus on problem solvers’ use of heuristics (discussed\nearlier, p. 589). In both cases, individuals resort to simple (and often inac-\ncurate) strategies. However, Newell and Simon assumed our limited pro-\ncessing capacity forces us to use heuristics. In contrast, cognitive misers use\nheuristics because they are reluctant to engage in effortful processing rather\nthan because they cannot.\nANALOGICAL PROBLEM SOLVING\nAND REASONING\nHere we discuss analogical problem solving. An analogy is “a comparison\nbetween two objects, or systems of objects, that highlights respects in which\nthey are thought to be similar” (Stanford Encylopedia of Philosophy, 2013).\nAnalogies are very important – we often cope successfully with novel situa-\ntions by relating them to situations encountered previously.\nAnalogical problem-solving performance correlates highly with IQ,\nleading Lovett and Forbus (2017, p. 60) to argue “Analogy is perhaps the\ncornerstone of human intelligence”. More specifically, there are close links\nbetween analogical problem solving and fluid intelligence, which “refers\nto the ability to reason through and solve novel problems” (Shipstead\net al., 2016, p. 771). The most used test of fluid intelligence is Raven’s\nProgressive Matrices (Raven et al., 1998). It involves geometrical analogies\nand requires analogical reasoning (see Figure 12.13).\nAnalogies have proved valuable in science. For example, the physi-\ncist Ernest Rutherford argued electrons revolve around the nucleus as the\nplanets revolve around the sun. This analogy (like nearly all others) has\nlimitations – planets in the solar system attract each other through gravita-\ntional force whereas electrons repel each other.\nScientists working on the Mars Rover Mission used analogies when\nthere was high uncertainty about scientific issues. Why did they use\nanalogies? According to Chan et al. (2012, p. 1362), “Analogy supports\nproblem solving under uncertainty by narrowing the space of possibilities\nto facilitate quick, approximate problem solving, reasoning, and decision\nmaking.”\nKEY TERMS\nAnalogy\nA comparison between\ntwo objects (or between\na current and previous\nproblem) that emphasises\nsimilarities between them.\nFluid intelligence\nNon-verbal reasoning\nability applied to novel\nproblems.\nCreated from usyd on 2022-02-17 03:28:25.",
    "594\nThinking and reasoning\nAnalogical problem solving\nIf we are to use a previous problem to solve the present one, we must detect\nsimilarities between them. Chen (2002) identified three main types of simi-\nlarity between problems:\n(1)  Superficial similarity: solution-irrelevant details (e.g., specific objects)\nare common to the two problems.\n(2)  Structural similarity: causal relations between the main components\nare shared by both problems.\n(3)  Procedural similarity: procedures (actions) for turning the solution\nprinciple into concrete operations are common to both problems.\nChen (2002) gave participants a problem providing them with an analogy\nhaving structural and procedural similarity with the target problem or one\nhaving only structural similarity with it. Performance was significantly\nbetter in the former condition because those participants were more likely\nto find the correct procedures or actions to solve the problem.\nWith most analogical problems, participants must first retrieve appro-\npriate past experience or knowledge and then adapt it to make explicit its\nrelevance to the current problem. Gick and Holyoak (1980) found retrieval\nfailures often underlie people’s inability to solve analogical problems. They\nused a problem where a patient with a malignant stomach tumour can only\nbe saved by a special kind of ray (Duncker, 1945). However, a ray strong\nenough to destroy the tumour will also destroy the healthy tissue, whereas\na ray that does not harm healthy tissue will be too weak to destroy the\ntumour. Only 10% of participants solved this problem when presented on\nits own.\nIf you find the above problem puzzling, here is an analogy. A general\nwants to capture a fortress. However, the roads to it are mined, making\nit too dangerous for the entire army to march along any one of them.\nFigure 12.13\nA problem resembling those used on the Raven’s Progressive Matrices. The image from\nthe bottom 8 images that best completes the top 3 x 3 matrix must be selected.\nFrom Lovett and Forbus (2017).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n595\nHowever, the mines were set so that small numbers of men could pass\nover safely. The general had his army converge on the fortress at the same\ntime by walking along several different roads. Among participants who\nhad previously memorised the story about the general and the fortress,\n80% of them solved the radiation problem when informed of its relevance.\nHowever, only 40% of them solved it when not so informed.\nWhy did so many of Gick and Holyoak’s (1980) participants fail to\nmake spontaneous use of the relevant, memorised story? Of relevance,\nthere were no superficial similarities between the story and problem. In con-\ntrast, when the story was superficially similar to the problem (it involved a\nsurgeon using rays on a cancer), 88% of participants spontaneously recalled\nit when given the radiation problem (Keane, 1987).\nKubricht et al. (2017) studied performance on Duncker’s (1945)\nradiation problem as a function of individual differences in fluid intelli-\ngence (see Glossary) assessed by Raven’s Progressive Matrices (discussed\nearlier, p. 593). Individuals high in fluid intelligence performed much better\nthan low scorers when the radiation problem was preceded by a verbal\nanalogy (approximately 85% vs 40%, respectively). Thus, high intelligence\nis a factor in facilitating effective use of analogies (discussed further later,\npp. 597–598).\nGick and Holyoak (1980) used the reception paradigm – participants\nreceived detailed information about a possible analogy before receiving\na problem. However, individuals in everyday life generally produce their\nown analogies: the production paradigm. Blanchette and Dunbar (2000)\nconfirmed that people given the reception paradigm often selected analo-\ngies based on superficial similarities. However, those given the production\nparadigm mostly produced analogies sharing structural features with the\ncurrent problem.\nExperts (e.g., scientists) often use analogies because they provide a\nmajor source of new concepts and ways of thinking about problems. What\nkinds of analogies do experts use? Dunbar and Blanchette (2001) studied\nlaboratory discussions of leading molecular biologists and immunolo-\ngists. When they used analogies to fix experimental problems, the previous\nproblem was often superficially similar to the current one. When they gen-\nerated hypotheses, however, their analogies involved fewer superficial simi-\nlarities and considerably more structural ones. Thus, the types of analogies\nused by scientists depend on their current goal.\nDo experts mostly use distant analogies (i.e., those linking different\ndomains) or less distant within-domain ones? Dunbar (1995) found that\n98% of analogies were within-domain when experts discussed issues with\nfellow experts. In contrast, more distant analogies are used when scien-\ntific experts communicate with less expert colleagues (Kretz & Krawczyk,\n2014). This difference occurs because within-domain analogies are gener-\nally more detailed and precise than distant analogies.\nEnhancing analogical problem solving\nHow can we increase people’s use of analogies in analogical problem\nsolving? There are two main approaches: (1) increasing the encoding of\nthe underlying structure of the current problem; (2) increasing the use\nCreated from usyd on 2022-02-17 03:28:25.",
    "596\nThinking and reasoning\nof effective retrieval strategies. Minervino et al. (2017) adopted the first\napproach. All participants were initially presented with the fortress story.\nSome identified the similarities and differences between Duncker’s problem\nand another problem with a similar structure before attempting Duncker’s\nproblem (experimental group). Others attempted Duncker’s radiation\nproblem on its own (control group).\nExperimental group participants were much more likely than control\ngroup participants to solve the radiation problem (34% vs 9%, respectively).\nTheir performance was superior because they understood more clearly the\nabstract or schematic structure of the radiation problem.\nTrench et al. (2016) found simply instructing individuals to use anal-\nogies when generating arguments to persuade a poor family to reduce its\nindebtedness increased their use of analogies fourfold. Other participants\nwere instructed to use analogies drawn from areas not directly related to\neconomic issues (e.g., health; human relations). This led to a substantial\nincrease in arguments based on analogies (especially structural analogies).\nIn sum, most individuals rarely produced analogies spontaneously but\ncould easily do so when prompted.\nProcesses in analogical reasoning\nSo far we have focused on analogical problem solving. However, much\nresearch on analogies has involved analogical reasoning. For example, con-\nsider four-term analogy problems taking the form A:B::C:D (A is to B as C\nis to D; e.g., GLOVE:HAND::SOCK:FOOT). Participants decide whether\nthe two-word pairs express the same relationship (i.e., is it true that glove is\nto hand as sock is to foot?). Alternatively, only the first three terms (i.e., A,\nB and C) are provided with participants supplying the fourth term (i.e., D)\nthemselves.\nWhy are four-term analogy problems used so often in research? They\ndiffer from analogical problem solving in that they are tightly controlled –\nall the necessary information is presented explicitly and there is a single\ncorrect answer. These features facilitate the task of understanding the\nunderlying processes.\nSequential processing stages\nAnalogical reasoning involves several sequential processing stages. For\nexample, Grossnickle et al. (2016) identified four component processes:\n(1) Encoding: information concerning the problem stimuli is processed.\n(2) Inferring: identifying a relation (i.e., similarity) between two items.\n(3) Mapping: identifying the overall relational pattern or rule governing\nthe problem.\n(4) Applying: using the outcome of the mapping process to select the\nresponse completing the analogy.\nGrossnickle et al. (2016) compared the performance of high and low per-\nformers on tasks involving relational reasoning (including analogical\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n597\nreasoning). The probabilities of successfully completing each process given\nthe previous process had been successfully completed are shown in Figure\n12.14. The inference and mapping processes were the hardest (especially for\nlow performers).\nVendetti et al. (2017) identified two major strategies used by people\nsolving four-term analogy problems. According to project-first models,\nindividuals first generate a rule relating the A and B terms, then they map\nthe A and C terms, and finally they apply a rule generating D. According\nto alignment-mapping models, individuals first align the A and C terms,\nand then align the B item with the target (D item).\nVendetti et al. (2017) used eye tracking to identify which strategy was\nused. The strategy identified by project-first models was used on 50% of\ntrials. In contrast, the strategy identified by alignment-mapping models\nwas used on 34% of trials. On average, reasoning performance was higher\nwhen the former strategy was used.\nWorking memory\nAnalogical reasoning is sufficiently complex for us to predict it requires the\ncentral executive component of the working memory system (see Glossary\nand Chapter 6). If so, problem-solving performance should be impaired if\na secondary task involving the central executive is performed at the same\ntime. That has been found with four-term analogies (Morrison et al., 2001)\nand with Raven’s Matrices problems (Rao & Baddeley, 2013).\nIndividual differences\nWe can increase our understanding of analogical reasoning by study-\ning individual differences in reasoning ability. Much research has consid-\nered the relationship between analogical reasoning and working memory\ncapacity (the ability to process and store information at the same time; see\nFigure 12.14\nProbability of successful\nencoding P(E), successful\ninferring given successful\nencoding P(I/E), successful\nmapping given successful\ninferring P(M/I), and\nsuccessful applying given\nsuccessful mapping for low\nand higher performers.\nFrom Grossnickle et al. (2016).\nReprinted with permission of\nElsevier.\n1\n0.95\n0.9\n0.85\n0.8\n0.75\n0.7\n0.65\n0.6\n0.55\n0.5\nP(E)\nP(I|E)\nConditional probabilities for each reasoning process\nP(M|I)\nAll participants\nLow performers\nHigh performers\nP(A|M)\nCreated from usyd on 2022-02-17 03:28:25.",
    "598\nThinking and reasoning\nGlossary). Ackerman et al. (2005) found in a meta-analysis the average cor-\nrelation between measures of working memory capacity and performance\non Raven’s Matrices (which requires analogical reasoning and involves\nfluid intelligence) was +.49.\nShipstead et al. (2016) identified key processes associated with\nworking memory capacity and fluid intelligence (see Figure 12.15). Most\ncognitive tasks (Level 3) require top-down, goal-focused executive atten-\ntion (Level  1). Such tasks differ in the extent to which they also require\nmaintenance (keeping relevant information accessible) and disengagement\n(removing or inhibiting outdated information) (Level 2). In essence, fluid\nintelligence involves executive attention + disengagement whereas working\nmemory capacity involves executive attention + maintenance.\nEvidence that fluid intelligence and working memory capacity both\ninvolve executive attention was reported by Clark et al. (2017). Frontal-\nparietal brain areas associated with executive attention were activated\nwhen participants performed tasks involving working memory or fluid\nintelligence.\nHarrison et al. (2015) obtained findings consistent with the above\ntheoretical approach using Raven’s Matrices problems. Some problems\ninvolved a repeated-rule combination (i.e., the same rule combination as a\nprevious problem) whereas others involved a novel-rule combination (i.e.,\na rule combination not previously used).\nHarrison et al. (2015) argued that individuals high in working memory\ncapacity are better than those with low working memory capacity at\nmaintaining information in memory. Accordingly, they should perform\nespecially well on Raven’s Matrices problems with a repeated rule rela-\ntive to those with a novel rule. That is exactly what they found. In con-\ntrast, individuals high in fluid intelligence (assessed by tests other than\nRaven’s Matrices) performed much better than those low in fluid intel-\nligence regardless of whether problems involved a repeated or a novel\nrule.\nFigure 12.15\nMajor processes involved in\nperformance of numerous\ncognitive tasks.\nFrom Shipstead et al. (2016).\nLevel 1\nExecutive attention/\ngoal state\nLevel 2\nActive processing/\nfocal attention\nLevel 3\nPhysical\nenvironment\nMaintenance\nDisengagement\nTo-be-performed\ntask\nTop-down\nexecutive signal\nTop-down signal organises\nmaintenance and\ndisengagement around a\ngoal.\nThe emphasis of\nmaintenance and\ndisengagement in carrying\nout top-down goals is\npartially determined by\nthe nature of the to-be-\nperformed task.\nTask provides an\nenvironmental medium\naround which cognitive\nprocesses are organised.\nSome tasks place a heavier\nburden on maintenance,\nothers on disengagement.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n599\nAccording to Shipstead et al.’s (2016) theoretical model, the excel-\nlent analogical reasoning of individuals high in fluid intelligence depends\nin part on their ability to disengage. An important aspect of disengage-\nment is the ability to think flexibly. With Raven’s Matrices problems,\nthat often involves a re-representation of problem structure by making it\nmore abstract (Lovett & Forbus, 2017). For example, consider a problem\nwith an upward-facing arrow followed by a rightward-facing arrow\nand then a downward-facing arrow. Participants who re-represent these\nfigures as an arrow rotating clockwise perform better than those who do\nnot.\nLovett and Forbus (2017, p. 83) attach great importance to\nre-representation:\nRe-representation is critical because analogies are slaves to their sym-\nbolic representation. If two cases happen to be represented with dif-\nferent relational structure, they will fail to align, and the only way to\ncomplete the analogy will be to change the structure.\nIn sum, successful performance on Raven’s Matrices problems requires a\nhigh level of goal-focused executive attention. In addition, it requires dis-\nengagement to inhibit task-irrelevant infor-\nmation. Key aspects of the disengagement\nprocess are flexibility and re-representation.\nBrain mechanisms\nKrawczyk\n(2012)\nreviewed\nresearch\non\nbrain-damaged patients and neuroimaging\nstudies to identify brain areas involved in ana-\nlogical reasoning (see Figure 12.16):\n(1) Occipital and parietal areas are associ-\nated with visual and spatial processing,\nfollowed by extensive involvement of the\nprefrontal cortex.\n(2) Left\nrostrolateral\nprefrontal\ncortex\n(centred on BA10) integrates informa-\ntion within analogical problems.\n(3) The dorsolateral prefrontal cortex and\ninferior frontal gyrus are involved in\ninhibitory processes to prevent distrac-\ntion and interference.\n(4) The temporal lobes are involved because\ninformation about concept meanings\n(semantic memory) is stored there.\nSuppose you are given the following problem:\nsandwich:lunchbox::hammer:____\nFigure 12.16\nSummary of key brain regions and their associated functions\nin relational reasoning based on patient and neuroimaging\nstudies. RLPFC, rostolateral prefrontal cortex; DLPFC,\ndorsolateral prefrontal cortex; LIFG, left inferior frontal gyrus;\nCtx, cortex.\nFrom Krawczyk (2012). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:25.",
    "600\nThinking and reasoning\nPossible answers are toolbox (correct), nail (a semantic distractor), gavel\n(auctioneer’s hammer, a perceptual distractor) and ribbon (an irrelevant\ndistractor). Krawczyk et al. (2008) argued inhibitory processes involving\nthe prefrontal cortex (brain area 3 above) are required on such problems\nto avoid incorrect answers involving relevant semantic or perceptual dis-\ntractors. As predicted, patients with damage to the prefrontal cortex were\nmore likely than those with damage to the temporal area to select semantic\nor perceptual distractors.\nThe left rostrolateral prefrontal cortex is of central importance in\nanalogical reasoning. Hobeika et al. (2016) conducted a meta-analysis of\nneuroimaging studies (mostly using visuo-spatial analogies based on the\nRaven’s Progressive Matrices or verbal four-word analogy problems –\ndiscussed earlier, pp. 596–597). The left rostrolateral prefrontal cortex was\nconsistently activated with both visuo-spatial and verbal analogies, proba-\nbly because of its involvement in mapping or relational integration.\nUrbanski et al. (2016) studied analogical reasoning performance in\npatients with frontal-lobe damage. Damage to the left rostrolateral pre-\nfrontal cortex (including BA10 and 47) was more consistently associated\nwith impaired analogical reasoning than other frontal damage. These find-\nings fit well with those of Hobeika et al. (2016).\nOther findings provide more direct support for the notion that the left\nrostrolateral prefrontal cortex is involved in mapping or relational integra-\ntion. Green (2016) discussed his own research using verbal four-term anal-\nogies (discussed earlier) varying in the difficulty of mapping or relational\nintegration. Activity within left rostrolateral prefrontal cortex increased\nprogressively as the demands on mapping increased.\nIn sum, research on brain mechanisms has identified the brain areas\nassociated with the major processes involved in analogical reasoning. The\nconsistent finding that the left rostrolateral prefrontal cortex is strongly\ninvolved when individuals solve several different analogical reasoning\ntasks implies (but not does prove) that these tasks involve similar cognitive\nprocesses.\nEXPERTISE\nSo far we have mostly discussed studies where the time available for learn-\ning was short, the tasks were relatively limited, and prior specific know-\nledge  was not required. In the real world, however, people often spend\nmany years acquiring knowledge and skills in a given area (e.g., psychol-\nogy; law; medicine; journalism). The end point of such long-term learning\nis expertise. Expertise is “elite, peak, or exceptionally high levels of perfor-\nmance on a particular task or within a given domain . . . An expert’s field of\nexpertise can be almost anything from craftsmanship, through sports and\nmusic, to science or mathematics” (Bourne et al., 2015, p. 211).\nThe development of expertise resembles problem solving in that\nexperts are extremely efficient at solving numerous problems in their area\nor domain of expertise. However, most traditional research on problem\nsolving involved “knowledge-lean” problems, requiring no special  knowledge\nor training. In contrast, studies on expertise typically use  “knowledge-\nrich” problems requiring much knowledge beyond that contained in the\nKEY TERM\nExpertise\nThe high level of\nknowledge and\nperformance in a given\ndomain that an expert has\nachieved through years of\nsystematic practice.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n601\nproblem;  this knowledge has typically been acquired through prolonged\npractice and study.\nIn what follows, we first consider chess expertise. There are various\nadvantages to studying chess. First, the ELO ranking system (named after\nthe chess master Arpad Elo) assesses chess players’ level of expertise.\nSecond, expert chess players develop cognitive skills (e.g., pattern recog-\nnition; selective search) of general usefulness. Sala et al. (2017) discussed\na meta-analytic review showing chess instruction improves achievement in\nmathematics and overall cognitive ability. Third, there are clear similari-\nties between the remarkable memory for chess positions shown by chess\nexperts and the vast knowledge experts in other domains have stored in\nlong-term memory.\nWe then discuss medical expertise (especially medical diagnosis), fol-\nlowed by a comparison of these two forms of expertise. After that, we\nconsider the role of brain plasticity in expertise. Finally, we evaluate the\nhypothesis that deliberate practice is the main requirement for the devel-\nopment of expertise and also consider alternative theoretical approaches.\nCHESS-PLAYING EXPERTISE\nAs already indicated, there are various reasons why it is valuable to study\nchess-playing expertise. For example, we can measure chess players’ levels\nof skill precisely based on their results against other players. In addition,\nthe existence of permanent records of chess players’ tournament records\nover their entire career means detailed longitudinal data are available for\nanalysis.\nThe most obvious reason why some individuals are much better than\nothers at playing chess is that they have devoted far more time to  practice –\nit takes about 10,000 hours on average to become a grandmaster. Of\nspecial importance, expert chess players have much more detailed informa-\ntion about chess positions stored in long-term memory than non-experts.\nIn classic research, De Groot (1965) presented chess players with brief\npresentations of board positions from actual games. After removing the\nboard, they reconstructed the positions. Chess masters recalled the posi-\ntions much more accurately than less expert players (91% vs 43%, respec-\ntively). This does not reflect differences in memory ability – there were no\ngroup differences when remembering random board positions.\nTemplate theory\nWhat is the nature of the vast amount of chess-related information experts\nhave stored in long-term memory? Gobet (e.g., Gobet & Waters, 2003)\nprovided an influential answer in his template theory. A template is an\nabstract, schematic structure more general than an actual board position.\nEach template consists of a core (fixed information) plus slots (containing\nvariable information about pieces and locations). Each template typically\nstores information relating to about ten pieces although it can be larger.\nTemplates’ possession of slots makes them adaptable and flexible in use.\nTemplates are built up out of small memory structures known as chunks\n(see Glossary).\nKEY TERM\nTemplate\nAs applied to chess,\nan abstract schematic\nstructure consisting of\na mixture of fixed and\nvariable information\nabout chess pieces and\npositions.\nCase study:\nEye movements of expert\nchess players\nCreated from usyd on 2022-02-17 03:28:25.",
    "602\nThinking and reasoning\nHere are the main predictions of template theory:\n(1) Chess positions are stored in three templates, some of which are large.\n(2) Outstanding chess players owe their excellence more to their supe-\nrior template-based knowledge of chess than slow, strategy-based\nprocesses. This knowledge can be accessed rapidly and permits expert\nplayers to narrow down the possible moves they consider.\n(3) Expert chess players store away the precise board locations of pieces\nafter studying a board position. Chess pieces close together are most\nlikely to be found in the same template (Gobet & Simon, 2000).\n(4) Expert players have superior recall than non-experts of random chess\npositions. The reason is they are better at recognising small chunks\noccurring by chance even in random positions. However, the memory\nsuperiority of experts should be greater with structured positions\nbecause experts can use their greater template knowledge as well as\ntheir greater chunk knowledge.\nFindings\nGobet and Clarkson (2004) reported support for the first prediction. Expert\nplayers recalled chessboard positions much better than novices. However,\nthe number of templates (averaging out at about 2) did not vary as a func-\ntion of playing strength. The maximum template size was 13–15 for masters\ncompared to only about 6 for novices.\nEvidence relating to the second prediction is less consistent. Charness\net al. (2001) reported supportive evidence. Expert players were significantly\nmore likely than intermediate players to fixate tactically relevant pieces\nvery rapidly (within about 1 second). Sheridan and Reingold (2017a) pre-\nsented four chess positions at the same time and asked chess players to find\nthe one allowing the knight to reach a target square in three moves. Expert\nplayers’ eye movements indicated they were much faster than novices to\nfixate the target board.\nFurther support was reported by Burns (2004), who\nfocused on blitz chess (the entire game must be completed\nin 5 minutes). He assumed performance in blitz chess must\ndepend mainly on players’  template-based knowledge\nbecause there is insufficient time to engage in slow searching\nthrough possible moves. As predicted, performance in blitz\nchess correlated highly (+.78 to +.90) with performance in\nstandard chess.\nEvidence less supportive of the second prediction was\nreported by van Harreveld et al. (2007) and Chang and\nLane (2016). Skill differences between players were less\npredictive of game outcome as the time available decreased\nsuggesting slow processes are more important for strong\nthan weak players. Chang and Lane studied speed chess\n(longer than blitz chess but much shorter than standard\nchess). Players (especially stronger ones) often spent a con-\nsiderable amount of time on a few moves indicating they\nwere using strategy- based processes.\nFernand Gobet.\nCourtesy Fernand Gobet.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n603\nMoxley et al. (2012) asked experts and\ntou rnament players to think aloud while\nselecting the best possible moves with several\nproblems. Their final move was generally\nmuch stronger than the first move consid-\nered for both groups (see Figure 12.17). Thus,\nslow, strategy-based processes play a key role\nin chess.\nWe turn now to the third prediction.\nChess players typically recall the precise\nsquares occupied by given pieces within a\ntemplate when asked to memorise board posi-\ntions. However, actual chess playing focuses\nmuch more on evaluating board positions.\nMcGregor and Howes (2002) asked expert\nplayers to evaluate various chess positions.\nThese players subsequently had much better\nmemory for attack/defence relations than\nprecise board locations of the pieces. Linhares\net al. (2012) found grandmasters outper-\nformed masters, more with respect to memory\nfor abstract features (e.g., strategically signifi-\ncant attacks or defences) than superficial fea-\ntures (e.g., specific board positions).\nThe fourth prediction is that expert\nplayers will have better recall than non-\nexperts of random chess positions. Supporting\nevidence was reported by Sala and Gobet\n(2017) in a meta-analysis. As predicted, the\nbeneficial effects of expertise on recall of\nrandom chess positions were smaller than\nthose obtained previously in structured chess\npositions.\nEvaluation\nTemplate theory has several successes to its credit. First, much of the infor-\nmation experts store from board positions consists of a few large templates.\nSecond, outstanding chess players possess much more knowledge about\nchess positions than experts, which gives them a substantial advantage when\nplaying chess. Third, the tendency of experts to win at blitz chess is due\nmainly to their superior template-based knowledge (Burns, 2004). Fourth,\nexperts have better recall of random board positions than non- experts (Sala\n& Gobet, 2017).\nWhat are the limitations of template theory? First, slow search pro-\ncesses are more important to expert players than assumed by the theory\n(Moxley et al., 2012; van Harreveld et al., 2007). This is even the case with\nspeed chess (Chang & Lane, 2016).\nSecond, the most expert players often use strategies allowing them\nto go beyond stored knowledge of chess positions. Bilalić et al. (2008a)\nFigure 12.17\nMean strength of the first-mentioned chess move and the\nmove chosen as a function of problem difficulty by experts\n(top panel) and by tournament players (bottom panel).\nFrom Moxley et al. (2012). With permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:25.",
    "604\nThinking and reasoning\npresented chess players with a problem solvable in five moves using a\nfamiliar strategy but in only three moves using a less familiar solution.\nInternational Masters were far more likely than Candidate Masters to find\nthe shorter solution (50% vs 0%) because they were better at avoiding the\nfamiliar, template-based solution.\nThird, the precise nature of the information stored in long-term\nmemory remains controversial. Template theory assumes the precise loca-\ntions of pieces are typically stored. However, it is likely attack/defence\nrelations are more important (Linhares et al., 2012; McGregor & Howes,\n2002). According to the theory, chess players have stored information in\nthe form of chunks and templates. However, it is often hard to identify\ntheir respective roles.\nFourth, template theory de-emphasises the importance of cognitive\nability. Grabner et al. (2007) found all chess masters they studied had\nabove-average intelligence. In addition, intelligence correlated significantly\nwith the players’ rated skill level. Burgoyne et al. (2016) found in a meta-\nanalytic review that chess skill correlated positively with several aspects\nof cognitive ability (e.g., processing speed; fluid reasoning, which involves\nunderstanding novel relationships).\nMEDICAL EXPERTISE\nThe processes involved in chess-playing expertise may (or may not) resemble\nthose involved in other forms of expertise. Accordingly we will now consider\nmedical expertise, specifically the ability of medical experts to make rapid\nand accurate diagnoses. This ability can literally be a matter of life-or-death.\nWe will focus mostly on the search for abnormalities in medical images\n(e.g., X-rays; brain scans). Various methods have been used including\neye-tracking and the think-aloud technique (Gegenfurtner et al., 2017).\nEye-tracking can provide useful information about visual attention and\nsubconscious processes, and think-aloud data can shed light on individu-\nals’ eye fixations and decision-making.\nHow do medical experts’ strategies differ from those of non-experts?\nOne approach assumes there are three main reasons why abnormalities in\nmedical images fail to be detected (see Figure 12.18):\n(1)  There are detection errors when the crucial area within the image is\nnot fixated.\n(2) There are recognition errors when the crucial area is fixated briefly but\nthe doctor fails to appreciate its significance.\n(3) There are judgemental errors when the crucial area is fixated for some\ntime (indicating it raised some concern) but its significance is not fully\nappreciated.\nThe most obvious prediction is that experts will have fewer errors of all\nthree types than non-experts.\nFigure 12.18 indicates three processes of relevance to the various error\ntypes. First, there is global or holistic perception of the image; if that is\nincomplete or ineffective, detection errors will occur. Second, there is focal\nor selective processing, involving deeper processing of only certain spe-\ncific visual elements; failure of such processing leads to recognition errors.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n605\nThird, there is pattern matching, which involves finding a match between\nthe visual medical image and patterns stored in long-term memory; failure\nof such processing leads to judgemental errors.\nThere is an important distinction between explicit and implicit rea-\nsoning (Engel, 2008). Explicit reasoning is slow, deliberate and is asso-\nciated with conscious awareness. In contrast, implicit reasoning is fast,\n“automatic” and not associated with conscious awareness. It involves the\nglobal processing identified by Al-Moteri et al. (2017; see Figure 12.18).\nDual-process theories of judgement (see Chapter 13) and reasoning (see\nChapter 14) are based on a similar distinction.\nThe crucial assumption is that medical experts engage mainly in\nimplicit reasoning whereas novices rely mostly on explicit (analytic) rea-\nsoning. This assumption makes sense given that experts have substantially\nmore relevant visual and other knowledge stored in long-term memory. As\na result, they can often rapidly engage in pattern matching (i.e., relating a\ngiven medical image to stored knowledge).\nWe will consider evidence relevant to the above explicit–implicit distinc-\ntion with respect to visual specialities (e.g., pathology; radiology). Note that\nexperts generally cross-check their diagnoses with slow, deliberate processes\neven if they start with fast, “automatic” ones (McLaughlin et al., 2008).\nFindings\nSheridan and Reingold (2017b) reviewed research testing the hypothesis\nthat experts engage in holistic or global processing. One prediction based\nFigure 12.18\nA theoretical framework of the main cognitive processes and potential errors in medical\ndecision-making.\nFrom Al-Moteri et al. (2017). Reprinted with permission of Elsevier.\nGlobal perception of the\nscene for identifying\nareas of value\nSelectivity for deeper\nprocessing\nDecision-making\nInsufcient analysis\nskills\njudgemental error\nInsufcient\nperceptual processing\ntime\nrecognition error\nInsufcient searching\nskills\ndetection error\nMissing cues\nPattern matching\nDecisional error\nCreated from usyd on 2022-02-17 03:28:25.",
    "606\nThinking and reasoning\non this hypothesis is that experts can extract useful information from\nrapidly presented images. Kundel and Nodine (1975) found expert radi-\nologists detected abnormalities very rapidly. Chest radiographs were pre-\nsented for only 200 milliseconds but were correctly interpreted 70% of the\ntime. Another prediction is that medical experts should be better able than\nnon-experts to make use of information presented in peripheral vision.\nSeveral studies support this prediction.\nKrupinski et al. (2013) carried out a longitudinal study of pathologists\nviewing breast biopsies at the start of their first, second, third and fourth\nyears of residency. Over time, there was a substantial reduction in fixations\nper slide and less examination of non-diagnostic regions (see Figure 12.19).\nThus, training produced enhanced attentional focus.\nKundel et al. (2007) showed doctors experienced in mammography dif-\nficult mammograms showing or not showing cancer. The mean time taken\nby experts to fixate a cancer was typically under 1 second. Time of first\nfixation on the cancer correlated –0.9 with performance (i.e., accurately\ndetected breast cancer). Thus, fast fixation was an excellent predictor of\nperformance.\nThe rapid detection of abnormalities by experts suggests they engage\nin pattern matching (matching medical images to images stored in long-\nterm memory). Of relevance, Jaarsma et al. (2014) considered how experts\nand non-experts explained their diagnoses after viewing medical images.\nFigure 12.19\nEye fixations of a\npathologist given the same\nbiopsy whole-slide image\nstarting in year 1 (a) and\nending in year 4 (d). Larger\ncircles indicate longer\nfixation times.\nFrom Krupinski et al. (2013).\nReprinted with permission from\nElsevier.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n607\nExperts were much more likely to use terms such as “typical”, “regular”\nand “increase of” suggesting their diagnoses were based on comparisons\nbetween presented and stored images.\nNodine and Mello-Thoms (2010) argued that experts use a detect-then-\nsearch process, starting with rapid detection of diagnostically relevant\ninformation followed by a brief search to check there is no other relevant\ninformation. In contrast, novices use a search-then-detect process,  involving\nextensive visual search and including much irrelevant information, followed\nby eventual detection of diagnostically relevant information. Brunyé et al.\n(2014) found novices were more likely than experts to fixate salient visual\nareas (e.g., brightly coloured ones) lacking diagnostic relevance.\nAccording to the theoretical framework shown in Figure 12.18, many\ndetection failures occur even though the crucial area is fixated. Manning\net al. (2006) studied nodule detection in chest radiology. Correct nega-\ntive decisions (i.e., no nodule) were made faster than incorrect negative\ndecisions. In the latter case, participants often fixated the nodule and were\nsuspicious of it but failed to recognise it as a nodule. Rubin et al. (2015)\nstudied the detection of very small lung nodules by experienced radiol-\nogists. The best performer detected 82% of fixated nodules whereas the\nworst performer detected only 47%.\nAccording to Al-Moteri et al. (2017), failures to detect abnormalities\nin medical images can occur because of judgemental errors. They discussed\nseveral studies in which medical experts sometimes fixated an abnormality\nfor more than 1 second but failed to report it. Such findings are suggestive\nof judgemental errors.\nAre the effects of expertise on eye movements similar across differ-\nent domains or areas? Gegenfurtner et al. (2011) reported a meta-analytic\nreview involving domains including medicine, sport and transportation.\nSeveral differences between experts and non-experts were common across\ndomains: (1) shorter fixations; (2) faster first fixations on task-relevant infor-\nmation; (3) more fixations on task-relevant information; (4) fewer fixations\non task-irrelevant areas; and (5) longer saccades (rapid eye movements).\nWe turn now to the roles of implicit and explicit (analytic) reasoning.\nMelo et al. (2012) argued medical experts use similar implicit or relatively\n“automatic” processes to those we all use when perceiving visual scenes.\nThey found comparably fast times to diagnose abnormalities in chest X-ray\nimages and to name animals (1.33 vs 1.23 seconds, respectively). Of most\nimportance, diagnosing abnormalities and naming animals involved activa-\ntion in very similar brain regions (see Figure 12.20). However, diagnosing\nabnormalities was associated with greater activation in the frontal sulcus and\nposterior cingulate cortex, suggesting diagnosis is more cognitively demand-\ning than naming animals. Naming letters involved similar brain regions to\ndiagnosing abnormalities and naming animals but with less activation.\nHow can we explain the above findings? Melo et al. (2012) suggested\nmedical experts engage in rapid pattern recognition: each slide is compared\nagainst stored patterns from the past. In other words, they use a predom-\ninantly visual strategy.\nKulatunga-Moruzi et al. (2004) asked three groups varying in expertise\nto diagnose skin diseases from photographs. Some participants made their\ndecisions from the photographs alone whereas others were also given a\nCreated from usyd on 2022-02-17 03:28:25.",
    "608\nThinking and reasoning\ncomprehensive verbal description before each photograph. The least expert\ngroup performed best when given the verbal descriptions plus the pho-\ntographs. In contrast, the more expert groups performed better without\nthe verbal descriptions. They used a rapid visual strategy and the verbal\ndescriptions interfered with their ability to use that strategy effectively.\nIn spite of the above evidence, experts typically make some use of slow,\nexplicit or analytic processes. Mamede et al. (2010a) compared the perfor-\nmance of medical experts and non-experts providing diagnoses immediately\nor after some analytic thinking. Analytic thinking enhanced the diagnostic\nperformance of experts with complex cases but not simple ones. In contrast,\nnon-experts derived no benefit from engaging in analytic thinking.\nEvaluation\nThe diagnostic strategies used by medical experts and non-experts often\ndiffer considerably. Experts use fast holistic processes more than non-\nexperts. In addition, experts are more proficient than non-experts at using\nFigure 12.20\nBrain activation while\ndiagnosing lesions in X-rays,\nnaming animals and naming\nletters. The first column\nprovides a right view, the\nmiddle column a left view\nand the last column a\nposterior view.\nFrom Melo et al. (2012).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n609\nslow, explicit or analytic processes. More generally, incorrect diagnoses can\nresult from detection, recognition or judgemental errors.\nWhat are the limitations of theory and research? First, there are very\nfew longitudinal studies (apart from Krupinski et al., 2013). Such studies\nare essential to understand the learning processes involved in the develop-\nment of expertise.\nSecond, we need more research on the ways fast and analytic processes\nare combined. For example, Kulatunga-Moruzi et al. (2011) found non-\nexperts benefited from this combination when fast processes preceded ana-\nlytic ones but not when analytic processes came first.\nThird, relatively little research has compared different training pro-\ngrammes designed to enhance diagnostic accuracy. Such research could\nclarify the advantages and disadvantages of different diagnostic strategies.\nChess expertise vs medical expertise\nChess and medical expertise have several similarities. First, intensive train-\ning is required to attain genuine expertise. Second, this training leads to\nthe acquisition of huge amounts of relevant stored knowledge. Third,\nexperts in both areas are superior to non-experts at using rapid (appar-\nently “automatic”) processes. Fourth, experts in both areas use analytic or\nstrategy-based processes effectively when necessary.\nWhat are the differences between chess and medical expertise? First,\nwhile much of the knowledge possessed by chess experts consists of fairly\nabstract templates, medical experts are more likely to possess knowledge\nthat is less abstract and more visual. Second, chess experts must relate a\ncurrent chess position to their stored knowledge and then consider their\npotential next move and that of their opponent. In contrast, medical\nexperts focus more narrowly on relating information about a specific case\nto their stored knowledge.\nBRAIN PLASTICITY\nThe development of expertise involves acquiring huge amounts of knowl-\nedge and specialised cognitive processes. Does the development of expertise\nalso cause modifications within the brain? The key concept here is plasticity:\n“changes in structure and function of the brain that affect behaviour and\nare related to experience or training” (Herholz & Zatorre, 2012, p. 486).\nIt is often assumed structural changes resulting from plasticity facilitate\nfurther learning and the development of expertise.\nBefore discussing research on expertise, we will mention compelling evi-\ndence for plasticity in individuals becoming blind at an early age. They exhibit\nhigh levels of activity in occipital cortex (typically involved in visual pro-\ncessing) when performing many non-visual tasks (e.g., reading Braille; local-\nising sound) (Heimler et al., 2014). This is known as cross-modal plasticity.\nTaxi drivers\nImportant research was carried out on London taxi or cab drivers, who\nhave to acquire “The Knowledge”. This consists of detailed knowledge\nKEY TERM\nPlasticity\nChanges within the brain\noccurring as a result\nof brain damage or\nexperience.\nCreated from usyd on 2022-02-17 03:28:25.",
    "610\nThinking and reasoning\nof the 25,000 streets within 6 miles of Charing Cross and the locations of\nthousands of hospitals, tube stations and so on. Unsurprisingly, it takes\nthree years to acquire all this information.\nHow do cab drivers develop this extraordinary knowledge and exper-\ntise? The hippocampus (an area within the medial temporal lobes) is of\nmajor importance, as might be expected given its central role in long-term\nmemory (see Chapter 6). Hippocampal damage is also associated with\nimpaired spatial navigation skills (McCormick et al., 2018). Unsurprisingly,\na taxi driver who had recently suffered extensive hippocampal damage had\nseverely impaired navigation skills (Maguire et al., 2006).\nAcquisition of “The Knowledge” probably has a direct effect on the\nhippocampus. Experienced London cab drivers have a greater volume of\ngrey matter in the posterior hippocampus than novice drivers (Woollett et\nal., 2009). However, cab drivers have a smaller volume of grey matter than\nother people in the anterior hippocampus. This is an area used in processing\nnovel stimuli, imagining events and recalling events (Zeidman & Maguire,\n2016). The finding that cab drivers perform poorly on tasks requiring them to\nlearn and remember new object-place associations may reflect their reduced\ngrey matter in the anterior hippocampus (Woollett & Maguire, 2009).\nCausality\nThe findings discussed so far are correlational and so cannot show acquir-\ning “The Knowledge” causes hippocampal changes. Somewhat more direct\nevidence was reported by Woollett and Maguire (2011). Among adults who\nhad spent several years acquiring “The Knowledge”, only those who suc-\nceeded in becoming London taxi drivers had a selective increase in grey\nmatter in their posterior hippocampus.\nHyde et al. (2009) studied 6-year-old children who received 15 months\nof instrumental musical training. They showed significant changes in voxel\nsize (a voxel is a small cube of brain tissue) in the primary motor area\n(see Figure 12.21) and the primary auditory area (see Figure 12.22). In\naddition, children having the greatest brain changes showed the greatest\nimprovement in musical skills.\nMore evidence that training can alter brain structure was reported by\nde Manzano and Ullén (2018). They studied monozygotic (identical) twins\nwhere one twin had received at least 1,000 hours of piano practice more\nthan the other, thus controlling for genetic factors. The brains of the more\nmusically trained twins differed in various ways from the less trained ones\n(e.g., they had greater cortical thickness within the auditory-motor network).\nHerholz et al. (2016) carried out a longitudinal study in which adults\nreceived six weeks of training in playing the piano. There was evidence\nfor plasticity: training enhanced activity in brain areas (e.g., premotor\nand posterior parietal regions) involved in motor preparation and sensori-\nmotor integration. Other brain areas (e.g., parts of the primary auditory\ncortex; premotor cortex) predicted individuals’ learning rates during piano\ntraining. These brain areas reflected individual differences in predisposi-\ntion (potential for learning musical skills). In sum, these findings emphasise\nthe value of considering individual differences in pre-training brain activity\n(predisposition).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n611\nFigure 12.21\nThe brain image shows areas in the primary motor cortex with differences in relative voxel size (a voxel is a small cube of\nbrain tissue) between children receiving 15 months of instrumental music training and non-trained controls: (a) changes\nin relative voxel size over time in trained and non-trained groups (a value of 1.00 indicates no change); (b) correlation\nbetween amount of improvement in motor-test performance and change in relative voxel size for all participants.\nCenter, Inc.\nEvaluation\nNumerous studies have shown predictable differences in brain structure and\nfunction between individuals with varying amounts of training in a given\ndomain (Zatorre, 2013). Support for the hypothesis that developing exper-\ntise can cause changes in brain structure has come from longitudinal studies\nwhere brain structure was assessed before, during and after training and\nfrom de Manzano and Ullén’s (2018) study on monozygotic twins. Progress\nhas been made in identifying brain areas associated with predisposition\n(potential for learning) and training-related plasticity during learning (e.g.,\nHerholz et al., 2016).\nWhat are the limitations of research on plasticity and expertise? First,\nit is hard to show definitively that practice has caused changes in brain\nstructure of relevance to performance improvement. Second, most research\nhas focused on musical training. This is reasonable given that musical\ntraining influences auditory perception and several aspects of higher-level\ncognition. However, it means the relevant database is relatively narrow.\nCreated from usyd on 2022-02-17 03:28:25.",
    "612\nThinking and reasoning\nThird, many complex effects of practice on neural plasticity have been\nreported in the literature. For example, Vaquero et al. (2016) found expert\npianists had greater grey matter volume than controls in the putamen\n(involved in motor control and reinforcement learning). However, these\nexperts had smaller grey matter volume than controls in other brain areas\n(e.g., superior temporal gyrus) involved in auditory processing and sen-\nsorimotor control. We lack a coherent theoretical understanding of such\ncomplexities.\nDELIBERATE PRACTICE AND BEYOND\nWe have seen deliberate practice over a period of many years is essential\nto become an expert in a given domain. That is obvious. Less obvious are\nthe answers to two related issues. First, what determines the effectiveness of\nprolonged practice? Second, what factors other than prolonged practice are\nrequired to become an expert?\nFigure 12.22\nBrain image showing areas in the primary auditory area with differences in relative voxel size between trained children\nand non-trained controls: (a) changes in relative voxel size over time; (b) correlation between improvement in melody-\nrhythm test and change in relative voxel size\nCenter, Inc.\nRight\nHeschl’s\ngyrus\nKEY TERMS\nDeliberate practice\nThis is an effective form\nof practice provided that\nlearns are given a task\nof moderate difficulty\nrepeatedly, and have\ninformative feedback so\nthey can correct their\nerrors.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n613\nEricsson (e.g., 2017) argued that the answer to the first ques-\ntion is  deliberate practice. More specifically, he claimed that ten years\n(10,000 hours) of deliberate practice is required to achieve expertise.\nControversially, he claimed such practice is the most important factor\nrequired to develop expertise and that innate talent or ability is of little or\nno relevance. Deliberate practice has four aspects:\n(1) The task is at an appropriate level of difficulty (not too easy or hard).\n(2) The learner is given informative feedback about their performance.\n(3) The learner has adequate chances to repeat the task.\n(4) The learner has the opportunity to correct their errors.\nWhat happens as a result of prolonged deliberate practice? According to\nEricsson and Kintsch (1995), experts can reduce the negative effects of\nhaving limited working memory capacity. They put forward the notion of\nlong-term working memory. The crucial notion is that “fast . . . transfer to\nLTM [long-term memory] becomes possible with expertise via knowledge\nstructures, which enables LTM [long-term memory] to be used during WM\n[working memory] tasks, thus giving the appearance of expanding individu-\nals’ WM capacity” (Guida et al., 2013, p. 1).\nSuppose expert and novice chess players learn the positions of chess\npieces on a board. Novices rely largely on working memory (a limited-\ncapacity system that processes and stores information briefly; see\nChapter 6). In contrast, experts use their huge relevant knowledge to store\nmuch of the information directly in long-term memory and thus enhance\ntheir recall of the board position. In other words, experts use long-term\nworking memory, but novices do not.\nIN REAL LIFE: MAGNUS CARLSEN,\nWORLD CHESS CHAMPION\nThe Norwegian Magnus Carlsen was born on\n30 November 1990. He became a chess grand-\nmaster at the amazingly young age of 13 and\nthe world chess champion in November 2013\n(aged 22). In 2014, he was rated the strongest\nplayer in chess history. The difference between\nhim and the second-best player (Levon Aronian)\nwas almost as great as that between the 2nd\nand 14th best players. One of his greatest\nstrengths is his “nettlesomeness” – meaning\nhe is a vexatious individual who is superb at\nmaking moves that pressurise opponents into\nmaking mistakes.\nMagnus Carlsen disproves the main assump-\ntions of Ericsson’s deliberate practice theory.\nFirst, he became a grandmaster after only five years of deliberate practice although Ericsson claimed\nten years of deliberate practice are required to achieve outstanding levels of performance.\nMagnus Carlsen, who became world chess champion in\n2013.\ndpa Picture-Alliance/Alamy Stock Photo.\nCreated from usyd on 2022-02-17 03:28:25.",
    "614\nThinking and reasoning\nSecond, according to Ericsson’s theory, we would expect Magnus Carlsen to have accumulated\nmore years of deliberate practice than other top chess players. However, when he became world\nchampion, he had devoted 6½ years fewer to deliberate practice than the average of the next\n10 best players in the world (Gobet & Ereku, 2014). Across the top 11 players in the world, the\nassociation between rating and number of years of practice was modestly negative. According to\nEricsson’s theory, it should have been strongly positive.\nIn sum, Magnus Carlsen’s career shows that talent and deliberate practice are both essential for\nthe development of outstanding expertise. Indeed, Carlsen’s extraordinary talent has led to him\nbeing called “the Mozart of chess”.\nFindings: positive\nEricsson and Chase (1982) demonstrated the powerful effects of deliberate\npractice. A student, SF, received extensive practice (one hour a day for two\nyears) on the digit-span task (random digits are recalled immediately in the\ncorrect order). He increased his digit span from 7 digits to 80 (10 times the\naverage performance level). SF made use of his great knowledge of running\ntimes (e.g., “3594” was Bannister’s world-record time for the mile and so\nhe stored these digits as a single unit or chunk). After that, he organised\nchunks into a hierarchical retrieval structure. Thus, SF made very effect-\nive use of long-term working memory. Another student (Dario Donatelli)\nincreased his digit span from 8 to 104 digits following 800 hours of practice\n(Yoon et al., 2018).\nGuida et al. (2012) reviewed neuroimaging studies comparing\nnovices and experts performing working memory tasks. There were two\nmain findings. First, experts and novices both showed activation in pre-\nfrontal and parietal areas associated with working memory processes.\nSecond, only experts showed activation in medial temporal regions\nstrongly associated with long-term memory. This finding suggests experts\nmake more use than novices of long-term memory processes during task\nperformance.\nTo what extent can individuals’ level of expertise be accounted for by\nindividual differences in deliberate practice? Campitelli and Gobet (2011)\nfound across many studies on chess-playing expertise that the correlation\nbetween total practice hours and chess skill exceeded +.50. However, such\ncorrelational evidence cannot prove that the former directly caused the\nlatter.\nFindings: negative\nWe turn now to findings indicating that expertise does not depend mainly\non deliberate practice. Macnamara et al. (2014) found in a meta-analytic\nreview that the average correlation between deliberate practice and per-\nformance was +.35, which suggests deliberate practice explains 12% of\nthe variance in performance. However, the percentage of the variance\nexplained differed considerably across domains: it was 26% for games,\n21% for music, 18% for sports, but only 4% for education and <1% for the\nprofessions.\nKEY TERM\nLong-term working\nmemory\nUsed by experts to store\nrelevant information\nrapidly in long-term\nmemory and to access it\nthrough retrieval cues in\nworking memory (see\nGlossary).\nResearch activity:\nSkill acquisition\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n615\nMacnamara et al. (2016b) confirmed in a further meta-analytic review\nthat deliberate practice accounted for 18% of the variance in sports per-\nformance. However, when they focused on elite samples, deliberate prac-\ntice explained only 1% of the variance in sports performance. How can\nwe explain this last finding? Nearly all elite individuals have benefited\nfrom excellent environmental conditions (e.g., prolonged deliberate prac-\ntice; top-class coaching) and so individual differences in expertise probably\nreflect genetic rather than environmental factors.\nMore direct evidence was reported by Güllich (2017). Those sports\npeople who had won medals at Olympic and/or world championships\naccumulated fewer hours of deliberate practice across their careers than\nnon-medallists.\nCampitelli and Gobet (2011) identified three predictions from deliber-\nate practice theory:\n(1) All individuals engaging in massive distributed practice should achieve\nvery high skill levels.\n(2) The variability across individuals in the number of hours required to\nachieve high expertise should be small.\n(3) Everyone’s skill level should benefit comparably from any given\namount of distributed practice.\nCampitelli and Gobet (2011) considered the above three predictions with\nreference to chess. None was supported. So far as the first prediction is con-\ncerned, there are several chess players who have devoted over 20,000 hours\nto practice without becoming masters.\nWith respect to the second prediction, the practice hours required to\nachieve master level varied between 3,000 and 23,600 hours.\nEvidence against the third prediction was reported by Howard (2009).\nHe studied candidates (elite players who have competed for the right to\nchallenge the world champion); non-candidate grandmasters (elite players\nbut less expert than candidates); and non-grandmasters. Their skill ratings\nas a function of games played are shown in Figure 12.23. There are two\npoints of interest. First, these three groups showed clear performance dif-\nferences early on which increased over games. Second, players in all groups\nshowed no improvement after playing about 750 games.\nHoward (2009) found additional evidence of a performance ceiling\namong five players who had played over 2,300 games (representing more\nthan 8,000 hours’ playing time!). These players showed no improvement\nover the last 1,000(+) games they played. Thus, the beneficial effects of\ndeliberate practice are limited.\nThe above findings suggest it is possible early in their careers to iden-\ntify those who will eventually become outstanding chess players, suggesting\nthey have very high natural talent. The same is true in sports such as tennis\nand golf (think of Federer, the Williams sisters and Woods). The findings\nalso suggest there is a ceiling on the performance level any individual can\nattain based on their natural talent.\nThe finding that deliberate practice typically correlates positively with\nexpert performance does not necessarily mean the former causes the latter.\nFor example, individuals with much innate talent are likely to enjoy early\nCreated from usyd on 2022-02-17 03:28:25.",
    "616\nThinking and reasoning\nsuccess, which may motivate them to devote more time to deliberate prac-\ntice than those with less talent. Thus, performance level can influence the\namount of practice.\nDramatic evidence supporting the above point of view was reported\nby Mosing et al. (2014) in a twin study on music practice and music ability.\nGenetic factors accounted for 40%–70% of individual differences in hours\nof music practice – this probably occurred because individuals with more\ninnate talent practised more. Of importance, there was no difference in\nmusic ability between monozygotic (identical) twins even when they dif-\nfered in the amount of music practice. Thus, the relationship between\nmusic practice and music ability depended mostly on genetic factors.\nEvaluation\nMemory in a domain of expertise can be developed via the use of long-term\nworking memory and this can reduce limitations on processing capacity.\nHowever, enhanced storage of domain-relevant information forms only\npart of what is required to develop expertise. Unsurprisingly, nearly all the\nevidence supports the contention that prolonged deliberate practice is nec-\nessary to achieve outstanding levels of expertise.\nWhat are the theory’s limitations? First, it is hard to test because of\nvague definitions. For example, “deliberate practice” sometimes refers to\nteacher- or coach-designed activities and sometimes to solitary practice\n(Hambrick et al., 2018), and several definitions of “expert” have been used\n(Macnamara et al., 2016a).\nSecond, Ericsson’s research is narrow in scope. Most factors influenc-\ning expertise could not be identified because of their focus on deliberate\npractice (see below, pp. 617–619). Even with such narrow research, individ-\nual differences in deliberate practice are only moderately related to perfor-\nmance (e.g., Macnamara et al., 2014, 2016b).\nThird, Ericsson emphasised the role of long-term working memory (see\nGlossary) in expertise. Experts use stored structures in long-term memory\nFigure 12.23\nMean chess ratings of\ncandidates, non-candidate\ngrandmasters (GMs) and\nall non-grandmasters as\na function of number of\ngames played.\nFrom Howard (2009). With\nkind permission from Springer\nScience+Business Media.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n617\nto enhance working memory performance. However, it is not necessary\nto hypothesise the existence of a brand new form of working memory\n(Baddeley, 2012).\nFourth, it is assumed deliberate practice causes expertise. This begs the\nquestion of why individual differences in distributed practice exist. The evi-\ndence suggests naturally talented individuals are more motivated to devote\nsubstantial time to deliberate practice than less talented individuals.\nFifth, deliberate practice theory provides an extreme environmen-\ntalist approach to understanding the development of expertise. As such, it\nignores several factors (e.g., intelligence; gene-environment interactions) of\ndemonstrable importance to expertise (Ullén et al., 2016; see below).\nSixth, the importance of deliberate practice depends on the domain\n(or area) of expertise (Macnamara et al., 2014). Deliberate prac-\ntice  influences the development of expertise more in relatively specific\ndomains  (e.g.,   increasing digit span) than in much broader and more\ncomplex ones (e.g., succeeding in the professions) (Gottfredson, 1997;\ndiscussed below).\nSeventh, the theory is very oversimplified. Its assumption that delib-\nerate practice is sufficient (as well as necessary) for the development of\nexpertise is wrong.\nBeyond deliberate practice: multifactorial\ngene- environment interaction model\nAs we have seen, deliberate practice is not the only important factor deter-\nmining the development of expertise. Ullén et al. (2016) used findings\nsuch as those discussed above to develop their impressive-sounding multi-\nfactorial gene-environment interaction model (see Figure 12.24).\nFigure 12.24\nThe main factors (genetic\nand environmental)\ninfluencing the\ndevelopment of expertise.\nMany of these factors\ninteract with each other.\nFrom Ullén et al. (2016).\nAbilities\nGeneral IQ\nNarrow abilities\nPersonality\nGrit/conscientiousness\nOpenness\nImpulsivity\nPhysical\nproperties\nMuscle strength\nHeight\nSize of body and\nextremities\nNeural\nmechanisms\nLTM-WM\nSensorimotor skills\nInterests\nMotivation\nDeliberate\npractice\nExpertise\nEnvironment\nGenes\nG-E covariation\nCreated from usyd on 2022-02-17 03:28:25.",
    "618\nThinking and reasoning\nWhat are the main assumptions of this model?\n(1) Hambrick et al. (2018, p. 291) pointed out, “At the core of MGIM\n[multifactorial gene-environment interaction model] is the assumption\nthat expertise is multiply determined.”\n(2) The development of expertise depends on both domain-specific know-\nledge and skills (fostered by deliberate practice) and domain-general\nabilities (e.g., intelligence; personality).\n(3) There is gene-environment interaction (the magnitude of genetic\ninfluences on performance varies as a function of the nature of envi-\nronmental experiences).\n(4) There is gene-environment correlation (individuals experience differ-\nent environments as a function of their genetic make-up).\n(5) Deliberate practice increases expertise in part by modifying neural\nmechanisms (e.g., brain plasticity).\n(6) Individual differences in deliberate practice are determined in part by\ngenetic factors relating to personality, abilities and motivation.\nFindings\nThere is considerable evidence supporting the second assumption above.\nHambrick et al. (2019) reviewed research indicating that expertise in many\nareas depends on the domain-general ability of intelligence or cognitive\nability. As we saw earlier, intelligence is positively correlated with chess\nexpertise (Burgoyne et al., 2016).\nEvidence indicating that intelligence or IQ influences the development\nof expertise was reviewed by Gottfredson (1997). The correlation between\nIQ and work performance was +.58 for high-complexity jobs (e.g., biolo-\ngist; city circulation manager). In addition, the mean IQ of those in very\ncomplex jobs (e.g., accountants; lawyers; doctors) was about 120–130 (much\nhigher than the population mean of 100). However, intelligence is much less\nrelevant for relatively specific skills. For example, Ceci and Liker (1986)\nfound experts at calculating the odds in harness racing had IQs ranged from\n81 to 128 and there was no relationship between performance and IQ.\nHambrick and Tucker-Drob (2015) reported findings supporting the\nmodel’s third and fourth assumptions in a study on music practice and\naccomplishment in twins. There was evidence for gene-environment inter-\naction: genetic influences on music accomplishment were greater among\nparticipants who engaged in music practice. There was also evidence for\ngene-environment correlation: there were genetic effects on the amount of\nmusic practice. Indeed, these effects were greater than genetic effects on\nmusic accomplishment.\nResearch relevant to the fifth assumption was discussed earlier. In spite\nof problems with establishing that deliberate practice has causal influences\non neural mechanisms, the evidence overall supports this assumption (e.g.,\nde Manzano & Ullén, 2018).\nEvidence that personality plays a role in determining individual differ-\nences in deliberate practice was discussed by Ullén et al. (2016). High levels\nof grit or conscientiousness are associated with high levels of deliberate\npractice whereas high impulsivity is associated with low levels of practice.\nKEY TERMS\nGene-environment\ninteraction\nIndividuals differing in\ntheir genetic make-up\nrespond in different\nways to environmental\nvariation.\nGene-environment\ncorrelation\nGenetic differences\nbetween individuals partly\ndetermine the different\nenvironments they\nexperience.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n619\nThere is also evidence that motivation influences the amount of deliberate\npractice. For example, individuals’ vocational interests influence what they\nchoose to focus on and how much time and effort they expend pursuing\nthose interests (Ackerman, 2014).\nEvaluation\nThe multifactorial gene-environment interaction model is considerably\nmore ambitious in scope than Ericsson’s approach based on deliberate\npractice. There is compelling evidence that all the factors identified by the\nmodel influence the development of expertise. There is also evidence that\nthese factors interact in complex ways largely consistent with the predic-\ntions of the model. In sum, this model is currently the most comprehensive\nmodel we have of the development of expertise.\nWhat are the model’s limitations? First, much more research is required\nto test some of the complex predictions made by the model. Second, we\nneed to move beyond predicting gene-environment interactions and corre-\nlations to identify the specific genes responsible for these effects. Third, the\nmodel predicts that interactions among the factors influencing the devel-\nopment of expertise will vary over time. As yet, there has been a dearth of\nlongitudinal studies testing such predictions.\nCHAPTER SUMMARY\n•\nIntroduction. This chapter is devoted to problem solving,\nanalogical problem solving and reasoning, and expertise. Most\nresearch on problem solving focuses on problems requiring no\nspecial knowledge. In contrast, research on expertise typically\ninvolves problems requiring considerable background knowledge.\nAnalogical problem solving focuses on the use of previous\nknowledge and experience on a current problem, whereas\nexpertise research is concerned with what differentiates experts\nfrom novices in a given area.\n•\nGestalt approach and beyond: insight and role of experience.\nMuch research supports the notion of insight. However, insight\nis hard to measure, and “insight” problems are often solved\nwith no evidence of insight. Incubation often benefits problem\nsolving because misleading information or ineffective strategies\nare forgotten. Representational change theory claims correctly\nthat solving insight problems often requires constraint relaxation\nand/or re-encoding of the problem representation. However, it\nunderestimates the range of strategies used on insight problems.\nThe phenomena of functional fixedness and mental set show\npast experience can impair problem solving. High cognitive\ncontrol sometimes impairs performance on tasks involving insight,\nfunctional fixedness or mental set.\nResearch activity:\nCognitive reflection test\nCreated from usyd on 2022-02-17 03:28:25.",
    "620\nThinking and reasoning\n•\nProblem-solving strategies. Problem solvers use heuristics\n(e.g., hill climbing; means–ends analysis). They also use meta-\ncognitive processes to determine their problem-solving strategies.\nMuch problem solving involves successive stages of problem\nrepresentation, planning and plan execution. The prefrontal cortex\nis heavily involved in planning and problem solving generally.\nThere is more planning when it is costly to access task-relevant\ninformation. Cognitive misers fail to solve some problems because\nof a reluctance to engage in effortful processing.\n•\nAnalogical problem solving and reasoning. Analogical problem\nsolving depends on three kinds of similarity: superficial, structural\nand procedural. Failures to use analogies often occur through\nfailures to retrieve relevant information from memory. Such failures\ncan be reduced if problem solvers identify the underlying structure\nof the current problem. Four-term analogy problems involve four\ncomponent processes: encoding, inferring, mapping and applying,\nof which inference and mapping are typically the hardest.\nIndividuals high in fluid intelligence have excellent analogical\nreasoning due to their superior top-down executive attention,\nability to disengage (e.g., inhibit irrelevant information) and think\nflexibly. The left rostrolateral prefrontal cortex is the brain area of\ngreatest relevance to analogical reasoning (especially mapping).\n•\nChess-playing expertise. Expertise is typically assessed by using\nknowledge-rich problems. Expert chess players differ from non-\nexpert ones in having greater cognitive ability and possessing\nfar more template-based and chunk-based knowledge. This\nknowledge permits expert players to identify good moves rapidly.\nHowever, the precise information contained in templates remains\nunclear. The template approach de-emphasises experts’ use of\nslow search processes and complex strategies.\n•\nMedical expertise. Medical experts (e.g., radiologists) often rely\nmore than non-experts on fast, automatic processes in diagnosis:\nthey rapidly fixate relevant information and ignore task-irrelevant\ninformation. Slow, analytic processes enhance diagnostic\nperformance (especially for experts). Diagnostic errors can be\ndue to failures in detection, recognition or judgement. Medical\nexpertise involves more visual and less abstract knowledge than\nchess expertise. It is also more narrowly focused.\n•\nBrain plasticity. There are differences in brain structure between\nexperts and non-experts (e.g., taxi drivers). Training studies\n(especially in music) have shown that these changes in brain\nstructure are often caused by experience and reflect brain\nplasticity. The structural changes associated with brain plasticity\nprobably provide experts with an additional benefit compared to\nnon-experts.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Problem solving and expertise\n621\n•\nDeliberate practice and beyond. According to Ericsson, the\ndevelopment of expertise depends only on deliberate practice\n(involving informative feedback and the opportunity to correct\nerrors). In fact, deliberate practice is necessary (but not sufficient)\nfor developing expertise. The importance of innate talent is\nsuggested by the variability in the amount of practice required to\nachieve high expertise and individual differences in the benefits\nof a given amount of practice. As predicted by the multifactorial\ngene-environment interaction model, innate ability is especially\nimportant in broad domains (e.g., career success). The model\nalso accurately predicts that genetic factors strongly influence\nthe amount of deliberate practice. More generally, individual\ndifferences in expertise depend heavily on gene-environment\ninteractions and gene-environment correlations.\nFURTHER READING\nAl-Moteri, M.O., Symmons, M., Plummer, V. & Cooper, S. (2017). Eye track-\ning to investigate cue processing in medical decision-making: A scoping review.\nComputers in Human Behavior, 66, 52–66. Modi Owied Al-Moteri and colleagues\nprovide a theoretical framework indicating the main processes involved in medical\ndecision-making.\nGobet, F. (2016). Understanding Expertise: A Multi-Disciplinary Approach. London:\nPalgrave. Fernand Gobet shows how expertise can be understood by integrating\nideas and research from several scientific disciplines.\nHambrick, D.Z., Burgoyne, A.P., Macnamara, B.N. & Ullén, F. (2018). Toward a\nmultifactorial model of expertise: Beyond born versus made. Annals of the New\nYork Academy of Sciences, 1423 (SI), 284–295. David Hambrick and colleagues\ndiscuss limitations with the notion that expertise depends almost totally on delib-\nerate practice and discuss their multifactorial gene-environment interaction model\nin detail.\nLovett, A. & Forbus, K. (2017). Modelling visual problem solving as analogical rea-\nsoning. Psychological Bulletin, 124, 60–90. This article provides interesting theo-\nretical insights into the processes underlying analogical reasoning.\nRobertson, S.I. (2017). Problem Solving: Perspectives from Cognition and\nNeuroscience (2nd edn). London: Routledge. This book provides a useful and\nreadable introduction to problem solving and expertise.\nWard, P., Schragen, J.M., Gore, J. & Roth, E. (eds.) (2019). Oxford Handbook of\nExpertise: Research and Application. Oxford: Oxford University Press. This edited\nbook contains chapters by leading experts on expertise.\nWeisberg, R.W. (2018). Problem solving. In L.J. Ball & V.A. Thompson (eds),\nRoutledge International Handbook of Thinking and Reasoning (pp. 607–623).\nAbingdon, Oxon.: Routledge. Robert Weisberg reviews contemporary theories\nand research on problem solving.\nZuk, J. & Gaab, N. (2018). Evaluating predisposition and training in shaping the\nmusician’s brain: The need for a developmental perspective. Annals of the New\nYork Academy of Sciences, 1423, 4–60. Jennifer Zuk and Nadine Gaab discuss a\ntheoretical model accounting for the role of brain plasticity in the development of\nmusical expertise (the “musician brain”).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and\ndecision-making\nINTRODUCTION\nIn this chapter, our focus is on the overlapping areas of judgement and\ndecision-making. Judgement involves deciding on the likelihood of various\nevents using incomplete information. For example, you might use informa-\ntion about your previous examination performance to judge the probability\nyou will succeed in your next examination. What matters in judgement is\naccuracy.\nDecision-making involves selecting one option from several possi-\nbilities. For example, you may have had to decide which college or uni-\nversity to attend, which courses to study and so on. The factors involved\nin decision-making depend on the importance of the decision – the pro-\ncesses involved in deciding on a career path are much more complex\nand time-consuming than deciding whether to drink a Coke or a Pepsi!\nProblem solving (discussed in Chapter 12) differs from decision-making in\nthat individuals must generate their own solutions rather than choosing\nfrom presented options.\nWe typically assess decision quality in terms of consequences – are we\nhappy with our choice of university or course? This can be unfair. There is\nthe story of a surgeon saying “The operation was a success. Unfortunately,\nthe patient died”. This sounds like a sick joke in every sense. In fact,\nhowever, a decision can be good given the information available at the\ntime even if its consequences are poor.\nJudgement typically forms an important initial part of the decision-\nmaking process. For example, someone deciding which car to buy might\nmake judgements about how much various cars would cost to run, how\nreliable they would be and how much he/she would enjoy owing one.\nWhat does research on judgement and decision-making tell us\nabout human rationality? That issue is part of a broader one concern-\ning human rationality and logicality in general. That issue (including con-\nsideration of research on judgement and decision-making) is discussed in\nChapter 14.\nChapter\n13\nKEY TERMS\nJudgement\nAn assessment of the\nprobability of a given\nevent occurred based on\nincomplete information.\nDecision-making\nMaking a selection from\nvarious options; if full\ninformation is unavailable,\njudgement is required.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n623\nJUDGEMENT RESEARCH\nOur subjective assessment of the probability of something is often changed\nby new information. Suppose you are 90% sure someone has lied to you.\nHowever, their version of events is later confirmed by someone else, leading\nyou to believe there is only a 60% chance you have been lied to. In everyday\nlife, new information often increases or decreases the strength of our beliefs.\nThe Rev. Thomas Bayes provided a precise way of thinking about\nsuch cases (unsurprisingly, his approach is known as Bayesian inference).\nHe focused on situations where there are two possible subjective beliefs or\nhypotheses (e.g., X is lying vs X is not lying) and showed how new data or\ninformation changes the subjective probabilities of each hypothesis being\ncorrect.\nAccording to Bayes’ theorem, we need to evaluate beliefs concerning\nthe relative probabilities of the two hypotheses before the data are obtained\n(prior odds or beliefs). We also need to calculate the relative probabilities\nof obtaining the observed data under each hypothesis (likelihood ratio).\nBayesian methods evaluate the probability of observing the data, D, if\nhypothesis A is correct, written p(D/HA), and if hypothesis B is correct,\nwritten p(D/HB). Bayes’ theorem is expressed as an odds ratio:\np(HA/D)\np(HA)\np(D/HA)\n–––––––– = –––––– × ––––––––\np(HB/D)\np(HB)\np(D/HB)\nThe above formula may look intimidating, but it is not really\n(honestly!). On the left side of the equation are the relative probabilities of\nhypotheses A and B in the light of the new data. These are the probabilities\nwe want to work out. On the right side of the equation, we have the prior\nodds of each hypothesis being correct before the data were collected mul-\ntiplied by the likelihood ratio based on the probability of the data given\neach hypothesis.\nWe can apply Bayes’ theorem to Kahneman and Tversky’s (1972) taxi-\ncab problem. A cab was involved in an accident one night. Of the city’s\ncabs, 85% belonged to the Green company and 15% to the Blue company.\nAn eyewitness identified the cab as a Blue cab. However, when her ability\nto identify cabs under similar visibility conditions was tested, she was\nwrong 20% of the time. What is the probability the cab was Blue?\nThe hypothesis the cab was Blue is HA and the hypothesis it was\nGreen is HB. The prior probability for HA is .15 and for HB it is .85\nbecause 15% of the cabs are blue and 85% are green. The probability of\nthe eyewitness identifying the cab as Blue when it was Blue, p(D/HA) is\n.80. Finally, the probability the eyewitness identifies the cab as Blue when\nit was Green, p(D/HB) is .20. According to the formula:\n0.15\n0.80\n0.12\n–––– × –––– = ––––\n0.85\n0.20\n0.17\nThus, the odds ratio is 12:17 and there is a 41% (12/29) the taxi cab\nwas Blue. Alas, this is not the most popular answer.\nKEY TERM\nBayesian inference\nA form of statistical\ninference in which initial\nbeliefs (prior probabilities)\nare modified by evidence\nor experience to produce\nposterior probabilities.\nInteractive exercise:\nTaxi-cab problem\nCreated from usyd on 2022-02-17 03:28:25.",
    "624\nThinking and reasoning\nNeglecting base rates\nAccording to Bayes’ theorem, individuals making judgements should take\naccount of the base-rate information (the relative frequency of an event\nwithin a given population). However, such information is often ignored or\nde-emphasised. With the taxi-cab problem, most people ignore the base-\nrate information about the relative numbers of Green and Blue cabs. They\nconsider only the evidence of the witness and so conclude wrongly there is\nan 80% probability the taxi was Blue rather than Green.\nKahneman and Tversky (1973) provided another example of people\nignoring base-rate information. Participants were given the lawyer-engineer\nproblem:\nJack is a 45-year-old man. He is married and has four children. He is\ngenerally conservative, careful and ambitious. He shows no interest in\npolitical and social issues and spends most of his free time on his many\nhobbies which include home carpentry, sailing and numerical puzzles.\nThe participants were told the description had been selected at random from\n100 descriptions. Half were told 70 descriptions were of engineers and 30 of\nlawyers, whereas the others were told 70 were of lawyers and 30 of engineers.\nOn average, the participants decided there was a .90 probability Jack\nwas an engineer regardless of whether most of the 100 descriptions were of\nlawyers or engineers. Thus, participants ignored the base-rate information\n(i.e., the 70:30 split in the 100 descriptions).\nHeuristics\nTversky and Kahneman (e.g., 1974) argued most people given judgement\ntasks use rules of thumb or heuristics. Heuristics are “strategies that ignore\npart of the information, with the goal of making decisions more quickly,\nfrugally and/or accurately than more complex methods” (Gigerenzer &\nGaissmaier, 2011, p. 454). Heuristics often greatly reduce the effort associ-\nated with cognitive tasks.\nRepresentativeness heuristic\nOur use of heuristics can lead us to ignore base-rate information. More spe-\ncifically, we use the representativeness heuristic, which involves deciding\nan object or person belongs to a given category because it appears typical\nor representative of that category. For example, Jack’s description (see\nabove) seems that of a typical engineer.\nTversky and Kahneman (1983) studied the conjunction fallacy, the mis-\ntaken belief that the conjunction or combination of two events (A and B) is more\nlikely than one event (A or B) on its own. Consider the following description:\nLinda is 31 years old, single, outspoken and very bright. She majored\nin philosophy. As a student, she was deeply concerned with issues of\ndiscrimination and social justice, and also participated in anti-nuclear\ndemonstrations.\nKEY TERMS\nBase-rate information\nThe relative frequency of\nan event within a given\npopulation.\nHeuristics: representa-\ntiveness heuristic\nThe assumption that\nan object or individual\nbelongs to a specified\ncategory because it is\nrepresentative (typical) of\nthat category.\nConjunction fallacy\nThe mistaken assumption\nthat the probability of\na conjunction of two\nevents is greater than\nthe probability of one of\nthem.\nCase study:\nThe base rate fallacy\nreconsidered\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n625\nIN THE REAL WORLD:\nHEURISTICS IN MEDICAL DIAGNOSIS\nThe importance of the representativeness heuristic\nwould be increased if experts in real life sometimes\nmistakenly used it. Supporting evidence was dis-\ncussed by Groopman (2007). Evan McKinley (a pseu-\ndonym) was a forest ranger in his early forties. He was\nslim and very fit. While hiking, he experienced severe\ndiscomfort in his chest so that it hurt every time he\ntook a breath. Accordingly, he went to see a doctor\n(Pat Croskerry). Croskerry ascertained McKinley had\nnever smoked, was not under stress, his blood pres-\nsure was normal, and no problems were revealed by\nelectrocardiogram and chest X-ray.\nDr Croskerry concluded, “I’m not at all worried\nabout your chest pain. You probably overexerted\nyourself in the field and strained a muscle. My sus-\npicion that this is coming from your heart is about\nzero.” Shortly afterwards, McKinley had a heart\nattack. This led Croskerry to admit, “I missed it\nbecause my thinking was overly influenced by how\nIs it more likely Linda is a bank teller or a bank teller active in the feminist\nmovement? Most people (including you?) argue it is more likely she is a\nfeminist bank teller. They seem to rely on the representativeness heuristic –\nthe description sounds more like that of a feminist bank teller than of a\nbank teller. This is the conjunction fallacy: all feminist bank tellers belong\nto the larger category of bank tellers!\nMany people misinterpret the statement “Linda is a bank teller”, as\nimplying she is not active in the feminist movement. However, the conjunc-\ntion fallacy is still found when almost everything is done to ensure people\ninterpret the problem correctly (Sides et al., 2002).\nStandard explanations of the conjunction fallacy (including those\nbased on the representativeness heuristic) assume it occurs because of the\nhigh perceived probability of the additional information (i.e., Linda is a\nfeminist activist) given the description. Tentori et al. (2013) argued for a\nsubtly different explanation: the hypothesis that Linda is a feminist activist\nis strongly supported by her description.\nTentori et al. (2013) contrasted these explanations by considering a\nfurther additional scenario: “Linda is a bank teller and owns a pair of\nblack shoes.” It is more probable Linda owns a pair of black shoes than\nthat she is an activist feminist. However, the information she owns a pair\nof black shoes is hardly supported by her description. Thus, standard\nexplanations would predict Linda owning a pair of black shoes would be\nrated as likelier than her being a feminist activist whereas the hypothesis\nexplanation predicts the opposite. Tentori et al.’s findings supported the\nhypothesis explanation.\nDr Pat Croskerry. Courtesy Pat Croskerry.\nCreated from usyd on 2022-02-17 03:28:25.",
    "626\nThinking and reasoning\nHeeding base rates\nIn spite of the findings discussed so far, people often make some use of\nbase-rate information. Bialek (2017) used the engineer-lawyer problem dis-\ncussed earlier (p. 624). The mean estimated probability that a description\ndrawn randomly from a sample of 1,000 was an engineer was .84 when 997\nof the sample were engineers compared to .53 when only 3 were engineers.\nMore strikingly, Bialek found with similar problems that many participants\nmade use of base-rate information irrelevant to the judgement task.\nKrynski and Tenenbaum (2007) argued that we possess valuable causal\nknowledge allowing us to make accurate judgements using base-rate infor-\nmation in our everyday lives. However, laboratory judgement problems\ngenerally fail to provide such knowledge.\nKrynski and Tenenbaum (2007) gave some participants the following\njudgement task (the false positive scenario):\nThe following statistics are known about women at age 60 who partic-\nipate in a routine mammogram screening, an X-ray of the breast tissue\nthat detects tumours:\n●\n2% of women have breast cancer at the time of screening. Most of\nthem will receive a positive result on the mammogram.\n●\nThere is a 6% chance that a woman without breast cancer will\nreceive a positive result on the mammogram.\nSuppose a woman at age 60 gets a positive result during a routine\nmammogram screening. Without knowing any other symptoms, what\nare the chances she has breast cancer?\nThe base rate of cancer in the population was often neglected by partic-\nipants given this task. This may have happened because breast cancer is\nthe only cause of positive mammograms explicitly mentioned. Suppose the\nhealthy this man looked, and the absence of risk factors.” In other words, McKinley seemed very\nrepresentative of healthy people with an extremely low risk of having a heart attack.\nCrupi et al. (2018) investigated the double conjunction fallacy: a conjunction of two statements\n(A + B) is judged to be more probable than statement (A) and then statement (B) when considered\non their own. Medical experts were provided with a scenario in which a man has chronic anaemia.\nCrupi et al. found 49% of the medical experts committed the double conjunction fallacy – they\njudged it more likely that the man suffered from alcoholism and thalassemia trait (a blood disorder)\nthan that he suffered from alcoholism or from thalassemia trait. However, this cannot be the case.\nWhy did almost half of the medical experts exhibit this bias? Some of the clinical evidence pre-\nsented in the scenario was very consistent with the hypothesis that the man had both alcoholism\nand thalassemia. Thus, the findings are consistent with Tentori et al.’s (2013) hypothesis explanation.\nSaposnik et al. (2016) and Croskerry (2018) reviewed studies on cognitive biases associated\nwith medical decisions. Common cognitive biases were anchoring (relying excessively on the first\nsymptom identified), omission bias (preferring inaction over action) and overconfidence (excessive\nconfidence in the correctness of one’s judgement). The reviewed evidence suggested cognitive\nbiases were associated with diagnostic inaccuracies in between 36% and 77% of cases. However,\nthe prevalence of cognitive biases in actual medical practice is currently unknown.\nKEY TERM\nDouble conjunction\nfallacy\nA stronger form of the\nconjunction fallacy in\nwhich a conjunction of\ntwo statements is judged\nmore likely than each of\nthe statements judged\nseparately.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n627\nproblem is reworded slightly to indicate an alternative cause of positive\nmammograms. Krynski and Tenenbaum (2007) did this by changing the\nwording of the third paragraph:\n●\nThere is a 6% chance that a woman without breast cancer will\nhave a dense but harmless cyst that looks like a cancerous tumour\nand causes a positive result on the mammogram.\nParticipants given the benign cyst scenario were far more likely to take full\naccount of the base-rate information than those given the standard false pos-\nitive scenario (see Figure 13.1). Krynski and Tenenbaum (2007) argued the\nreasonably full causal knowledge available to participants with the benign cyst\nscenario allowed them to solve the problem. It also corresponds to real life.\nIn Kahneman and Tversky’s (1972) taxi-cab problem (discussed earlier,\npp. 623–624), most participants ignored the base-rate information about the\nnumbers of Green and Blue cabs. Krynski and Tenenbaum (2007) argued that\nthis happened because it was hard for participants to see the causal structure.\nAccordingly, they devised a version providing a reason why the witness might\nhave made a mistake. Here is the crucial addition to the problem:\nWhen testing a sample of cabs, only 80% of the Blue Co. cabs appeared\nblue in colour, and only 80% of the Green Co. cabs appeared green in\ncolour. Due to faded paint, 20% of Blue Co. cabs appeared green in\ncolour, and 20% of Green Co. cabs appeared blue in colour.\nOnly 8% of participants showed base-rate neglect with the faded paint\nversion compared to 43% with the standard version. Correct answers\nincreased from 8% with the standard version to 46% with the faded paint\nversion. Thus, many people use base-rate information when they under-\nstand the underlying causal factors.\nPeople also use base-rate information when strongly motivated to do\nso. Suppose you were asked to put some saliva on a strip of paper. If it\nturned blue, that would mean you had an enzyme deficiency indicating a\nhealth problem. However, there is a 1/10 probability the test was mislead-\ning. Unfortunately, the paper turned blue.\nFigure 13.1\nPercentages of correct\nresponses and various\nincorrect responses (based\non base-rate neglect, odds\nform, base-rate overuse,\nand other) with the false-\npositive and benign cyst\nscenarios.\nFrom Krynski and Tenenbaum\nAmerican Psychological\nAssociation. Reproduced with\npermission.\nCreated from usyd on 2022-02-17 03:28:25.",
    "628\nThinking and reasoning\nDitto et al. (1998) gave participants the above task. Most used the\nbase-rate information (i.e., 1/10 probability of a misleading result) to argue\nthe test was inaccurate. In contrast, participants who were told the paper\nturning blue meant they did not have a health problem perceived the test as\naccurate – they were not motivated to take account of the base-rate infor-\nmation. Motivation also distorts informal reasoning (see Chapter 14). For\nexample, there is much evidence for myside bias (the tendency to favour\ninformation consistent with one’s prior beliefs over information inconsist-\nent with those beliefs).\nAvailability heuristic\nWe turn now to the availability heuristic – the frequencies of events can be\nestimated by how easy or hard it is subjectively to retrieve them from long-\nterm memory.\nLichtenstein et al. (1978) asked people to judge the relative likelihood\nof different causes of death. Those attracting much publicity (e.g., murder)\nwere judged more likely than those that do not (e.g., suicide) even when\nthe opposite was the case.\nPachur et al. (2012a) argued that we can explain people’s judged fre-\nquencies of various causes of death in three ways. First, they may use an\navailability heuristic based on their own direct experience. Second, they may\nuse an availability heuristic based on media coverage of causes of death\nplus their own experience (availability by total experience). Third, they may\nuse the affect heuristic: “Gauge your feeling of dread that Risk A and Risk\nB, respectively, evoke and infer that risk to be more prevalent in the popu-\nlation for which the dread is higher” (Pachur et al., 2012a, p. 316).\nWhat did Pachur et al. (2012a) find? Availability based on recall of\ndirect experiences was the best predictor of the judged frequencies of dif-\nferent causes of death (see Figure 13.2). Judged risks were also predicted\nby the affect heuristic. Availability based on media coverage was the least\nsuccessful predictor.\nIt should be emphasised that affect influences numerous kinds of\njudgements and that the term “affect heuristic” is used in various ways\nFigure 13.2\nPercentage of correct\npredictions of the judged\nfrequencies of different\ncauses of death based\non the affect heuristic\n(overall dread score), affect\nheuristic (single dread item),\navailability-by-recall (direct\nexperience) and availability-\nby-total-experience (TEX:\ndirect experience + media).\nFrom Pachur et al. (2012a).\n© American Psychological\nAssociation.\nKEY TERMS\nAvailability heuristic\nThe rule of thumb that the\nfrequencies of events can\nbe estimated accurately\nby the subjective ease\nwith which they can be\nretrieved.\nAffect heuristic\nUsing one’s emotional\nresponses to influence\nrapid judgements or\ndecisions.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n629\n(Rakow & Skylark, 2018). For example, Scherer et al. (2018) asked par-\nticipants to judge the benefits of medical tests (e.g., magnetic resonance\nimaging scan for migraine headaches). Those receiving information indi-\ncating that a given test might cause harm experienced more negative affect\nand judged the benefits of the test as less than those put into a negative\nmood.\nFazio et al. (2015) found truth ratings for false statements (e.g., “A\ndate is a dried plum”) were greater for participants who had previously\nencountered them. Surprisingly, this was so even for participants who\nknew the correct answer. Thus, individuals often rely on readily availa-\nble information even when they possess knowledge indicating they should\nnot.\nOppenheimer (2004) found the availability heuristic is sometimes\noverridden. Participants were presented with pairs of names (one famous,\none non-famous) and asked to indicate which was more common. They\nwould have chosen the famous names if using the availability heuristic,\nbut mostly selected the non-famous ones. What happened was that the\nparticipants used deliberate thought to override the availability heuristic.\nWhen the task was performed under cognitive load to reduce deliberate\nthought, participants mistakenly chose the famous name 80% of the time\n(Oppenheimer & Monin, 2009).\nIN THE REAL WORLD: AVAILABILITY HEURISTIC IN MEDICAL DIAGNOSIS\nGroopman (2007) discussed an example of poor medical decision-making triggered by the avail-\nability heuristic. When Dr Harrison Alter was working at a hospital in Arizona, he saw dozens of\npatients suffering from viral pneumonia in a three-week period. One day, Blanche Begaye, a Navajo\nwoman, arrived complaining of having trouble breathing. She said she had taken a few aspirin and\nwas breathing at almost twice the normal rate.\nDr Alter diagnosed viral pneumonia even though she lacked the white streaks in her lungs as\nwell as lacking rhonchi (harsh sounds in the lungs characteristic of that disease). However, her\nblood had become slightly acidic, which can occur when someone has a major infection. A few\nminutes later, an internist argued correctly Blanche Begaye had aspirin toxicity, which occurs\nwhen patients  overdose on that drug. Dr Alter used the availability heuristic because he was\noverly  influenced by the numerous recent cases of viral pneumonia making that disease spring to\nmind.\nMamede et al. (2010b) confirmed the problems potentially associated with the availability heu-\nristic. Doctors faced with a case resembling ones recently encountered tended mistakenly to make\nthe diagnosis appropriate only to the earlier cases.\nHow can we reduce cognitive biases (e.g., those based on the availability and representativeness\nheuristics?). Lambe et al. (2016) reviewed studies using cognitive interventions to enhance diagnos-\ntic accuracy. The most effective intervention was guided reflection, which involved use of guided,\nstructured, reflective processes.\nAnother effective intervention involved considering possible alternative diagnoses. Of relevance,\nDr Alter learned from his misdiagnosis to “make sure even when I think I have the answer to gen-\nerate a short list of alternatives”. A heuristic that has proved useful is to focus on ruling out the\nworst-case scenario (ROWS; Croskerry, 2018).\nCreated from usyd on 2022-02-17 03:28:25.",
    "630\nThinking and reasoning\nOverall evaluation\nKahneman and Tversky identified numerous general heuristics or rules\nof thumb underlying judgements in many different contexts. Only a few\nof these heuristics (e.g., representativeness heuristic; availability heuris-\ntic) have been discussed here. Another important heuristic discovered by\nKahneman and Tversky is the anchoring-and-adjustment heuristic: judges\nuse an initial estimate (the anchor) and then adjust it to produce a final\nestimate; however, the adjustment is typically insufficient. For example,\njudgements of the number of African countries in the United Nations are\nsystematically biased by initial numbers produced randomly by a roulette\nwheel (Fiedler & von Sydow, 2015).\nKahneman and Tversky established the field of judgement research and\ntheir emphasis on the role of heuristics has spread to several other research\nareas including decision-making (this chapter, pp. 640–663), and reasoning\n(Chapter 14). Their ideas have also been hugely influential outside psychol-\nogy (e.g., in economics and philosophy). There is plentiful evidence that\nmost people frequently prefer to minimise the cognitive demands on them\nby using heuristics (Fiedler & von Sydow, 2015).\nThere are several limitations with the heuristics and biases approach.\nFirst, the heuristics are defined vaguely. As Fiedler and von Sydow (2015,\np. 150) pointed out, “One-word labels like ‘representativeness’ are theory\nsurrogates [substitutes] that fail to place any testable constraints on the\ncognitive decision process.”\nSecond, theorising based on the heuristics-and-biases approach\nhas been limited (but see later discussion, pp. 634–637). According  to\nFiedler and von Sydow (2015, p. 154), “What is disillusioning and\ndisappointing . . . is how little precision, refinement, and progress has been\nobtained at the theoretical level.” For example, there is little evidence that\nthe  anchoring-and-adjustment heuristic depends on an incomplete adjust-\nment process rather than a simpler process (e.g., the initial numerical value\ntriggers or primes values similar to it). In addition, the precise conditions\nthat elicited the various heuristics and the relationships between different\nheuristics remain unspecified.\nThird, inaccurate judgements are not necessarily due to biased process-\ning. Instead, inaccurate judgements often occur because individuals have\nbeen exposed to a small and biased sample of information (an environ-\nmental factor). For example, most people judge skin cancer to be a more\ncommon cause of death than cancer of the mouth and throat although\nthe opposite is actually the case (Hertwig et al., 2005). Such findings have\nbeen attributed to an internal cause (the availability heuristic). In fact, they\nare due primarily to the much greater media coverage of skin cancer (an\nexternal cause).\nFourth, emotional and motivational factors influence our judgements\nin the real world but were rarely studied in the laboratory until relatively\nrecently (see Chapter 15). For example, the judged risk from formaldehyde\n(a toxic chemical compound) was greater when individuals were in a sad\nrather than neutral mood (Lench & Darbor, 2014).\nFifth, it has often been argued that the cognitive biases (e.g., failure to\ntake account of the underlying base rate) observed in much research are\nKEY TERM\nAnchoring-and-\nadjustment heuristic\nWhen someone makes\nan initial estimate (the\nanchor) and then adjusts\nit to produce a final\nestimate, the adjustment\nis generally insufficient.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n631\ndue in part to the artificiality of much laboratory research (McDowell &\nJacobs, 2017). Reasons why our judgements might be more accurate under\nmore naturalistic conditions are discussed next.\nNatural frequency hypothesis\nWe are rarely presented with summary statistics providing base-rate\ninformation in our everyday lives although this is common in laboratory\nresearch. Instead, what is common in our everyday experience is natural\nsampling – “the process of encountering instances in a population sequen-\ntially” (McDowell & Jacobs, 2017, p. 425).\nAccording to Gigerenzer and Hoffrage (1995), our evolutionary history\nmakes it easy for us to calculate the frequencies of different kinds of events.\nIn contrast, we are ill-equipped to deal with fractions and percentages: this\nhelps to explain why we often perform so poorly on judgement problems\ninvolving base rates. The central prediction is that performance on such\nproblems would be greatly enhanced if natural frequencies were used.\nThis theoretical approach poses some problems. First, we encoun-\nter only a sample of events in the real world, and the frequencies of such\nevents may differ substantially from “natural” samples. For example, the\nfrequencies of highly intelligent and less intelligent people encountered by\nuniversity students differ from those in the general population.\nSecond, we must distinguish between natural frequencies and the word\nproblems actually used in research. With most word problems, participants\nreceive frequency information and so bypass the complexities of natural\nsampling.\nFindings\nGigerenzer and Hoffrage (1995) presented a judgement task closely resem-\nbling the mammogram problem used by Krynski and Tenenbaum (2007;\ndiscussed earlier, pp. 626–627). When the problem was presented in proba-\nbilities, only 16% of participants produced the correct answer. In contrast,\n46% of participants were correct when frequencies were used.\nMcDowell and Jacobs (2017) reported a meta-analysis (see Glossary) of\nstudies comparing performance on judgement tasks using probabilities or\nnatural frequencies. Overall, there was a clear-cut advantage when natural\nfrequencies were presented. Performance on tasks presented using probabil-\nities was improved when the task was made easier by presenting a limited\namount of information or by using visual aids. However, these manipula-\ntions also improved performance on tasks using natural frequencies.\nEven individuals with much relevant knowledge benefit from frequency\ninformation. Hoffrage et al. (2015) used four realistic diagnostic tasks\nrequiring use of base-rate information in probability or natural frequency\nversions with advanced medical students. These tasks varied in complexity\n(e.g., the number of relevant cues; more than two possible hypotheses).\nCorrect judgements on each task were far more common with the natural\nfrequency than the probability version (see Figure 13.3). Overall, 45% of\nnatural frequency problems were solved correctly compared to only 7% of\nprobability problems.\nCreated from usyd on 2022-02-17 03:28:25.",
    "632\nThinking and reasoning\nFiedler et al. (2000) used a problem where there was an 80% chance a\nwoman with breast cancer would have a positive mammogram compared\nto 9.6% for a woman without breast cancer. The base rate of breast cancer\nin women is 1%. Participants engaged in frequency sampling cards from\nfiles organised into the categories of women with and without breast cancer\nto decide the probability that a woman has breast cancer if she has a pos-\nitive mammogram.\nParticipants’ sampling was heavily biased towards women with breast\ncancer because they mistakenly believed that category was more informa-\ntive. This led them to produce an average estimate of 63% a woman has\nbreast cancer given a positive mammogram (the correct answer is 7.8%).\nThe participants performed poorly because they engaged in biased fre-\nquency sampling.\nEvaluation\nThe natural frequency hypothesis has two major apparent strengths. First,\nwe often use information based on natural sampling when making judge-\nments in everyday life. Second, judgements are often more accurate when\nbased on natural frequency rather than probability information.\nWhat are the limitations of the hypothesis?\n(1) Enhanced performance with frequency versions may be due to its\n“computational simplicity” (Amitani, 2015) rather than because evo-\nlution has equipped us to process frequency information efficiently. So\nfar research has not resolved this theoretical controversy (McDowell\n& Jacobs, 2017).\n(2) It is generally assumed participants make accurate judgements because\nthey use Bayes theorem (discussed earlier, p. 623). However, Domurat\net al. (2015) found that, using a natural sampling approach, partici-\npants sometimes produced accurate judgements by using a simpler\n100\n90\n59%\n46%\n38%\nProbabilities\nNatural frequencies\n38%\n6%\n6%\n16%\n1%\n80\n70\n60\n50\n40\n30\n20\n10\n0\nPercentage of correct inferences\nTask 1\nThree cue\nvalues\nThree\nhypotheses\nTwo cues\nThree cues\nTask 2\nTask 3\nTask 4\nFigure 13.3\nPercentage of correct\ninferences on tasks\npresented in probability of\nnatural frequency versions.\nThe simplest task (Task 3)\nhas one hypothesis and two\ncue values; Task 1 has one\nhypothesis and three cue\nvalues; Task 2 has three\nhypothesis and two cue\nvalues each; Task 4 has one\nhypothesis with three cues.\nFrom Hoffrage et al. (2015).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n633\nstrategy. More generally, research has rarely identified with precision\nthe strategies actually used on judgement tasks.\n(3) There is often a yawning chasm between people’s actual sampling\nbehaviour and the neat-and-tidy frequency data provided in labora-\ntory experiments. This can occur because their sampling behaviour\nis biased due to inaccurate hypotheses (e.g., Fiedler et al., 2000) or\nbecause readily accessible information is biased.\n(4) People sometimes find it harder to think in frequencies than percent-\nages. Keeping track of frequency information in the real world can\nimpose considerable demands on memory (Amitani, 2015).\nTHEORIES OF JUDGEMENT\nSeveral theories of judgement have been proposed. Below we discuss those\ntheories that have contributed the most to our understanding of the pro-\ncesses underlying judgement and its biases.\nSupport theory\nTversky and Koehler (1994) proposed their support theory based partly on\nthe availability heuristic (discussed earlier, pp. 628–629). Their key assump-\ntion was that an event appears more or less likely depending on how it is\ndescribed. Thus, we must distinguish between events and descriptions of\nthose events.\nYou will almost certainly assume the probability you will die on your\nnext summer holiday is extremely low. However, it might seem more likely\nif you were asked “What is the probability you will die on your next\nsummer holiday from a disease, a car accident, a plane crash, contam-\ninated food, or any other cause?”.\nWhy is the subjective probability of death on holiday greater in the\nsecond case? According to support theory, there are two main reasons:\n(1) An explicit description draws attention to aspects of the event less\nobvious in the non-explicit description.\n(2) Memory limitations may prevent people remembering all the relevant\ninformation if it is not supplied.\nMore generally, the subadditivity effect follows from the theory. The sub-\nadditivity effect is “the tendency to judge the probability of the whole set\nof outcomes to be less than the total probabilities of its parts” (Riege &\nTeigen, 2017, p. 96).\nFindings\nWe might assume experts’ probability estimates would not be influenced\nby the explicitness of descriptions because they can readily provide missing\ndetails from their extensive knowledge. However, Redelmeier et al. (1995)\ndisconfirmed this assumption. Expert doctors received the description of a\nwoman with abdominal pain. Half assessed the probabilities of two specified\ndiagnoses (gastroenteritis and ectopic pregnancy) and a residual category\nKEY TERM\nSubadditivity effect\nThe judged probability of\nthe whole is less than the\ncombined probabilities of\nits parts.\nCreated from usyd on 2022-02-17 03:28:25.",
    "634\nThinking and reasoning\n(everything else). The other half assigned probabilities to five specified diag-\nnoses (including gastroenteritis and ectopic pregnancy) and everything else.\nThe key comparison was the subjective probability of all diagnoses other\nthan gastroenteritis and ectopic pregnancy. It was .50 with the non-explicit\ndescription but .69 with the explicit (more detailed) one. Thus, subjective\nprobabilities were higher for explicit descriptions even with experts.\nRiege and Teigen (2017) obtained strong evidence for the subadditivity\neffect. Participants were given the names and descriptions of the five actors\nnominated for the best actor award at the 2014 Oscars and indicated the\nprobability of each one winning. The sum of the five probabilities came to\n156% (the correct figure must be 100%).\nSloman et al. (2004) found participants estimated the probability an\nAmerican person selected at random would die of disease rather than some\nother cause was .55. The probability was similar when three typical dis-\neases (heart disease, cancer, stroke) were explicitly mentioned. However, it\nwas only .40 when three atypical diseases (pneumonia, diabetes, cirrhosis)\nwere mentioned. Thus, an explicit description can reduce subjective prob-\nability (rather than increase it as predicted theoretically) if it leads us to\nfocus on low-probability causes.\nLimitations\nSupport theory has various limitations. First, the theory does not explain\nin detail why providing an explicit description generally increases an event’s\nsubjective probability. However, Hilbert (2012) argued the processes con-\nverting objective evidence into subjective estimates are “noisy”, leading us\nto overestimate the probabilities of events having an objectively low prob-\nability. This leads to subadditivity and also explains several other cognitive\nbiases.\nSecond, the theory is oversimplified because it assumes the perceived\nsupport for a given hypothesis provided by relevant evidence is independent\nof the support for rival hypotheses. However, we often compare hypotheses\nand so this independence assumption is incorrect (Pleskac, 2012).\nThird, support theory cannot easily explain Sloman et al.’s (2004)\nfinding that superadditivity (the opposite of subadditivity) is found when\nexplicit descriptions focus on low-probability causes. This probably happens\nbecause focusing participants’ attention on low-probability causes reduces\ntheir awareness of high-probability ones.\nFast-and-frugal heuristics\nWe have seen our judgements are often inaccurate because we rely on\nvarious heuristics. In contrast, Gigerenzer and colleagues (e.g., Gigerenzer\n& Gaissmaier, 2011) argued heuristics are often very valuable when judging\nprobabilities and making decisions. Their central focus is on fast-and-frugal\nheuristics involving rapid processing of limited information. They assumed\nwe possess an “adaptive toolbox” consisting of several such heuristics which\nare often surprisingly accurate.\nThe take-the-best heuristic is a key fast-and-frugal heuristic based on\n“take the best, ignore the rest”. Suppose you must decide which of two\nResearch activity:\nSmart heuristics\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n635\nGerman cities (Cologne and Herne) has the larger population. You might\nassume the most valid cue is that cities whose names you recognise have\nlarger populations than unrecognised cities. However, you recognise both\nnames. After that, you think of another valid cue to city size (e.g., cities\nwith cathedrals tend to be larger than those without). Since you know\nCologne has a cathedral but are unsure about Herne, you say Cologne.\nThe take-the-best strategy has three components:\n(1) search rule: search cues (e.g., name recognition; cathedral) in decreas-\ning order of validity;\n(2) stopping rule: stop after finding a discriminatory cue (i.e., the cue\napplies to only one option).\n(3) decision rule: choose outcome.\nThe recognition heuristic (selecting the recognised object rather than\nthe unrecognised object) is a much researched example of the take-the-\nbest strategy. In the example above, if you recognise the name Cologne\nbut not Herne, you guess (correctly) Cologne is the larger city. Goldstein\nand Gigerenzer (2002) argued controversially that when individuals rec-\nognise one object but not the other, no other information influences their\njudgement.\nHow do people decide which heuristic to use on judgement or deci-\nsion-making tasks? Kruglanski and Gigerenzer (2011) argued there is a\ntwo-step process. First, the nature of the task and individual memory limit\nthe number of available heuristics. Second, individuals select one heuristic\nbased on the likely outcome of using it and its processing demands.\nFindings\nEvidence indicating the importance of the recognition heuristic was\nreported by Goldstein and Gigerenzer (2002). American students were pre-\nsented with pairs of German cities and decided which was larger. When\nonly one city name was recognised, participants apparently used the recog-\nnition heuristic 90% of the time. However, selecting the recognised city does\nnot necessarily mean the recognition heuristic was used – it could have been\nchosen for other reasons.\nIn another study, Goldstein and Gigerenzer (2002) told participants\nthat German cities with football teams tend to be larger than those\nwithout. When participants decided whether a recognised city without a\nfootball team was larger or smaller than an unrecognised city, participants\napparently used the recognition heuristic 92% of the time. Thus, as pre-\ndicted theoretically, they mostly ignored conflicting information about the\nabsence of a football team.\nBasehore and Anderson (2016) presented participants with pairs of fic-\ntitious cities (having pre-exposed them to one in each pair) and asked them\nto select the one with the larger population. This approach has the advan-\ntage that recognition was manipulated experimentally so its impact could\nbe assessed unconfounded by any other differences between the two cities.\nAs predicted, selections consistent with the recognition heuristic were made\non 74% of trials.\nKEY TERM\nRecognition heuristic\nUsing the knowledge\nthat only one out of two\nobjects is recognised as\nthe basis for making a\njudgement.\nCreated from usyd on 2022-02-17 03:28:25.",
    "636\nThinking and reasoning\nThe validity of the recognition heuristic depends on the precise task.\nFor example, suppose participants must decide which of two Italian cities\nhas the larger population or is higher above sea level. Unsurprisingly, the\nrecognition heuristic is more valid with the former decision and is also used\nmore often (Pohl et al., 2017). Most people are sensitive to validity: Pachur\net al. (2012b) obtained a correlation of +.64 between usage of the recogni-\ntion heuristic and its validity in a meta-analysis.\nControversially, it is assumed that use of the recognition heuristic\nmeans no other knowledge is taken into account. In contrast, it is assumed\nwithin the parallel constraint satisfaction theory (e.g., Glöckner et al.,\n2014) that all available information is integrated “automatically” in par-\nallel. Heck and Erdfelder (2017) compared predictions from the two the-\nories with respect to decisions with pairs of objects, one recognised and\nthe other not. According to the parallel constraint satisfaction theory, the\nmore information available, the faster the decision times. According to the\nrecognition heuristic account, in contrast, decision times should be slower\nwhen influenced by additional information.\nHeck and Erdfelder (2017) carried out a meta-analysis of decision\ntimes based on 19 data sets. Their findings were striking: 87.5% of partici-\npants performed as predicted by the parallel constraint satisfaction theory.\nIn contrast, only 11.3% conformed to predictions based on the recognition\nheuristic.\nMore evidence that people often utilise additional information, even\nwhen the recognition heuristic could be used on its own, was reported by\nRichter and Späth (2006). German students were asked to decide, which of\ntwo American cities was larger. The recognised city was identified as larger\nmore often when they were told it had an international airport than when\ntold it did not: 98% vs 82%, respectively.\nDummel et al. (2016) focused on participants making decisions con-\nsistent with the take-the-best strategy (i.e., based on the best cue). When\nthe next-best cue conflicted with the best cue, participants inhibited infor-\nmation about that cue and made slower decisions than when the two cues\ndid not conflict. Thus, the next-best cue was processed even though theo-\nretically it should not have been.\nThe take-the-best strategy is used less often than predicted theoreti-\ncally (Fiedler & von Sydow, 2015). For example, Newell et al. (2003) had\nparticipants choose between the shares of two fictitious companies. Only\n33% used all three components of the take-the-best strategy. This strategy\nwas least likely to be used when the cost of obtaining information was\nlow and cue validities were unknown. In those circumstances, participants\nused more complex processes than those associated with the take-the-best\nstrategy.\nGigerenzer’s theoretical approach is based on a toolbox metaphor:\ndifferent strategies (e.g., take-the-best) are chosen in different situations.\nSöllner and Bröder (2016) contrasted that approach with one based on an\nadjustable spanner metaphor: the same strategy is used in different situa-\ntions, but it is used flexibly. The amount of information participants chose\nto acquire before making a decision was better predicted by the adjustable\nspanner metaphor.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n637\nEvaluation\nIndividuals often use fast-and-frugal heuristics (e.g., the recognition\nheuristic; the take-the-best strategy). Such heuristics involve more pre-\ncisely spelled-out mechanisms than those emphasised by Kahneman and\nTversky (Fiedler & von Sydow, 2015). These heuristics can be surprisingly\neffective  despite their simplicity. Factors determining strategy selection\non judgement tasks have been identified. The fast-and-frugal approach\naccounts for much applied decision-making (discussed later in the chapter,\np. 655).\nWhat are the limitations of this theoretical approach? First, as Evans\nand Over (2010, p. 174) pointed out, “The suggestion that we are always\nbetter off following intuitions and ‘gut feelings’ is an extraordinary claim.\nWhy would we have the capacity for logical reasoning if it was of no\nvalue?”\nSecond, the assumption that the recognition heuristic is often used\nwith additional information being ignored is often wrong (e.g., Heck &\nErdfelder, 2017). Many findings are better explained by other theories (e.g.,\nparallel constraint satisfaction theory). It is also likely people consider why\nthey recognise an object before deciding whether to use the recognition\nheuristic (Newell, 2011).\nThird, the take-the-best strategy is used less often than suggested the-\noretically. Its use requires us to organise the various cues hierarchically\nbased on their validity, but often we lack adequate knowledge of cue valid-\nities. Lawrence et al. (2018) discovered that the precise cues used by indi-\nviduals depend on their accessibility in memory, a factor not emphasised\nby Gigerenzer. Another issue is that people often use information (e.g.,\nabout the next-best cue) that theoretically should be ignored with the take-\nthe-best strategy.\nFourth, the approach de-emphasises the importance of the decision.\nDecision-making may stop after finding a single discriminatory cue when\ndeciding which of two cities is larger. However, most women want to\nconsider all the relevant evidence before deciding which of two men to\nmarry!\nDual-process theory: Kahneman (2003)\nMost people rely heavily on heuristics when making judgements because\nthey can be used rapidly and effortlessly. However, individuals sometimes\nuse more complex cognitive processes. As a result, some theorists (e.g., De\nNeys, 2012; Kahneman, 2003) have proposed dual-process models. Similar\nmodels have also been applied to performance on reasoning problems (see\nChapter 14).\nAccording to Kahneman (2003), probability judgments depend on pro-\ncessing within two systems:\nSystem 1: “The operations of System 1 are typically fast, automatic,\neffortless, implicit (not open to introspection) and often emotionally\ncharged; they are also difficult to control or modify” (Kahneman,\n2003, p. 698).\nCreated from usyd on 2022-02-17 03:28:25.",
    "638\nThinking and reasoning\nSystem 2: “The operations of System 2 are slower, serial [one at a time],\neffortful, more likely to be consciously monitored and deliberately\ncontrolled; they are relatively flexible and potentially rule- governed”\n(Kahneman, 2003, p. 698).\nHow are these two systems related? System 1 rapidly generates intuitive\nanswers to judgement problems (e.g., those based on the representativeness\nheuristic). These answers are then monitored or evaluated by System 2,\nwhich may correct them. Thus, judgement involves serial processing start-\ning with System 1 and sometimes followed by System 2.\nMorewedge and Kahneman (2010) subsequently modified the above\naspect of the theory, arguing that System 1 and System 2 processes “can\noperate in parallel” (p. 439). They also argued that System 1 processes\ncause some information to become strongly activated. This information\nis then often overweighed and leads to biased judgements. Finally, they\nassumed that System 1 processing often produces errors which may then\nbe corrected by System 2 processing.\nFindings\nDe Neys (2006) obtained support for Kahneman’s theory using the Linda\nproblem (discussed earlier, pp. 624–625). Those producing the correct\nanswer (and so presumably using System 2) took almost 40% longer than\nthose apparently using only System 1. This is consistent with the assumption\nit takes longer to use System 2. There was a reduction in correct solutions\nfrom 17% to 9.5% when participants performed a cognitively demanding\ntask at the same time. This is as predicted given that System 2 requires cog-\nnitively demanding processes.\nDe Neys et al. (2011) found on standard base-rate problems that incor-\nrect answers neglecting base-rate information were obtained on 80% of\ntrials. This suggests participants often totally ignored base-rate informa-\ntion. However, they were less confident about their responses when they\nproduced incorrect answers than when producing correct ones suggesting\nthere is some processing of base-rate information even when it does not\ninfluence people’s judgements.\nEarlier we discussed the lawyer-engineer problem (p. 624; Kahneman &\nTversky, 1973) on which base-rate information is often ignored. Pennycook\nand Thompson (2012) used similar problems such as the following:\nIn a study 1,000 people were tested. Among the participants there were\n995 nurses and 5 doctors. Paul is a randomly chosen participant of\nthis study. Paul is 34 years old. He lives in a beautiful home in a posh\nsuburb. He is well spoken and very interested in politics. He invests a\nlot of time in his career. What is the probability that Paul is a nurse?\n(p. 528)\nThere is a conflict between the base-rate information (suggesting Paul\nis a nurse) and the personality description (suggesting he is a doctor). Use\nof System 1 processing might lead participants to focus on the personal-\nity description using the representativeness heuristic and decide Paul was\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n639\nprobably a doctor. The participants answered each problem twice: initially\nwith the first answer coming to mind and then with a more deliberate\nanswer.\nOn Kahneman’s theory, people must use System 2 processing for their\nanswers to reflect base-rate information. As a result, initial answers should\nrarely reflect base-rate information but instead should be based on the\nrepre sentativeness heuristic. In addition, base-rate information should be\nused much more often in deliberate than in initial answers. Neither pre-\ndiction was supported. Half the initial answers were based primarily on\nbase-rate information. Of the participants changing their responses, 30%\ntook more account of base-rate information in their deliberate answer.\nHowever, nearly as many (23%) took less account of base-rate information\nin their deliberate answer which is inconsistent with Kahneman’s theory.\nNewman et al. (2017) obtained similar findings when instructing par-\nticipants to give an immediate answer (“Please provide us with the FIRST\nANSWER that comes to mind”) and a more deliberate one. Base-rate\ninformation often influenced their immediate answer. Newman et al. con-\ncluded the distinction between System 1 and System 2 responses should be\nabandoned. Perhaps responses differ primarily with respect to complexity:\n“more complex responses . . . are more time-consuming and challenging to\nproduce” (pp. 1165–1166).\nChun and Kruglanski (2006) also obtained findings indicating the\nimportance of complexity. They used various versions of the lawyer-\nengineer problem in which base-rate and personality information was pre-\nsented. Some information was easy to process because it was presented\nbriefly whereas the remainder was complex (presented at length).\nChun and Kruglanski (2006) assessed the effect of cognitive load.\nAccording to dual-process theory, cognitive load should reduce System\n2 processing and use of base-rate information. In fact, cognitive load led\nto increased use of easily processed information regardless of whether it\nreferred to base rate or personality.\nEvaluation\nThere is support for the notion there are two different processing systems,\nwith System 2 being slower and more effortful than System 1 processing.\nSimilar dual-process theories have proved reasonably successful in account-\ning for reasoning (Chapter 14).\nWhat are the limitations of Kahneman’s (2003) theory? First, and most\nimportantly, there is “the alignment problem” (Melnikoff & Bargh, 2018,\np. 281). In essence, it is assumed System 1 processes are unintentional,\nuncontrollable, unconscious and efficient (i.e., they use minimal processing\ncapacity) whereas System 2 processes are intentional, controllable, con-\nscious and inefficient. These assumptions have rarely been tested. However,\nthe available evidence indicates strongly that these attributes are much less\nhighly correlated than assumed theoretically (Melnikoff & Bargh). As a\nconsequence, it is not possible to define System 1 processes with precision.\nSecond, and related to the first point, the assumption that rapid judge-\nment responses reflect the use of System 1 whereas slow responses reflect\nthe use of System 2 is also oversimplified. In fact, rapid responses often\nCreated from usyd on 2022-02-17 03:28:25.",
    "640\nThinking and reasoning\nreflect System 2 processing and slow responses often reflect System 1 think-\ning (Newman et al., 2017; Pennycook & Thompson, 2012).\nThird, there is relatively little support for Kahneman’s (2003) origi-\nnal assumption that System 1 and System 2 processes occur serially. How\ncan we detect rapidly that responses produced by System 1 are incor-\nrect if System 2 has not been used up to that point? More generally, the\ntheory fails to provide an explicit account of the monitoring determining\nwhether we decide to use System 2 processes as well as System 1 processes.\nHowever, as noted earlier, Morewedge and Kahneman (2010) argued that\nSystem 1 and 2 processes could occur in parallel.\nFourth, Morewedge and Kahneman (2010) committed the “good/\nbad fallacy” (Melnikoff & Bargh, 2018, p. 282). This fallacy involves the\nassumptions that System 1 processing is often “bad” and error-prone\nwhereas System 2 processing is “good” and leads to rational judgements.\nMuch of the evidence discussed above illustrates the oversimplifications\ninvolved in these assumptions.\nThe way forward?\nProcessing on judgement tasks is much more flexible than implied by\nKahneman’s (2003) dual-process theory. It is also clear different processes\noften operate in parallel rather than serially as assumed theoretically. De\nNeys (2012, 2014) proposed a logical intuition model (see Figure 14.4 on\np. 685) to resolve some issues. He argued there is rapid intuitive heuristic\nprocessing (System 1) and intuitive logical processing (e.g., of base-rate\ninformation) in parallel. This initial processing is sometimes followed by\ndeliberate System 2 processing if the two types of intuitive processing gener-\nate different responses.\nSupport for the logical intuition model was reported by Bago et al.\n(2018). They presented base-rate judgement problems involving conflict\nbetween information in the problem and base-rate information. Event-\nrelated potentials (ERPs; see Glossary) revealed sensitivity to conflict\nwithin approximately 200 ms even on trials where participants produced\nthe wrong answer. It is improbable that System 2 processes occurred so\nrapidly, and so this conflict sensitivity was probably due to System 1 pro-\ncesses operating in parallel.\nThis model has several advantages over Kahneman’s theory. First,\nheuristic and base-rate information can both be accessed rapidly through\nintuitive processing. This is consistent with the findings of Pennycook and\nThompson (2012) and Newman et al. (2017). Second, the finding that\neasily processed base-rate information is often used under high cognitive\nload (Chun & Kruglanski, 2006) is more consistent with De Neys’ model.\nThird, the model clarifies how conflicts between heuristic and base-rate\ninformation are rapidly detected (e.g., De Neys et al., 2011) and trigger\nSystem 2 processes.\nDECISION-MAKING UNDER RISK\nLife is full of decisions. Would I prefer to date Dick or Harry? Who will\nI share an apartment with next year? At one time, it was assumed people\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n641\nthink rationally and so generally select the best option. This assumption\nwas built into normative theories, which focused more on how people\nshould make decisions rather than their actual decisions.\nHere we will consider von Neumann and Morgenstern’s (1944) expressed\nutility theory. They argued we try to maximise utility (the subjective value\nwe attach to an outcome). When we choose between simple options, we\nassess the expected utility or value of each one via the following formula:\nExpected utility =  (probability of a given outcome) × (utility of the\noutcome).\nvon Neumann and Morgenstern (1944) treated decisions as if they\nwere gambles. This approach was subsequently coupled with Savage’s\n(1954) mathematical approach based on using information from people’s\npreferences to combine subjective utilities and subjective probabilities. This\nled to the development of subjective expected utility theory.\nIn the real world, various factors are generally associated with each\noption. For example, one holiday option may be preferable to another\nbecause it is in a more interesting area with better weather. However, the\nfirst holiday is more expensive, and more time would be spent travelling.\nIn such circumstances, people allegedly calculate the expected utility or\ndisutility (cost) of each factor to assess the overall expected value or utility\nof each option. In fact, our choices are often decided by factors other than\nsimply utility.\nDecisions differ enormously in complexity (e.g., making life choices vs\nmeal choices). We start with relatively simple decision-making. The most\ninfluential such theory (prospect theory) will be discussed, followed by the-\nories focusing more on emotional and/or social factors. After that, we con-\nsider more complex decision-making.\nLosses and gains\nIt is reasonable to assume we make decisions to maximise the chances of\nmaking a gain and minimise the chances of making a loss. Suppose someone\noffered you $200 if a tossed coin came up heads but a loss of $100 if it came\nup tails. You would jump at the chance (wouldn’t you?) because the bet\nprovides an average expected gain of $50 per throw.\nHere are two more decisions. Would you prefer a sure gain of $800\nor an 85% chance of gaining $1,000 and a 15% probability of gaining\nnothing? Since the expected value of the latter decision is greater than that\nof the former ($850 vs $800, respectively), you might well choose the latter\noption. Finally, would you prefer a sure loss of $800 or an 85% probability\nof losing $1,000 with a 15% probability of avoiding any loss? The average\nexpected loss is $800 for the former choice and $850 for the latter one, so\nyou go with the former choice, do you not?\nThe first problem was from Tversky and Shafir (1992) and the other\ntwo from Kahneman and Tversky (1984). In every case, most participants\nfailed to make what appears to be the best choice. Two-thirds refused to\nbet on the coin toss and a majority preferred the choices with the smaller\nexpected gain and the larger expected loss! Below we discuss attempts to\nunderstand such seemingly irrational decision-making.\nCreated from usyd on 2022-02-17 03:28:25.",
    "642\nThinking and reasoning\nProspect theory\nKahneman and Tversky (1979, 1984) developed prospect theory to explain\napparently paradoxical findings such as those above. Here are two key\nassumptions:\n(1) Individuals identify a reference point representing their present state.\n(2) Individuals are much more sensitive to potential losses than potential\ngains: loss aversion. This explains why most people are unwilling to\naccept a 50:50 bet unless the amount they might win is about twice\nthe amount they might lose (Kahneman, 2003).\nThe above assumptions are represented in Figure 13.4. The reference point\nis where the line labelled losses and gains intersects the line labelled value.\nThe positive value associated with gains increases relatively slowly as gains\nbecome greater. Thus, winning £2,000 (2,200 euros) instead of £1,000 (1,100\neuros) does not double the subjective value of the money won. In contrast,\nthe negative value associated with losses increases relatively rapidly as\nlosses become greater.\nHow does prospect theory account for the findings discussed earlier?\nIf people are much more sensitive to losses than gains, they should be\nunwilling to accept bets involving potential losses even when the potential\ngains outweigh the potential losses. They should also prefer a sure gain to\na risky (but potentially greater) gain; this is risk aversion. However, the\ntheory does not predict people will always avoid risky decisions. If offered\na chance to avoid a loss, most people will take it because they are so con-\ncerned to avoid losses: this is risk seeking.\nTversky and Kahneman (1992) put forward cumulative prospect\ntheory, which is more comprehensive than prospect theory. However, it\n“retains the major features of . . . prospect\ntheory” (p. 317). Accordingly, we use the\nterm “prospect theory” to refer to both\nversions.\nIt is assumed theoretically that people\noverweigh low-probability events: rare events\nreceive more weight than they should given\ntheir actual probability of occurrence. This\nhelps to explain why people bet on the\nNational Lottery where the chances of\nwinning the jackpot are 1 in 14 million.\nFindings: framing effect\nMuch research has considered the framing\neffect in which decisions are influenced\nby irrelevant aspects of the situation.\nTversky and Kahneman (1981) used the\nAsian disease problem to study this effect.\nAll participants were given the following\ninformation:\nKEY TERMS\nLoss aversion\nThe finding that losses\nhave a greater subjective\nimpact on individuals\nthan gains of the same\nmagnitude.\nRisk aversion\nA preference for certain\ngains over potentially\nlarger (but less certain)\ngains.\nFraming effect\nThe finding that decisions\ncan be influenced by\nsituational aspects\n(e.g., problem wording)\nirrelevant to optimal\ndecision-making.\nFigure 13.4\nA hypothetical value function.\nFrom Kahneman and Tversky (1984). © American Psychological\nAssociation.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n643\nImagine that the US is preparing for the outbreak of an unusual\nAsian disease, which is expected to kill 600 people. Two alternative\nprogrammes to combat the disease have been proposed. Assume that\nthe exact scientific estimate of the consequences of the program are as\nfollows . . .\nIn the gain-frame condition, participants chose between the following\nprospects:\n●\nIf programme A is adopted, 200 people will be saved.\n●\nIf programme B is adopted, there is a 1 in 3 probability 600 people will\nbe saved, and a 2 in 3 probability that no people will be saved.\nIn this condition, 72% chose the certain gain (programme A) even though\nthe two programmes (if implemented several times) would on average both\nlead to the saving of 200 lives.\nIn the loss-frame condition, participants chose between the following\nprospects:\n●\nIf programme C is adopted, 400 people will die.\n●\nIf programme D is adopted, there is a 1 in 3 probability that nobody\nwill die, and 2 in 3 probability that 600 people will die.\nIn this condition, 78% of participants chose programme B. This was the\ncase even though the two programmes would have the same effect if imple-\nmented several times.\nSteiger and Kühberger (2018) carried out a meta-analysis based on 81\nexperimental findings. There was much variation across studies, but the\noverall framing effect was moderately strong.\nAccording to prospect theory, the framing effect occurs because\npeople focus on potential gains in the gain-frame condition whereas they\nare motivated by loss aversion in the loss-frame condition. Mandel (2014)\nclaimed the framing effect is trivial because it depends on ambiguity about\nunstated information (e.g., programme A is interpreted as meaning at least\n200 people would be saved). However, Chick et al. (2016) still obtained a\nrobust framing effect when all ambiguities were eliminated.\nWang (1996) argued performance on the Asian disease problem is\ninfluenced by social and moral factors de-emphasised by prospect theory.\nParticipants chose between definite survival of two-thirds of the patients\n(deterministic option) versus a 1/3 probability of all patients surviving and\na 2/3 probability of none surviving (probabilistic option).\nThe deterministic option leads, on average, to the survival of twice as\nmany patients. However, the probabilistic option seems fairer because all\npatients share the same fate. Participants strongly preferred the determin-\nistic option when the problem related to six unknown patients. However,\nthey preferred the probabilistic option when it related to six close rela-\ntives because participants were especially concerned about fairness in that\ncondition.\nCreated from usyd on 2022-02-17 03:28:25.",
    "644\nThinking and reasoning\nFindings: sunk-cost effect\nA phenomenon resembling loss aversion is the sunk-cost effect: “the\nbias . . . to persist in a course of action because of the prior investments in\nthat option, and not because of the future consequences of pursuing that\noption” (Magalhães & White, 2016, p. 339). This effect involves “throw-\ning good money after bad”. The sunk-cost effect is found in long-term\nrelationships – the more money and effort individuals have invested in an\nunhappy relationship, the more likely they are to stay (Rego et al., 2018).\nIn one study, participants were told two people had paid a $100\nnon-refundable deposit for a weekend at a resort (Dawes, 1988). On the\nway there, they both became slightly unwell and felt they would probably\nhave a more pleasurable time at home. Many participants argued the two\npeople should drive on to avoid wasting the $100 – the sunk-cost effect.\nThis decision involves extra costs (money spent at the resort) and is less\npreferred than being at home!\nOne explanation for the sunk-cost effect is that many people would\nfind it embarrassing if others knew they had wasted money or other\nresources on an abandoned project (see study by Simonson and Staw,\n1992, discussed later, p. 653). Domeier et al. (2018) identified another\nreason. Individuals chose whether to continue with an option in which they\nhad already invested time and money (sunk-cost option) or to switch to an\nalternative option having a higher probability of being successful. Those\nchoosing the sunk-cost option did so because it satisfied their need to feel\ncompetent more than the alternative option (see Figure 13.5).\nFindings: Loss aversion\nLoss aversion (greater sensitivity to potential losses than potential gains)\nis of central importance within prospect theory. Much research involv-\ning large amounts of money supports the notion of loss aversion (see also\nresearch on experts in the Box below, pp. 645–646). However, this is much\nless the case with small amounts (Yechiam, 2018). For example, consider\nthe following choice:\n(1) 50% to win £1 (1.15 euro); 50% to lose £1 (1.15 euro)\n(2) 50% to win £5 (5.75 euros); 50% to lose (5.75 euros)\nKEY TERM\nSunk-cost effect\nInvesting additional\nresources to justify a\nprevious commitment\nthat has so far proved\nunsuccessful.\n5\n4.5\n4\n3.5\n3\n2.5\n2\n1.5\n1\nSCO\nChoice of option\nCompetence\nsatisfaction\nAO\nSCO-selectors\nAO-selectors\nFigure 13.5\nRatings of competence\nsatisfaction for the sunk-\ncost option (SCO) and the\nalternative option (AO)\nfor those selecting the\nsunk-cost option and those\nselecting the alternative\noption.\nFrom Domeier et al. (2018).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n645\nAccording to prospect theory, people are loss averse and so should choose\n(1) because it reduces potential losses. In fact, the typical finding is loss\nneutrality – individuals do not favour one option over the other unless the\nstakes are high (Yechiam & Hochman, 2013). This consistent finding is con-\ntrary to prospect theory.\nPachur et al. (2018) argued that attentional processes influence loss\naversion. More specifically, individuals who attend more to losses (relative\nto gains) should exhibit greater loss aversion than those attending more to\ngains. Pachur et al. manipulated participants’ attention to losses and gains\nand obtained their predicted findings. In similar fashion, the loss neutrality\nwith small stakes found by Yechiam and Hochman (2013) depends in part\nbecause small potential losses do not attract much attention.\nIN THE REAL WORLD: LOSS AVERSION AND RISK AVERSION\nIN EXPERTS\nMost research on prospect theory is laboratory-based, raising doubts about its real-world appli-\ncability. First, individuals taking risks to avoid losses in the laboratory using hypothetical money\nmay not do so in everyday life. Second, most participants performing laboratory tasks have limited\nrelevant experience. In contrast, experts in the real world might know how to prevent biases (e.g.,\nloss aversion) from influencing their behaviour and reducing their income.\nFigure 13.6\nRisk aversion for gains\nand risk seeking for\nlosses on a money-\nbased task by financial\nprofessionals and\nstudents.\nFrom Abdellaoui et\nal. (2013). With kind\npermission from Springer\nScience+Business Media.\nCreated from usyd on 2022-02-17 03:28:25.",
    "646\nThinking and reasoning\nFor professional golfers, a birdie (one under par) on a hole is a gain whereas a bogey (one over\npar) is a loss. Loss aversion would lead them to be more cautious when putting for a birdie than\nfor par. In the latter case, failure to hole the putt would produce a bogey and thus a loss. Pope\nand Schweitzer (2011) studied 2½ million putts by professional golfers. Par putts were less likely\nthan same-length birdie putts to stop short of the hole (indicative of loss aversion). Loss aversion\nwas found in 94% of golfers (including Tiger Woods).\nMcFall (2016) reported additional evidence of loss aversion among professional golfers playing\npar five holes. Golfers penalised for hitting their tee shot out of bounds adopted a riskier approach\nto playing the rest of the hole than those not penalised. This attempt to avoid loss (i.e., a bogey\nor worse) was ineffective because it impaired their performance.\nEil and Lien (2014) studied very experienced poker players. In spite of their expertise, they typ-\nically played more aggressively (i.e., betting and raising more often) when losing (indicating loss\naversion). In addition, as predicted by prospect theory, they were risk averse when winning.\nAbdellaoui et al. (2013) studied financial professionals handling an average of £200 million (230\nmillion euros) each. As prospect theory predicts, they were risk averse for gains and risk seeking for\nlosses on a money-based task. Their risk aversion for gains was comparable to students but they\nwere less loss averse than students (see Figure 13.6).\nIn sum, experts in several different areas show clear evidence of loss aversion when losing. They\nalso exhibit risk aversion when winning. Thus, prospect theory is applicable to the real world.\nFindings: description-experience gap\nMost research on prospect theory has used a description-based approach\nwhere outcomes and their associated probabilities are presented explicitly.\nThere is also an experience-based approach where information about out-\ncomes and associated outcomes is acquired through sampling. Wulff et al.\n(2018) carried out a meta-analysis of relevant research. Overall, there was a\nrobust description-experience gap: individuals are more likely to overweigh\nthe probability of rare events when exposed to descriptions than when expe-\nriencing events. Since prospect theory predicts that rare events should be\noverweighed, the description-based findings are apparently more consistent\nwith the theory than the experience-based findings.\nHow can we explain the description-experience gap? The single most\nimportant factor is a sampling error when the experience-based approach\nis used because participants making decisions from experience often fail to\nencounter rare events. However, Wulff et al. (2018) found there was still a\ndescription-experience gap (but much smaller) when experienced frequen-\ncies of events closely resembled actual probabilities.\nGlöckner et al. (2016) pointed out that nearly all studies finding a\ndescription-experience gap had compared choices of a certain option\nagainst a risky option. This could partially explain the gap because cer-\ntainty of outcome cannot be achieved in experience. When Glöckner et al.\navoided using certain options, they consistently obtained a reversal of the\ndescription-experience gap (i.e., a reverse description-experience gap, or a\ngreater overweighting of rare events in decisions made from experience than\nfrom descriptions). Thus, the relationship between experience-based and\ndescription-based decision-making is more complex than usually assumed.\nIn sum, description-experience gaps are of importance for various\nreasons. First, most research has involved description-based decisions\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n647\nIN THE REAL WORLD: NIK\nWALLENDA’S DECISION-MAKING\nIndividuals differ enormously in their willingness\nto take risky decisions. Consider Nik Wallenda,\nthe American tightrope walker known as “the\nKing of the Wire” (Newell, 2015). On 23 June\n2013, he walked along a wire suspended 1,500\nfeet above the Grand Canyon without a safety\nharness or safety net. The conditions were\nwindy, and at one point Wallenda said “Winds\nare way worse than I expected”. However, he\nsuccessfully reached the other side.\nMost people would never consider making\nNik Wallenda’s life-threatening decision. How\ncan we explain his decision-making? He focused\nvery much on the gains: “I do this because\nI love what I do . . . Walking the wire to me\nis life.” Most importantly, his strong Christian faith allowed him to minimise potential losses:\n“I  know  where I’m going to go when I die . . . I’m not scared of dying.” His friend Michael\nMascitto said that Wallenda had realised that “God is giving him a platform to use his abilities\nfor God’s glory”.\nNik Wallenda at the Grand Canyon.\nTim Boyles/Getty images.\nwhereas experience-based decisions are common in everyday life. Second,\nprospect theory cannot provide a coherent account of the different\ndescription-experience gaps reported in the literature. Third, descriptions\nhave been used to test most aspects of prospect theory. We need to assess\nexperience-based decisions much more often to test the generality of find-\nings obtained based solely on descriptions.\nFindings: individual differences\nProspect theory de-emphasises individual differences (see discussion above\nof Nik Wallenda). Consider research on the show Deal or No Deal, a game\nof chance on which contestants can win or lose large sums of money. As\npredicted by prospect theory, most participants are risk averse, especially\nwhen the stakes are high (Brooks et al., 2009). However, there are large\nindividual differences in willingness to take risks even with very high\nstakes.\nNarcissism, a personality dimension involving excessive self-regard,\nwas studied by Foster et al. (2011). Individuals high in narcissism engaged\nin riskier stock-market investing because they have high sensitivity to\nreward but low sensitivity to punishment.\nAccording to prospect theory, people should be risk averse for gains but\nrisk seeking to avoid losses. Contrary evidence was reported by Gigerenzer\nand Garcia-Retamero (2017). Only 25% of participants showed the\nexpected pattern whereas 44% were consistently risk averse or risk seeking\nfor both gains and losses (21% risk averse and 23% risk seeking). How can\nCreated from usyd on 2022-02-17 03:28:25.",
    "648\nThinking and reasoning\nwe explain these findings? Individuals especially motivated to avoid regret\nare consistently risk averse whereas those attaching less concern to possible\nregret are more likely to be consistently risk seeking.\nEvaluation\nProspect theory represents a substantial advance over previous approaches\n(e.g., subjective expected utility theory). The value function (especially the\nnotion that losses loom larger than gains) accounts for many phenomena\n(e.g., loss aversion; sunk-cost effect; framing effect). The theory has wide\napplicability as has been shown by the discovery that professional golfers,\nexperienced poker players and financiers all show loss aversion. More\ngenerally, prospect theory was crucial in the development of behavioural\neconomics – using a knowledge of psychological processes to understand\neconomic decision-making.\nWhat are prospect theory’s limitations? First, “[It] lacks any unifying\nprinciple that might explain why such preferences [e.g., loss aversion] exist”\n(Houston et al., 2014, p. 502). Part of the answer may lie in our evolu-\ntionary history (McDermott et al., 2008). For example, engaging in risky\nbehaviour may be optimal for someone starving, whereas it makes evolu-\ntionary sense to minimise risk when resources are abundant. However, this\napproach needs to consider whether individuals’ ability to predict likely\nfuture conditions influences their tendency to engage in risky behaviour\n(Mallpress et al., 2015).\nSecond, the reference point is a cornerstone of prospect theory (see\nFigure 13.4) because it determines whether any given outcome is desir able\nor undesirable. Terzi et al. (2016) provided participants with several pos-\nsible reference points (e.g., the average payoff received by other partici-\npants; the experimenter’s prediction as to the individual participant’s likely\npayoff). Participants chose different reference points. Lack of clarity about\nparticipants’ reference points makes it hard to test theoretical predictions.\nThird, prospect theory has little to say about the cognitive processes\nunderlying the various decision-making biases. However, Pachur et al.\n(2018) found that variations in loss aversion depended in part on partici-\npants’ allocation of attention, showing the value of considering cognitive\nprocesses.\nFourth, much research is artificial because participants receive\nsummary descriptions of the relevant probabilities and outcomes rather\nthan experiencing them directly as in real life. There is sometimes less\nsupport for prospect theory with more naturalistic conditions (e.g., Wulff\net al., 2018).\nFifth, loss aversion occurs less often than predicted by the theory\n(Yechiam, 2018). This is especially the case when decision-making involves\nrelatively small amounts of money.\nSixth, individual differences in the willingness to make risky decisions\nare de-emphasised. For example, the theory does not predict that many\npeople are risk averse (or risk seeking) for both gains and losses.\nSeventh, prospect theory also de-emphasises the impact of social and\nemotional factors (Newell, 2015; see below, pp. 649–654). Of particular\nimportance, prospect theory has poor predictive power when the potential\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n649\nlosses associated with a decision are of great personal relevance (e.g.,\nmedical side effects; Suter et al., 2016 (discussed below)).\nDECISION-MAKING: EMOTIONAL AND SOCIAL\nFACTORS\nEmotional factors are important in decision-making because winning\nand losing both have emotional consequences. The underlying processes\ninvolved are discussed here.\nSocial factors are also important. Laboratory decisions are rarely\ntaken in a social context. However, we often need to justify our decisions\nto others in our everyday lives. Consider a contestant on Who Wants to be\na Millionaire? deciding whether to attempt a question when there are two\npossible answers left. If they answer correctly, they gain £75,000 (82,000\neuros), but they lose £25,000 (27,300 euros) if they are wrong. In strict\nfinancial terms, the balance of advantage lies with answering the question.\nSuppose, however, the contestant’s family is poor, and their lives would\nbe transformed by taking home the money already won. In that case, the\nsocial context strongly indicates the contestant should take the money.\nSocial factors influencing decision-making are discussed later.\nEmotional factors\nThe effects of emotion on decision-making are complex. Giorgetta et al.\n(2013) studied gambling with the choices made by the participant or a com-\nputer. When participants lost, they experienced regret if they had made the\ndecision, but disappointment if the computer had. Regret was followed by\nriskier choices than disappointment. Wins were experienced as rejoicing\n(personal choices) or elation (computer choices), with elation being fol-\nlowed by riskier choices. Overall, the findings were more consistent with\nprospect theory when participants had a sense of personal agency (i.e.,\nregret and rejoicing conditions).\nAccording to Kahneman (2011, p. 287), “Humans described by pros-\npect theory are guided by the immediate emotional impact of gains and\nlosses.” The details of what is involved are unclear in prospect theory.\nHowever, here are two plausible predictions stemming from prospect\ntheory (Charpentier et al., 2016):\n(1) The theory assumes there is diminishing sensitivity to changes in\nvalue as gains and losses increase (see Figure 13.4). It might be pre-\ndicted the same diminishing sensitivity would be found for feelings\nassociated with gains and losses.\n(2) The theory assumes the subjective value of a given loss is greater than\nthe impact of an equivalent gain (see Figure 13.4) and this produces\nloss aversion. We might predict feelings would be influenced more by\na given loss than an equivalent gain.\nCharpentier et al. (2016) tested the above predictions. They obtained strong\nsupport for the first prediction with both expected (anticipated) and experi-\nenced feelings associated with gains and losses. There was also evidence for\nCreated from usyd on 2022-02-17 03:28:25.",
    "650\nThinking and reasoning\nimpact bias – the impact of given losses or gains was greater on expected\nfeelings than on experienced feelings.\nCharpentier et al. (2016, p. 768) surprisingly failed to support the\nsecond prediction: “When feelings associated with losses and gains are\nevaluated separately . . . losses are not experienced more intensely than\ngains.” How, then, can we explain loss aversion? Individuals often make\nloss-averse decisions because they attend more to (and weigh more heavily)\nthe negative feelings anticipated from loss than the positive feelings antici-\npated from gain. Note that we saw the impact of attentional processes on\nloss aversion earlier in the chapter (Pachur et al., 2018).\nSuter et al. (2016) distinguished between decision-making when the\nnegative prospects are affect-poor (e.g., monetary losses) and when they\nare affect-rich (e.g., medical side effects). They investigated whether pros-\npect theory could explain findings from both affect-poor and affect-rich\nproblems. With affect-rich problems, participants imagined they suffered\nfrom an unspecified illness requiring medication. They chose between two\nmedications each producing a given side effect with some probability (e.g.,\nmedication A: insomnia with a probability of 15%; medication B: fever\nwith a probability of 10%). With affect-poor problems, participants chose\nbetween two monetary lotteries each leading to a given amount of loss\nwith some probability.\nThe findings are shown in Figure 13.7. First, the decisions made by\nover 90% of participants with affect-poor problems conformed to expec-\ntations from prospect theory, whereas the comparable figure was much\nless with affect-rich problems. Second, many more participants used the\nminimax rule (ignoring probabilities), which is inconsistent with prospect\ntheory, and focusing only on outcomes, i.e., unpleasantness of the possible\nside effects) with affect-rich problems. In sum, prospect theory is much less\napplicable to affect-rich choices than affect-poor ones.\nKEY TERM\nImpact bias\nOverestimation of the\nintensity and duration\nof negative emotional\nreactions to losses and\npositive emotional\nreactions to gains.\n(a) Afect–poor\n(b)\nAfect–poor\nAfect–rich\nwithout WTP\nAfect–rich\nwith WTP\n5%\n95%\n5%\n2.5%\n32.5%\n45%\n22.5%\n92.5%\n29%\n40%\n31%\nCPT\nMinimax\nUnclassifed\nFigure 13.7\nPercentages of participants\nadhering to cumulative\nprospect theory (CPT), the\nminimax rule, or unclassified\nwith affect-poor and\naffect-rich problems (a) with\nor (b) without numerical\ninformation concerning\nwillingness to pay (WTP) for\nmedication.\nFrom Suter et al. (2016).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n651\nOmission bias and status quo bias\nThere is other evidence that emotional factors influence decision-making.\nOne example is omission bias, a preference for inaction to action with risky\ndecision-making. For example, British parents were asked questions about\nhaving their children inoculated against various diseases (Brown et al.,\n2010). They were willing to accept a greater risk of their children having\na disease than of their children suffering adverse reactions to vaccination.\nOmission bias with respect to having children vaccinated occurs because\nparents believe this would increase their anticipated responsibility and\nregret (Wroe et al., 2005).\nEven experts exhibit omission bias. Pulmonologists (experts in treat-\ning lung disease) received scenarios involving an evaluation of pulmonary\nembolism and treatment of septic shock (Aberegg et al., 2005). They were\nsignificantly less likely to select the best management strategy when they\nhad the option of doing nothing.\nFeldman and Albarracin (2017) found social norms (accepted standards\nof behaviour) influenced regret following action and inaction. Perceived\nregret was greater for action than inaction when social norms favoured\ninaction. However, this effect was much reduced (or even reversed) when\nsocial norms favoured action.\nBrewer et al. (2016) conducted a meta-analytic study focusing on\naction vs inaction with respect to health behaviour and anticipated regret.\nAnticipated regret strongly predicted whether individuals engaged in action\nor inaction. Thus, action regret was associated with inaction and inaction\nregret was associated with action. Overall, anticipated regret predicted\nindividuals’ behaviour more strongly than did other negative emotions\n(e.g., worry).\nAnother example of decision avoidance caused by emotional factors is\nstatus quo bias – individuals often prefer to accept the status quo (current\nstate) rather than change their decision. For example, many individuals\nmaintain the same allocation of retirement funds year after year even when\nno costs would be incurred by changing (Samuelson & Zeckhauser, 1988).\nNicolle et al. (2011) found mistaken rejection of the status quo trig-\ngered stronger feelings of regret than mistaken acceptance of the status\nquo. In addition, mistaken rejection of the status quo was associated with\ngreater activation in brain regions (medial prefrontal cortex; insula) asso-\nciated with regret.\nAnderson (2003) proposed a rational-emotional model to account for\ndecision avoidance. Within the model, the omission and status quo biases\nwere both explained in terms of regret and fear. We have seen regret is\nimportant. Fear is relevant because it reduces when someone decides to\ndefer making a decision.\nAnderson’s (2003) model cannot explain why individuals often experi-\nence more regret for inaction than errors of action when asked a long time\nafterwards (Leach & Plaks, 2009). It also fails to explain why status quo\nbias is more common when decision-makers have numerous options rather\nthan just a few (Dean et al., 2017). Finally, status quo bias is found even\nwith trivial decisions (e.g., deciding whether to switch television channels:\nEsteves-Sorenson & Perrett, 2012). It is hard to believe regret or fear lie\nKEY TERMS\nOmission bias\nA biased preference for\nrisking harm through\ninaction compared to\nrisking harm through\naction.\nStatus quo bias\nA preference for\nmaintaining the status\nquo (present state) rather\nthan acting to change\ntheir decision.\nCreated from usyd on 2022-02-17 03:28:25.",
    "652\nThinking and reasoning\nbehind people’s decision to remain on the same television channel rather\nthan switching!\nBrain mechanisms\nWe can obtain additional insights into the role of emotion in risky deci-\nsion-making by studying patients with damage to brain areas associated\nwith emotion. Shiv et al. (2005) used a gambling task where the most\nprofitable strategy was to gamble on every round. Patients with damage\nto emotion regions (amygdala, ventromedial prefrontal cortex and insula)\ngambled significantly more often than other brain-damaged patients and\nhealthy controls, and thus gained the most money. Why was this? The other\ntwo groups were much less likely to gamble immediately following a loss. In\ncontrast, the patients with damage to emotion areas were totally unaffected\nby the outcome of the previous round.\nThe above findings do not mean emotional involvement necessarily\nimpairs decision-making. Seo and Barrett (2007) studied decision-making\nperformance on a stock-investment simulation among experienced stock\ninvestors. Those reporting more intense feelings performed better than\nthose with less intense feelings because they had a good understanding of\ntheir emotions.\nKandasamy et al. (2016) studied individuals’ sensitivity to their own\nbodily stimuli (interoception). Financial traders working on a London\ntrading floor showed superior interoceptive ability by perceiving their own\nheartbeats more accurately than controls. Interestingly, traders with the\nhighest interoceptive ability generated greater profits and survived longer\nin the financial markets. These findings suggest “gut feeling” is important\nfor successful risk taking.\nResearch has clarified the roles of specific brain areas in risky deci-\nsion-making. De Martino et al. (2010) studied loss aversion in two women\n(SP and AP) with severe damage to the amygdala (see Glossary; and\nChapter 15). Neither had loss aversion, suggesting the amygdala acts as\na “cautionary brake”. Sokol-Hessner et al. (2013) studied risky financial\ndecision-making. Participants instructed to engage in emotion regula-\ntion (designed to reduce their emotional involvement in the task) showed\nreduced loss aversion. Other findings suggested this happened because\nemotion regulation decreased amygdala responses to losses.\nPatients with damage to the ventromedial prefrontal cortex display\nelevated risk-taking behaviour with respect to potential gains and losses\nespecially when the probability of success is low (e.g., Weller et al., 2007).\nStuder et al. (2015) investigated the impact of damage to the ventro medial\nprefrontal cortex using a task assessing risk-sensitive decision-making.\nThey distinguished between risk appetite (overall level of betting) and\nrisk  adjustment (adjusting bets to take account of the probability of\nwinning).\nWhat did Studer et al. (2015) find? The patients showed greater risk\nappetite than healthy controls (especially when risk taking was disadvan-\ntageous) and poorer risk adjustment. Unsurprisingly, their betting perfor-\nmance was poor. Thus, the ventromedial prefrontal cortex plays a key role\nin processing of risk and in successful decision-making under risk.\nKEY TERM\nInteroception\nSensitivity to bodily\nstimuli (especially those\nrelating to emotion) at\nthe conscious or non-\nconscious level.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n653\nSocial factors\nTetlock (2002) emphasised the importance of social factors in his social\nfunctionalist approach. He argued people often act like intuitive politicians:\n“They are accountable to a variety of constituencies . . . their long-term\nsuccess at managing impressions hinges on their skill at anticipating objec-\ntions that others are likely to raise to alternative courses of action” (p. 454).\nSimonson and Staw (1992) studied the effects of accountability on\ndecision- making in a study on the sunk-cost effect (see Glossary; see p. 644).\nSome participants were told their decisions would be shared with instructors\nand other students (high-accountability condition) whereas others were told\ntheir decisions would be confidential (low-accountability condition). High-\naccountability participants were more likely to continue with their previ-\nously ineffective course of action. They showed a stronger sunk-cost effect\nbecause they experienced a greater need to justify their previous decisions.\nTetlock and Boettger (1994) found that accountability influenced per-\nformance when participants decided on the acceptability of a new drug\n(Carozile) that was not yet on the market. Participants were told it would\nprobably save many lives but would also probably cause many deaths.\nThere was much more evidence of the status quo bias (maintaining the\npresent state but not accepting the drug) when they felt accountable for\ntheir decision.\nAccountability pressures also influence experts’ decisions (see Box).\nSchwartz et al. (2004) asked medical experts to choose treatment for a\npatient with osteoarthritis. Their decision-making was more biased when\nthey were made accountable for their decision by writing an explanation\nfor it and agreeing to be contacted later to discuss it.\nIN THE REAL WORLD: POLITICIANS’ DECISION-MAKING\nIt has sometimes been argued (e.g., Axelrod, 2015) that many (or most) politicians are experts at\ndecision-making because they work in an environment requiring numerous decisions. A counter-\nargument is that politicians’ decisions are often open to public scrutiny (and thus accountability)\nwhich might increase their tendency to make biased decisions. For example, politicians in the\nUnited Kingdom (and elsewhere) often greatly increase spending on failing projects: this is basi-\ncally the sunk-cost effect.\nSheffer et al. (2018) presented participants with a sunk-cost decision scenario involving a failing\ngovernment scheme to provide loans to small businesses. The participants consisted of politicians\nand population samples from three countries. The proportions voting to extend the loan pro-\ngramme are shown in Figure 13.8. Politicians showed more evidence of the sunk-cost effect in all\nthree countries.\nSheffer et al. (2018) also studied the status quo bias (see Glossary) in politicians and population\nsamples. Participants decided whether to whether to abandon the present economy policy plan\nin favour of a different plan that would increase economic growth but also increase the budget\ndeficit.\nWhat findings would we expect? Earlier we discussed findings indicating that high accountability\nincreases the probability that individuals will show the status quo bias (Tetlock & Boettger, 1994).\nSuppose we assume politicians experience greater feelings of accountability than non-politicians\nCreated from usyd on 2022-02-17 03:28:25.",
    "654\nThinking and reasoning\n(especially with respect to being held accountable for the increase in the budget deficit). That\nwould lead us to predict politicians would show more evidence of the status quo bias (i.e., sticking\nwith the present plan). Sheffer et al. (2018) obtained the predicted findings.\nIn sum, politicians are more prone to various decision-making biases (sunk-cost effect; status\nquo effect) than other people. These findings help to explain some of the poor decisions made by\npoliticians and suggest that accountability can distort the decision-making process.\n0.3\nAll\nProportion voting to extend (predicted probabilities)\nBelgium\nCanada\nIsrael\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFigure 13.8\nProportion of\npoliticians (circles)\nand population\nsamples (diamonds) in\nBelgium, Canada and\nIsrael voting to extend\na loan programme\n(proportions above\n0.5 indicate the sunk-\ncost effect).\nFrom Sheffer et al., 2018.\nThe social functionalist approach could be developed to account for cul-\ntural factors. Consider the distinction between individualistic cultures\n(emphasising individual responsibility) and collectivistic cultures (emphasis-\ning interpersonal relationships). Those living in individualistic cultures are\nmore sensitive to losses and so exhibit more loss aversion than those in col-\nlectivistic cultures (Wang et al., 2017; Xie et al., 2018). The above findings\ncan be interpreted by the cushion hypothesis, according to which the social\nsupport provided by others in collectivistic cultures provides a “cushion”\nfor potential financial losses.\nWhat are the limitations with the social functionalist approach? First,\nindividual differences in the extent to which people feel the need to justify\nthemselves to others are de-emphasised. Second, most research has involved\nlaboratory tasks lacking real demands on social responsibility. Third, we\nhave a limited understanding of the underlying mechanisms. For example,\nincreased accountability often changes decisions but the role of cognitive\nprocesses (e.g., attention; deliberate or analytic thinking) remains largely\nunexplored.\nAPPLIED AND COMPLEX DECISION-MAKING\nThere are two important differences between decision-making in the lab-\noratory and the real world. First, decision-making has more serious\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n655\nconsequences in the real world. For example, medical experts make life-\nor-death diagnostic decisions (see Chapter 12). Some other decisions are\nalso both important and complex (e.g., “Should I marry John?”; “Should I\nmove to Australia?”). Second, laboratory-based decision-makers typically\nmake a single decision. In contrast, in real life we often make several deci-\nsions over time as we strive towards important goals (e.g., establishing a\ncareer).\nFast-and-frugal heuristics: applied decision-making\nIt seems reasonable to assume effective real-world decision-making typically\ninvolves complex strategies. In contrast, advocates of the fast-and- frugal\napproach (e.g., Gigerenzer, 2014; discussed earlier, pp. 634–637), assume\nsimple heuristics or rules of thumb can be more effective than complex\nstrategies.\nThe approach based on fast-and-frugal heuristics explains some deci-\nsions in applied settings (see Hafenbrädl et al., 2016). For example, the\nfast-and-frugal approach has been applied to investment decision-making.\nDeMiguel et al. (2009) compared a simple heuristic (1/N: allocate funds\nequally to each of N funds) against 14 other much more complex models\nincluding the mean-variance portfolio, which won its creator (Harry\nMarkowitz) the Nobel Prize in economics. None of these complex models\nwas consistently better than 1/N. How can this be? Complex models are\nvery sensitive to past data about stocks. However, they are sensitive to\n“noise” in the data as well as its underlying structure which leads to overly\ncomplex and distorted models.\nHow can doctors decide whether a patient with acute vestibular syn-\ndrome (symptoms include vertigo, nausea and unsteady gait) has had a\nstroke? They can use magnetic resonance imaging (MRI) but that is expen-\nsive. A much cheaper (and easier) approach is to administer three short\ntests of abnormalities in eye movements and then apply a simple tallying\nheuristic – a stroke is diagnosed if at least one test indicates abnormality.\nNewman-Toker et al. (2013) found strokes were detected more often using\nthis heuristic than with MRI, both typically used within two days of arrival\nat a medical centre.\nIn sum, the approach based on fast-and-frugal heuristics sometimes\nprovides reasonable decisions in complex situations. As discussed earlier,\nan issue with this approach is whether it is really as simple as is gen-\nerally assumed. For example, there are unresolved problems relating to\nhow we acquire the various heuristics and how decision-makers select\nthe most appropriate heuristic for a given problem (Otworowska et al.,\n2018).\nComplex decision-making\nIn an ideal world, our decision-making would involve strategies maximising\nutility (the subjective desirability of an outcome). Such strategies “involve\nexhaustive computations based on perfect knowledge of decision-relevant\ninformation, possible choices, and their outcome probabilities and conse-\nquences” (Oh et al., 2016, p. 1937).\nKEY TERM\nUtility\nHow rewarding or\nsatisfying a given\noutcome is perceived to\nbe subjectively.\nCreated from usyd on 2022-02-17 03:28:25.",
    "656\nThinking and reasoning\nMulti-attribute utility theory (see Dyer, 2016) is an approximation to\nan ideal strategy involving the following stages:\n(1) Identify attributes relevant to the decision.\n(2) Decide how to weigh those attributes.\n(3) List all options under consideration.\n(4) Rate each option on each attribute.\n(5) Obtain a total utility (i.e., subjective desirability for each option by\nsumming its weighted attribute values) and select the one with the\nhighest weighted total.\nWe can see this theory’s workings by considering someone deciding which\nflat to rent. First, the relevant attributes (e.g., number of rooms; rent per\nweek) are identified. Second, the relative utility of each attribute is calcu-\nlated. Third, the flat with the highest total utility is chosen.\nIt has often been assumed that individuals rarely adopt this optimal\nstrategy. They typically possess incomplete knowledge of decision-\nrelevant information and they are constrained by processing limitations\n(e.g., small short-term memory capacity). However, some evidence sug-\ngests that individuals can approximate to this optimal strategy provided\nthe  decision-making task is only moderately complex. For example,\nBrusovansky et al. (2018) asked participants acting as job interviewers to\nchoose one of two candidates based on the candidates’ attributes (3, 4 or\n5 attributes) and the importance of those attributes (weights of 1, 2, 3 or\n4). Participants were required to make rapid decisions (mean response time\nwas 1.5 seconds).\nWhat did Brusovansky et al. (2018) find? Mean overall accuracy was\n86% in spite of the speed of responding (varying between 90% for  3-attribute\nproblems and 84% for 5-attribute problems). The key finding was that 59%\nof the participants used a strategy approximating that assumed by multi-\nattribute utility theory. Since decisions were made rapidly, the processing\nof attributes and their weights must have occurred fairly “automatically”.\nIn spite of findings such as those of Brusovansky et al. (2018), our\nlimited processing ability means we cannot readily use the strategy described\nby multi-attribute utility theory with more complex decision-making prob-\nlems. Instead, we often engage in satisficing (formed from the words satis-\nfactory and sufficing). Satisficing involves “fast but ‘good-enough’ heuristic\ndecision-making that prioritises some sources of information while ignor-\ning others” (Oh et al., 2016, p. 1937).\nSchwartz et al. (2002) emphasised the importance of individual dif-\nferences. They distinguished between satisficers (content with making rea-\nsonably good decisions) and maximisers (perfectionists). Satisficers were\nhappier and more optimistic than maximisers and experienced less regret\nand self-blame. According to Cheek and Schwartz’s (2016) two-component\nmodel, maximisers differ from satisficers in setting higher goals (i.e., choose\nthe best) and in strategy (seek out numerous options and compare them).\nIn similar fashion, Luan and Li (2017) distinguished between goal\ndesirability and feasibility (the effort required to achieve the goal). The\nmain difference between maximisers and satisficers was that the former\nwere willing to put more effort into achieving desirable goals. For example,\nKEY TERM\nSatisficing\nSimplifying the decision-\nmaking process by using\nheuristics and ignoring\nsome relevant information\nsources; the term\nrepresents a blend of the\nwords satisfactory and\nsufficing.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n657\nmaximisers were willing to wait much longer than satisficers for a table at\na highly desirable restaurant (78 vs 51 minutes).\nElimination by aspects\nTversky (1972) argued that we often use relatively simple strategies.\nAccording to his elimination-by-aspects theory, decision-makers eliminate\noptions by considering one relevant attribute or aspect after another. For\nexample, someone buying a house may initially consider geographical loca-\ntion, eliminating all houses outside a given area. They may then consider\nthe attribute of price, eliminating all properties costing above a certain\nfigure. This process continues attribute by attribute until only one option\nremains.\nElimination by aspects has the advantage that it is relatively unde-\nmanding cognitively. However, the option selected often varies as a func-\ntion of the order in which the attributes are considered. As a result, the\nselected option may not be the best one.\nKaplan et al. (2011) proposed a modified version of Tversky’s (1972)\ntheory. In their two-stage theory, the initial stage resembles elimination\nin that only options fulfilling certain criteria are retained, which reduces\nthe options being considered to a manageable number. The second stage\ninvolves detailed comparisons of the patterns of attributes of the retained\noptions and is only feasible when the number of options is relatively small.\nFindings\nPayne (1976) asked students to decide among flats based on information\nabout various attributes (e.g., rent; distance from campus). When there\nwere many flats to consider, the students typically started with a simple\nstrategy (e.g., satisficing; elimination-by-aspects). When only a few flats\nremained, they often switched to a more complex strategy corresponding to\nthe assumptions of multi-attribute utility theory.\nKaplan et al. (2011) obtained support for their two-stage theory. Student\nparticipants selected an apartment after having searched through informa-\ntion relating to 600 apartments. In the first stage, the three most popular\ncriteria for retaining or eliminating apartments were location, walking time\nto the university and rental price. In the second stage, participants’ calcu-\nlations included complex interactions between attributes. For example, the\nimportance attached to a low rental price depended on several other factors\n(e.g., price knowledge; frequency of going to the university; experience of\nsearching for apartments). More specifically, low rent was most important\nwhen participants had little price knowledge, went frequently to the univer-\nsity and had often searched for apartments in recent years.\nLenton and Stewart (2008) obtained similar findings when single\nwomen made selections from a real dating website with 4, 24 or 64 poten-\ntial dates. Unsurprisingly, the women shifted from complex to simple strat-\negies with increased numbers of potential dates. The weighted averaging\nstrategy assumed by multi-attribute utility theory was used by 81% with 4\npotential dates but only 41% choosing from 64. The respective figures for\nthe elimination-by-aspects strategy were 39% and 69%, respectively, and\nCreated from usyd on 2022-02-17 03:28:25.",
    "658\nThinking and reasoning\nfor the satisficing strategy were 6% and 16% (the numbers exceed 100%\nbecause many women used multiple strategies).\nWhich attributes most influence date choice depends on how easily\nthey are assessed. Speed-dating decisions at large events were determined\nmostly by easily assessable attributes (e.g., age; height; weight) rather than\nthose harder to assess (e.g., occupation; academic achievements) (Lenton\nand Francesconi, 2010). The opposite was the case at small events. These\nfindings probably reflect the increased cognitive load at large events.\nEvaluation\nElimination-by-aspects theory has proved reasonably successful when indi-\nviduals choose among numerous options. However, individuals often adopt\na more complex approach resembling that of multi-attribute utility theory\nwith relatively few options. Thus, elimination by aspects is a useful filter at\nan early stage of decision-making but is less valuable subsequently.\nElimination-by-aspects theory does not take account of our preference\nfor options sharing many attributes with other options. Adding this prefer-\nence to the elimination-by-aspects approach enhances its ability to predict\npeople’s choices in decision making (Won, 2012).\nComplicating factors: changing preferences and selective\nexposure\nMost theories (including those discussed earlier) assume a given individual’s\nassessment of the utility or preference (desirability X importance) of any\ngiven attribute remains constant. Simon et al. (2004) tested this assump-\ntion. Participants decided between job offers from two department stores\nusing four attributes (e.g., salary; commuting time). They were then told\none job was in a much better location. This increased preferences for desir-\nable attributes of the chosen job and decreased preferences for undesirable\nattributes of that job. These findings are inconsistent with the notion that\npreferences remain constant.\nDecisions can even cause individuals to misremember factual informa-\ntion used during decision-making. Advanced nursing students prioritised a\nmale or female patient for surgery. Afterwards, their memory for the facts\n(e.g., probability of surviving surgery) was distorted to increase the appar-\nent support for their decision.\nIt may seem changing preferences is irrational and likely to impair\ndecision-making. However, changing preferences can be entirely rational if\nindividuals’ initial preferences are based on uncertain or “noisy” observa-\ntions (Howes et al., 2016). This viewpoint is supported by the finding that\npreference changing is more common when time pressure decreases, suggest-\ning preference changing is based on deliberate or analytic thinking.\nMost theories discussed earlier assumed decision-makers are pro-\nvided with all the information relevant to making a decision. However, an\nimportant factor in poor decision-making is selective exposure – the ten-\ndency to prefer information consistent with one’s beliefs over inconsistent\ninformation. Fischer and Greitemeyer (2010) proposed a model predicting\nincreased selective exposure when individuals have high defence motivation\nKEY TERM\nSelective exposure\nA preference for\ninformation that\nstrengthens pre-existing\nviews and avoidance of\ninformation conflicting\nwith those views.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n659\n(i.e., a need to defend their personal position) (see Figure 13.9). Increased\nselective exposure should also be found when decision-makers have high\naccuracy motivation but restricted access to information. Reduced selec-\ntive exposure occurs when there is high accuracy motivation produced by\ninstructing decision-makers to make the best choice. All these findings were\nreported in a meta-analysis (Hart et al., 2009).\nNaturalistic decision-making\nThe artificiality of much laboratory research has led to an increasing inter-\nest in naturalistic decision-making. For example, in the laboratory, indi-\nviduals typically make decisions from a clear set of options. In contrast,\nreal-life decision-making often occurs in relatively unstructured situations\nwhere individuals must generate their own options.\nGalotti (2002) proposed a theory of naturalistic decision-making in\nunstructured environments involving five phases: setting goals; gathering\ninformation; structuring the decision (i.e., listing options + criteria for\ndeciding among them); making a final choice; and evaluating the decision.\nPhase order is flexible, with decision-makers often returning to previous\nphases when struggling to make a decision (see Figure 13.10).\nA key phase in Galotti’s theory is decision structuring. Galotti (2007)\ndiscussed five studies on important real-life decisions (e.g., students choos-\ning a college; students choosing their main subject). There were several\nfindings:\n(1) Decision-makers constrained the amount of information they consid-\nered, focusing on between two and five options (mean = four) at any\ngiven time.\nFigure 13.9\nA model of selective\nexposure. Defence\nmotivation (a need to\ndefend one’s own position)\nincreases the individual’s\nselective exposure to\nconfirmatory information.\nAccuracy motivation\nreduces selective exposure\nwhen it is triggered by the\ngoal of making the optimal\ndecision but increases it\nwhen it is triggered during\nthe search for information.\nFrom Fischer and Greiemeyer\n(2010). Reprinted by permission\nof SAGE Publications.\nCreated from usyd on 2022-02-17 03:28:25.",
    "660\nThinking and reasoning\n(2)  The number of options considered\ndecreased over time.\n(3)  The number of attributes considered at\nany given time was between three and\nnine (mean = six).\n(4)  The number of attributes did not\ndecrease over time; sometimes it actually\nincreased.\n(5)  Individuals of higher ability and/or more\neducation considered more attributes.\n(6)  Most of the decisions were assessed as\ngood.\nThe most striking finding is that people con-\nsistently limited the amount of informa-\ntion (options + attributes) considered. This\nis consistent with Simon’s (1957) notion of\nbounded rationality but not multi- attribute\nutility theory. In addition, the number of\noptions considered decreased by 18% over\nseveral months. A reduction (though larger\nthan this) is predicted by Tversky’s (1972)\nelimination-by-aspects theory.\nGalotti and Tinkelenberg (2009) obtained\nsimilar findings to Galotti (2007). Parents\nchoosing a first-grade school focused on a restricted number of options\n(typically 3 out of the 8+ available) and typically considered only about\n5 criteria or attributes at any given time. However, their decision-making\nwas dynamic – one-third of the options and over half the criteria changed\non average over a six-month period.\nExpert decision-making\nWe turn now to the processes involved in experts’ naturalistic decision-\nmaking focusing on Klein’s (e.g., 1998, 2008) recognition-primed\ndecision-making model (see Figure 13.11).\nWhen the situation is familiar or typical, experts match the situation to\nlearned patterns of information stored in long-term memory using pattern\nrecognition. This rapid automatic process typically leads to retrieval of\na single option. It is followed by mental simulation (i.e., imagining what\nwould happen if the expert acted on the retrieved option). If the imagined\noutcome is satisfactory, that option rapidly determines his/her actions.\nThere is much support for the model. Klein (1998) found in an anal-\nysis of over 600 decisions that various kinds of experts (e.g., fireground\ncommanders; military commanders) generally considered only one option\nat a time. Experts typically rapidly categorised even a novel situation as an\nexample of a familiar type of situation. After that, they simply retrieved\nthe appropriate decision from long-term memory.\nKlein et al. (2010) obtained further support for the model based on\nretrospective semi-structured interviews with fireground commanders.\nFigure 13.10\nThe five phases of decision-making according to Galotti’s\ntheory. Note the flexibility in the ordering of the phases.\nFrom Galotti (2002).\nKEY TERM\nBounded rationality\nThe notion that people\nare as rational as the\nenvironment and their\nlimited processing\ncapacity permit.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n661\nThese commanders considered only one option at 80% of the decision\npoints encountered while firefighting. There is an interpretive issue here.\nDid the fireground commanders consider only one option because it was\nobjectively the best one (to the extent this can be calculated) or because\nthere was insufficient time to consider other options?\nAnother issue is that it is generally assumed fireground commanders\nmake rapid decisions. However, as Launder and Perry (2014) pointed out,\nfireground commanders often obtain relevant information (e.g., from the\ninitial radio contact) prior to arriving at the fire itself.\nThere is general agreement that pattern recognition plays a key role\nin experts’ responses to a crisis situation. However, Launder and Perry\n(2014) argued the decision-making involved in urban fire settings is more\ncomplex than assumed within the model. More specifically, they identified\nfive sequential stages: “Awareness of the situation, deciding on a strategy\nto handle the situation, planning how to implement the strategy, actually\nimplementing the strategy, and reviewing how the emergency is and/or\nwas handled” (p. 145). The existence of these five stages was supported by\ninterviews with experienced firefighters.\nIndividual differences are de-emphasised within the model. Consistent\nwith the model, most individuals use an intuitive (or System 1) thinking\nstyle when making decisions in areas involving relevant expertise (Pachur\n& Spaar, 2015). However, Pachur and Spaar found some individuals pre-\nferred a reflective (or System 2) thinking style even when they possessed\nrelevant expertise.\nEvaluation\nThe recognition-primed decision-making model explains experts’ ability\nto make rapid, accurate decisions under considerable pressure, often while\nFigure 13.11\nKlein’s recognition-primed decision model. Decision-making is easy if the situation is typical: pattern recognition based\non information in long-term memory generates a decision that confirms expectancies. Decision-making is more complex\nif the decision-maker’s expectancies are violated or if the situation is perceived as not typical. In either case, there is a\nprocess of clarifying and diagnosing the situation and collecting more data.\nFrom Patterson et al. (2009). British Computer Society.\nCreated from usyd on 2022-02-17 03:28:25.",
    "662\nThinking and reasoning\nconsidering only one option (see Schraagen, 2018). The model’s empha-\nsis on their ability to use pattern recognition effectively is consistent with\nexperts’ chess and medical decision-making (see Chapter 13). It also offers a\npotential explanation for slower, more deliberate decision-making in atypi-\ncal or unfamiliar situations.\nWhat are the model’s limitations? First, the model provides a general\noutline of expert decision-making but provides few details. For example,\nwhen a crisis situation is perceived as unfamiliar it is assumed experts\nengage in clarification and diagnosis. However, the precise information\nprocessing involved depends substantially on the nature of the crisis and\nthe expert’s relevant knowledge.\nSecond, the fact that most evidence has been obtained in real-life sit-\nuations is a mixed blessing. One problem is that the crisis situations inves-\ntigated were generally so complex it is hard to identify the key factors\ntriggering experts’ decisions. In addition, there has (inevitably) been exten-\nsive reliance on experts’ fallible memories for their thought processes\nduring crisis situations.\nUnconscious thought theory\nDijksterhuis and Nordgren (2006) argued that unconscious thinking is\noften more effective than conscious thinking with complex decision- making.\nConscious thinking is constrained by the limited capacity of conscious\nawareness, and so unconscious thinking is better than conscious thinking\nat integrating large amounts of information. Dijksterhuis and Strick (2016)\nupdated this theory, arguing that unconscious thinking is most likely to be\neffective with inherently interesting problems.\nFindings\nMuch research on unconscious thought theory has taken the following\nform:\n(1) Participants are presented with a problem providing several options;\n(2) Problem presentation is followed by a period of conscious delibera-\ntion or distraction (designed to prevent conscious thought about the\nproblem);\n(3) Finally, participants select one option.\nTheoretically, the prediction is that decision-making performance will be\nsuperior for participants in the distraction condition (who have used only\nunconscious thought) than those in the conscious deliberation condition.\nStrick et al. (2011) reported significant support for this prediction in a\nmeta-analysis. However, the magnitude of the effect depended on several\nfactors (e.g., problem complexity; duration of distraction or deliberation).\nNieuwenstein et al. (2015) also carried out a thorough meta-analysis based\non more studies than those considered by Strick et al., and obtained weaker\noverall evidence for an unconscious thought advantage.\nNordgren et al. (2011) argued complex decision-making should be best\nif it involved conscious and unconscious thought. Performance was optimal\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n663\nfor 57% of participants using conscious thought followed by unconscious\nthought, compared to 26% for those using only conscious thought, and\n28% for those using only unconscious thought.\nEvaluation\nUnconscious thought theory has focused attention on the strengths and lim-\nitations of conscious and unconscious thought. Unconscious thought some-\ntimes (but probably rarely) produces superior decision-making to conscious\nthought. The theory may have relevance to some cases where problem\nsolving has benefited from incubation (putting a problem to one side for\nsome time; see Chapter 12). Decision-making can be optimal when individ-\nuals combine conscious and unconscious thought (Nordgren et al., 2011).\nWhat are the theory’s limitations? First, the main problem is that the\nrelevant findings are weak and inconsistent (Nieuwenstein et al., 2015).\nSecond, participants assigned to the distraction condition are assumed to\nrely heavily on unconscious, intuitive processes in their decision- making.\nHowever, they often claim to rely on conscious memory (Aczel et al.,\n2011).\nCHAPTER SUMMARY\n•\nIntroduction. There are close links between judgement and\ndecision-making. However, decision-making covers all processes\ninvolved in deciding on a course of action. In contrast, judgement\nfocuses mainly on aspects of decision-making concerning with\nestimating the probability of various events. Judgements are\nevaluated in terms of their accuracy whereas decisions are\nevaluated on their consequences.\n•\nJudgement research. Our estimates of the probability of\nsomething happening change in the light of new evidence. When\nmaking such estimates, people often fail to take full account of\nbase-rate information in part because of their reliance on the\nrepresentativeness heuristic. Base-rate information is used more\noften when people are strongly motivated to use such information\nor when full causal knowledge is available. Some judgement errors\ndepend on use of the availability heuristic. Errors based on use of\nthe representativeness and availability heuristics occur in everyday\nlife and are even found in experts. Medical misdiagnosis based\non heuristics can be reduced by training in guided, structured,\nreflective processes. According to the natural frequency hypothesis,\njudgements are more accurate when based on natural sampling\nand frequencies rather than probabilities. In fact, the reasons for\nthe superiority of frequency formats are varied and complex.\n•\nTheories of judgement. According to support theory, an event’s\nsubjective probability increases as its description becomes\nCreated from usyd on 2022-02-17 03:28:25.",
    "664\nThinking and reasoning\nmore explicit and detailed. However, the opposite finding has\nsometimes been obtained (e.g., when the problem focuses\npeople’s attention on low-probability causes). Fast-and-frugal\nheuristics (e.g., the recognition and take-the-best heuristics) are\nclearly specified and are often useful. However, judgements often\ninvolve making use of more information sources than assumed by\nadvocates of fast-and-frugal heuristics. According to Kahneman’s\ndual-process theory, initial intuitive processing (System 1) is\nsometimes followed by more conscious and controlled processing\n(System 2). This serial processing assumption is oversimplified as\nis the notion that the processes used on judgement tasks can be\nneatly divided into heuristic and controlled ones.\n•\nDecision-making under risk. According to prospect theory,\npeople are more sensitive to potential losses than gains, and so\nare willing to take risks to avoid losses. The theory is supported by\nresearch on phenomena such as the framing and sunk-cost effects.\nThere is also evidence of loss aversion in professional golfers,\nexperienced poker players and financial experts. The theory\nhas limited explanatory principles and the crucial notion of a\n“reference point” is often vague. There is sometimes less support\nfor prospect theory when decisions are based on experience rather\nthan descriptions. According to prospect theory, people should\nbe risk averse for gains but risk seeking to avoid losses. However,\nmany individuals are risk averse (or risk seeking) for both gains and\nlosses.\n•\nDecision-making: emotional and social factors. A plausible\nprediction from prospect theory is that losses are experienced\nmore intensely than gains. However, this is not the case when\nlosses and gains are evaluated separately. Prospect theory is less\napplicable to affect-rich problems than affect-poor ones. The\nemotions of regret and fear often explain the existence of the\nomission and status quo biases. Brain areas of relevance to risky\ndecision-making include the amygdala and ventromedial prefrontal\ncortex. According to Tetlock’s social functionalist approach,\npeople’s need to justify their decisions to others accounts for some\nbiases in decision-making. This approach could be developed to\nexplain cultural differences in loss aversion.\n•\nApplied and complex decision-making. Decision-makers in\nthe laboratory and the real world often start by reducing the\nnumber of options considered by eliminating aspects, followed by\ndetailed comparisons of the retained options. However, experts\noften consider a single option and make rapid intuitive decisions\nespecially when there is considerable time pressure. Making a\ndecision can cause decision-makers to misremember relevant\nfactual information to increase the apparent support for that\ndecision. According to Dijksterhuis’s unconscious thought theory,\nCreated from usyd on 2022-02-17 03:28:25.",
    "Judgement and decision-making\n665\nunconscious thinking is more useful than conscious thinking, but\nthis is contradicted by most available research. However, decision-\nmaking is sometimes best when conscious thought is followed by\nunconscious thought\nFURTHER READING\nHoffrage, U., Hafenbrädtl, S. & Marewski, J.N. (2018). The fast-and-frugal heuris-\ntics programme. In L.J. Ball and V.A. Thompson (eds), Routledge International\nHandbook of Thinking and Reasoning (pp. 325–345). Abingdon, Oxon.: Routledge.\nThe role of fast-and-frugal heuristics in judgement and decision-making is dis-\ncussed thoroughly by Ulrich Hoffrage and his colleagues.\nKeren, G. & Wu, G. (eds) (2016). The Wiley Blackwell Handbook of Judgment and\nDecision-Making (2 vols). Hoboken: Wiley-Blackwell. This two-volume hand-\nbook contains chapters covering all the main topics in judgement and deci-\nsion-making research.\nRakow, T. & Skylark, W.J. (2018). Judgement heuristics. In L.J. Ball and V.A.\nThompson (eds), Routledge International Handbook of Thinking and Reasoning\n(pp. 451–471). Abingdon, Oxon.: Routledge. The authors evaluate prominent\ntheoretical accounts of the heuristics or rules of thumb used on judgement tasks.\nSchraagen, J.M. (2018). Naturalistic decision-making. In L.J. Ball and V.A.\nThompson (eds), Routledge International Handbook of Thinking and Reasoning\n(pp. 487–501). Abingdon, Oxon.: Routledge. This chapter focuses on what is\nknown about complex decision-making in the real world.\nSchulz, C. & Newell, B.R. (2018). Decision-making under risk: An experience-based\nperspective. In L.J. Ball and V.A. Thompson (eds), Routledge International\nHandbook of Thinking and Reasoning (pp. 502–522). Abingdon, Oxon.: Routledge.\nChristin Schulz and Ben Newell discuss theory and research on decision-making\nwith an emphasis on the roles played by learning and experience.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis\ntesting\nINTRODUCTION\nFor hundreds of years, philosophers have distinguished between two kinds\nof reasoning. One is inductive reasoning, which involves drawing general\nconclusions from premises (statements) referring to particular instances.\nA key feature of inductive reasoning is that the conclusions of inductively\nvalid arguments are probably (but not necessarily) true.\nThe philosopher Bertrand Russell provided the following example. A\nturkey might use inductive reasoning to draw the conclusion “Each day I\nam fed”, because that has always been the case in the past. However, there\nis no certainty that the turkey will be fed tomorrow. Indeed, if tomorrow is\nChristmas Eve, it is likely to be proven false.\nScientists very often use inductive reasoning similarly to Russell’s\nhypothetical turkey. A psychologist may find across numerous experiments\nthat reinforcement (reward) is needed for learning. This might lead them\nto use inductive reasoning to propose the hypothesis that reinforcement is\nessential for learning. This conclusion is not necessarily true because future\nexperiments may not replicate past ones.\nThe other kind of reasoning identified by philosophers is deductive\nreasoning. Deductive reasoning allows us to draw conclusions that are\ndefinitely or certainly valid provided other statements are assumed to be\ntrue. For example, the conclusion Tom is taller than Harry is necessarily\ntrue if we assume Tom is taller than Dick and Dick is taller than Harry.\nDeductive-reasoning problems owe their origins to formal logic.\nAn important issue is whether the distinction between inductive and\ndeductive reasoning is as clear-cut in practice as it appears above. There is\nincreasing evidence that similar processes are involved in both cases. For\nexample, Stephens et al. (2018) asked participants to evaluate identical sets\nof arguments after receiving inductive- or deductive-reasoning instructions.\nWith the former instructions, participants decided whether the conclusion\nwas plausible, strong or likely to be true. With the latter instructions, they\ndecided whether the conclusion was necessarily true.\nKEY TERMS\nInductive reasoning\nForming generalisations\n(that may be probable\nbut are not certain)\nfrom examples or\nsample phenomena; see\ndeductive reasoning.\nDeductive reasoning\nReasoning to a conclusion\nfrom a set of premises\nor statements where\nthat conclusion follows\nnecessarily from the\nassumption the premises\nare true; see inductive\nreasoning.\nChapter\n14\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n667\nStephens et  al. (2018) found participants used the same processes\nwhether instructed to reason inductively or deductively. The only major\ndifference was that greater argument strength was required to decide that a\nconclusion was necessarily true (deductive condition) than to decide it was\nstrong or likely to be true.\nThe wide chasm between the artificial, logic-driven, deductive- reasoning\ntasks traditionally used in the laboratory and everyday reasoning in the\nform of argumentation has led to a rapid increase in research on informal\nreasoning. Informal reasoning (discussed later, pp. 694–701) is based on\nour knowledge and experience rather than logic. It is a form of inductive\nreasoning that resembles our everyday reasoning.\nA major consequence of this shift in research is that it is increasingly\naccepted that reasoning processes often resemble those used in judgement\nand decision-making. For example, the Bayesian approach, according to\nwhich our subjective probabilities (i.e., that X is dishonest) are adjusted in\nthe light of new information, plays a prominent role in theorising about\njudgements (see Chapter 13). In a similar fashion, the Bayesian approach is\nincreasingly applied to reasoning (Navarrete and Mandel, 2016).\nHYPOTHESIS TESTING\nKarl Popper (1968) distinguished between confirmation and falsifica-\ntion.  Confirmation involves the attempt to obtain evidence confirming\nor  supporting one’s hypothesis. In contrast, falsification involves the\nattempt to falsify hypotheses by experimental tests. Popper claimed we\ncannot achieve confirmation via hypothesis testing. Even if all the avail-\nable evidence supports a hypothesis, future evidence may disprove it.\nHe argued falsifiability (the potential for falsification) separates scien-\ntific from  unscientific activities such as religion or pseudo-science (e.g.,\npsychoanalysis).\nAccording to Popper, scientists should focus on falsification. In fact,\nas discussed later, they often seek confirmatory rather than disconfirmatory\nevidence when testing their hypotheses. It has also been claimed the same\nexcessive focus on confirmatory evidence is found in laboratory studies on\nhypothesis testing – research to which we now turn.\nWason’s 2-4-6 task\nWason (1960) devised a much-researched hypothesis-testing task (see\nEvans, 2016, for a review). Participants were told three numbers 2-4-6 con-\nformed to a simple relational rule. Their task was to generate sets of three\nnumbers and provide reasons for generating each set. After each choice,\nthe experimenter indicated whether the set of numbers conformed to the\nexperimenter’s rule. Here is the rule: “Three numbers in ascending order of\nmagnitude.” The participants could announce what they believed to be the\nrule on any trial and were told whether it was correct.\nThe rule sounds (very) simple. However, only 21% of university stu-\ndents were correct with their first attempt (Wason, 1960). In spite of the\nemphasis in the literature on the poor levels of performance with the 2-4-6\ntask, Wason found 72% of participants eventually solved it.\nKEY TERMS\nInformal reasoning\nA form of reasoning\nbased on one’s relevant\nknowledge and\nexperience rather than\nlogic.\nFalsification\nProposing hypotheses and\nthen trying to falsify them\nby experimental tests; the\nlogically correct means\nby which science should\nwork, according to Popper\n(1968).\nCreated from usyd on 2022-02-17 03:28:25.",
    "668\nThinking and reasoning\nWhy is performance so poor? One explanation focuses on confirma-\ntion bias – most people seek information confirming their hypothesis. For\nexample, participants whose original hypothesis or rule is that the second\nnumber is twice the first, and the third number is three times the first\nnumber often generate sets of numbers (test triples) consistent with that\nhypothesis (e.g., 6-12-18; 50-100-150).\nWason assumed participants produced test triples conforming to their\ncurrent hypothesis. However, this is an oversimplification (Evans, 2016).\nIt is true that participants mostly produce positive or confirmatory tests\nconforming to their hypothesis and expected to receive positive feedback\n(conforms to the rule).\nHowever, participants sometimes produce negative tests, not con-\nforming to their hypothesis, where they expect to receive negative feed-\nback (does not conform to the rule). There are two types of negative tests\n(Evans, 2016):\n(1) those (e.g., 12-8-4) where participants expect to receive the answer\n“No” and which are therefore confirmatory;\n(2) those (e.g., 1-4-9) where participants expect to receive the answer\n“Yes” and which are therefore disconfirmatory.\nFindings\nParticipants typically engage in very few falsification attempts on the 2-4-6\ntask and have a low success rate. Tweney et  al. (1980) enhanced perfor-\nmance by telling participants the experimenter had two rules in mind and\nthey had to identify both. One rule generated DAX triples and the other\nMED triples. They were also told 2-4-6 was a DAX triple. After generating\neach test triple, participants were informed whether the set fitted the DAX\nor MED rule. The DAX rule was any three numbers in ascending order and\nthe MED rule covered all other sets of numbers.\nOver 50% of participants produced the correct answer on their first\nattempt (much higher than with the standard problem). Of importance,\nparticipants could identify the DAX rule by using positive testing to\nconfirm the MED rule, and so they did not have to try to disconfirm the\nDAX rule.\nGale and Ball (2012) carried out a study resembling that of Tweney\net  al. (1980). They always used 2-4-6 as an example of a DAX triple,\nbut the example of a MED triple was 6-4-2 or 4-4-4. Success in identify-\ning the DAX rule was much greater when the MED example was 6-4-2\n(75%) rather than 4-4-4 (23%). The greatest difference between solvers and\nnon-solvers of the DAX rule was the number of descending triples they\nproduced. This indicates the importance of participants focusing on the\nascending/descending dimension, which was difficult to do when the MED\nexample was 4-4-4.\nCowley and Byrne (2005) argued people show confirmation bias because\nthey are loath to abandon their initial hypothesis. They suggested people\nmight be much better at managing to falsify a given incorrect hypothesis\nif told it was someone else’s. As predicted, 62% of participants abandoned\nthe other person’s hypothesis compared to only 25% who abandoned their\nKEY TERM\nConfirmation bias\nIn hypothesis testing,\nseeking evidence that\nsupports one’s beliefs.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n669\nown hypothesis. Cowley (2015) extended these findings. Participants were\ntold the hypothesis “even numbers ascending in two” was theirs or that of\nan imaginary participant Peter. They generated more negative falsifying\ntests when the hypothesis was Peter’s rather than their own (32% vs 7%,\nrespectively).\nIn another experiment by Cowley (2015), all participants were told\nPeter’s hypothesis was “even numbers ascending in twos”. In two condi-\ntions, they were also told another participant, James, had a different explicit\nhypothesis (“any ascending numbers”) or implicit hypothesis (“something\nelse”). In the third, condition, there was no mention of James. There were\nthree key findings. First, there were numerous falsifying test triples (posi-\ntive + negative tests) in all conditions (percentages between 43% and 54%;\npredominantly negative falsifying tests). Second, Peter’s incorrect hypoth-\nesis was rejected by nearly 80% of participants. Third, the correct rule was\ndiscovered by 50% of participants given James’ explicit hypothesis and\n31% given his implicit hypothesis.\nIn sum, “Negative falsifying is possible more often than the literature\nhas ever shown . . . falsification is sufficient to announce that a hypothesis\nis untrue, but an explicit alternative hypothesis that explains the falsifying\nresult is necessary for truth discovery” (Cowley, 2015, pp. 32–33).\nPerformance on the 2-4-6 task involves separable processes of hypoth-\nesis generation and hypothesis testing. Most research has focused on the\nlatter, but Cherubini et al. (2005) focused on hypothesis generation. They\nargued participants try to preserve as much of the information contained in\nthe example triple (i.e., 2-4-6) as possible in their initial hypothesis, making\nthis hypothesis much more specific than the general rule.\nCherubini et  al. (2005) presented participants with two initial triples\nexemplifying the rule. When these triples inhibited the generation of a very\nspecific rule (e.g., 6-8-10; 9-14-15), participants generated more general\nhypotheses than when the two triples were consistent with a specific rule\n(e.g., 6-8-10; 16-18-20). The success rate was much higher in the former\ncondition (70% vs 30%).\nTheoretical analysis\nMost hypotheses are sparse or narrow (applying to under half the possi-\nble entities in any given domain: Navarro & Perfors, 2011). For example,\nPerfors and Navarro (2009) asked people to generate all the rules and\nhypotheses applying to numbers in a given domain (numbers 1 to 1,000).\nThe key finding was that 83% of the rules (e.g., two-digit numbers; prime\nnumbers) applied to fewer than 20% of the numbers.\nWith sparse hypotheses, positive testing is optimal “because there\nare so many ways to be wrong and so few to be right”. In such circum-\nstances, the learner will discover “the world has a bias towards saying\n‘no’, and asking for ‘yes’ is the best way to overcome it” (Perfors &\nNavarro, 2009, p. 2746). Thus, positive testing is typically successful. In\ncontrast, the 2-4-6 task penalises positive testing because the target rule is\nso general.\nCreated from usyd on 2022-02-17 03:28:25.",
    "670\nThinking and reasoning\nEvaluation\nWason’s 2-4-6 task has been “the classic test-bed reasoning task for investi-\ngations of hypothesis falsification for over forty years” (Cowley, 2015, p. 2),\nwith research having clarified the strengths and limitations of human induc-\ntive reasoning. The processes involved in the 2-4-6 task are of relevance to\nunderstanding scientists’ hypothesis testing.\nWhat are the limitations of Wason’s approach? First, his task differs\nfrom real-life hypothesis testing. Participants given the 2-4-6 task receive\nimmediate accurate feedback but are not told why the numbers they pro-\nduced attracted a “yes” or “no” response. In the real world (e.g., scientists\ntesting hypotheses), the feedback is much more informative, but is often\ndelayed in time and sometimes inaccurate.\nSecond, the correct rule or hypothesis in the 2-4-6 task (three numbers\nin ascending order of magnitude) is very general because it applies to a\nfairly high proportion of sets of three numbers. In contrast, most rules\nor hypotheses apply to only a smallish proportion of possible objects or\nevents. Positive testing works poorly on the 2-4-6 task but not with most\nother forms of hypothesis testing.\nThird, Wason argued most people show confirmation bias and find a\nfalsification approach very hard to use. However, there is much less con-\nfirmation bias but more evidence of falsification when testing someone\nelse’s hypothesis (Cowley, 2015; Cowley & Byrne, 2005). This is consistent\nwith scientists’ behaviour. For example, at a conference in 1977 on the\nlevels-of-processing approach to memory (see Chapter 6), nearly all the\nresearch presented identified limitations with that approach.\nHypothesis testing: simulated and real research\nenvironments\nAccording to Popper (1968), a crucial feature of all truly scientific theories\nis falsifiability. Scientists should focus on falsification rather than confir-\nmation because the latter cannot be achieved. His arguments possess merit\nbut are oversimplified (see below). Suppose a scientist obtains findings\napparently inconsistent with their hypothesis. The findings may mean the\nhypothesis is incorrect. However, they may reflect problems with the exper-\nimental design or the accuracy of the data. Of relevance, a recent study\n(Open Science Collaboration, 2015; see Chapter 1) found that attempts to\nreplicate 100 findings in psychology were successful only 36% of the time.\nDunbar (1993) found evidence of confirmation bias using a simulated\nresearch environment. Participants had to explain how genes are controlled\nby other genes using a computer-based molecular genetics laboratory. This\nproblem is so difficult that those solving it in real life (Jacques Monod\nand François Jacob) received the Nobel prize! The participants were led to\nfocus on the hypothesis that the gene control was by activation whereas it\nwas actually by inhibition.\nParticipants who simply sought data consistent with their activation\nhypothesis failed to solve the problem. In contrast, the 20% of partici-\npants solving the problem tried to explain the discrepant findings. Most\nparticipants started with the general hypothesis that activation was the key\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n671\ncontrolling process, focusing on one gene after another as the potential\nactivator. Only after every activation hypothesis had been disconfirmed\ndid some participants focus on explaining data inconsistent with activation\nhypotheses.\nConfirmation bias: analysis and interpretation\nWe have seen scientists generally adopt a confirmatory approach during\nhypothesis testing. We now focus on confirmation bias when scientists\nanalyse and interpret their findings (see Nuzzo, 2015, for a review).\nFugelsang et al. (2004) studied professional scientists working on issues\nin molecular biology relating to how genes control and promote replication\nIN THE REAL WORLD: HYPOTHESIS TESTING BY SCIENTISTS\nWhat actually happens in real-life science? Uchino et al. (2010) analysed numerous research articles\nin psychology. The great majority (77%) sought confirmation by testing the hypothesis favoured\nby the researcher(s) and 91% supported an existing theory. Only 22% discussed other hypoth-\neses.  These findings suggest, “Someone must be wrong: either scientists are going about their\nbusiness incorrectly or Popper was mistaken about how science progresses” (Sanbonmatsu et al.,\n2015, p. 2).\nSanbonmatsu et al. (2015) proposed a solution based on a distinction between absolute or uni-\nversal hypotheses and non-absolute hypotheses. Absolute hypotheses claim a given phenomenon\nalways occurs, whereas non-absolute hypotheses claim a phenomenon occurs only in some condi-\ntions. Popper (1968) assumed scientific theories are absolute or universal. On that assumption, the\noptimal approach involves falsification or disconfirmation – a single negative observation would\ndisprove an absolute theory. In contrast, a confirmatory approach is generally more informative\nthan a disconfirmatory one with non-absolute hypotheses.\nWhat do scientists actually do? Sanbonmatsu et al. (2015) found 96% of researchers in psychol-\nogy indicated their research was mostly driven by non-absolute hypotheses. Nearly all (96%) said\nthey generally used a confirmatory approach. With absolute hypotheses, 81% of researchers would\nuse a disconfirmatory approach. With non-absolute hypotheses, in contrast, only 9% would use a\ndisconfirmatory approach with 91% favouring a confirmatory approach.\nFeist (2008) argued a useful heuristic in science is “confirm early – disconfirm late”. Scientists\nshould initially seek confirmatory evidence for a theory; when they have such evidence, they should\nfocus more on disconfirming the theory and discovering its breadth of application. Eighty-three\npercent of scientists were most likely to use a confirmatory approach early in a research pro-\ngramme, and 87% were most likely to use a disconfirmatory approach subsequently (Sanbonmatsu\net al., 2015).\nIn sum, Popper adopted an excessively black-and-white approach. The reality is messy: research\nrarely provides a definitive falsification of a theory. Instead, theories are modified as their limita-\ntions become increasingly apparent (Lakatos, 1978).\nScientists’ strategies when engaged in hypothesis testing approximate to maximising the infor-\nmativeness of the evidence obtained. Thus, describing their typical approach as “confirmation\nbias” (see Glossary) is misleading. Kane and Webster (2013) suggested using the term “confirma-\ntion heuristic” to refer to appropriate focus on a confirmation strategy, limiting the use of “con-\nfirmation bias” to situations where scientists refuse to use the disconfirmatory strategy even when\noptimal.\nCreated from usyd on 2022-02-17 03:28:25.",
    "672\nThinking and reasoning\nin bacteria, parasites and viruses. Of 417 experimental results, over half\n(223) were inconsistent with the scientists’ predictions. They responded to\n88% of these inconsistent findings by blaming problems with their methods.\nIn only 12% of cases did the scientists modify their theories. Thus, the sci-\nentists showed considerable reluctance to change their original theoretical\nposition.\nApproximately two-thirds of the inconsistent findings were followed\nup, generally by changing the methods used. In 55% of cases, the incon-\nsistent findings were replicated. The scientists’ reactions were very different\nthis time – in 61% of cases, they changed their theoretical assumptions.\nHow defensible was the scientists’ behaviour? Note that almost half the\ninconsistent findings were not replicated when a second study was carried\nout. Thus, it was reasonable for the scientists to avoid prematurely accept-\ning possibly spurious findings. Overall, these findings suggest the scientists’\nexhibited only a modest tendency towards confirmation bias.\nJohn et  al. (2012) asked over 2,000 psychologists to provide anony-\nmous information about their questionable research practices. There was\nsubstantial evidence of such practices. For example, John et al. estimated\n78% of respondents had selectively reported studies that “worked”, 62%\nhad excluded data (typically those inconsistent with their hypotheses), and\n36% had stopped data collection after achieving the desired result.\nHere are two other examples of confirmation bias. First, Bakker and\nWicherts (2011) found in an analysis of statistical analyses in research jour-\nnals that over 10% of p values were incorrect. In the great majority of\ncases where such errors changed the statistical significance of the results,\nthe change was from non-significant to significant.\nSecond, researchers often expect their meta-analyses (see Glossary)\nto support their existing hypotheses. As Watt and Kennedy (2017, p. 1)\nargued, “Decisions about studies to be included [in a meta-analysis], statis-\ntical analyses, and moderating factors are made after the analysts know the\noutcomes of the studies. These retrospective decisions provide high poten-\ntial for [confirmation] bias.”\nHow can we reduce confirmation bias in the analysis and interpretation\nof data? Several answers have been proposed (Hamlin, 2017). First, more\nopenness or transparency is required by experimenters so other research-\ners can see precisely what has been done. Second, there is blind analysis –\nall relevant statistical analyses are completed before the experimenter(s)\nis aware of the outcomes of such analyses. Third, and most importantly,\nthere is pre-registration – experimenters announce the rationale, hypoth-\neses, design and proposed methods of data analysis before conducting a\npiece of research.\nDEDUCTIVE REASONING\nIn deductive reasoning, conclusions can be drawn with certainty. In this\nsection, we will mostly consider conditional and syllogistic reasoning prob-\nlems based on traditional logic. In the next section, we consider general\ntheories of deductive reasoning. As we will see, theory and research increas-\ningly focus on the non-logical strategies and processes used when people\nsolve deductive-reasoning problems.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n673\nConditional reasoning\nConditional reasoning (basically, reasoning with “if”) had its origins in\npropositional logic, in which logical operators such as or, and, if . . . then, if\nand only if are included in sentences or propositions. In this system, symbols\nrepresent sentences and logical operators are applied to them to reach con-\nclusions. Thus, we might use P to stand for the proposition “It is raining”\nand Q to stand for “Nancy gets wet”, and then use the logical operator\nif . . . then to relate these two propositions: if P then Q.\nThe meanings of words and propositions in propositional logic differ\nfrom their natural language meanings. For example, propositions can have\nonly one of two truth values: true or false. If P stands for “It is raining”,\nthen P is true (in which case it is raining) or P is false (it is not raining).\nPropositional logic does not admit any uncertainty about the truth of P,\nsuch as when it is so misty you could almost call it raining.\nMany people produce incorrect answers when given certain condi-\ntional-reasoning problems. Consider the following (affirmation of the\nconsequent):\nPremises\nIf Nancy is angry, then I am upset.\nI am upset.\nConclusion\nTherefore, Nancy is angry.\nMany people accept the above conclusion as valid. However, it is not valid\nbecause I may be upset for some other reason (e.g., my football team has\nlost).\nHere is another problem in conditional reasoning:\nPremises\nIf it is raining, then Nancy gets wet.\nIt is raining.\nConclusion\nNancy gets wet.\nThis conclusion is valid. It illustrates the rule of inference known as modus\nponens: “If P, then Q” and also given “P”, we can validly infer Q.\nAnother major rule of inference is modus tollens: from the premise “If\nP, then Q” and the premise “Q is false”, the conclusion “P is false” neces-\nsarily follows. Here is an example:\nPremises\nIf it is raining, then Nancy gets wet.\nNancy does not get wet.\nConclusion\nIt is not raining.\nKEY TERM\nConditional reasoning\nA form of deductive\nreasoning based on if . . .\nthen propositions.\nInteractive exercise:\nConditional reasoning\nCreated from usyd on 2022-02-17 03:28:25.",
    "674\nThinking and reasoning\nPeople consistently perform much better with modus ponens than modus\ntollens: many people argue incorrectly that the conclusion to the above\nproblem is invalid.\nAnother inference involves denial of the antecedent:\nPremises\nIf it is raining, then Nancy gets wet.\nIt is not raining.\nConclusion\nTherefore, Nancy does not get wet.\nMany people argue the above conclusion is valid although it is invalid.\nIt does not have to be raining for Nancy to get wet (e.g., she might have\njumped into a swimming pool).\nTraditionally, research on conditional reasoning was limited in three\nways. First, unlike everyday life, it focused on disinterested reasoning\n(goals and preferences are irrelevant). For example, denial of the anteced-\nent is invalid in traditional logic. In natural language, however, “If P, then\nQ” often means “If and only if P, then Q”. If someone says to you “If you\nmow the lawn, I will give you five dollars”, you are likely to interpret it to\nimply, “If you don’t mow the lawn, I won’t give you five dollars.”\nSecond, traditional research typically involved instructions indicat-\ning that background knowledge was irrelevant. Nowadays, participants\nare generally not instructed to disregard their relevant knowledge with\nconditional-reasoning problems.\nThird, traditional research required participants to draw definite con-\nclusions (true or false). In contrast, participants nowadays are often asked\nto assess the probability of the conclusion being true. This change is desir-\nable because we often assign probabilities to conclusions in everyday life\n(Singmann et al., 2016).\nTheories\nHere we briefly discuss theories of conditional reasoning. More general\ntheories of deductive reasoning are discussed later. Klauer et  al. (2010)\nproposed a dual-source model of conditional reasoning. There is a\nknowledge-based process influenced by premise content where the subjec-\ntive probability of the conclusion depends on individuals’ relevant know-\nledge. There is also a form-based process influenced only by the form of the\npremises.\nVerschueren et  al. (2005) also proposed a dual-process model (other\nmore general dual-process models are discussed later, pp. 683–690). They\nfocused on individual differences in conditional reasoning more than\nKlauer et  al. (2010). Some reasoners use a relatively complex counter-\nexample strategy: a conclusion is considered invalid if the reasoner can\nfind a counterexample to it (this process is discussed later in the section\non mental models, pp. 681–683). The other process is an intuitive\nstatistical strategy based on probabilistic reasoning triggered by relevant\nknowledge.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n675\nFindings\nSingmann et al. (2016) tested the dual-source model using many condition-\nal-reasoning problems. For each problem, participants rated the likelihood\nof the conclusion being true on a probability scale running from 0% to\n100%. Knowledge-based processes were more important than form-based\nones. Overall, the model accounted very well for participants’ performance.\nDe Neys et  al. (2005) obtained evidence relevant to Verschueren\net  al.’s (2005) dual-process model. On some trials, participants were pre-\nsented with few or many counterexamples conflicting with valid conclu-\nsions (modus ponens and modus tollens). According to classical logic, these\ncounterexamples should have been ignored. In fact, however, participants\nwere more likely to decide wrongly the conclusions were invalid when there\nwere many counterexamples.\nMarkovits et al. (2013) tested the dual-process model using problems\ninvolving affirmation of the consequent (where the conclusion is invalid).\nHere are two examples:\n(1) If a rock is thrown at a window, then the window will break.\nA window is broken. Therefore, a rock was thrown at the window.\n(2) If a finger is cut, then it will bleed. A finger is bleeding. Therefore, the\nfinger was cut.\nReasoners using the statistical strategy were influenced by the fact that\nthe subjective probability that “If a finger is bleeding, it was cut” is greater\nthan the probability that “If a window is broken, it was broken by a rock”.\nAs a result, such reasoners accepted the invalid conclusion more often in\nproblem (2) than (1).\nIn contrast, reasoners using the counterexample strategy accepted the\nconclusion if no counterexample came to mind. They also accepted the\ninvalid conclusion more often in problem (2). This was because it was\neasier to find counterexamples with respect to the conclusion of problem\n(1) (the window might have been broken by several objects other than a\nrock) than the conclusion of problem (2).\nAccording to the model, the counterexample strategy is more cogni-\ntively demanding than the statistical strategy. Accordingly, Markovits\net  al. (2013) predicted it would be used less often when participants had\nlimited time. This prediction was supported: that strategy was used on 49%\nof trials with unlimited time but only 1.7% of trials with limited time.\nMarkovits et al. (2017) gave their participants modus ponens inferences\nwhich are always valid. Each problem was presented with additional infor-\nmation indicating the relative strength of evidence supporting the inference\n(50%; 75%; 99%; or 100%). Markovits et al. compared groups of partici-\npants previously identified as using counterexample or statistical strategies.\nMarkovits et al. (2017) found clear differences between the two groups\n(see Figure 14.1). Statistical reasoners were strongly influenced by relative\nstrength when deciding whether to accept modus ponens inferences. In con-\ntrast, counterexample reasoners showed a sharp reduction in acceptance\nwhen some evidence failed to support the inference (e.g., the 99% and 75%\nconditions). These findings were as predicted.\nCreated from usyd on 2022-02-17 03:28:25.",
    "676\nThinking and reasoning\nSummary\nResearch on conditional reasoning has become much more realistic. For\nexample, reasoners are encouraged to use their relevant knowledge on rea-\nsoning tasks. They also assign probabilities to the correctness of conclu-\nsions rather than simply deciding conclusions are valid or invalid.\nTheoretically, it is assumed reasoners are influenced by the form of the\npremises. More importantly, however, their relevant knowledge and expe-\nrience lead them to engage in probabilistic reasoning (dual-source model)\nor to try to find counterexamples to the stated conclusion (dual-process\nmodel).\nWason selection task\nThe Wason selection task has been studied intensively by researchers inter-\nested in deductive reasoning. However, it is more accurately described as a\ntask involving hypothesis testing using a conditional rule.\nIn the standard version of the task, four cards lie on a table (R, G, 2, 7;\nsee Figure 14.2). Each card has a letter on one side and a number on the\nother, and there is a rule applying to the four\ncards (e.g., “If there is an R on one side of\nthe card, then there is a 2 on the other side of\nthe card”). The participants’ task is to select\nonly those cards needing to be turned over\nto decide whether or not the rule is correct.\nWhat is your solution? Most people select the\nR and 2 cards. If you did the same, you are\nwrong!\nYou need to see whether any cards fail\nto obey the rule when turned over. From this\nperspective, the 2 card is irrelevant: if there\nis an R on the other side, this indicates only\nthat the rule might be correct. If there is any\n100%\n0\n0.5\nMean number of MP inferences accepted\n1\n1.5\n2\n2.5\n3\n99%\n75%\n50%\nCounterexample\nStatistical\nRelative strength\nFigure 14.1\nMean number of MP\n(modus ponens) inferences\naccepted (out of 3) as a\nfunction of relative strength\nof the evidence and\nstrategy.\nFrom Markovits et al. (2017).\nFigure 14.2\nThe Wason selection task. Rule: If there is an R on one side of\nthe card, then there is a 2 on the other.\nResearch activity:\nDeductive reasoning\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n677\nother letter on the other side, we have discovered nothing about the rule’s\nvalidity. The correct answer is to select the R and 7 cards, an answer given\nby only about 10% of university students. The 7 is necessary because it\nwould definitely disprove the rule if it had an R on the other side.\nHow can we explain performance on the Wason selection task?\nSeveral  factors are involved. First, performance is worse with abstract\nversions of the task (as above) compared to concrete versions referring\nto everyday events (e.g., “Every time I travel to Manchester, I travel by\ntrain”). Ragni et  al. (2018) found in a meta-analysis that the percentage\nof correct answers increased from 7% with abstract versions to 21% with\nconcrete versions.\nSecond, there is matching bias (the tendency to select cards matching\nthe items named in the rule). Thompson et al. (2013a) obtained strong evi-\ndence for matching bias on the selection task. In addition, cards named in\nthe rule were selected faster than other cards and produced greater feelings\nof rightness.\nThird, the logical solution to the Wason selection task conflicts with\neveryday life (Oaksford, 1997). According to formal logic, we should test\nthe rule “All swans are white” by searching for swans and non-white birds.\nHowever, this would be extremely time-consuming because only a few\nbirds are swans and the overwhelming majority of birds are non-white. It\nwould be preferable to adopt a probabilistic approach based on the likely\nprobabilities of different kinds of events or objects.\nThe problem of testing the above rule resembles the Wason selection\ntask, which has the form “If p, then q”. We should choose q cards (e.g., 2)\nwhen the expected probability of q is low but not-q cards when q’s expected\nprobability is high to maximise information gain. As predicted, far more\nq cards were selected when the percentage of q cards was low (17%) than\nwhen it was high (83%) (Oaksford et al., 1997).\nFourth, motivation is important. People are more likely to select the\npotentially falsifying card (7 in the original version of the task) if moti-\nvated to disprove the rule. Dawson et al. (2002) gave some participants the\nrule that individuals high in emotionality lability experience an early death.\nThe four cards showed high emotional lability, low emotional lability,\nearly death and late death, with the correct answer involving selecting the\nfirst and last cards. Of participants led to believe they had high emotional\nlability (and so motivated to disprove the rule), 38% solved the problem\n(versus 9% of control participants).\nMotivation is also involved with deontic rules (rules concerned with\nobligation or permission). Sperber and Girotto (2002) used a deontic rule\nrelating to cheating. Paolo must decide whether he is being cheated when\nbuying things through the internet: the answer is to select the “item paid\nfor” and “item not received” cards (selected by 68% of participants). This\nunusually high level of performance was achieved because the motiva-\ntion to detect cheating led participants to select the “item not received”\ncard. In a meta-analysis, Ragni et al. (2018) found the correct answer was\nselected by 61% of participants with deontic versions but 7% using abstract\nversions.\nMarrero et  al. (2016) proposed a general motivational approach\naccounting for the above findings. Individuals concerned about potential\nKEY TERMS\nMatching bias\nThe tendency on the\nWason selection task to\nselect cards matching the\nitems explicitly mentioned\nin the rule.\nDeontic rules\nRules relating to\nobligation and\npermissibility.\nCreated from usyd on 2022-02-17 03:28:25.",
    "678\nThinking and reasoning\ncosts focus on disconfirming evidence whereas those concerned about\npotential benefits focus on confirming evidence.\nFifth, Ragni et al. (2018) evaluated 15 theories of relevance to Wason’s\nselection task. In a large-scale meta-analysis, they found Johnson-Laird’s\n(1983) mental model theory (discussed shortly, pp. 681–683) best predicted\nperformance. In essence, this theory assumes that selections on Wason’s\nselection task depend on two processes:\n(1) There is an intuitive process producing selections matching the rea-\nsoners’ hypothesis (e.g., selection of R in the version of the task\nshown in Figure 14.2).\n(2) There is a more deliberate process producing selections of potential\ncounterexamples to the hypothesis (e.g., selection of 7 in the same\nversion).\nThe extent to which reasoners search for counterexamples depends on\nfactors discussed above including task content, instructions and so on.\nSyllogistic reasoning\nSyllogistic reasoning has been studied for over 2,000 years. A syllogism\nconsists of two premises or statements followed by a conclusion. Here is\nan example: “All A are B; all B are C. Therefore, all A are C”. A syllogism\ncontains three items (A, B and C), with one (B) occurring in both premises.\nThe premises and conclusion all contain one of the following quantifiers:\nall; some; no; and some . . . not.\nWhen presented with a syllogism, you must decide whether the conclu-\nsion is valid assuming the premises are valid. The validity (or otherwise)\nof the conclusion depends only on whether it follows logically from the\npremises – the conclusion’s truth or falsity in the real world is irrelevant.\nConsider the following example:\nPremises\nAll children are obedient.\nAll girl guides are children.\nConclusion\nTherefore, all girl guides are obedient.\nThe conclusion follows logically from the premises. Thus, it is valid regard-\nless of your views about children’s obedience.\nFindings\nVarious biases cause errors in syllogistic reasoning. Of special impor-\ntance is belief bias, the tendency to accept invalid conclusions as valid\nif  believable and to reject valid (but unbelievable) conclusions as invalid\n(theoretical explanations are discussed later). Klauer et al. (2000) investi-\ngated belief bias thoroughly. The conclusions of half their syllogisms were\nbelievable (e.g., “Some fish are not trout”) whereas the others were unbe-\nlievable (e.g., “Some trout are not fish”). Half the syllogisms were valid\nKEY TERMS\nSyllogism\nA type of problem used\nin deductive reasoning;\nthere are two statements\nor premises and a\nconclusion that may or\nmay not follow logically\nfrom the premises.\nBelief bias\nIn syllogistic reasoning,\nthe tendency to accept\ninvalid but believable\nconclusions and reject\nvalid but unbelievable\nones.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n679\nand half invalid; however, some participants\nwere told only one-sixth of the syllogisms\nwere valid whereas others were told five-\nsixths were.\nWhat did Klauer et al. (2000) find? First,\nthere was a base-rate effect: syllogistic rea-\nsoning performance was influenced by the\nperceived probability of syllogisms being\nvalid (see Figure 14.3). Second, there was\nstrong evidence for belief bias. Third, there\nwas a belief-by-logic interaction. Performance\non syllogisms with valid conclusions was\nbetter when those conclusions were believ-\nable, whereas performance on syllogisms with\ninvalid conclusions was worse when those\nconclusions were believable. In sum, reason-\ners’ performance was influenced by factors\nirrelevant to logic.\nStupple and Ball (2008) found with syl-\nlogistic reasoning that unbelievable premises\nwere processed more slowly than believable\nones. This finding suggests people experi-\nenced conflict between their beliefs and what\nthey were asked to assume and resolving this\nconflict was time-consuming.\nSome problems in syllogistic reasoning\noccur because of differences in the meanings\nof expressions in formal logic and everyday\nlife. For example, we often assume “All As\nare Bs” means “All Bs are As” and “Some\nAs are not Bs” means “Some Bs are not As”.\nCeraso and Provitera (1971) spelled out such\npremises unambiguously (e.g., “All As are\nBs, but some Bs are not As”). This greatly\nenhanced reasoning performance. In similar\nfashion, “some” means “some but not all” in\neveryday usage but “at least one and possibly\nall” in formal logic. Schmidt and Thompson\n(2008) found syllogistic reasoning improved\nwhen the meaning of “some” in formal logic\nwas made explicit.\nFinally, people’s syllogistic reasoning per-\nformance is influenced by whether the con-\nclusion matches the premises in surface or superficial features. Here is an\nexample of matching: no A are not B; no B are not C; therefore, no C are\nnot A; and an example of non-matching: all A are B; all B are C; therefore\nno A are not C. In spite of the irrelevance of matching vs non-matching\nto formal logic, people are more likely to accept conclusions matching the\npremises (Stupple et al., 2013).\nFigure 14.3\nPercentage acceptance of conclusions as a function of\nperceived base rate validity (low vs. high), believability of\nconclusions and validity of conclusions.\nBased on data in Klauer et al. (2000). © American Psychological\nAssociation.\nCreated from usyd on 2022-02-17 03:28:25.",
    "680\nThinking and reasoning\nIN THE REAL WORLD: INVALID DEDUCTIVE REASONING\nSo far we have focused on laboratory-based examples of invalid deductive reasoning. However,\nsuch reasoning is also very common in everyday life. Here are a few examples starting with the\npolitician’s syllogism, which is along the following lines:\nPremises\nWe must do something to save the country.\nOur policy is something.\nConclusion\nOur policy will save the country.\nInvalid conditional reasoning occurs frequently in everyday life. Earlier we discussed the logical\nfallacy known as denial of the antecedent. Here is a real-world example:\nPremises\nIf you have got nothing to hide, you have nothing to fear.\nYou have nothing to hide.\nConclusion\nYou have nothing to fear.\nThe above argument is invalid because it implies that people are only interested in privacy\nbecause they have something to hide. In fact, of course, we all have a basic human right to\nprivacy. Ironically, the authorities who argue strongly in favour of greater surveillance of the public\nare often notoriously reluctant to provide information about their own activities!\nFinally, we consider an everyday example of the logical fallacy known as affirmation of the con-\nsequent (discussed earlier, p. 673).\nPremises\nIf the Earth’s climate altered throughout pre-human history, this was due to natural climate\nchange.\nThe Earth’s climate is currently altering.\nConclusion\nNatural climate change is occurring currently.\nThis is clearly an invalid argument. The fact that past climate change was not due to humans\ndoes not necessarily mean that current climate change is not due to human intervention.\nIn sum, many groups in society (e.g. politicians; climate change deniers) are strongly motivated\nto persuade us of the rightness of their beliefs. This often leads them to engage in invalid forms of\nreasoning. The take-home message is that we all need to be sceptical and vigilant when exposed\nto their arguments.\nTHEORIES OF “DEDUCTIVE” REASONING\nHere we will focus on two very influential theoretical approaches to\ndeductive reasoning. First, there is Johnson-Laird’s mental model theory,\nwhich represents a relatively “traditional” approach. Second, we turn our\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n681\nattention to the increasingly popular dual-process approach. The word\ndeductive in the title of this section has been put in quotation marks to indi-\ncate that individuals presented with deductive-reasoning problems often fail\nto use deductive processes when trying to solve them.\nMental models\nJohnson-Laird (e.g., 1983; Johnson-Laird et al., 2018) argues that reasoning\ninvolves constructing mental models. What is a mental model? According\nto Johnson-Laird et al. (2015, p. 202), a mental model is “an iconic rep-\nresentation of a possibility that depicts only those clauses in a compound\nassertion that are true. The mental models of a disjunction, ‘A or B but\nnot both’ accordingly represent two possibilities: possibly (A) and possibly\n(B)”. It is iconic because its structure corresponds to what it represents.\nHere is a concrete example of a mental model:\nPremises\nThe lamp is on the right of the pad.\nThe book is on the left of the pad.\nThe clock is in front of the book.\nThe vase is in front of the lamp.\nConclusion\nThe clock is to the left of the vase.\nAccording to Johnson-Laird (1983), people use the information contained\nin the premises to construct a mental model like this:\nbook\npad\nlamp\nclock\nvase\nThe conclusion the clock is to the left of the vase clearly follows from the\nmental model. The fact we cannot construct a mental model consistent\nwith the premises (but inconsistent with the conclusions) (i.e., we cannot\nconstruct a counterexample) indicates the model is valid.\nHere are the theory’s main assumptions:\n●\nA mental model describing the given situation is constructed and the\nconclusions that follow are generated.\n●\nAn attempt is made to construct alternative models to falsify the conclu-\nsion by finding counterexamples to the conclusion. If a  counterexample\nmodel is not found, the conclusion is deemed valid.\n●\nThe construction of mental models involves the limited resources of\nworking memory (see Chapter 6).\n●\nReasoning problems requiring the construction of several mental\nmodels are harder than those requiring only one mental model because\nthe former impose greater demands on working memory.\n●\nThe principle of truth: “Mental models represent what is true, but not\nwhat is false” (Khemlani & Johnson-Laird, 2017, p. 16). This mini-\nmises demands on working memory.\nKEY TERMS\nMental models\nAn internal representation\nof some possible situation\nor event in the world\nhaving the same structure\nas that situation or event.\nPrinciple of truth\nThe notion that assertions\nare represented by\nforming mental models\nconcerning what is true\nwhile ignoring what is\nfalse.\nCreated from usyd on 2022-02-17 03:28:25.",
    "682\nThinking and reasoning\nFindings\nSeveral studies support the notion that working memory plays a central\nrole in the formation of mental models. Brunyé et  al. (2008) found the\ncentral executive (see Glossary) and visuo-spatial sketchpad (see Glossary)\ncomponents of the working memory system were heavily involved in con-\nstructing mental models. Copeland and Radvansky (2004) found working\nmemory capacity (see Glossary) correlated +.42 with syllogistic reasoning\nperformance.\nKhemlani and Johnson-Laird (2017) reviewed 20 studies testing the\nprinciple of truth. These studies used various reasoning tasks, in all of which\nindividuals failing to represent what is false in their mental models would\nproduce illusory inferences. Numerous illusory inferences were drawn. In\ncontrast, performance was very good with similar problems where adher-\nence to the principle of truth was sufficient to produce the correct answer.\nConsider the following problem:\nOnly one of the following premises is true about a particular hand of\ncards:\nThere is a king in the hand or there is an ace, or both.\nThere is a queen in the hand or there is an ace, or both.\nThere is a jack in the hand or there is a 10, or both.\nIs it possible there is an ace in the hand?\nWhat is your answer? Nearly everyone says “Yes”, but this is wrong!\nIf there were an ace in the hand, both the first two premises would be true.\nHowever, the problem states that only one of the premises is true.\nTheoretically, individuals make illusory inferences because they ignore\nwhat is false. As predicted, people are less susceptible to such inferences if\nexplicitly instructed to falsify the premises of reasoning problems (Newsome\n& Johnson-Laird, 2006).\nKhemlani and Johnson-Laird (2012) carried out a meta-analysis of\nsyllogistic reasoning studies to compare seven theories. The mental model\ntheory was best at predicting participants’ responses with a 95% success\nrate. However, it was relatively weak at rejecting responses people do not\nproduce.\nAccording to the theory, people search for counterexamples after\nhaving constructed their initial mental model and generated a conclu-\nsion. As a result, they may construct several mental models and con-\nsider several conclusions. Newstead et  al. (1999) obtained no support\nfor this   conclusion: the average number of conclusions considered with\nmultiple- and single-model syllogisms was very low (1.12. and 1.05,\nrespectively).\nKhemlani et al. (2012) also found that people generate relatively few\ncounterexamples. Participants were given this problem: They’re not living\nadult males. So, who could they be? There are seven possibilities (e.g., dead\nadult males; living girls) but participants listed only four possibilities on\naverage.\nThe theory struggles with ambiguous reasoning problems. Here is an\nexample (Ragni & Knauff, 2013):\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n683\nThe Porsche is to the right of the Ferrari.\nThe Beetle is to the left of the Porsche.\nThe Dodge is in front of the Beetle.\nThe Volvo is in front of the Porsche.\nThere is no definite answer to the question “Which relation holds\nbetween the Beetle and the Ferrari?”. Mental model theory does not\npredict which answer will be given by most participants. Ragni and Knauff\n(2013) argued that reasoners prefer easily constructed mental models (e.g.,\nthe Beetle is to the left of the Ferrari in the above problem). Their findings\nsupported their theory over mental model theory.\nEvaluation\nThe theory has several successes to its credit. First, the theory compares\nwell against other theories of reasoning (Khemlani & Johnson-Laird, 2012;\nJohnson-Laird et al., 2018) and also performs well when predicting perfor-\nmance on Wason’s selection task (Ragni et al., 2018). Second, as predicted,\nworking memory is involved in the construction of mental models. Third,\nthere is substantial support for the principle of truth. Fourth, as discussed\nlater (pp. 704–705), the theory has recently been developed to account for\nreasoning about probabilities (Johnson-Laird et al., 2015).\nWhat are the theory’s limitations? First, most people find deductive\nreasoning very hard and so resort to easier forms of processing (discussed\nshortly). Second, most people do not typically search for  counterexamples\nas predicted theoretically. Third, the processes involved in forming mental\nmodels are underspecified. It is assumed people use background knowledge\nwhen forming mental models, but the theory does not spell how we decide\nwhich information to include in a mental model. Fourth, mental model\ntheory often fails to predict people’s answers with ambiguous reasoning\nproblems (e.g., Ragni & Knauff, 2013).\nDual-process theories\nSeveral theorists (e.g., Kahneman, 2003; see Chapter 13 and Evans, 2018)\nhave proposed dual-process (sometimes called dual-system) theoreti-\ncal accounts of human reasoning and other aspects of higher-level cog-\nnition. While they differ from each other in various ways, “dual-process\ntheories should be viewed as a family whose members share some fea-\ntures . . . it includes close relatives . . . as well as distant cousins” (Evans,\n2018, p. 151). Commonalities among dual-process theories are discussed\nbelow.\nEvans and Stanovich (2013a,b) provided an integrative account of\ndual-process theories based on a distinction between Type 1 intuitive pro-\ncessing and Type 2 reflective processing. One defining feature of Type 1\nprocessing is autonomy (it is mandatory or necessary when the appropriate\ntriggering stimuli are encountered). Its other defining feature is the lack of\ninvolvement of working memory (see Glossary). Note there is substantial\ndiversity among Type 1 processes. In contrast, a defining feature of Type\n2 processing is that it requires working memory. Its other defining feature\nCreated from usyd on 2022-02-17 03:28:25.",
    "684\nThinking and reasoning\nis cognitive decoupling or mental simulation – hypothetical reasoning not\nconstrained by the immediate environment.\nEvans and Stanovich (2013a,b) also identified several features often\n(but not invariably) associated with the two types of processing. Features\nof Type 1 processing include the following: fast; high capacity; parallel;\nnon-conscious; automatic; and independent of cognitive ability. Features\nof Type 2 processing include the following: slow; capacity-limited; serial;\nconscious; controlled; and correlated with cognitive ability.\nEvans and Stanovich (2013a,b) assumed that individuals trying to\nsolve reasoning problems initially use intuitive Type 1 processing to gener-\nate a rapid heuristic answer which may be corrected by a subsequent more\ndeliberate answer produced via slow Type 2 processing. A key assumption\nis that reasoning performance will generally (but not invariably) be supe-\nrior when it involves Type 2 processing in addition to Type 1 processing.\nThis approach is often referred to as the default-interventionist model.\nWhy is it wrong to equate Type 1 processing with biased (and often\nincorrect) reasoning and Type 2 processing with correct reasoning? This\nquestion was addressed by Evans (2018). He pointed out that we have\nall had the experience of using effortful Type 2 processing when trying to\nsolve a problem in mathematics without producing the correct response.\nIn addition, correct reasoning does not always require Type 2 processing:\n“We often get things right via habit or reliable intuition [both involving\nType 1 processing], as all dual-process authors agree” (p. 163).\nWe will start by considering predictions made by early dual-process\ntheories of reasoning (e.g., Evans, 2006). According to these theories,\nvarious factors increase reasoners’ use of time-consuming and effortful\nanalytic or Type 2 processes:\n(1) the reasoners are highly intelligent;\n(2) sufficient time is available for Type 2 processing;\n(3) reasoners do not need to perform a secondary demanding task at the\nsame time.\nFindings\nMuch research to test the above predictions has focused on belief bias (dis-\ncussed earlier, pp. 678–679; see Ball & Thompson, 2018). This bias occurs\nin syllogistic reasoning when a logically valid but unbelievable conclu-\nsion is rejected as invalid, or a logically invalid but believable conclusion\nis accepted as valid. According to dual-process theories, there will be less\nbelief bias (and superior performance) when Type 2 processes are used.\nThus, reasoners’ use of Type 2 processes will generally reduce belief bias.\nThere is much support for the first prediction that more intelligent rea-\nsoners exhibit less belief bias than less intelligent ones (e.g., Trippas et al.,\n2013). More intelligent reasoners might show less belief bias because of\ntheir high cognitive ability or because they choose to adopt an analytic\ncognitive style. Trippas et al. (2015) found the willingness to engage in ana-\nlytic thinking was more important. These findings are consistent with dual-\nprocess theory because they emphasise the role played by Type 2 processes\nin reducing belief bias and enhancing reasoning performance.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n685\nThere is also support for the second prediction that there should be\nless belief bias with ample thinking time (e.g., Evans and Curtis-Holmes,\n2005) because restricting thinking time reduces reasoners’ ability to use\nType 2 processes. In similar fashion, errors in conditional reasoning occur\nmore often when reasoners must respond rapidly (Markovits et al., 2013;\ndiscussed earlier, p. 675).\nDe Neys (2006) tested the third prediction above by presenting rea-\nsoning problems on their own or with a secondary task low or high in its\ndemands. As predicted, reasoners exhibited much more belief bias when\nperforming a demanding secondary task.\nTheoretical differences and developments\nWe have seen early dual-process theories of reasoning generated many pre-\ndictions supported by experimental evidence. However, these theories were\noversimplified. For example, as we will see, the assumption that correct rea-\nsoning performance reflects Type 2 processing whereas incorrect reasoning\nperformance reflects Type 1 processing is only partially correct.\nAnother oversimplification concerns the relationship between Type 1\nand 2 processing during reasoning tasks. As we saw earlier, several theo-\nrists (e.g., Evans & Stanovich, 2013a) proposed serial models for reasoning\nin which Type 1 processing provides a rapid intuitive answer. This is often\nfollowed by slow Type 2 processing which may lead to the initial intuitive\nanswer being corrected and replaced by a more reflective answer.\nDe Neys (2012) argued the above theoretical position is too narrow\nand incomplete. He identified three models of how Type 1 and 2 processing\ncombine (see Figure 14.4).\n(1) The traditional theoretical approach described above (serial model)\ninvolves serial processing with intuitive (or Type 1) processing being\nfollowed by deliberate (or Type 2) processing.\nFigure 14.4\nThree models of the\nrelationship between the\nintuitive and deliberate\nsystems. (a) Serial model:\nintuitive processing may\nor may not be followed by\ndeliberate processing. (b)\nParallel model: intuitive\nand deliberate processing\nare both involved from\nthe outset. (c) Logical\nintuition model: deliberate\nprocessing is triggered if\nthere is a conflict between\ninitial intuitive heuristic and\nintuitive logical responses\nproduced in parallel.\nFrom De Neys (2012). Reprinted\nby permission of SAGE\nPublications.\nCreated from usyd on 2022-02-17 03:28:25.",
    "686\nThinking and reasoning\n(2) In the parallel model, intuitive (Type 1) and deliberate (Type 2) pro-\ncesses occur at the same time. This model is wasteful of cognitive\nresources because effortful processes are always used.\n(3) According to the logical intuition model (advocated by De Neys, 2012,\n2014), two types of intuitive responses (intuitive heuristic and intui-\ntive logical) are activated in parallel. If these two responses conflict,\ndeliberate (Type 2) processes resolve matters. The notion of intuitive\nlogical processing sounds paradoxical. However, De Neys argued that\ntraditional logical principles can be activated fairly automatically.\nFindings\nEvidence consistent with the logical intuition model was reported by De\nNeys et al. (2010) using a syllogistic reasoning task involving conflict (or no\nconflict) between the logical validity and believability of the conclusions.\nThere was strong belief bias – accuracy was only 52% on conflict (belief\nbias) trials compared to 89% on non-conflict trials.\nThe very poor performance on conflict problems (marginally greater\nthan chance) suggests reasoners failed to detect their logical structure.\nHowever, De Neys et al. (2010) found participants had greater physiolog-\nical arousal on conflict trials suggesting conflict was registered within the\nprocessing system below the conscious level. The implication is that some\nlogical processing can be intuitive rather than analytic.\nFurther support for the logical intuition model was reported by Trippas\net al. (2016). Participants simply decided how much they liked various sen-\ntences. Sentences following logically from preceding sentences were rated\nmore likeable than those that did not. Since the task made no reference to\nlogical validity, this finding suggests participants had an implicit sensitivity\nto logical structure based primarily involving Type 1 processes.\nBago and De Neys (2017) presented participants with various syllo-\ngistic reasoning problems involving conflict between the believability and\nvalidity of the conclusion. The participants provided two responses to each\nproblem: (1) a fast, intuitive response; and (2) a much slower and more\ndeliberate response.\nAccording to the default-interventionist model (e.g., Evans &\nStanovich, 2013a; discussed earlier, pp. 683–684), we would predict low\nlevels of accurate fast responses and substantially more correct deliber-\nate responses than intuitive ones. Neither prediction was supported. On\naverage, 44% of the fast responses were accurate, and only 7% of initially\ninaccurate fast responses were followed by accurate slow responses.\nIn one of their experiments, Bago and De Neys (2017) used the same\nsyllogistic reasoning task described above. However, there was an additional\nrequirement on participants – they performed a secondary demanding task\nat the same time to reduce their engagement in Type 2 analytic process-\ning. Nevertheless, 49% of fast responses on conflict problems were correct.\nOverall, these findings support the logical intuition model in that fast (and\npresumably Type 1) processes often produce logically correct responses.\nSimilar findings to those of Bago and De Neys (2017) have been\nreported in research on conditional reasoning (see Glossary; see\npp.  673–676). Newman et al. (2017) used conditional-reasoning problems\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n687\ninvolving belief bias (see Glossary). Reasoners provided a fast and a slow\nresponse to each problem. Contrary to the predictions of early dual-\nprocess theories, fast responses were often correct based on logical validity\nand slow responses were often incorrect and exhibited belief bias. These\nfindings suggest a blurring of the distinction between Type 1 and Type\n2  processes – there was a mixture of logically correct and belief-based\nresponses regardless of whether Type 1 processes (fast responses) or Type\n2 processes (slow responses) were involved.\nImagine we presented reasoners with conditional-reasoning problems\ninvolving a conflict between logical validity and believability (e.g., “If a child\nis happy, then it cries; suppose a child laughs; does it follow that the child\nis happy?”). According to logic, the correct answer is “No”. According to\nbeliefs and our knowledge of the world, the answer is “Yes”. Trippas et al.\n(2017) used problems like that but with the novel twist that reasoners were\nsometimes told to answer the question based on their beliefs rather than logic.\nAccording to early dual-process theories (e.g., the default-intervention-\nist model), responding on the basis of belief should involve Type 1 process-\ning and so should be faster than responding on the basis of logic (involving\nType 2 processing). In addition, the believability of the conclusion (accessed\nrapidly) should interfere with logic-based responses (accessed slowly) but\nthe reverse should not be the case.\nNeither prediction was supported (Trippas et al., 2017). Response times\nwere comparable on belief-based and logic-based trials, and the logical\nvalidity of the conclusion interfered with belief-based responding. However,\nthese findings are entirely consistent with parallel-processing theories.\nThompson et al. (2018) carried out a similar study. Participants differ-\ning in cognitive ability received incongruent reasoning problems involving\na conflict between belief and logic and had to respond on the basis of belief\nor logic. There were two main findings (see Figure 14.5):\n1.0\nIncongruent\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n1st quartile\n2nd quartile\n3rd quartile\n4th quartile\nLogic\nProportion correct\nBelief\nFigure 14.5\nProportion correct on\nincongruent syllogisms as\na function of instructions\n(respond on the basis\nof logic or belief)\nand cognitive ability\n(1st quartile = lowest;\n4th quartile = highest).\nFrom Thompson et al. (2018).\nCreated from usyd on 2022-02-17 03:28:25.",
    "688\nThinking and reasoning\n(1) The more intelligent reasoners had greater difficulty resolving con-\nflict when providing belief-based responses rather than logic-based\nresponses.\n(2) The less intelligent reasoners exhibited the opposite pattern.\nThese findings suggest more intelligent individuals generate logic-based\nresponses faster than belief-based ones, whereas less intelligent individuals\ngenerate belief-based responses faster.\nWhat conclusions should we draw? First, rather than arguing belief-\nbased responses involve fast Type 1 processing whereas logic-based\nresponses involve slow Type 2 processing, we need to consider individ-\nual differences. Second, “If responses (belief- or logic-based) can be gen-\nerated either quickly and effortlessly or slowly and deliberately, perhaps\nthese responses merely differ on a single dimension, namely, complexity”\n(Newman et al., 2017, p. 1165).\nWhat causes Type 2 processing?\nWhat determines whether reasoners’ responses are based on analytic (Type\n2) processing or whether they reflect only intuitive (Type 1) processes?\nThe theories discussed above address this issue. Traditional serial models\nassume that Type 2 processes monitor the output of Type 1 processes and it\nis this monitoring process that determines whether reasoning performance\nis based on Type 2 processes. In similar fashion, many parallel models\nassume Type 2 reasoning is triggered when conflict monitoring (involving\nType 2 processing) leads to conflict detection. What is puzzling about all\nthese theories is that, “They assume that Type 2 processing is effectively\ncaused by itself” (Pennycook et al., 2015, p. 36).\nAckerman and Thompson (2017, p. 607) provided a detailed account\nof meta-reasoning: “The processes that monitor the progress of our rea-\nsoning and problem-solving activities and regulate the time and effort\ndevoted to them” (see Figure 14.6). Monitoring processes assess the proba-\nbility of success before, during and after performing a reasoning task. The\nmost important monitoring feature is the feeling of rightness: “the degree\nto which the first solution that comes to mind feels right” (p. 608). Only\nwhen this feeling is weak do reasoners engage in substantial Type 2 or\nanalytic processing.\nThompson et al. (2011) studied the role of feeling-of-rightness ratings\non the use of Type 2 processes with syllogistic and conditional-reasoning\ntasks. Participants provided an initial answer immediately after reading\neach problem (intuitive, or Type 1, answer) followed by an assessment\nof that answer’s correctness (feeling of rightness). Participants then had\nunlimited time to reconsider their initial answer and provide a final ana-\nlytic, or Type 2, answer. As predicted, participants spent longer reconsider-\ning their intuitive answer and were more likely to change it when they had\nlow feelings of rightness.\nWhat determines feeling-of-rightness ratings? Thompson et al. (2013b)\naddressed this issue in a study on syllogistic reasoning. Participants produced\nthe first response that came to mind, provided a feeling-of- rightness rating,\nand then produced a slower, more deliberate response. Feeling-of-rightness\nKEY TERM\nMeta-reasoning\nMonitoring processes\nthat influence the time,\neffort and strategies used\nduring reasoning and\nproblem solving.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n689\nratings were higher when the first response was produced rapidly rather\nthan slowly, indicating the importance of response fluency.\nMost research indicates response fluency is a fallible measure of response\naccuracy. For example, people give higher feeling-of-rightness ratings to\nreasoning problems having familiar rather than unfamiliar content even\nwhen the former problems are harder (Ackerman & Thompson, 2017).\nEvaluation\nWhat are the strengths of the contemporary dual-process approach? First,\ndual-process theories have become increasingly popular and wide-ranging.\nFor example, they provide explanations for syllogistic reasoning and con-\nditional reasoning (Verschueren et al, 2005, discussed earlier, pp. 674–675).\nIn addition, such theories account for findings in problem solving (see\nChapter 12), judgement and decision-making (see Chapter 13). Second,\n“Dual-process theory . . . provides a valuable high-level framework within\nwhich more specific and testable models can be developed” (Evans, 2018,\np. 163).\nThird, there have been increasingly sophisticated attempts to clarify\nthe relationship between Type 1 and Type 2 processes (e.g., whether they\nare used serially or in parallel). Fourth, we have an enhanced understand-\ning of meta-reasoning processes (especially those involved in monitoring).\nFifth, recent theory and research are starting to take account of the flexi-\nbility of processing on reasoning problems due to the precise form of the\nproblem and individual differences (Thompson et al., 2018).\nWhat are the limitations with the dual-process approach? First, the pro-\ncesses used by reasoners vary depending on their abilities and preferences,\nIdentify components\nand goal\nAnalytic processing\nAnswer choice\nFinal\nconfdence\nFeeling\nof error\nFinal judgement\nof solvability\nIntermediate\nconfdence\nFeeling of\nrightness\nInitial judgement\nof solvability\nAssessment of\nknowledge and\nstrategies\nMeta-cognitive\nmonitoring\nMeta-cognitive\ncontrol\nThink? Search\nmemory? Change\nstrategy? Stop?\nTime-\nline\nReasoning\nMeta-reasoning\nGenerate an initial,\nautonomous, response\nEngage in solving?\nGive up?\nProvide the initial\nresponse?\nReconsider?\nProvide current\nresponse? Try\nanother strategy?\nProvide chosen\nanswer?\n“Don’t know”?\nSeek help?\nFigure 14.6\nThe approximate time\ncourses of reasoning and\nmeta-reasoning processes\nduring reasoning and\nproblem solving.\nFrom Ackerman & Thompson\n(2017).\nCreated from usyd on 2022-02-17 03:28:25.",
    "690\nThinking and reasoning\ntheir motivation and their task requirements. Melnikoff and Bargh (2018;\nsee Chapter 13) identified two ways many dual-process theories are over-\nsimplified: (1) they often imply that Type 1 processes are “bad” and error-\nprone, whereas Type 2 processes are “good”; and (2) they assume many\ncognitive processes can be assigned to just two types.\nSecond, “The absence of a clear and general definition of a Type 1\nor Type 2 response does create difficulty for researchers wishing to test\n[dual-process] theories” (Evans, 2018, p. 163). For example, it is often\nassumed theoretically that fast responses reflect Type 1 processing and are\nerror-prone whereas slow responses reflect Type 2 processing and are gen-\nerally accurate. However, we have discussed various studies disconfirming\nthose assumptions.\nThird, there has been a rapid increase in the findings that require to be\nexplained theoretically, and theories have not kept pace with this increase.\nFor example, meta-reasoning often plays an important role in influenc-\ning reasoners’ processing strategies and performance. As yet, however, no\ntheorists have integrated meta-reasoning processes into a comprehensive\ndual-process theory of reasoning.\nBRAIN SYSTEMS IN REASONING\nIn recent years, there has been increased research designed to identify\nthe brain regions associated with deductive reasoning. Prado et al. (2011)\nreported a meta-analytic review of 28 neuroimaging studies on deductive\nreasoning (see Figure 14.7). They obtained evidence for a core brain system\ncentred in the left hemisphere involving frontal and parietal areas. Specific\nbrain areas activated during deductive reasoning included the inferior\nfrontal gyrus, the medial frontal gyrus, the precentral gyrus and the basal\nganglia.\nCoetzee and Monti (2018) reported findings broadly consistent with\nthose of Prado et  al. (2011). They used fMRI to assess brain activation\nwhile participants performed deductive-reasoning tasks. There were two\nkey findings. First, core regions (left rostrolateral cortex, in BA10; medial\nprefrontal cortex, in BA8) were more strongly activated with complex\n(rather than) simple deductive reasoning. Second, the main language areas\nFigure 14.7\nBrain regions most\nconsistently activated\nacross 28 studies of\ndeductive reasoning.\nPG = precentral gyrus;\nMFG = middle frontal\ngyrus; PPC = posterior\nparietal cortex;\nIFG = inferior frontal gyrus;\nBG = basal ganglia;\nMeFG = medial frontal\ngyrus.\nFrom Prado et al. (2011).\n© Massachusetts Institute of\nTechnology, by permission of\nthe MIT Press.\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n691\nin the left hemisphere had very little involvement in deductive reasoning –\ntheir main role was in encoding problems presented verbally.\nThe left hemisphere dominance reported by Prado et al. (2011) has also\nbeen found in patient data. Goel et al. (2007) studied patients with damage\nto the left or right parietal cortex. Those with left-side damage performed\nworse than those with right-side damage on reasoning tasks when complete\ninformation was provided. In similar fashion, Reverberi et al. (2009) found\npatients with damage to the right frontal cortex had intact deductive rea-\nsoning whereas those with left frontal damage showed reasoning deficits.\nStrong evidence for the crucial role of the left hemisphere in deduc-\ntive reasoning was reported by Urbanski et  al. (2016) in a meta-analytic\nreview (see Chapter 12). Impaired analogical reasoning was more strongly\nassociated with damage to the left rostrolateral prefrontal cortex area than\ndamage to any other area. Goel and Waechter (2018) provide an overview\nof research on reasoning in brain-damage patients.\nHow can we explain the left hemisphere’s role in deductive reason-\ning? Gazzaniga et al. (e.g., 2008; see Chapter 16) argued there is a single\nconscious system based in the left hemisphere. This system is the inter-\npreter, which tries to make coherent sense of the information available to\nit. According to Prado et al. (2011), the core brain system they identified in\nthe left hemisphere may depend at least in part on this interpreter.\nIndividual differences\nLarge individual differences have been found in belief bias (the tendency to\naccept invalid but believable conclusions and reject valid but unbelievable\nones). As we saw earlier, more intelligent individuals exhibit less belief bias\nbecause they make more use of analytic processing strategies (e.g., Trippas\net al., 2015, see p. 684). According to Houdé and Borst’s (2015) inhibitory\ncontrol theory of reasoning, the ability to inhibit incorrect responses pro-\nduced by Type 1 thinking is of crucial importance in reducing belief bias.\nHoudé and Borst’s (2015) theory was based in part on research by\nTsujii and Watanabe (2009). They argued the right inferior frontal cortex\nis involved in inhibiting incorrect responses triggered by Type 1 processes.\nAccordingly, they predicted individuals with high levels of activation in\nthat area would have less belief bias than those with low activation. In their\nstudy, the reasoning task was accompanied by a secondary task involving\nlow or high cognitive load.\nThe findings supported their hypothesis (see Figure 14.8). High per-\nformance accuracy (and thus low belief bias) were strongly associated\nwith activation in the right inferior frontal cortex regardless of secondary\ntask. In addition, this brain region was less activated under high- than\nlow-load conditions and there was much more belief bias in the high-load\ncondition.\nSequence of processes\nNeuroimaging data typically indicate the brain areas activated during rea-\nsoning, but provide no information about when each brain area was acti-\nvated. Bonnefond et  al. (2013) used magneto-encephalography (MEG)\nKEY TERM\nMagneto-\nencephalography (MEG)\nA non-invasive brain-\nscanning technique\nbased on recording the\nmagnetic fields generated\nby brain activity; it has\ngood spatial and temporal\nresolution.\nCreated from usyd on 2022-02-17 03:28:25.",
    "692\nThinking and reasoning\nto study brain processes associated with conditional reasoning focusing\non modus ponens (If P then Q:P//Therefore, Q; see earlier in the chapter,\npp. 673–674).\nBonnefond et al. (2013) reported two main findings. First, participants\nexpected the second premise to match the first one (e.g., P following If P\nthen Q): there was enhanced brain activity 300 ms after presentation of\nthe second premise when it failed to match the first one. Second, when\nthe second premise matched the first one, participants generated the infer-\nence that followed validly from the two premises (activation in the parieto-\nfrontal network at 400 ms). This occurred sometime before the conclusion\nwas presented. Thus, participants engaged in much anticipatory processing\nbefore the second premise and conclusion were presented.\nMore evidence that reasoners form expectations was reported by\nBonnefond et al. (2014) in a study on conditional reasoning involving valid\nmodus ponens inferences. Here is an example:\nPremises\nIf John studies hard, he will pass the test.\nHe studies hard.\nConclusion\nJohn passes the test.\nFigure 14.8\nRelationships between\nreasoning task performance\n(accuracy) and inferior\nfrontal cortex activity in the\nleft hemisphere (LH) and\nthe right hemisphere (RH)\nin (a) the low-load condition\nand (b) the high-load\ncondition.\nFrom Tsujii and Watanabe\n(2009). Reprinted with\npermission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n693\nThe conclusion is logically valid. However, many people can readily\nthink of additional considerations making the conclusion invalid (e.g.,\nJohn has a low IQ; the test was very hard).\nBonnefond et  al. (2014) recorded event-related potentials (ERPs; see\nGlossary) while participants read the conclusion. They reported two key\nfindings. First, valid conclusions were much less likely to be accepted\nwhen there were several additional considerations rather than only a few.\nSecond, presentation of a valid conclusion was more associated with an\nERP pattern indicative of violated expectations when there were several\nadditional considerations.\nEvaluation\nWhat are the strengths of the cognitive neuroscience approach to reason-\ning? According to Goel and Waechter (2018, p. 240), its main contribution\nhas been “the fractionation of the [reasoning] system and the identification\nof some of the component parts, such as a conflict detection system [and]\na system sensitive to conceptual content”. However, Goel and Waechter\nadmitted the data tell us little about how these systems interact.\nSecond, progress has been made in identifying important executive or\ncontrol processes involved in effective deductive reasoning. For example, it\nappears that inhibitory processes are used to prevent incorrect responses\n(e.g., Houdé & Borst, 2015).\nThird, many reasoners form expectations in conditional reasoning\nprior to the presentation of the second premise and the conclusion. This\nanticipatory processing is an important new finding given that reasoners\nmight equally well await the presentation of the conclusion before engag-\ning in full processing.\nWhat are the limitations of the cognitive neuroscience approach? First,\nmuch research is based on oversimplified assumptions (e.g., there is a “rea-\nsoning module”: Goel & Waechter, 2018, p. 232). In fact, “The brain did\nnot develop a dedicated device for reasoning . . . Reasoning . . . is associ-\nated with an internally-driven dynamics: processing times and stages, and\nbrain geometry are largely unconstrained” (Papo, 2015, p. 2).\nSecond, relatively little research has focused on testing contemporary\ntheories (e.g., dual-process theories). For example, only a few studies (e.g.,\nBonnefond et al., 2014) have provided evidence of the brain areas associ-\nated with Type 1 intuitive processing (Oaksford, 2015).\nThird, and related to the second point, most research in this area has\nused functional magnetic resonance imaging (fMRI; see Glossary). It has\nlimited temporal resolution meaning we cannot establish precisely when\nany given brain area is involved in reasoning. This makes it hard to iden-\ntify rapid Type 1 processes using fMRI.\nFourth, there are problems with Prado et  al.’s (2011) identification\nof their core left-hemisphere brain system with Gazzaniga’s interpreter.\nThis is problematical since the interpreter is not specifically involved in\ndeductive reasoning but is more involved in drawing elaborative inferences\n(Oaksford, 2015).\nCreated from usyd on 2022-02-17 03:28:25.",
    "694\nThinking and reasoning\nINFORMAL REASONING\nTraditional research on deductive reasoning is artificial because it empha-\nsises the role of formal logic and treats past knowledge as irrelevant. As\nmentioned earlier, these limitations have led to the rapid development of\nresearch on informal reasoning (see Glossary) designed to assess how rea-\nsoning depends on knowledge and experience rather than logic.\nThe switch in research from formal or deductive reasoning to infor-\nmal reasoning is very important. Elqayam (2018, p. 145) discussed the\nemergence of a new paradigm, according to which “We reason, not with\nthe binary truth and falsity of classical logic, but with the many shades of\nuncertainty and of degrees of belief”. Thus, the contemporary focus is on\nprobabilities.\nThe content of an argument is generally important in informal reason-\ning but (in principle) is irrelevant in formal deductive reasoning. Consider\nthe following superficially similar arguments (Hahn & Oaksford, 2007):\n(a) Ghosts exist because no one has proved they do not.\n(b) The drug is safe because we have found no evidence that it is not.\nThe implausibility of ghosts existing means most people find (a) much less\npersuasive than (b).\nAnother difference is that contextual factors are important in informal\nreasoning but not formal deductive reasoning. For example, in informal\nreasoning we are typically more persuaded by an expert’s arguments than\nthose of a non-expert (Walton, 2010).\nWe turn now to the most important difference between deductive and\ninformal reasoning. As Elqayam (2018) noted, traditional research on\ndeductive reasoning is based on binary logic. We must assume the initial\npremises or statements in a problem are definitely true and then we decide\nwhether the conclusion necessarily follows (answering “yes” or “no”). In\ncontrast, informal (or everyday) reasoning is all about probabilities – we\nregard most statements, arguments or conclusions as possibly or probably\ntrue rather than certainly true or certainly false.\nWe can see the importance of the above differences by considering\nfallacies (Hahn & Oaksford, 2014). Take the straw man fallacy in which\nsomeone else’s views are misrepresented by distorting or weakening them.\nAccording to classical logic, such fallacies are totally inadequate arguments\nunsupported by logic. However, that position is too extreme given there are\nvarious forms of straw man argument (Aikin & Casey, 2016). One version\nof the straw man fallacy (the weak man fallacy) involves selecting one’s\nopponent’s weakest arguments without distorting them and then trying to\ndemolish. This version seems legitimate and so is not a fallacy. There is\nmore on fallacies shortly (see pp. 700–701).\nFinally, the reasoner’s motives often differ in deductive reasoning com-\npared to informal reasoning. Individuals solving deductive-reasoning prob-\nlems are supposed to be motivated to reason accurately and logically. In\ncontrast, much informal reasoning occurs in social contexts and involves\nproducing arguments that will persuade other people. More generally,\npeople are “natural-born arguers” (Mercier et  al., 2017, p. 1), and “their\nKEY TERM\nStraw man fallacy\nRefuting an opponent’s\nviews by misrepresenting\nthem in some way.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n695\nreasoning seeks to identify reasons that support their . . . prior beliefs or\ndecisions” (p. 4).\nIn sum, there several differences between deductive and informal rea-\nsoning. However, the processes used by most individuals confronted by\ndeductive-reasoning tasks are closer to informal than deductive reasoning.\nFor example, many reasoners exhibit belief bias with syllogistic  reasoning –\nthey accept invalid but believable conclusions and reject valid but unbeliev-\nable ones (see earlier in the chapter, pp. 678–679). In essence, belief bias\noccurs when people make use of their world knowledge when reasoning\neven though they have been told to ignore such knowledge. Such find-\nings suggest the value of studying informal reasoning processes directly by\nusing informal-reasoning tasks rather than indirectly via the errors made\non formal logic tasks.\nFindings: motivation\nMany people’s informal reasoning and thinking are seriously flawed. For\nexample, tens of millions of Americans believe the moon landing was a hoax,\nthat global warming is not a problem, and do not believe humans evolved\nfrom apes. Why is this the case? According to Thagard (2011, pp. 156–157),\nthe answer lies in motivated inference, which “occurs when people distort\ntheir judgements because of their underlying personal goals . . . motivated\ninference is based on wishes, not facts”. Supporting evidence is discussed in\nthe Box on climate change.\nIN THE REAL WORLD: DOES CLIMATE CHANGE EXIST?\nOver 95% of the world’s greatest experts on climate believe in climate change. However, many\npeople refuse to accept this strong scientific consensus. Climate change deniers show evidence\nof distorted memory. For example, Howe and Leiserowitz (2013) tested Americans’ memory of the\nprevious unusually hot summer. Those most dismissive of global warming were only half as likely\nas those most alarmed by it to remember the preceding summer had been very hot.\nLeviston et  al. (2013) discovered another distortion. Australian disbelievers in climate change\ngrossly overestimated the percentage of other people holding the same views (43% vs the actual\nfigure of 6%). Individuals exhibiting this high false consensus bias were less likely than others to\nchange their opinions over time.\nCann and Raymond (2018) reported evidence that those opposing climate change increas-\ningly resort to attacks on the integrity of climate scientists rather than the uncertainties of climate\nscience. This is an example of the ad hominem fallacy – dismissing an argument by belittling the\nperson advocating the argument.\nThe association between beliefs about global warming and political ideology is strongest in the\nUnited States. For example, Kahan (2015) found 75% of Americans with left-wing or liberal views\nagreed there is solid evidence of global warming compared to only 22% of those with right-wing or\nconservative views. In general, Americans strongly supporting the industrial capitalist system (e.g.,\nright-wing individuals; men) are most likely to be sceptical of global warming (McCright et al., 2016).\nCampbell and Kay (2014) asked right-wing Americans to indicate whether they believed in climate\nchange in the context of two possible solutions (restrictive emissions policies or green technol-\nogy). Far fewer indicated a belief in climate change when the proposed solution was undesirable\nKEY TERM\nAd hominem fallacy\nDiscrediting an argument\nby attacking the person\nmaking the argument.\nCreated from usyd on 2022-02-17 03:28:25.",
    "696\nThinking and reasoning\n(restrictive emissions) rather than desirable: 22% vs 55%. This is an example of solution aversion\n(see Glossary). It is irrational because the existence of climate change is totally independent of the\ndesirability of any proposed solutions.\nWe might expect individuals having high science literacy and numeracy to be most concerned\nabout climate change. In fact, cultural values are much more important. Kahan et al. (2012) iden-\ntified two groups having different values: (1) egalitarian communitarians believing in equality and\nthe value of society; (2) hierarchical individualists believing in a hierarchical society and personal\nresponsibility. Both groups estimated the risks of climate change.\nWhat did Kahan et al. (2012) find? First, the impact of science literacy and numeracy was surpris-\ningly small (see Figure 14.9). Second, egalitarian communitarians regarded climate-change risks as\nconsiderably greater than hierarchical individualists.\nHow can we explain the above findings? In essence, “Positions on climate change have come\nto signify the kind of person one is. People whose beliefs are at odds with those of the people\nwith whom they share their basic cultural commitments risk being labelled as weird” (Kahan, 2012,\np.  255). This explains why many disbelievers in climate change largely ignore the scientific evi-\ndence and show a false consensus bias.\nFigure 14.9\nMean responses to the question “How much risk do you believe climate change poses\nto human health, safety or prosperity?” by individuals who were low or high in science\nliteracy/numeracy and who were egalitarian communitarians or hierarchical individualists.\nFrom Kahan et al. (2012).\nThe notion of motivated inference resembles that of myside bias, which\nis the tendency for people to select and interpret information in a manner\nbiased towards their prior beliefs. Stanovich and West (2007) asked students\nto rate the accuracy of contentious (but factually correct)  propositions such\nas the following:\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n697\n(1) College students who drink alcohol while in college are more likely to\nbecome alcoholic in later life.\n(2) The gap in salary between men and women generally disappears when\nthey are employed in the same position.\nWhat did Stanovich and West (2007) find? Students who regularly drank\nalcohol rated the accuracy of proposition (1) lower than those who did not.\nWomen rated the accuracy of proposition (2) lower than men. Thus, there\nwas strong myside bias with its extent depending on the strength of par-\nticipants’ prior beliefs. However, the extent of myside bias was unrelated\nto cognitive ability or intelligence suggesting participants made little use of\nanalytical thinking. These findings were replicated in subsequent research\n(Stanovich et al., 2013).\nČavojová et  al. (2018) conducted a stronger test of the existence\nof myside bias. Participants (who had pro-life or pro-choice views with\nrespect to abortion) were presented with abortion-relevant syllogisms (see\nGlossary; and pp. 678–679). They were instructed to assume the two prem-\nises were valid and decide whether the conclusion followed logically from\nthem. Evidence was obtained for myside bias – participants found it hard\nto accept logically valid conclusions conflicting with their beliefs and to\nreject invalid conclusions coinciding with their beliefs. Thus, myside bias\ncan be found even when people are instructed not to allow their beliefs to\ninfluence their reasoning.\nHow can we reduce myside bias? McCrudden et al. (2017) asked par-\nticipants to rate the strength of arguments concerning climate change from\ntheir own perspective and also from that of a climate scientist. Adopting\nthe perspective of a climate scientist eliminated myside bias when rating\nweak arguments but not strong arguments. Thus, perspective taking can\nproduce a modest decrease in myside bias.\nBefore proceeding, we should note the motivation to support one’s\nown beliefs or view sometimes improves performance. Earlier (p. 677), we\ndiscussed Dawson et  al.’s (2002) study using the Wason selection task.\nIndividuals strongly motivated to disprove the rule because it implied they\nwould die young showed much more accurate reasoning than those lacking\nsuch motivation.\nArgumentative theory\nMercier (e.g., 2016) proposed an argumentative theory of reasoning empha-\nsising the importance of argumentation. For example, according to Mercier\n(2018, p. 1), “Reason is a specific cognitive mechanism that evolved so that\nhumans can exchange justifications and arguments with each other.”\nMercier (2016, p. 690) claimed that his theory provided an explanation\nfor myside bias:\nThe function of argument production is to convince someone in an\ninteractive setting. Conviction can hardly be achieved by providing\ninterlocutors [others involved in a discussion] with arguments for their\nviews or against that of the speaker. Argument production should thus\nbe marked by a strong myside bias.\n(p. 690)\nKEY TERMS\nSolution aversion\nA bias in reasoning in\nwhich individuals deny the\nexistence of a problem\n(e.g., climate change)\nbecause they dislike the\nproposed solution (e.g.,\nrestricting damaging\nemissions).\nMyside bias\nIn informal reasoning, the\ntendency to select and\ninterpret information in\nterms of one’s own beliefs\nor to generate reasons\nor arguments supporting\nthose beliefs.\nCreated from usyd on 2022-02-17 03:28:25.",
    "698\nThinking and reasoning\nIt also follows that we should be more critical of others’ arguments than of\nour own (especially when their views disagree with ours).\nSupport for argumentative theory was reported by Trouche et  al.\n(2016). Participants solved syllogistic reasoning problems, produced argu-\nments for their answers, and then evaluated other people’s arguments for\nthe same problems. The key condition was one in which participants eval-\nuated their own arguments but were led to believe these arguments were\nsomeone else’s. Participants not detecting this deception were highly criti-\ncal of their own arguments, rejecting them 56% of the time. Of importance,\nthey were more likely to reject their own arguments for invalid answers\nthan valid ones (66% vs 41%, respectively). Thus, the participants were\nmore critical and better able to discriminate between valid and invalid\narguments when they believed they were someone else’s.\nIn a second experiment, Trouche et al. (2016) presented syllogisms and\nasked participants to provide “fast, intuitive answers”. After that, they pro-\nvided arguments for their answers and were able to change their answer.\nThe arguments participants provided for their invalid answers were gener-\nally superficial with only 17% of these answers being changed. These find-\nings provide further evidence that most individuals are not critical of their\nown arguments.\nEvaluation\nInformal reasoning is far more important than deductive reasoning in our\neveryday lives. Motivational factors (e.g., myside bias; desire to win argu-\nments by persuading others) play a major role in informal reasoning. In\nthe case of climate change, people’s views are often much more strongly\ninfluenced by their notions concerning the kind of person they regard them-\nselves as being than by the available research evidence.\nWhat are the limitations of the research discussed so far? First, we lack\na comprehensive theory clarifying how motivational factors influence infor-\nmal reasoning. Second, several studies (e.g., Kahan et al., 2012; Stanovich\n& West, 2007) have found surprisingly small differences in informal rea-\nsoning between individuals of high and low cognitive ability or intelligence.\nMore research is needed to establish whether this is a general finding or\nwhether it depends on the precise nature of the reasoning task.\nFindings: probabilities\nAs noted earlier, probabilities are much more important in informal than\nin deductive reasoning (e.g., we believe statements are possibly or proba-\nbly true). In contrast, statements in formal logic are true or false – there is\nno half-way house. The Bayesian approach (also discussed in Chapter 13\nand below), focuses on probabilities. According to this approach, our\nprior beliefs have subjective probabilities associated with them based on\nour knowledge and experience. These subjective probabilities are changed\n(increased or decreased) as we encounter new evidence.\nSupport for the Bayesian approach was reported by Hahn and\nOaksford (2007). They identified several factors influencing the perceived\nstrength of a conclusion:\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n699\n(1) degree of previous conviction or belief;\n(2) positive arguments have more impact than negative ones;\n(3) strength of the evidence.\nHahn and Oaksford (2007) studied the above factors using scenarios such\nas the following (note that digesterole is a fictitious drug):\nBarbara:\nAre you taking digesterole for it?\nAdam:\nYes, why?\nBarbara:\nWell, because I strongly believe that it does have\nside-effects.\nAdam:\nIt does have side-effects.\nBarbara:\nHow do you know?\nAdam:\nBecause I know of an experiment in which they found\nside-effects.\nThis scenario presents a strong prior belief (i.e., strongly believe), a posi-\ntive belief (i.e., it has side-effects) and weak evidence (i.e., one experiment).\nThe three factors were manipulated in other versions of this scenario.\nParticipants decided how strongly Barbara should now believe the conclu-\nsion the drug has side-effects.\nArgument strength was regarded as greater when the prior belief was\nstrong rather than weak, when the prior belief was positive rather than\nnegative, and when the evidence was strong rather than weak. Thus, as\npredicted by the Bayesian approach, ratings of argument strength took\naccount of Barbara’s prior beliefs and the strength of the new evidence. In\naddition, Hahn and Oaksford (2007) found a model based on the Bayesian\napproach provided an excellent fit to the data.\nHarris et  al. (2016) carried out a similar study where participants\nreceived fictional medical information (e.g., concerning whether Pfortanine\nlowers cholesterol). Three factors were manipulated: (1) expert vs non-\nexpert opinion; (2) trustworthiness of the expert/non-expert: high (friend)\nvs low (enemy); and (3) opinion of other experts: agreed with expert/non-\nexpert; disagreed with expert/non-expert; or not mentioned. Participants\nindicated their degree of belief in the medical information by providing\nconvincingness ratings.\nAll three factors had the predicted effects: convincingness was higher\nwith expert than non-expert opinion, with a friend’s opinion rather than\nan enemy’s, and with other experts agreeing rather than disagreeing. Some\nfindings are shown in Figure 14.10. A Bayesian model predicted the con-\nvincingness ratings extremely well.\nHornikx et al. (2018) investigated the impact of expert opinion in more\ndetail. They presented scenarios in which an expert’s opinion differed from\nthat of laypeople. There were five levels of expert expertise and five levels of\nlayperson expertise. Participants indicated how many laypeople they thought\nwere required to counter the expert’s opinion. According to the Bayesian\napproach, participants should have been sensitive to the expertise of the\nexpert and the laypeople in their responses. Thus, the number of laypeople\nrequired should increase as the expert’s expertise increases and that of lay-\npeople decreases. The findings were in general agreement with prediction.\nCreated from usyd on 2022-02-17 03:28:25.",
    "700\nThinking and reasoning\nWithin the framework of traditional reasoning research, several types\nof arguments were classified as “fallacies”. For example, consider the\nslippery-slope argument, according to which a small first step will lead\nto a chain of events producing an undesirable outcome. One such argu-\nment (from Corner et al., 2011) is as follows: “If voluntary euthanasia is\nlegalised, then in the future there will be more cases of ‘medical murder’.”\nAnother example concerns genetic engineering, which, it has been argued,\nwill inevitably lead to attempts to create a super race of human beings\n(Walton, 2017).\nAs mentioned earlier, so-called “fallacies” were rejected as totally\ninvalid according to classical logic. In contrast, it is assumed within the\nBayesian approach that most so-called fallacies involve weak conclusions\npoorly supported by the evidence presented. According to this approach,\nthen, we should not reject all slippery-slope arguments. Such arguments\nvary in strength, with strong arguments being regarded as more persuasive\nthan weak ones. Two important factors determining argument strength\nare: (1) the probability of the negative outcome; and (2) how negative the\noutcome would be. Thus, strong slippery-slope arguments are those where\nthe negative outcome is both highly probable and very undesirable.\nCorner et  al. (2011) tested the above predictions using various topics\n(e.g., legislation of euthanasia; introduction of ID cards). As predicted, both\nfactors influenced the assessment of argument strength (see Figure 14.11).\nHaigh et al. (2016) pointed out that slippery-slope arguments are typ-\nically perceived to be arguments implying resistance to change. They then\nhypothesised such arguments will only be perceived as persuasive when it\nis clear the speaker is resistant to change. That is exactly what they found.\nThis finding indicates the importance of a contextual factor (i.e., the speak-\ner’s beliefs). As such, it is entirely consistent with the Bayesian approach\nwith its emphasis on perceived persuasiveness being influenced by all rele-\nvant factors.\n80\n70\n60\n50\n40\n30\n20\n10\n0\nEnemy\nMean convincingness ratings (%)\nTrustworthiness\nFriend\nNo mention\nAgree\nDisagree\nFigure 14.10\nEffects of trustworthiness\nand others’ opinions on\nconvincingness ratings.\nFrom Harris et al. (2016).\nKEY TERM\nSlippery-slope argument\nThe claim that an\ninnocuous first step will\nlead to an undesirable\noutcome; sometimes\nregarded as a fallacy.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n701\nEvaluation\nThe Bayesian approach (assuming that prior\nsubjective probabilities are modified by new\ninformation to produce posterior subjective\nprobabilities) provides a valuable framework\nfor understanding informal reasoning. Several\nfactors (e.g., strength of prior beliefs; strength\nof evidence) influencing the rated strength\nof informal arguments have been identified.\nThe Bayesian approach accounts for the per-\nceived strength (or otherwise) of the argu-\nments within so-called fallacies. The Bayesian\napproach has generated precise models pre-\ndicting accurately the perceived strength of\nconclusions in informal reasoning. Other the-\noretical approaches have proved less success-\nful (Hahn & Hornikx, 2016).\nWhat are the limitations of the Bayesian\napproach? Bowers and Davis (2012) argued\nit is too flexible and thus hard to falsify. For\nexample, the strength of prior beliefs is often\nnot assessed with precision. This argument\nis too sweeping in two ways. First, Bayesian\nmodels vary considerably in terms of their fal-\nsifiability (Hahn, 2014).\nSecond, we must distinguish between model flexibility and vague\npredictions. Bayesian models are often flexible in terms of their assump-\ntions. However, many such models make precise predictions from those\nassumptions (Hahn, 2014). For example, Harris et al. (2012) studied the ad\nhominem fallacy (see Glossary). The convincingness of an argument was\nsystematically affected when it was attributed to Hitler. Of most impor-\ntance, however, the perceived persuasiveness of ad hominem arguments\nwas influenced by the content of the arguments. Of note, a Bayesian model\nprovided a precise quantitative fit to the data.\nThird, while Bayesian models accurately predict the perceived effec-\ntiveness of arguments, they often fail to identify the underlying processes.\nAccording to the Bayesian approach, informal reasoning involves exten-\nsive use of probabilities. However, “People flounder with even the simplest\nprobability questions . . . How can a supposedly Bayesian brain reason so\npoorly with probabilities?” (Sanborn & Chater, 2016, p. 883). As yet, it\nremains somewhat unclear how we use probabilities in numerous cognitive\ntasks (including informal reasoning).\nARE HUMANS RATIONAL?\nMuch research discussed in this chapter and the previous two apparently\nindicates deficient and irrational human thinking and reasoning. For\nexample, we often fail on fairly simple problems (e.g., Frederick’s Cognitive\nReflection Test), we generally ignore base-rate information when making\nFigure 14.11\nMean-rated argument strength as a function of the probability\nof the outcome (likely vs unlikely) and how negative the\noutcome would be (very negative vs moderately negative).\nFrom Corner et al. (2011). With permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:25.",
    "702\nThinking and reasoning\njudgements (see Chapter 13), 90% of us produce the wrong answer on the\nWason selection task, and we perform poorly on deductive-reasoning tasks.\nThe above findings lead to an apparent paradox. Most people (but not\nall!) cope reasonably well with everyday problems and challenges but often\nseem “irrational” and “illogical” with laboratory thinking and reasoning\nproblems. We can resolve this paradox by assuming our everyday thinking\nis less rational than we like to believe, whereas our thinking and reasoning\nin the laboratory is more rational than often supposed. With respect to\nthe latter point, laboratory deductive-reasoning tasks are often very arti-\nficial: background knowledge is totally irrelevant, and conclusions involve\ncertainties (i.e., valid vs invalid) rather than varying levels of probability.\nBefore examining the relevant evidence, we must consider what we\nmean by “human rationality”. As we will see, there is controversy concern-\ning the appropriate definition.\nBounded rationality\nSimon considered the issue of human rationality at length (Schraagen,\n2018). He argued behaviour is rational “in so far as it selects alternatives . . .\nconducive to the achievement of previously selected goals” (Simon, 1945,\np. 5). Thus, an individual’s informal reasoning is rational if it achieves their\ngoal of arguing persuasively even if it differs from the experimenter’s prior\nexpectations (e.g., by demonstrating myside bias; see Glossary).\nSimon (1957) argued we possess bounded rationality (our thinking and\ndecision-making are “bounded” by environmental constraints (e.g., infor-\nmation costs) and cognitive constraints (e.g., limited attention). This allows\nus to produce workable solutions to problems in spite of limited processing\nability by using various short-cut strategies (e.g., heuristics). More specif-\nically, our thinking is “bounded” or constrained by the environment and\nprocessing constraints (e.g., limited attention; limited short-term memory).\nAccording to Simon (1990, p. 7), “Human rational behaviour is shaped\nlike a scissors whose blades are the structure of task environments and the\ncomputational capabilities of the actor.” If we consider only one blade, we\nwill have only a partial understanding of human thinking.\nIn sum, many “errors” in human thinking reflect limited processing\ncapacity rather than irrationality. As mentioned above, Simon also argued\nsuch “errors” can also reflect environmental constraints. Simon’s definition\nof “bounded rationality” included factors such as incomplete knowledge,\nproblems in anticipating future consequences and limited behavioural alter-\nnatives. As Schraagen (2018, p. 488) pointed out, “These issues have more\nto do with the complexity of the environment that humans find themselves\nin than with their limited information processing capacities.”\nInstrumental vs broad rationality\nDeciding whether humans are rational depends on how we define “ration-\nality”. Historically, an important approach (championed by Piaget, Wason\nand many others) claimed rational thought is governed by logic. It follows\nthat deductive reasoning (which many have thought requires logical think-\ning) is very relevant for assessing human rationality. Sadly, most people\nKEY TERM\nBounded rationality\nThe notion that people\nare as rational as the\nenvironment and their\nlimited processing\ncapacity permit.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n703\nperform poorly on complex deductive-reasoning tasks. Thus, humans are\nirrational if we define rationality as logical reasoning.\nThe above approach exemplifies normativism. Normativism “is the\nidea that human thinking reflects a normative system [one conforming\nto norms or standards] against which it should be measured and judged”\n(Elqayam & Evans, 2011, p. 233). For example, human thinking is “correct”\nonly if it conforms to classical logic.\nLogic (or deductive reasoning) does not provide a suitable normative\nsystem for evaluating human thinking. Why is that? As Sternberg (2011,\np. 270) pointed out, “Few problems of consequence in our lives had a\ndeductive or even any meaningful kind of ‘correct’ solution. Try to think\nof three, or even one!”\nWe can make headway by distinguishing two broad types of rational-\nity (Stanovich, 2013, 2016). First, there is instrumental rationality, which\ninvolves “the maximisation of expected utility [subjective value associated\nwith our choices or decisions]” (Stanovich, 2016, p. 24). We could label\nthis thin rationality because it is narrowly focused on the current task.\nSecond, there is broad rationality, which involves taking account of the\nindividual’s personal goals and contextual factors (especially social ones)\nadditional to the immediate task goals. One type of broad rationality was\nlabelled “social rationality” by Hoffrage et  al. (2018). Social rationality\n“is concerned with goals, such as choosing an option that one can defend\nwith argument or moral justification, or that can create a consensus”\n(pp.  331–332). In Chapter 13, we discussed Tetlock’s (2002) social func-\ntionalist approach, which focuses on social rationality and the role played\nby accountability in decision-making.\nWe will clarify the above distinction. Consider a situation where indi-\nviduals must decide between risking harm through inaction and risking\nharm through action. An example would be a parent deciding whether to\nhave their child vaccinated against various diseases. If the decision is to\nselect the option where the probability of harm is less, the decision would\nbe based on instrumental rationality.\nHowever, as Brewer et al. (2016) found in a meta-analysis, such deci-\nsions are often strongly influenced by anticipated regret (i.e., the option\ninvolving less anticipated regret is selected). Thus, the decision to select\nthe option having less instrumental rationality may be selected because it\nis associated with less anticipated regret. It is arguable that such decisions\nare consistent with broad rationality.\nIn sum, we should distinguish between thin or instrumental rational-\nity and broad rationality. We may exaggerate human irrationality if we\nfocus only on instrumental or thin rationality. However, it is often hard\nto decide whether an individual is demonstrating broad rationality. Why is\nthat? Broad rationality involves thinking and reasoning consistent with an\nindividual’s goals, but these goals are often unclear.\nFindings\nStanovich (2013) compared rationality in humans and other species. If\nwe focus on instrumental rationality, other species sometimes outperform\nhumans. For example, Pope et al. (2015; see Chapter 12) found baboons\nKEY TERMS\nNormativism\nThe notion that human\nthinking should be\nregarded as “correct” or\n“incorrect” depending\non how closely it\nfollows certain norms or\nstandards (e.g., those of\nclassical logic).\nInstrumental rationality\nMaximising the utility\n(subjective value) of one’s\nchoices or decisions\nwith respect to achieving\ntask-related goals.\nCreated from usyd on 2022-02-17 03:28:25.",
    "704\nThinking and reasoning\nwere much less likely than humans to exhibit the negative effects of mental\nset (see Glossary) in problem solving. How can we explain such surprising\nfindings? Humans are far more likely than other species to pursue complex\ngoals not directly relevant to the current task.\nThe fact that our cognitive processes and goals are often complex\nmeans human thinking can often be regarded as rational even when it does\nnot correspond to instrumental rationality. Here we will consider another\nexample of the sunk-cost effect (see Glossary). Two people decide to go on\na holiday for which they have paid a non-refundable deposit even though\nthey both feel slightly unwell on the way there and think they would prefer\nto go home (Dawes, 1988; see Chapter 13).\nKeys and Schwartz (2007) argued some participants may well have\ntaken into account the regret they would experience if they returned home\nhaving forfeited the deposit. In that case, it might be more “rational”\nto exhibit the sunk-cost effect. Thus, we should distinguish between\nthe decision and its consequences. According to Keys and Schwartz,\nthe anticipated experience following a decision often “leaks” into the\ndecision-making process.\n“Leakage” may also explain apparently irrational framing effects (see\nGlossary and Chapter 13). Most people choose beef labelled “75% lean”\nrather than beef labelled “25% fat”, which seems irrational (Levin &\nGaeth, 1988). However, the labelling influenced participants’ experience:\nthe 75% lean beef tasted better than the 25% fat beef. Thus, we could argue\nparticipants’ choices were rational.\nFindings such as those discussed above may suggest human think-\ning and behaviour typically correspond to broad rationality. However,\nthere are plentiful exceptions (more are discussed shortly). In one study\n(Koehler & James, 2009) 40 marbles were drawn from a bag: 30 were\ngreen and 10 red. Participants guessed the colours of 20 more marbles\ndrawn as replacements from the bag. The optimal strategy is maximising\n(i.e., choosing green every time). However, most participants used proba-\nbility matching (i.e., guessing green about 75% of the time). Subsequently,\n39%  of participants using probability matching acknowledged the supe-\nriority of maximising, thus accepting the inadequacy of their chosen\nstrategy.\nLimitations of human rationality\nAn important theoretical approach of relevance to the issue of human\nrationality is the dual-process (or dual-system) approach (reviewed by\nEvans & Stanovich, 2013a). In essence, it is assumed there is a rapid process\n(Type 1 or System 1) which is often followed by a slower process (Type\n2 or System 2) that involves working memory. This theoretical approach\nhas been applied to deductive reasoning (see earlier in this Chapter) and to\njudgement (Kahneman, 2003; see Chapter 13).\nIt was originally assumed Type 2 or System 2 responses are gener-\nally based on analytical, logical or rational processes, whereas Type 1 or\nSystem 1 responses reflect more intuitive processes. In fact, matters are\nmuch more complicated. Research on reasoning discussed (e.g., Newman\net  al., 2017; Trippas et  al., 2017) indicates there is only modest evidence\nCase study:\nExploring dual-system\ntheories of deductive\nreasoning\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n705\nfor the assumptions that fast responses are intuitive whereas slow ones are\nanalytical or rational. For example, there are numerous exceptions to the\nprediction that Type 2 or System 2 responses should be associated with\nfar more correct answers on reasoning problems than Type 1 or System 1\nresponses (Evans, 2018).\nOaksford and Hall (2016, p. 343) proposed a radical new theoreti-\ncal approach: “In a reversal of current wisdom [i.e., dual-system theory],\nSystem 1 is rational whereas System 2 leads to error.” Why did they\npropose this reversal?\n(1) They argued that other species rely primarily on System 1 but seem\nless prone than humans to serious cognitive biases.\n(2) System 2 depends heavily on working memory, but working memory\nis limited in its functioning (Johnson-Laird, 1983; see Chapter 6).\n(3) System 2 involves language often lacking in precision (e.g., individu-\nals differ greatly in their interpretations of words such as “probable”\nand “likely”).\nIn sum, the assumptions that irrationality stems from System 1 and ration-\nality from System 2 are seriously flawed.\nAn interesting example of limited human rationality is the Dunning-\nKruger effect (Kruger & Dunning, 1999), in which “those who are\nincompetent . . . have little insight into their incompetence” (Dunning,\n2011, p.  260). Individuals largely unaware of their own thinking exhibit\nsigns of “irrationality”. For example, Motta et  al. (2018) found those\nknowing the least about the causes of autism were most likely to think they\nknew more than medical doctors about autism’s causes!\nWhy does the Dunning-Kruger effect exist? Perhaps those showing\nthe effect lack the knowledge and expertise to evaluate the correctness (or\notherwise) of their own thinking. Dunning (2011) discussed a study using\nthe Wason selection task (see earlier in the chapter, pp. 676–678). Some\nparticipants used the same correct rule across different versions of the\ntask and so achieved a success rate of 100%. Other participants used the\nsame incorrect rule consistently and had a 0% success rate. However, both\ngroups believed they had solved between 80% and 90% of the problems\ncorrectly!\nIndividual differences: intelligence\nEven though average performance on most judgement, decision-making\nand reasoning tasks appears relatively poor, it is still possible highly intelli-\ngent individuals perform consistently well. That is partially true (Stanovich,\n2012). Students with high IQs perform better than those with lower IQs on\nmany deductive-reasoning tasks. However, intelligence often only modestly\npredicts performance on judgement tasks (e.g., framing problems; sunk-\ncost effects; omission bias). For example, Toplak et al. (2011) obtained a\ncorrelation of +.32 between cognitive ability and performance across 15\njudgement and decision tasks.\nStanovich (2012) developed a tripartite model to explain the impact of\nintelligence on thinking and reasoning (see Figure 14.12). At the bottom\nKEY TERM\nDunning-Kruger effect\nThe finding that less\nskilled individuals\noverestimate their abilities\nmore than those who are\nmore skilled.\nCreated from usyd on 2022-02-17 03:28:25.",
    "706\nThinking and reasoning\nis Type 1 processing (e.g., use of heuris-\ntics) within the autonomous mind. It is\nrapid and fairly “automatic”. Above that\nis Type 2 processing which is slow and\neffortful.\nStanovich’s (2012) model has two major\nnovel features. First, there are two levels of\ncognitive control at the higher level. One\nconsists of Type 2 processes (the algorithmic\nmind) which contains mindware – “the rules,\nknowledge, procedures, and strategies that\na person can retrieve from memory . . . to\naid decision making and problem solving”\n(Stanovich, 2012, p. 355). The algorithmic\nmind can override the (often incorrect) heu-\nristic responses generated by the autono-\nmous mind.\nType 2 processes are only used when\nindividuals realise that they are necessary\nand have sufficient motivation to initiate\nthem. The other level of control involves the\nreflective mind which has access to individ-\nuals’ goals, beliefs and general knowledge.\nDeciding whether to use Type 2 processes\ninvolves the reflective mind.\nSecond, the model considers individual\ndifferences in intelligence. Fluid intelligence\nis of direct relevance to the functioning of\nthe algorithmic mind. Individuals high in\nfluid intelligence possess more Type 2 processes and use them more effi-\nciently (Stanovich, 2012).\nStanovich (2016) developed a test (the Comprehensive Assessment of\nRational Thinking: the CART) to assess individual differences in the reflec-\ntive mind. The items in the CART (e.g., various heuristics and biases tasks;\nitems based on the Cognitive Reflection Test: see Glossary) mostly involve\na conflict between a readily available intuitive answer and the correct one.\nThe development of the CART opens the way to more systematic study\nof the similarities and differences between the algorithmic and reflective\nminds.\nAccording to the tripartite model incorrect, intuition-based answers on\nproblems can occur for three reasons:\n(1) Individuals may lack the appropriate mindware within the algorith-\nmic mind to override incorrect responses.\n(2) Individuals with the appropriate mindware may have insufficient pro-\ncessing capacity to override incorrect Type 1 processing using the\nalgorithmic mind.\n(3) Individuals may have the appropriate mindware but fail to use it\nbecause its use is not triggered by the reflective mind.\nFigure 14.12\nStanovich’s tripartite model of reasoning. According to the\nmodel, Type 1 processing within the autonomous mind is\ntypically fast and fairly automatic. There are two major forms\nof Type 2 processing: (1) the algorithmic mind, which contains\ninformation about rules, strategies and procedures; and (2) the\nreflective mind, which makes use of the individual’s goals and\nbeliefs. Individual differences in reasoning are generally much\ngreater with respect to the reflective mind and the algorithmic\nmind than the autonomous mind.\nFrom Stanovich (2012). By permission of Oxford University Press.\nKEY TERM\nFluid intelligence\nNon-verbal reasoning\nability applied to novel\nproblems.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n707\nFindings\nSeveral findings are consistent with the tripartite model. First, different\nmeasures of rational thinking typically correlate moderately with each\nother (e.g., Toplak et al., 2017 obtained correlations between +.26 and .60).\nThis suggests rational thinking is a relatively general aspect of individual\ndifferences. Second, as predicted, rational thinking assessed by heuristics\nand bias tasks correlates moderately with active open-minded thinking\nassessed by self-report questionnaire (Toplak et al., 2017). Third, individual\ndifferences in rational thinking as assessed by heuristics and bias tasks (e.g.,\nbelief bias) predict several real-world outcomes (e.g., sound financial behav-\niour; good security on computers) (Toplak et al., 2017).\nThere are two important limitations with Stanovich’s approach. First,\nconsider his claim that “rationality and intelligence are two different\nthings” (Stanovich, 2016, p. 23). The CART (designed to assess ration-\nality) correlates +.69 with measures of cognitive ability (e.g., analogies)\n(Ritchie, 2017). Thus, there is much overlap between rationality and\nintelligence.\nSecond, and relatedly, there is only limited evidence concerning incre-\nmental validity (the extent to which a new test has predictive power over\nand above that provided by previous tests). For example, the relationship\nbetween rational thinking and real-world outcomes found by Toplak et al.\n(2017) may have been due mostly to individual differences in intelligence\nrather than to rational thinking itself.\nConclusions\nWhat are the main arguments for human rationality? First, as argued by\nSimon (1957) with his notion of bounded rationality, human reasoning is\ngenerally moderately effective given constraints in our processing ability\n(e.g., limited attention; limited short-term memory) and environmental con-\nstraints. Our lives mostly involve uncertain information and so our reason-\ning and decision-making often appear “rational” when evaluated against\nBayesian and other models of probabilistic thinking.\nSecond, we should distinguish between thin and broad rationality\n(Stanovich, 2013). Human reasoning can seem “irrational” when consid-\nered solely within the context of the current task (thin rationality) but\n“rational” when we take account of our personal goals. These goals can\ninclude the need to be accountable to others (Tetlock, 2002), the desire to\nwin arguments (Mercier, 2018), and the wish to signify the kind of person\none is (Kahan, 2012).\nThird, apparent “errors” involving heuristics (rules of thumb) often\nfail to indicate “irrationality”. As Maule and Hodgkinson (2002, p. 71)\npointed out, “Often . . . people have to judge situations or objects that\nchange over time, making it inappropriate to expend a good deal of time\nto make a precise judgment . . . an approximate judgement based on a\nsimpler, less effortful heuristic may be much more appropriate.”\nWhat are the main arguments against human rationality? First, humans\nare often cognitive misers – even when they possess the necessary knowledge\nKEY TERM\nIncremental validity\nThe ability of a new test to\npredict behaviour or other\noutcomes to a greater\nextent than existing tests.\nCreated from usyd on 2022-02-17 03:28:25.",
    "708\nThinking and reasoning\nand skills to reason effectively, they often fail to do so. For example, inac-\ncurate performance on the Cognitive Reflection Test (Frederick, 2005; see\nChapter 12) often reflects a failure to use the reflective mind (Stanovich,\n2012, 2016).\nSecond, people often fail to think rationally because they are unaware\nof limitations and errors in their thinking (the Dunning-Kruger effect).\nThey are also often too ready to accept incorrect responses associated with\na strong feeling-of-rightness (Ackerman & Thompson, 2017).\nThird, we might expect experts to interpret correctly problems in their\narea of expertise and so avoid cognitive biases. However, medical experts\noften make biased judgements and decisions (Croskerry, 2018).\nFourth, Camerer and Hogarth (1999) reviewed 74 studies concerned\nwith the effects of motivation (financial incentives) on thinking and reason-\ning. The provision of incentives rarely improved performance suggesting\npoor reasoning is not typically due to insufficient motivation.\nCHAPTER SUMMARY\n•\nIntroduction. Inductive reasoning involves drawing general\nconclusions from statements referring to particular instances. These\nconclusions can never be shown to be definitely valid. Inductive\nreasoning is often used when testing scientific hypotheses.\nDeductive reasoning (originating in formal logic), allows us to draw\ndefinitely valid conclusions provided we assume other statements\nare true. It is of little relevance to everyday life. As a result, there\nhas been a rapid increase in research on informal reasoning based\non our knowledge and experience rather than logic.\n•\nHypothesis testing. Wason argued that performance was poor\non his 2-4-6 task because people show confirmation bias and\nrarely engage in falsification. However, there are many falsification\nattempts when participants test others’ hypotheses. The 2-4-6\ntask is unrepresentative of hypothesis testing because the rule is\nvery general and so hard to discover. Scientists typically adopt\na confirmatory approach when testing non-absolute hypotheses\nbut a disconfirmatory or falsificatory approach when testing\nabsolute or universal hypotheses. Many scientists show evidence\nof confirmation bias when analysing and interpreting their research\nfindings.\n•\nDeductive reasoning. Performance is generally poor on\nconditional-reasoning problems. Such problems have their\norigins in propositional logic. However, researchers increasingly\nencourage participants to use their relevant knowledge and to\nthink probabilistically on conditional-reasoning tasks. With Wason’s\nselection task, reasoners typically perform poorly unless the rule\nis deontic or they are motivated to disprove the rule because\nof concerns about future costs. Syllogistic reasoning is based on\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n709\npropositional logic. Performance is often poor because reasoners\nignore the dictates of logic and interpret problems based\non everyday meanings of expressions. This leads to incorrect\nreasoning (e.g., belief bias).\n•\nTheories of “deductive” reasoning. According to Johnson-Laird’s\nmental model theory, people form mental models representing\nwhat is common to a set of possibilities. As predicted, reasoners\noften reduce the load on working memory by forming mental\nmodels representing explicitly only what is true. There is much\nless search for counterexamples than assumed theoretically, the\nprocesses involved in forming mental models are underspecified,\nand most people engage in less deductive reasoning than\nassumed theoretically.\nAccording to early dual-process theories, reasoners initially\nuse rapid, intuitive Type 1 processes generating an answer that\nis sometimes corrected by a slower and more deliberate answer\nbased on analytic Type 2 processes. In contrast to this serial\nprocessing approach, recent dual-process theories (e.g., the logical\nintuition model) emphasise the importance of parallel Type 1 and\nType 2 processes. These theories provide more detailed accounts\nof the monitoring processes determining whether reasoners\naccept the first answer they produce. They also focus on how\nthe requirements of reasoning tasks and individual differences\nin reasoners’ abilities lead to considerable flexibility in reasoning\nstrategies.\n•\nBrain systems in reasoning. Key brain regions (e.g., left\nrostrolateral prefrontal cortex; left parietal cortex) are involved in\ndeductive reasoning. Individuals having superior inhibitory control\nabilities often outperform others on reasoning tasks (e.g., they\nare less likely to exhibit belief bias). Reasoners often engage in\nanticipatory processing in conditional reasoning (e.g., anticipating\nthe second premise and conclusion). Much research in cognitive\nneuroscience is relatively uninformative concerning contemporary\nreasoning theories. Of relevance, fMRI’s limited temporal resolution\nmeans we cannot establish precisely when any given brain area is\nactive.\n•\nInformal reasoning. Informal reasoning depends on the\nreasoner’s knowledge and experience as well as on the content\nof arguments and contextual factors. Motivational factors are\noften important with individuals seeking support for their beliefs\n(e.g., when arguing with others). The Bayesian approach based\non the assumption that new information changes the probabilities\nof beliefs is more realistic than the traditional approach based\non binary logic. For example, the Bayesian approach explains\nwhy so-called “fallacies” differ in persuasiveness, whereas the\nCreated from usyd on 2022-02-17 03:28:25.",
    "710\nThinking and reasoning\ntraditional approach dismisses them as totally invalid. The Bayesian\napproach does not provide a detailed account of the processes\ninvolved in informal reasoning.\n•\nAre humans rational?  Human rationality often seems “irrational”\non many laboratory tasks because such tasks are often very\nartificial (e.g., background knowledge is irrelevant). We possess\nbounded rationality, which allows us to produce workable solutions\nto problems despite limited processing ability. Humans appear\nmore rational if we focus on broad rationality, interpreting our\nreasoning performance with reference to our personal goals and\nthe social context. Dual-system theories propose an oversimplified\ndistinction between fast intuitive processes and slow analytical or\nrational processes. Human reasoning is often deficient because\nwe have limited awareness of our own cognitive incompetence.\nMore intelligent individuals perform better than less intelligent\nones on reasoning (especially deductive reasoning) tasks. However,\nsome intelligent individuals fail to think rationally because they\nare cognitive misers who use limited mental effort when solving\nproblems.\nFURTHER READING\nChater, N., Felin, T., Funder, C.D., Gigerenzer, G., Koenderink, J.J., Krueger,\nJ.I. (2018). Mind, rationality, and cognition: An interdisciplinary debate.\nPsychonomic Bulletin and Review, 25, 793–826. This article contains the contrast-\ning views of many experts on key issues relating to rationality.\nCollins, P.J. & Hahn, U. (2018). Fallacies of argumentation. In L.J. Ball and V.A.\nThompson (eds), Routledge International Handbook of Thinking and Reasoning\n(pp. 88–108). Abingdon, Oxon.: Routledge. Peter Collins and Ulrike Hahn\ndiscuss recent theory and research on informal reasoning.\nDe Neys, W. (ed.) (2018). Dual Process Theory 2.0. Abingdon, Oxon.: Routledge.\nWim De Neys is the editor of this book in which leading experts discuss (and\nevaluate) various versions of dual-process theory as applied to thinking and\nreasoning.\nElqayam, S. (2018). The new paradigm in psychology of reasoning. In L.J. Ball\nand V.A. Thompson (eds), Routledge International Handbook of Thinking and\nReasoning (pp. 130–150). Abingdon, Oxon.: Routledge. Shira Elqayam discusses\nin detail the shift from traditional theories of reasoning based on logic to theories\nfocusing on informal reasoning.\nGoel, V. & Waechter, R. (2018). Inductive and deductive reasoning: Integrating\ninsights from philosophy, psychology, and neuroscience. In L.J. Ball and V.A.\nThompson (eds), Routledge International Handbook of Thinking and Reasoning\n(pp. 218–247). Abingdon, Oxon.: Routledge. This chapter indicates how cognitive\nneuroscience has enhanced our understanding of human reasoning.\nGorman, M.E. (2018). Scientific thinking. In L.J. Ball and V.A. Thompson (eds),\nRoutledge International Handbook of Thinking and Reasoning (pp.  248–267).\nCreated from usyd on 2022-02-17 03:28:25.",
    "Reasoning and hypothesis testing\n711\nAbingdon, Oxon.: Routledge. Real-life and laboratory research of relevance to\nscientific thinking and hypothesis testing is discussed by Michael Gorman.\nPohl, R.F. (ed.) (2017). Cognitive Illusions: Intriguing Phenomena in Thinking,\nJudgement and Memory (2nd edn). Abingdon, Oxon.: Routledge. This book, with\nits emphasis on discussing a very wide range of cognitive illusions, provides solid\nevidence for evaluating human rationality.\nStanovich, K.E. (2013). Why humans are (sometimes) less rational than other\nanimals: Cognitive complexity and the axioms of rational choice. Thinking &\nReasoning, 19, 1–26. Keith Stanovich provides an excellent of the complexities of\nhuman rationality.\nCreated from usyd on 2022-02-17 03:28:25.",
    "Created from usyd on 2022-02-17 03:28:25.",
    "713\nBroadening horizons\nOne of the most exciting developments within cognitive psychology has\nbeen a broadening of its horizons. In this section of the book, we con-\nsider two of the most important manifestations of that broadening. First,\nthere is the issue of the ways in which emotion and mood are related to\nhuman cognition (Chapter 15). Second, there is the issue of consciousness\n(Chapter 16).\nIt is appropriate to place these two topics here because both are relevant\nto most of the topics within cognitive psychology that we have discussed\nthroughout the book. Emotional factors influence attention, perception,\nmemory, language processing, judgements and decision-making. In addi-\ntion, our current mood state is strongly influenced by cognitive processes.\nSo far as consciousness is concerned, it is important to distinguish between\nconscious and non-conscious processes when studying almost any aspect of\nhuman cognition.\nCOGNITION AND EMOTION\nThe origins of the notion that our emotional states are partly determined by\nour cognitions go back at least as far as Aristotle over two thousand years\nago. Aristotle (who may have been the cleverest person who ever lived)\nhad this to say: “Let fear, then, be a kind of pain or disturbance resulting\nfrom the imagination of impending danger” (quoted by Power & Dalgleish,\n2008, p. 35). The key word is “imagining” – how much fear we experience\ndepends on our expectations. Aristotle developed this point: “Those in\ngreat prosperity . . . would not expect to suffer; nor those who reckon they\nhave already suffered everything terrible and are numbed as regards the\nfuture, such as those who are actually being crucified” (quoted by Power &\nDalgleish, 2008, p. 35).\nAristotle emphasised the impact that cognitions have on emotion. However,\nemotional states influence our cognitions. As  discussed in Chapter 15, emo-\ntional states influence many cognitive processes. There has been significant\nprogress in psychologists’ ability to predict the circumstances in which such\neffects will occur.\nPART V\nCreated from usyd on 2022-02-17 03:28:58.",
    "714\nBroadening horizons\nOne reason why it is important to study the effects of emotional states on\ncognition is because such effects are often present in everyday life. For\nexample, we have more negative thoughts about ourselves and the future\nwhen feeling sad or depressed than when happy.\nFinally, note that some research on emotion and cognition has been dis-\ncussed earlier in this book. For example, emotional states influence eye-\nwitness memory and autobiographical memory (Chapter 8) and can impair\ndecision-making (Chapter 13).\nCONSCIOUSNESS\nThe topic of consciousness did not fare well during most of the twentieth\ncentury. John Watson, a leading behaviourist, argued strongly that the\nconcept of “consciousness” should be eliminated from psychology. He was\nalso scathing about the value of introspection, which involves an exam-\nination and description of one’s own thoughts. Consider, however, this\nquotation from Watson (1920): “A good deal more can be learned about\nthe psychology of thinking by making subjects think aloud about definite\nproblems, than by trusting to the unscientific method of introspection.”\nThis quotation is somewhat bizarre given that “thinking aloud” is essentially\nsynonymous with introspection! Watson’s view was that thinking aloud is\nacceptable because it can simply be regarded as verbal behaviour.\nIt is increasingly accepted that consciousness is an extremely important\nand fascinating (although undeniably complex!) topic. The first author\nremembers clearly a conversation with Endel Tulving (a leading memory\nresearcher) in the mid-1980s. He said one criterion he used when evaluating\na textbook on cognitive psychology was the amount of coverage of con-\nsciousness. Reference back to the fourth edition of this textbook indicated\nthat consciousness was discussed on only 2 pages out of 525 – so that\nedition clearly failed the Tulving test! However, the burgeoning research\non consciousness was reflected by an increase to 30 pages in the seventh\nedition (and even more in this edition).\nThe role of non-conscious processes in human cognition is considered in\nseveral chapters of this book. Subliminal perception and blindsight are\ndiscussed in Chapter 2, “automatic” processes are analysed in Chapter 5,\nimplicit learning is discussed in Chapter 6, implicit memory is dealt with\nin Chapter 7, and the potential importance of non-conscious processing in\ndecision-making is discussed in Chapter 13. Such research has increased\ninterest in studying consciousness – if some processes are conscious\nwhereas others are non-conscious, we clearly need to identify the crucial\ndifferences between them.\nFinally, several concepts used by cognitive psychologists are very relevant\nto consciousness. Examples include many theoretical ideas about atten-\ntion (Chapter 5) and the central executive of Baddeley’s working memory\nsystem (Chapter 6).\nKEY TERM\nIntrospection\nA careful examination and\ndescription of one’s own\nmental thoughts.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\nINTRODUCTION\nHistorically, most cognitive psychologists ignored the effects of emotion\non cognition by trying to ensure their participants were in a neutral emo-\ntional state. In recent years, however, there has been a dramatic increase\nin research concerned with the relationship between cognition and\nemotion. Examples include research on everyday memory (Chapter 8) and\ndecision-making (Chapter 13).\nTwo issues are central. First, how do cognitive processes influence\nour emotional experience? Second, how does emotion influence cognitive\nprocesses? For example, how do different emotions influence learning and\nmemory? In short, we consider the effects of cognition on emotion and\nthose of emotion on cognition.\nFour major topics are discussed in this chapter. First, we consider how\nour emotional experience is influenced by our cognitive appraisals (inter-\npretations) of our current situation. Second, we discuss issues relating to\nemotion regulation. Emotion regulation is concerned with the processes\n(mostly deliberate) involved in managing our emotions and so allowing us\nto be relatively happy and achieve our goals.\nThird, we consider the effects of emotion on cognition. Emotional\nstates influence attention, memory, judgement and decision-making. Of\npractical and theoretical importance, each emotional state produces a dif-\nferent pattern of effects.\nFourth, we discuss cognitive biases (e.g., interpreting ambiguous sit-\nuations in a threatening way) associated with anxiety and depression. A\nkey issue is whether cognitive biases influence the development of anxiety\nand depression or whether they are merely a consequence of anxiety\nor depression. We address this issue by considering research designed\nto reduce or eliminate these biases. Such research has high societal\nrelevance.\nChapter\n15\nCreated from usyd on 2022-02-17 03:28:58.",
    "716\nBroadening horizons\nEmotion, mood and affect\nHow can we define “emotion”? According to Colman (2015, p. 244),\nemotion is “any short-term evaluative, affective, intentional, psychological\nstate”. How do emotions differ from moods? First, emotions typically last\nfor less time. Second, emotions are more intense than moods and so are\nmore likely to attract our attention. Third, emotions are generally caused\nby a specific event (e.g., passing an examination), whereas the reason for\nbeing in a given mood is often unclear.\nHowever, there is no sharp distinction between emotions and moods;\nthey are “parallel interacting processes” (Eldar et al., 2016, p. 16). We will\noften use the broader term affect which encompasses emotions and moods.\nPositive affect refers to positive emotions and moods whereas negative\naffect refers to negative emotions and moods. Valence refers to the emo-\ntional value (positive or negative) associated with a stimulus (e.g., person;\nevent).\nStructure of emotions\nWhat is the structure of emotions? Some theorists (e.g., Izard, 2007) argue\nwe should adopt a categorical approach, according to which there are\nseveral distinct emotions. For example, Cowen and Keltner (2017, 2018)\nanalysed the emotional states produced by over 2,000 short videos and\nidentified 27 different emotions (e.g., admiration; adoration; amusement;\nanger; calmness; envy; fear; guilt; relief; and sadness). This approach proba-\nbly fits your subjective experience.\nOther theorists prefer a dimensional\napproach. Barrett and Russell (1998) argued\nfor two uncorrelated or orthogonal dimensions\nof misery–pleasure (valence) and arousal–\nsleep. In contrast, Watson and Tellegen (1985)\nfavoured two uncorrelated dimensions of pos-\nitive and negative affect.\nIn spite of their differences, both\napproaches refer to the same  two-dimensional\nspace (see Figure 15.1). This figure also indi-\ncates how we can reconcile the categori-\ncal and dimensional approaches. Emotions\nsuch as happy and excited fall in the top-\nright quadrant, contented, relaxed and calm\nare in the bottom-right quadrant, depressed\nand bored are in the bottom-left quadrant,\nand stressed and tense are in the top-left\nquadrant.\nThere is much support for the dimen-\nsional approach. Watson and Tellegen (1985)\nanalysed data from numerous studies using\nvarious self- report mood measures and found\n50%–65% of the variance was accounted for\nby dimensions of negative and positive affect.\nKEY TERMS\nEmotion\nA short-lived affective\nstate typically triggered by\na specific event.\nMood\nState resembling emotion\nbut generally longer\nlasting, less intense and of\nunknown cause.\nAffect\nA general term referring\nto evaluative (positive\nor negative) reactions; it\nencompasses mood and\nemotion.\nValence\nThe positive or negative\ncharacter of emotional\nexperience.\nFigure 15.1\nThe two-dimensional framework for emotion showing the two\ndimensions of pleasure–misery and arousal–sleep (Barrett &\nRussell, 1998) and the two dimensions of positive affect and\nnegative affect (Watson & Tellegen, 1985).\nBased on Barrett and Russell (1998), and Watson and Tellegen (1985).\n© American Psychological Association.\nCase study:\nBasic emotions as natural\nkinds\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n717\nBrain mechanisms\nWhat brain mechanisms are associated with emotion? The full answer is\nunknown, but we discuss very briefly a few key points.\nFirst, locationist theories (assuming each emotion is associated with\na different brain area) used to be popular (see Lindquist et al., 2012,\nfor  a review). For example, fear was allegedly strongly associated with\nthe amygdala, disgust with the insula, anger with the orbitofrontal cortex\nand sadness with the anterior cingulate. However, Lindquist et al. found\nminimal support for the locationist approach in a meta-analytic review.\nInstead, it is now generally accepted that most emotions are associated\nwith the same (or similar) large-scale brain networks (Pessoa, 2017).\nSecond, support for the importance of large-scale networks to emo-\ntional experience was reported by Lindquist et al. (2016). They carried\nout a meta-analysis (see Glossary) of studies focusing on brain regions\nassociated with positive and negative affect. Very similar brain areas were\nactivated to emotionally positive and negative stimuli (see Figure 15.2).\nBrain areas common to positive and negative stimuli included the anterior\ninsula, ventromedial prefrontal cortex, anterior cingulate cortex, amygdala,\nthalamus and occipito-temporal cortex. Of theoretical importance, these\nfindings suggest the same high-arousal brain networks are associated with\npositive and negative affect.\nThird, our ability to move beyond broad dimensions such as arousal\nand valence depends largely on various cognitive processes. For example,\nLindquist et al. (2012) found brain areas associated with attentional\nFigure 15.2\nThe top and middle rows show brain areas more activated by positive than neutral stimuli (illustrated in purple) and\nnegative than neutral stimuli (illustrated in green); the bottom row shows areas more activated by both positive and\nnegative stimuli than neutral ones (illustrated in orange).\nFrom Lindquist et al. (2016).\n–24\n–14\n–4\n6\n16\n26\n36\n46\nInteractive feature:\nPrimal Pictures’\n3D atlas of the brain\nCreated from usyd on 2022-02-17 03:28:58.",
    "718\nBroadening horizons\nKEY TERM\nAmygdala\nA small almond-shaped\nsubcortical structure\ntowards the front of the\ntemporal lobe strongly\nassociated with several\nemotions including fear.\nprocesses, language and long-term memory were activated across several\nemotions.\nLindquist et al. (2014) showed the importance of language to emotion.\nThey studied patients with semantic dementia (a condition involving sub-\nstantial impairments of concept knowledge; see Glossary). These patients\nviewed photographs of faces showing anger, sadness, fear, disgust, happi-\nness or a neutral expression, and sorted them into meaningful piles. They\ndistinguished clearly between positive and negative emotions but showed\npoor discrimination between the negative emotions.\nBottom-up and top-down processes\nEmotional experience depends on bottom-up (or stimulus-driven) processes\ninvolving attention and perception. It also depends on top-down processes\ninvolving appraisal of the situation (see below, pp. 719–723), drawing on\nstored knowledge of situations similar to the present one. We can see the\ndifferences between these two kinds of processes in a study by Ochsner et al.\n(2009) using brain imaging. In the bottom-up condition, participants were\npresented with aversive photographs and told to respond naturally to the\nimages. In the top-down condition, participants interpreted neutral photo-\ngraphs as if they were aversive.\nWhat did Ochsner et al. (2009) find? The answer is shown in\nFigure 15.3. In the bottom-up condition, brain areas in the occipital, tem-\nporal and parietal lobes associated with visual perceptual processing were\nactivated. There was also high activation within the amygdala (a structure\nFigure 15.3\nBrain areas showing greater\nactivity for top-down than\nfor bottom-up processing\n(shades of blue) and those\nshowing greater activity for\nbottom-up than for top-\ndown processes (shades of\nyellow and red).\nFrom Ochsner et al. (2009).\nReprinted by permission of\nSAGE Publications.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n719\nlocated deep within the temporal lobe). Self-reported negative affect was\nassociated most closely with amygdala activation.\nSomewhat different brain areas were activated in the top-down condi-\ntion. Top-down processing involved the dorsolateral and medial prefrontal\ncortex (areas associated with high-level cognitive processes) and the ante-\nrior cingulate and amygdala were also activated. Self-reported negative\naffect was associated most strongly with activation of the medial prefron-\ntal cortex (associated with producing cognitive representations of stimulus\nmeaning).\nInhibitory control is an important top-down process in human cog-\nnition (see Chapter 6). Individuals with good inhibitory control showed\nsmaller increases in anger and anxiety than those with poor control when\nthose emotions were induced (Tang & Schmeichel, 2014). Thus, inhibitory\ncontrol influences the experience of negative emotional states.\nIn sum, there are substantial differences between bottom-up and top-\ndown processes in emotion. Appraisal and emotion regulation theories (see\nbelow, pp. 723–730) emphasise the role of top-down processes in emotional\nexperience. However, we must not neglect bottom-up processes. Note the\ndistinction between bottom-up or relatively “automatic” processes and\ntop-down or effortful processes is oversimplified. Emotional experience\nmay also depend on intermediate processes (neither entirely automatic nor\neffortful) (Viviani, 2013).\nAPPRAISAL THEORIES\nCognitive processes (especially cognitive appraisal of the situation) influ-\nence when we experience emotional states and what emotional state we\nexperience. Appraisal theories assume “emotional responses are elicited\nas the organism evaluates the relevance of environmental changes for its\nwell-being” (Brosch, 2013, p. 370).\nMost appraisal theories assume each emotion is elicited by its own\nspecific appraisal pattern. For example, Scherer and Ellsworth (2009)\nidentified appraisal profiles for major emotions. For example, you experi-\nence anger if you blame someone else for the current situation and you\nappraise it as offering you control and power. In contrast, you experience\nsadness if you appraise the situation as one permitting very little control\nor power.\nC. Smith and Kirby (e.g., 2009) distinguished between appraisal\ninvolving deliberate conscious processing and appraisal involving auto-\nmatic processes and based on activation of memories. The former is\nslower and more flexible. Smith and Lane (2015) developed this idea by\nproposing multiple appraisal mechanisms (see Figure 15.4). Fast appraisal\nmechanisms start 100 ms after stimulus presentation and respond to its\nnovelty and concern relevance (i.e., relevance to the individual’s concerns).\nSlower appraisal mechanisms process information about goal congruence,\nagency  and norm or value compatibility. Finally, there is a situational\nappraisal.\nAppraisal theories typically assume appraisal is the key determinant of\nemotional states. They also assume appraisal leads to other components\nof emotion (e.g., bodily sensations; action tendencies).\nCreated from usyd on 2022-02-17 03:28:58.",
    "720\nBroadening horizons\nFindings: conscious appraisals\nFontaine et al. (2013) investigated appraisal’s importance in emotion.\nParticipants from 27 countries indicated, for various emotion words, the\nprobability that various features of appraisal and other components of\nemotion would apply to someone experiencing each emotion. Emotions\nwere correctly classified solely from appraisal features in 71% of cases. The\nother components of emotion (e.g., bodily sensations; motor expressions;\naction tendencies) improved classification accuracy only slightly.\nTong (2015) asked participants to recall an experience of 13 differ-\nent positive emotions (e.g., amusement; contentment; hope; pride) and to\nprovide appraisals for each experience. The correct positive emotion was\nidentified from these appraisals 42% of the time (chance = 7.7%).\nMuch research has used scenarios with participants identifying with\nthe central character. Here is an example from Smith and Lazarus (1993).\nA student performed poorly in an examination and then appraised the\nsituation. Participants indicated he would experience anger if he blamed\nthe unhelpful teaching assistant but guilt if he blamed himself (e.g., for\ndoing work at the last minute). Appraisal manipulations generally had\nthe predicted effects on emotion ratings. However, manipulated appraisals\naccounted for less than 30% of the variance in emotion ratings (Parkinson,\n2001).\nThere are substantial individual differences in cognitive appraisal of\nemotional events (Kuppens, 2013). Kuppens et al. (2003) studied four\nappraisals (goal obstacle; other accountability: someone else is to blame;\nunfairness; and control) relevant to anger. No appraisal component was\nFigure 15.4\nMultiple appraisal\nmechanisms used in\nemotion generation.\nVTA = ventral tegmental\narea; nACC = nucleus\naccumbens; DMPFC =\ndorsomedial prefrontal\ncortex; DLPFC =\ndorsolateral PFC; VLPFC =\nventrolateral PFC; VMPFC\n= ventromedial PFC;\ndACC = dorsal anterior\ncingulate cortex; TPJ =\ntemporoparietal junction;\nMTL = medial temporal\nlobe.\nFrom Smith and Lane (2015).\nReprinted with permission of\nElsevier.\nAppraisal hierarchy\nFast appraisal mechanisms (100–140 ms)\nSlower appraisal mechanisms (340–800 ms)\nStable fnal appraisal of the afective\nsignifcance of one’s situation\nSensory representation\n(externally or internally generated)\nProcessing time\nAfective meaning\nVMPFC, MTL\n•\nNorm/value compatibility\nSuperior temporal cortex\nDLPFC\n•\n•\nAgency (caused by self or other?)\nSensorimotor feedback\nDMPFC, TPJ\n•\n•\nGoal congruence\nVTA, nACC (congruent)\ndACC, DLPFC (incongruent)\n•\n•\nConcern relevance\nAmygdala (modulated by other\nstructures)\n•\nNovelty\nAmygdala\nHippocampus/perirhinal cortex\nOrbitofrontal cortex\n•\n•\n•\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n721\nessential for the experience of anger in unpleasant situations (e.g., some\nindividuals felt angry without the appraisal of unfairness or the pres-\nence of a goal obstacle). Tong (2010) studied four negative emotions\n(anger; sadness; fear; and guilt). No single appraisal (or combination of\nappraisals) was necessary or sufficient for the experience of any emotional\nstate.\nParticipants are typically presented with hypothetical scenarios and so\nexperience little actual emotion. Bennett and Lowe (2008) rectified this by\nasking nurses to identify their most stressful recent work-related incident.\nAnger and frustration were the emotions most strongly experienced and\nthese emotional reactions were predicted reasonably well by the nurses’\nappraisals of the stressful situation.\nMost research reports associations or correlations between cognitive\nappraisals and emotional states and so cannot shed direct light on causal-\nity. We can decide whether appraisals help to cause emotional states by\nmanipulating people’s cognitive appraisals when confronted by emotional\nstimuli. Schartau et al. (2009) had participants watch films of humans and\nanimals experiencing marked distress. Some participants received training\nin positive cognitive appraisal (e.g., “silver lining: there are usually some\ngood aspects to every situation” (p. 19)). This training reduced horror, dis-\ntress and physiological arousal indexed by the galvanic skin response (see\nFigure 15.5).\nSimilar research has focused on interpretive bias (interpreting ambigu-\nous situations as threatening). The existence of interpretive bias in anxious\nindividuals suggests their appraisals are unduly negative. We could show\nsuch appraisals influence emotional reactions by using training to reduce\ninterpretive bias (interpretive bias modification). As predicted, reductions\nin experienced anxiety generally follow such training (Liu et al., 2017; dis-\ncussed later, p. 762).\nFigure 15.5\nChanges in self-reported\nhorror and distress and\nin galvanic skin response\n(GSR) between pre-\ntraining and post-training\nfor individuals instructed\nto simply watch the films\n(watch condition) and\nthose training in positive\ncognitive appraisal\n(appraisal condition).\nFrom Schartau et al. (2009).\n© American Psychological\nAssociation.\nCreated from usyd on 2022-02-17 03:28:58.",
    "722\nBroadening horizons\nFactors other than situational appraisal influence emotional experi-\nence. According to the James-Lange theory of emotion (James, 1890),\nour awareness of our own bodily states influences experienced emotion.\nThe theory predicts those who have had Botox (which often paralyses\nthe muscles involved in facial expression) should have reduced emotional\nexperi ence. Davis et al. (2010) obtained support for this prediction using\npositive and negative video clips.\nAccording to the James-Lange theory, each emotion has its own specific\npattern of physiological activity. Which emotion we experience in any given\nsituation depends importantly on our awareness of the current pattern of\nphysiological activity. Thus, patients with spinal cord injury (who have dra-\nmatically reduced awareness of their own bodily activity) should have very\nweak emotional experience. In fact, most such patients report experiencing\nas much emotion as healthy controls (Deady et al., 2010).\nSiegel et al. (2018) carried out a meta-analysis of studies focusing on\nthe autonomic nervous system activity associated with each emotion. They\nfailed to support the James-Lange theory because each emotion did not\nhave its own “fingerprint” (autonomic nervous system pattern). In sum, the\nemotions we experience probably depend far more on situational appraisal\nthan on feedback from physiological activity.\nFindings: non-conscious emotional processing\nMuch evidence suggests emotional reactions can depend on non-conscious\nprocesses. Winkielman et al. (2005) presented happy and angry faces sub-\nliminally (below the conscious level) to thirsty participants. Those presented\nwith subliminal happy faces poured and drank twice as much liquid as\nthose presented with subliminal angry faces. In another experiment, thirsty\nparticipants paid an average of 38 cents for a drink after being presented\nwith happy faces but only 10 cents following angry faces. Thus, affective\nreactions can be unconscious.\nIn Chapter 2, we discussed patients with blindsight (see Glossary).\nSeveral of these patients show affective blindsight – emotional stimuli\nare discriminated in the absence of conscious perception of those stimuli.\nTamietto et al. (2009) presented two blindsight patients with pictures of\nfacial or bodily expressions of fear or happiness to their intact or blind\nvisual field. The zygomaticus major muscle (involved in smiling) was\nactivated more by happy expressions whereas the corrugator supercilli\n(involved in frowning) was activated more by fearful expressions whether\nor not the expressions were consciously perceived. Of importance, these\nfacial reactions occurred 200–300 ms faster for non-consciously perceived\nexpressions, probably because this emotional processing largely bypasses\nthe cortex.\nDiano et al. (2017) reviewed research on conscious and non-conscious\nemotion processing. There are two routes between presentation of an emo-\ntional stimulus and activation of the amygdala (a brain area of central\nimportance in emotion):\n(1) Processing typically involves a cortical route with emotional stimuli\nbeing consciously perceived.\nKEY TERM\nAffective blindsight\nThe ability of brain-\ndamaged patients to\ndiscriminate among\ndifferent emotional stimuli\nin spite of the absence\nof conscious perception of\nthose stimuli.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n723\n(2) There is also a subcortical route involving the superior colliculus and\npulvinar when emotional stimuli are not consciously perceived.\nEvaluation\nAppraisal processes influence whether we experience emotion and which\nemotion we experience. Individual differences in emotional experience\noccur in part because appraisals vary across individuals. Evidence supports\nthe proposed distinction between conscious and “automatic” appraisal pro-\ncesses. Evidence based on manipulating cognitive appraisals suggests they\ncausally influence emotion. Most evidence suggests that situational apprais-\nals are more important in determining which emotion is experienced than is\nfeedback from physiological activity.\nWhat are appraisal theory’s limitations? First, the assumption that sit-\nuational appraisal is always crucial in determining emotional experience is\ntoo strong. In fact, individuals’ emotional experience is only moderately\nwell predicted by their situational appraisals because there are other deter-\nminants of emotional experience (e.g., awareness of one’s own bodily state).\nSecond, most research focuses on individuals on their own responding\npassively to a hypothetical emotional situation. In the real world, however,\nmost emotional experiences occur in social settings and our emotional\nreactions depend on the reactions of others (Parkinson & Manstead, 2015).\nThird, appraisal theorists assume a clear-cut distinction between cog-\nnition and emotion. However, appraisals and emotional experiences often\nblur into each other (McEachrane, 2009).\nFourth, most research has used relatively unambiguous situations pro-\nducing a single emotion. In real life, however, we often experience mixed\nemotions (e.g., nostalgia combines wonderful memories with sadness for\nwhat has been lost) (Frijda, 2013).\nFifth, appraisal theories typically focus on appraisals of the current\nsituation. However, appraisals can also relate to the past and/or future.\nFor example, part of the anger experienced by one person towards another\nperson may be caused by appraisals relating to that person’s past behav-\niour and concerns whether they will make amends in the future (Parkinson,\n2011).\nSixth, the impact of appraisals on other components of emotion is\nmore flexible than assumed theoretically. For example, individuals produc-\ning the same appraisal in a given situation may nevertheless differ in their\nphysiological responding and behaviour because of their past experiences\nand personality (Kuppens, 2013).\nEMOTION REGULATION\nSo far we have considered what happens when an individual encounters a\nsituation and responds to it with an emotional experience. This is emotion\ngeneration (a spontaneous emotional response to the current situation). In\nthe real world, matters are often more complex. For example, an author-\nity figure makes you angry by saying something unpleasant. You decide\n(wisely!) to inhibit your anger and pretend all is well. This illustrates a\nKEY TERM\nEmotion generation\nThe immediate and\nspontaneous emotional\nresponse to a given\nsituation; see emotion\nregulation.\nResearch activity:\nAppraisals in daily life\nCreated from usyd on 2022-02-17 03:28:58.",
    "724\nBroadening horizons\ntwo-stage approach: an initial emotional reaction is followed by attempts\nto change it.\nThe above example involves emotion regulation. Emotion regulation\nis “the activation of a goal to modify which emotion one has, when one has\nthe emotion, or how one experiences or expresses the emotion” (Ghafur\net  al., 2018, p. 31). Thus, emotion regulation occurs when an individual\noverrides their initial, spontaneous emotional response.\nWe can compare emotion generation and emotion regulation in the\nlaboratory. For example, two groups of participants experience the same\nemotional situation. One group is instructed to react naturally (emotion\ngeneration). The other group is told to regulate their emotional responses\nusing a specified strategy (emotion regulation). Emotional responding\n(e.g., self-reported emotion; brain activation) in the two conditions is then\ncompared.\nThe distinction between emotion generation and emotion regulation\nis often blurred. For example, emotional-generation processes often lead\nto behaviour that changes the situation and thus the emotional response.\nMore generally, the notion of emotion generation implies unrealistically\nthat our emotional experiences are often unregulated and that emotions\noccur as passive reactions to appraisals (Parkinson, 2015).\nSuppose you see several very unpleasant pictures. You can simply watch\nthem or use the emotion-regulation strategy of reappraisal (reinterpreting\nthe meaning of the pictures to reduce negative emotions). Since reappraisal\nis generally effective, it seems very likely you would prefer reappraisal. In\nfact, when such a study was carried out (Suri et al., 2015), reappraisal\nwas used only 16% of the time. Thus, most individuals are not fully aware\nof the potential benefits of emotion regulation.\nProcess model\nA process model of emotion regulation put forward by Gross and\nThompson (2007) has been very influential. In Figure 15.6, the basic pro-\ncesses involved in emotion generation are shown along the horizontal line.\nOf importance, it is assumed emotional intensity generally increases over\ntime as we move from left to right.\nFigure 15.6 also incorporates the crucial assumption that emotion-\nregulation strategies can alter the emotion-generation process at various\npoints in time (indicated by the arrows). For example, a socially anxious\nperson could reduce anxiety in the following ways:\n(i)\navoiding potentially stressful social situations (situation selection);\n(ii) asking a friend to accompany them (situation modification);\n(iii) focusing on distracting thoughts (attention deployment);\n(iv) telling themselves that most people are friendly (cognitive change);\n(v) inhibit the behavioural expression of anxiety (response modulation).\nIt is unclear in the above process model how emotion-regulation strategies\nstart and stop. Accordingly, Gross (2015) proposed the extended process\nmodel of emotion regulation, which identifies three stages of emotion\nregulation:\nKEY TERM\nEmotion regulation\nThe use of explicit\n(deliberate and effortful)\nprocesses or implicit\n(relatively automatic)\nprocesses to change the\nspontaneous emotional\nstate (usually a negative\none) produced by the\nemotion-generation\nprocess.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n725\nKEY TERMS\nDistraction\nA strategy used in\nemotion regulation\nin which the individual\ndisengages attention from\nemotional processing\nand focuses on neutral\ninformation.\nReappraisal\nA strategy used in\nemotion regulation\nin which the individual\nelaborates emotional\ninformation from an event\nprior to changing its\nmeaning.\n(1) identification (deciding whether to regulate);\n(2) selection (deciding which strategy to select);\n(3) implementing (making use of a given strategy).\nIn the original process model, the emphasis was on a linear sequence of pro-\ncesses starting with situation selection and ending with response  modulation.\nIn the extended model, the processes are arranged in a  circular format – this\nmakes it clear that response modulation can influence  situation selection\nand so set off a new chain of processes.\nMost emotion-regulation strategies involve the attentional deployment\nstage (e.g., distraction – disengaging attention from emotional processing)\nor the cognitive change stage (e.g., reappraisal – elaborating emotional\ninformation and then changing its meaning). Sheppes et al. (2014) con-\nsidered when distraction and reappraisal are most likely to be used. They\nassumed the emotional intensity of an event generally increases over time\nif not subject to emotion regulation. Distraction is less cognitively demand-\ning than reappraisal and can be used early to control negative emotion and\n“nip it in the bud”. Reappraisal is more cognitively demanding but can\nproduce long-lasting benefits.\nSheppes et al. (2014) used the above analysis to make two predictions\n(both supported by research). First, distraction will be preferred to reap-\npraisal in high negative intensity situations because it blocks emotional\ninformation before it intensifies. Second, reappraisal will be used more\noften with emotional stimuli encountered frequently than those encoun-\ntered only once – reappraisal of repeated stimuli reduces their subsequent\nemotional impact.\nSo far we have considered controlled conscious processes (explicit\nemotion regulation). In contrast, implicit emotion regulation “is character-\nised by the absence of an explicit instruction, is evoked automatically by\nthe stimulus itself, runs to completion without conscious monitoring, and\ncan happen without insight and awareness” (Etkin et al., 2015, p. 694).\nUsing an explicit-regulation strategy repeatedly often leads to the devel-\nopment of implicit processes (Braunstein et al., 2017). Implicit regulation\nhas the advantage over explicit regulation that it is less costly in its use of\ncognitive resources.\nHow do implicit processes support emotion regulation? Koole et  al.\n(2015) put forward three answers. First, implicit processes can help\nFigure 15.6\nA process model of\nemotion regulation based\non five major types of\nstrategy (situation selection,\nsituation modification,\nattention deployment,\ncognitive change and\nresponse modulation).\nFrom Gross and Thompson\n(2007). Reprinted with\npermission of Guilford Press.\nCreated from usyd on 2022-02-17 03:28:58.",
    "726\nBroadening horizons\nindividuals decide whether to engage in emotion regulation. Second, they\ncan simplify the selection of appropriate emotion-regulation strategies.\nThird, they may facilitate the execution of such strategies.\nFindings: behavioural\nWhich are the most effective emotion-regulation strategies? In a meta-\nanalysis, Augustine and Hemenover (2009) distinguished between cognitive\nstrategies (involving thinking) and behavioural strategies (involving physical\naction). In general, cognitive strategies (especially reappraisal and distrac-\ntion) were more effective.\nWebb et al. (2012) carried out the most thorough meta-analysis of the\neffectiveness of different emotion-regulation strategies making use of the\nprocess model shown in Figure 15.6. Overall, strategies involving cogni-\ntive change had a moderately beneficial effect on emotion, those involving\nresponse modulation had a small effect, and strategies involving deploy-\nment had a non-significant effect.\nWebb et al. (2012) argued that combining several different strategies\nin the same category is oversimplified. For example, although attentional\ndeployment strategies overall had a non-significant effect, distraction\nclearly had beneficial effects. With respect to cognitive-change strategies,\nreappraising the emotional situation was more beneficial than reapprais-\ning the emotional response. With response modulation, suppressing emo-\ntional  expression had a moderate effect on emotion but suppressing\nemotional experience had no effect. In sum, what matters is the specific\nstrategy rather than the broad category.\nThere is an important qualification on the findings discussed so far –\nthe effectiveness of any given emotion-regulation strategy typically varies\nacross situations. For example, consider a study by Troy et al. (2013).\nThey hypothesised that reappraisal would be effective in situations where\nstress was uncontrollable but not those where it was controllable. In the\nlatter situations, problem-focused coping would be superior to changing\none’s emotional state.\nTroy et al.’s (2013) findings confirmed their hypotheses. Participants\nwith high appraisal ability were less depressed than those with low\nappraisal ability when high stress was uncontrollable (see Figure 15.7).\nHowever, high appraisal ability was associated with more depression when\nhigh stress was controllable.\nDeciding which of two emotion-regulation strategies is more “effective”\ncan be harder than might be imagined. Troy et al. (2018) compared the\nemotion-regulation strategies of reappraisal (reinterpreting meaning) and\nacceptance (accepting one’s emotions) when participants saw sad movie\nclips. Reappraisal was more effective than acceptance at reducing negative\nemotions. However, acceptance was more effective than reappraisal at reg-\nulating physiological responding and it was also less effortful.\nWe turn now to the use of implicit processes in emotion regula-\ntion. Mauss et al. (2007) exposed participants to an anger-provocation\nexperience (the experimenter was impatient and irritated). Those previ-\nously encountering reappraisal-relevant words (e.g., restrains; stable) on\nan unrelated task experienced less anger and fewer negative emotions\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n727\ngenerally than controls because of the implicit processes they used when\nprovoked.\nWang and Xuebing (2017) carried out a similar study and obtained\nsimilar findings. They also found that implicit emotion regulation affected\nprocessing within the brain approximately 170 ms after stimulus onset.\nThus, implicit emotion regulation influences early processing and is proba-\nbly relatively “automatic”.\nDoré et al. (2016) argued the effectiveness of emotion regulation\ndepends on interactions involving the individual person, the situation and\nthe strategy being adopted. Moreover, such interactions are present at\nthree different stages of emotion regulation: identification of an  opportunity\nto regulate; selection of a specific regulation strategy; and implementation\nof that strategy (Gross, 2015). More research is needed before we can\nspecify which strategies are most beneficial for a given person in a given\nsituation.\nFindings: neuroimaging\nMuch research on emotion regulation has focused on the relevant brain\nmechanisms (e.g., Braunstein et al., 2017; Etkin et al., 2015). Most effective\nemotion-regulation strategies involve cognitive control processes associ-\nated with activation within the prefrontal cortex (especially the dorsolat-\neral and ventrolateral prefrontal cortex). These effortful processes cause\nreduced  activation in the amygdala (strongly implicated in emotional\nresponding) and reduced negative affect.\nLee et al. (2012) reported relevant evidence in a study on the use\nof reappraisal to reduce negative affect while viewing negative pictures.\nIndividuals with the strongest links between prefrontal areas and the amyg-\ndala used reappraisal most effectively. Klumpp et al. (2018) found that\nFigure 15.7\nMean level of depression as a function of stress severity and cognitive reappraisal ability (high = - - - -; low = ––––––)\nwhen the situation was low in controllability (left-hand side) and high in controllability (right-hand side).\nFrom Troy et al. (2013). Reprinted by permission of SAGE Publications.\nCreated from usyd on 2022-02-17 03:28:58.",
    "728\nBroadening horizons\nindividuals most successful at using reappraisal to reduce negative emo-\ntions had the greatest prefrontal activity and the least amygdala activation.\nIn a meta-analysis, Kohn et al. (2014) identified several brain areas\nassociated with explicit emotion regulation. Their findings were consistent\nwith a three-stage neural network model (see Figure 15.8):\n(1) Emotion evaluation: this network centres on the ventrolateral prefron-\ntal cortex (VLPFC) and is involved in initiating appraisal and signal-\nling the need to regulate emotion.\n(2) Initiation of regulation: this network centres on the dorsolateral pre-\nfrontal cortex (DLPFC) and is involved in processing the regulation\nof emotion.\n(3) Execution of regulation: this network regulates affective arousal by\nchanging the emotional state.\nThe crucial role played by the dorsolateral prefrontal cortex in emotion\nregulation received strong support from Feeser et al. (2014). Participants\nused reappraisal to increase or decrease their emotional reactions to\nnegative pictures. On some trials, transcranial direct current stimulation\n(tDCS; see Glossary) was used to increase the excitability of the dorso-\nlateral prefrontal cortex. As predicted, the use of tDCS increased self-\nreported emotional arousal when participants were instructed to increase\ntheir emotional reactions and decreased it when they were told to decrease\ntheir reactions. In sum, tDCS enhanced cognitive control mediated by the\ndorsolateral prefrontal cortex.\nBraunstein et al. (2017) reviewed neuroimaging research showing\nthe brain mechanisms associated with implicit emotion regulation differ\nfrom those associated with explicit regulation. More specifically, implicit\nregulation involves the ventral anterior cingulate and the ventrome-\ndial prefrontal cortex but not the dorsolateral or ventrolateral prefrontal\ncortex.\nFigure 15.8\nA three-stage neural network model of emotion regulation. (a) In the emotion evaluation network, affective arousal is\nrelayed via the amygdala (Amy) and basal ganglia (BG) to the ventrolateral prefrontal cortex (VLPFC). (b) In the initiation-\nof-regulation network, the dorsolateral prefrontal cortex (DLPFC) is involved in processing the emotion regulation. (c) The\nexecution-of-regulation network centring on the superior temporal gyrus (STG), the supplementary motor area (SMA) and\nthe angular gyrus generates a regulated emotional state.\nFrom Kohn et al. (2014). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n729\nKEY TERM\nMajor depressive\ndisorder\nA mental disorder\ncharacterised by\ndepressed mood,\ntiredness and lack of\npleasure and interest in\nvarious activities.\nIN THE REAL WORLD: EMOTION REGULATION AND\nMENTAL DISORDERS\nUnsurprisingly, patients with anxiety disorders or major depressive disorders have difficulties in\nexplicit emotion regulation. For example, D’Avanzato et al. (2013) found anxious and depressed\npatients engaged in the maladaptive emotion-regulation strategies of rumination (obsessive thinking\nabout emotional issues) and expressive suppression (hiding or inhibiting emotional behaviour).\nVisted et al. (2018) confirmed these findings in a meta-analysis of studies on depressed patients.\nThey also found that these patients made less use than healthy controls of adaptive strategies such\nas acceptance (accepting one’s emotions), problem solving and reappraisal.\nIt has often been argued that flexible emotion regulation is desirable because of frequent\nchanges in the problems we face. Patients with emotional disorders often exhibit inflexible emotion\nregulation which probably contributes to their emotional disturbances (Aldao et al., 2015).\nThere is also evidence that patients with emotional disorders have difficulties with implicit\nemotion regulation. For example, patients with generalised anxiety disorder (characterised by\nexcessive worry and anxiety in several life domains) have deficient implicit regulation of emotional\nconflict (Etkin & Schatzberg, 2011).\nWhy are patients with emotional disorders poor at emotion regulation? Fernandez et al. (2016)\ndiscussed four reasons. First, they find it hard to identify emotions that need regulating; (2) they\noften fail to select an effective emotion-regulation strategy; (3) they sometimes implement the\nselected strategy ineffectively; and (4) they often fail to monitor the implemented strategy to\ndecide whether a different strategy should be used.\nWhich emotion-regulation strategies are associated with beneficial effects on anxiety and\ndepression? In their review, Aldao et al. (2010) found acceptance, problem solving and reappraisal\nall reduced the symptoms of anxiety and depression.\nMennin et al. (2015) argued emotion-regulation therapy might be valuable. Accordingly,\nthey devised therapy emphasising the teaching of effective emotion-regulation strategies and\nencouraging patients to use these strategies when they anticipated being in a stressful situation.\nThis therapy was used with anxious patients, half of whom also had depressive symptoms. Therapy\nincreased patients’ use of effective emotion-regulation strategies (e.g., reappraisal) and reduced\nthe symptoms of anxiety and depression. Renna et al. (2018) obtained similar findings. Reductions\nin anxious and depressive symptoms produced by emotion regulation therapy were maintained\nover a period of nine months post-treatment.\nWhat are the long-term effects of emotion-regulation therapy? One approach is to consider\nchanges in brain activity resulting from therapy. Successful emotion regulation often involves\nincreased activity in prefrontal areas (e.g., dorsolateral prefrontal cortex), indicative of enhanced\ncognitive control, and decreased activity in limbic areas (e.g., amygdala), reflecting responsiveness\nto emotional stimuli. This pattern has often been found in anxious and depressed patients post-\ntherapy (Messina et al., 2016).\nEvaluation\nSeveral advances have been made. First, effective emotion-regulation strat-\negies often involve effortful cognitive processing in the prefrontal cortex\nleading to reduced amygdala activation. Second, the extended process model\n(Gross, 2015) is more realistic than Gross’s previous model, which was\nbased on a linear sequence of processes, and it also identifies factors respon-\nsible for the initiation of emotion regulation. Third, emotion-regulation\nCreated from usyd on 2022-02-17 03:28:58.",
    "730\nBroadening horizons\nstrategies can be explicit or implicit. Fourth, factors influencing which\nstrategy is selected in a given situation have been identified. Fifth, there are\npromising signs emotion-regulation therapy is successful in treating anxiety\nand depression.\nWhat are the limitations of theory and research in this area?\n(1) There is no clear-cut distinction between emotion generation and\nemotion regulation.\n(2) Behavioural emotion-regulation strategies (e.g., drinking alcohol;\narguing with others) have been de-emphasised.\n(3) The effectiveness of emotion regulation depends on complex (but\npoorly understood) interactions involving the individual, the situation\nand the emotion-regulation strategy selected (Doré et al., 2016).\n(4) We do not know why most people have limited awareness of the ben-\nefits of emotion-regulation strategies and often fail to use effective\nstrategies. For example, Suri et al. (2015) found only 16% of parti-\ncipants used the effective strategy of reappraisal even when its use was\nexplicitly suggested. A possible explanation is that people prefer strat-\negies they have used recently and/or frequently even when such\nstrategies are relatively ineffective in the current situation (Ghafur\net al., 2018).\n(5) Little is known concerning individual differences in the ability to use\nany given strategy. However, McRae et al. (2012) made a start: indi-\nviduals using reappraisal successfully had above-average well-being\nand working memory capacity (see Glossary).\nAFFECT AND COGNITION: ATTENTION AND\nMEMORY\nMuch laboratory research differs considerably from everyday life because\nindividuals’ cognitive processes and performance are assessed in a relatively\nneutral emotional state. In real life, emotions often influence our behav-\niour. Consider “road rage” (i.e., frustrated drivers become angry and so\ndrive dangerously). Zhang and Chan (2016) reviewed studies on driving\nanger and driving behaviour. Driving anger was associated with aggressive\ndriving, risky driving and driving errors. However, it was only modestly\nassociated with near misses and accidents.\nQu et al. (2016) confirmed that experiencing driving anger was a poor\npredictor of car crashes. However, individuals expressing anger verbally\n(e.g., shouting insults) and physically (e.g., making hostile gestures) were\nmuch more likely to cause car crashes.\nOur emotional state influences numerous aspects of cognition includ-\ning perception, attention, interpretation of situations, learning, memory,\njudgement, decision-making and reasoning (Blanchette & Richards, 2010).\nWe discuss research on attention and memory here and the next section\nfocuses on judgement and decision-making.\nMost theories assume the effects of positive and negative affect on cog-\nnitive processes (e.g., attention; memory; judgement; decision-making) are\nfixed and constant. However, this assumption is oversimplified. Huntsinger\net al. (2014) and Ray and Huntsinger (2017) argued persuasively the\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n731\ninfluence of affect on cognitive processes is typically flexible. More specif-\nically, affect provides useful feedback concerning an individual’s current\nmental state: “Positive affective feelings act as a ‘go signal’ that promotes\nthe use of accessible processing styles, and negative affective feelings act as\na ‘stop signal’ that inhibits their use” (Ray & Huntsinger, 2017. p. 2). This\nis an affect-as-cognitive-feedback account.\nSeveral techniques have been used to manipulate people’s mood state\n(Lench et al., 2011). The most common technique (24% of studies) involves\npresenting emotional films. Another popular technique (20% of studies)\ninvolves autobiographical recall (e.g., describing an intense emotional\nexperience).\nAttention\nWe have flexibility in what we attend to and also the scope of focal atten-\ntion (see Chapter 5). Some theorists (e.g., Eriksen & St James, 1986) have\ncompared visual attention to a zoom lens allowing the attended area to\nbe increased or decreased. This issue is relevant to understanding long-\nterm memory: our memory of an event is strongly influenced by what we\nattended to during learning.\nHow does affect influence attentional breadth? Easterbrook (1959)\nprovided an influential answer with respect to negative affect. He hypoth-\nesised the range of cues processed (i.e., the breadth of attention) decreases\nas arousal or anxiety increases. Thus, high negative affect produces “tunnel\nvision”.\nEasterbrook’s hypothesis enhances our understanding of eyewitness\nmemory (see Chapter 8), because eyewitnesses are often very anxious\nwhen observing a crime. It is also relevant to the effects of anxiety on\ndriving. Anxious drivers attend less than non-anxious ones to peripheral\ninformation (Janelle et al., 1999). Briggs et al. (2011) used a simulated\ndriving task with spider-phobic drivers. They showed narrowing of atten-\ntion while driving when made anxious by having a conversation about\nspiders.\nWhat about the effects of positive affect on attentional breadth?\nAccording to Fredrickson and Branigan (2005, p. 315), positive emotions\n“widen the array of percepts, thoughts, and actions presently in mind.”\nThus, positive affect produces broadening of attention rather the narrow-\ning of attention assumed for negative affect by Easterbrook (1959).\nGable et al. (2015a) argued we should also consider motivational inten-\nsity (e.g., having the goal of approaching or avoiding a stimulus). Positive\naffect can involve low motivational intensity (e.g., listening to music) or\nhigh motivational intensity (e.g., seeing an attractive member of the oppo-\nsite sex). Similarly, negative affect can involve low motivational intensity\n(e.g., being exposed to sad situations) or high emotional intensity (e.g.,\nbeing exposed to threatening situations).\nGable et al. (2015a) argued positive and negative affective states of\nhigh motivational intensity produce attentional narrowing because this\nhelps individuals to acquire desirable objects and avoid unpleasant ones.\nIn contrast, there is attentional broadening with positive and negative\nCreated from usyd on 2022-02-17 03:28:58.",
    "732\nBroadening horizons\naffective states of low motivational intensity because it leaves people open\nto encountering new opportunities.\nFindings\nEasterbrook’s hypothesis and the theoretical viewpoint of Gable et al.\n(2015a) both predict that anxiety (which has high motivational intensity)\nshould produce attentional narrowing. Relevant evidence has been obtained\nfrom several studies where participants performed a primary task presented\nin the centre of the visual field and a secondary task in the periphery. If\nanxiety causes attentional narrowing, it should impair performance on the\nsecondary task more than the primary task. That prediction has received\nconsistent support (Eysenck et al., 2007). Both theories predict anger (also\nhaving high motivational intensity) should produce attentional narrowing;\nthis finding was reported by Gable et al. (2015b).\nThe two theories differ with respect to the effects of sadness (a mood\nstate involving low motivational intensity). According to Gable et al.’s\nmotivational intensity theory, sadness should produce attentional broaden-\ning whereas the opposite prediction follows from Easterbrook’s hypothesis.\nGable and Harmon-Jones’ (2010b) findings supported motivational inten-\nsity theory.\nFredrickson and Branigan (2005) predicted that positive affect leads\nto attentional broadening. Vanlessen et al. (2016) reported strong support\nfor this prediction in their meta-analytic review. How can we explain\nthese findings? According to Pourtois et al. (2017), positive affects leads to\nreduced cognitive control and so less attentional selectivity.\nNote that Gable et al.’s (2015a) motivational intensity theory predicts\npositive affect should produce attentional narrowing if there is high moti-\nvational intensity. This prediction (opposite to that of Fredrickson and\nBranigan’s theory) was supported in a study by Gable et al. (2015b).\nIn sum, most of the findings support Gable et al.’s (2015a) theoreti-\ncal approach. Thus, attentional narrowing (or broadening) depends much\nmore on whether affective states have high or low motivational intensity\nthan on whether they are positive or negative. Huntsinger (2012) added\na complication to this picture. He argued individuals generally interpret\npositive affect as indicating they should continue with their current process-\ning strategy. In contrast, negative affect indicates they should inhibit their\ncurrent processing strategy. These assumptions were incorporated into the\naffect-as-cognitive-feedback account mentioned earlier.\nIn Huntsinger’s (2012) study, participants initially performed a task\nusing a broad (global) attentional focus, a narrow or local attentional\nfocus, or a mixture. Then they performed a different task: deciding whether\na central letter was an H or S. This central letter was flanked by letters\ncompatible or incompatible with it. It was assumed individuals with a\nbroad attentional focus would be more influenced by flanker compatibility\nthan those with a narrow attentional focus. As predicted, those in a happy\nmood had the same attentional focus as on the initial task whereas those in\na sad mood had the opposite attentional focus (see Figure 15.9).\nThe effects of mood on memory (discussed further shortly, pp. 734–738)\ndepend in part on whether the mood narrows or broadens attention. For\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n733\nexample, emotion often increases memory for information central to our\ncurrent goals but reduces it for unimportant information (Levine & Edelstein,\n2009). Consider the weapon focus effect (the tendency for eyewitnesses to\nattend narrowly to a weapon and thus fail to remember peripheral details)\nreviewed by Fawcett et al. (2016) (see Chapter 8).\nIt is tempting to link “memory narrowing” associated with emotional\nstates to attentional narrowing during learning. However, there are prob-\nlems with that argument. First, visual attention at learning often fails\nto predict the extent of “memory narrowing” (Steinmetz et al., 2016).\nSecond, the predicted memory narrowing is not always found. Steinmetz\net al. (2016) presented positive, negative or neutral objects on neutral\nbackgrounds. When the object cued recall of the associated background,\nmemory for background or peripheral information was actually greater\nwhen emotional objects (positive or negative) had been presented. Thus,\nperipheral information is often stored in memory and emotional cues may\nfacilitate its retrieval.\nThird, it follows from Gable et al.’s (2015a,b) theory that attention (and\nperhaps memory) depend on the motivational intensity of an  emotional\nstate. Thus, there should be memory broadening if the emotional state\nhas low motivational intensity. Talarico et al. (2009) asked participants\nto recall eight emotional autobiographical memories. Peripheral details\nwere poorly recalled with memories associated with emotions having\nhigh  motivational intensity (anger; fear; negative surprise). However, sad\nmemories were associated with reasonably good recall of peripheral mem-\nories perhaps because of the low motivational intensity of that emotional\nstate.\nTalarico et al. (2009) found good recall of peripheral details for all\ntypes of positive memories. This fits with Frederickson and Branigan’s\n(2005) theory and also fits Gable et al.’s (2015a,b) theory if we assume\n(perhaps mistakenly) that most positive mood states occur with low moti-\nvational intensity. Of relevance, Gable and Harmon-Jones (2010a) found\npositive affect enhanced memory for peripheral details when there was low\nmotivational intensity but not when there was high motivational intensity.\nFigure 15.9\nThe incompatibility flanker\neffect (incompatible\ntrials–compatible trials) on\nreaction times as a function\nof mood (happy or sad)\nand whether a global, local\nor mixed focus had been\nprimed on a previous task.\nFrom Huntsinger (2012).\n40\nHappy\nSad\n35\n30\n25\n20\n15\n10\n5\n0\nGlobal\nLocal\nPerceptual prime\nFlanker imcompatibility efect\nMixed\nCreated from usyd on 2022-02-17 03:28:58.",
    "734\nBroadening horizons\nConclusions\nThe hypotheses that negative affect produces attentional narrowing and\npositive affect produces attentional broadening are oversimplified. The\nobtained findings depend mostly on the level of motivational intensity.\nThe notion (Huntsinger et al., 2014) that positive affect leads individuals to\nmaintain their previous cognitive processes whereas negative affect causes\nthem to change those processes has received support.\nThere is strong support for two conclusions. First, positive and neg-\native affect typically have significant influences on attentional processes.\nSecond, “Affective influences on cognition are . . . not fixed but mallea-\nble [flexible]” (Clore et al., 2018, p. 78). We probably benefit from this\nattentional flexibility rather than having our attentional processes inflexibly\ndetermined by our current emotional state.\nMemory\nHow does emotion influence long-term memory? Emotional events are for-\ngotten more slowly than neutral ones (especially those that produce nega-\ntive rather than positive affect: Bowen et al., 2018). As a result, the memory\nadvantage for emotional events generally increases over time (Yonelinas\n& Ritchey, 2015). Evidence that emotional events are often better remem-\nbered than neutral ones comes from research on flashbulb memories (vivid\nmemories of dramatic events such as 9/11; see Chapter 8). Flashbulb mem-\nories are especially long-lasting when there is an initial intense emotional\nexperience. For example, those near the World Trade Centre when it was\ndestroyed had more vivid memories of that event than those further away\n(Sharot et al., 2007).\nBrain mechanisms: amygdala\nThe effects of mood or emotion on long-term memory depend on activa-\ntion within several brain regions. Of central importance is the amygdala\n(see Glossary), which is associated with several emotions. Researchers\noften refer to the amygdala but note that it consists of at least three com-\nponent parts (Hortensius et al., 2017) and so is more complex than usually\nassumed.\nEmotion’s memory-enhancing effects depend in part on amygdala acti-\nvation (Dolcos et al., 2017). Tambini et al. (2017) even found participants\nshowed enhanced long-term memory for neutral items presented up to 30\nminutes following the processing of emotionally arousing stimuli. This\noccurred because the emotionally arousing stimuli produced long-lasting\nactivation within the amygdala and related brain areas.\nAdolphs et al. (2005) found healthy controls showed enhanced memory\nfor gist when the encoding context was emotional rather than neutral. In\ncontrast, patients with amygdala damage showed a specific impairment\nlimited to gist memory with an emotional context at encoding, but such\ndamage was not associated with impaired memory for background details.\nThese findings suggest the amygdala is required for focused attention on\nCase study:\nHills et al. (2011)\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n735\nKEY TERM\nUrbach-Wiethe disease\nA disease in which the\namygdala and adjacent\nareas are destroyed;\npatients with this disease\nhave impaired emotional\nprocessing.\nimportant information and are thus consistent with Easterbrook’s (1959)\nhypothesis (discussed above, see p. 731).\nWe can also assess the role of the amygdala in influencing the effects\nof emotion on memory by studying patients with Urbach-Wiethe disease,\nin which the amygdala and nearby areas are largely or totally destroyed\n(see Feinstein, 2013, for a review). Cahill et al. (1995) found a patient (BP)\nhad poorer recall of a very emotional story event than of an emotionally\nneutral event. In contrast, healthy controls had much better recall of the\nemotional event. Similarly, Siebert et al. (2003) found Urbach-Wiethe\npatients had greater memory impairment for emotional pictures than\nneutral ones.\nIt is often assumed amygdala activation facilitates the storage of emo-\ntional memories in long-term memory via a physiologically based process\nof consolidation (see Glossary). This theory implies healthy individuals\nwould have superior long-term memory for all the information associated\nwith an emotional event. In fact, that is not the case. Sharot and Yonelinas\n(2008) found negative pictures were remembered better than neutral ones\n24 hours after learning. However, emotion did not influence contextual\ninformation (i.e., whether the pictures had been presented in the context of\na colour or complexity task).\nA major reason why the amygdala is of importance in explaining the\nenhancing effects of mood on memory is because it is a hub having numer-\nous connections to 90% of cortical regions and it is involved in various\nbrain networks. Supporting evidence was reported by Murty et al. (2010)\nin a meta-analysis of neuroimaging studies. Good long-term memory for\nemotional material was associated with greater activation during learning\nin a network including the amygdala, the hippocampus and the medial pre-\nfrontal cortex.\nDolcos et al. (2017) provided a comprehensive account of the brain\nnetworks concerned with emotion’s memory-enhancing effects (see Figure\n15.10). They identified two brain mechanisms. First, there is a bottom-up\nOFC\nmPFC\nInsula\nMedia temporal lobe\n(MTL) memory system\nPCC/PCun\nTOC\nAMY\nLateral\nparietal\ncortex\ndIPFC\nvIPFC\nFigure 15.10\nTwo main brain mechanisms\ninvolved in the memory-\nenhancing effects of\nemotion: (1) the medial\ntemporal lobes (MTL,\nincluding the hippocampus)\nand the amygdala (AMY);\n(2) the medial, dorsolateral\nand ventrolateral prefrontal\ncortex (mPFC; dlPFC;\nand vlPFC, respectively).\nEncoding of negative\nemotions involves the\ntemporo-occipital cortex\n(TOC) and encoding of\nself-relevant information\ninvolves the posterior\ncingulate cortex/precuneus\n(PCC/PCun).\nFrom Dolcos et al. (2017).\nCreated from usyd on 2022-02-17 03:28:58.",
    "736\nBroadening horizons\nmechanism, including the medial temporal lobes, which is strongly influ-\nenced by emotional arousal. Second, there is a top-down mechanism,\nwhich includes several areas within the prefrontal cortex and is involved\nin various cognitive processes (e.g., attention; working memory; and\ncognitive control). Of importance, the amygdala is involved in both\nmechanisms.\nMood congruity\nAffect influences learning and memory in various ways. What memories\nwould spring to mind if you were in a negative mood because of personal\nproblems? People generally recall mostly negative or unpleasant memories\nin such circumstances. In contrast, we typically recall happy memories when\nin a good mood. These examples illustrate mood congruity – emotionally\ntoned material is learned and retrieved best when its affective value matches\nthe learner’s (or rememberer’s) mood state.\nThere is much evidence for mood-congruent memory. For example,\ndepressed individuals recall more negative information than positive or\nneutral information (e.g., Rinck & Becker, 2005; discussed later, p. 759).\nHolland and Kensinger (2010) reviewed research on mood and autobio-\ngraphical memory. Positive mood was associated with strong evidence\nof mood congruity. However, mood congruity was less apparent with\nnegative mood. Similar findings have been found in studies using non-\nautobiographical material (Rusting & DeHart, 2000).\nMany failures of mood congruity in a negative mood state occur\nbecause individuals in that mood state are motivated to enhance their\nmood state. Rusting and DeHart (2000) used a negative mood induc-\ntion and found participants claiming they could successfully reduce their\nnegative moods showed less evidence of mood congruity than other\nparticipants.\nHow can we explain mood congruity? Tulving’s (1979) encoding\nspecificity principle (Chapter 6) is applicable. According to this princi-\nple, memory depends on the overlap between the information available\nat retrieval and that in the memory trace. This overlap is greater when\nthe to-be-remembered material is congruent with the rememberer’s mood\nstate.\nLewis et al. (2005) extended the encoding specificity principle, arguing\nthat brain activation at learning and at retrieval would be more alike in\nconditions producing mood congruity. As predicted, one brain region (the\nsubgenual cingulate) was activated when positive stimuli were presented\nand was reactivated when participants were in a positive mood at test. A\ndifferent brain region (the posteriolateral orbitofrontal cortex) was acti-\nvated when negative stimuli were presented and was reactivated when par-\nticipants’ mood at test was negative.\nMood-state-dependent memory\nAnother effect of mood on memory is mood-state-dependent memory:\nmemory is better when an individual’s mood state at retrieval matches\n(rather than mismatches) that at learning. In a review, Ucros (1989) found\nKEY TERMS\nMood congruity\nLearning and memory of\nemotional material are\nbetter when the learner’s/\nrememberer’s mood state\nmatches the affective\nvalue of the material than\nwhen it does not.\nMood-state-dependent\nmemory\nMemory performance\nis better when the\nindividual’s mood state\nis the same at learning\nand retrieval than when it\ndiffers.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n737\nstronger evidence for mood-state-dependent\nmemory when participants were in a positive\nrather than negative mood. This probably\noccurred because individuals experiencing a\nnegative mood state are motivated to change\ntheir mood state into a positive one.\nWe can clarify the processes underly-\ning mood-state-dependent memory effects\nby considering a study by Kenealy (1997).\nParticipants viewed a map and learned a\ngiven route. The next day they received\ntests of free recall (no cues) and cued recall\n(the map’s visual outline). Happy or sad\nmood states were created at learning and\ntest. Mood-state-dependent memory was\nfound in free recall but not cued recall (see\nFigure 15.11).\nThe free recall findings can be explained\nwith reference to the encoding specificity prin-\nciple (discussed above, p. 736). If information\nabout mood state is stored during learning,\nthe overlap between retrieval information\nand information in the memory trace will be\ngreater when the mood state is the same at\nlearning and test.\nHow can we explain the absence of\nmood-state-dependent memory with cued\nrecall? Eich (1995) argued mood state has\nless influence when crucial information is\npresented explicitly at retrieval, as happens\nwith cued recall. He discussed a “do-it-your-\nself principle” – memory is most likely to be\nmood-dependent when effortful processing at learning and/or retrieval is\nrequired.\nSupport for the “do-it-yourself principle” was obtained by Eich and\nMetcalfe (1989). At learning, participants were assigned to read (e.g.,\nriver-valley) or generate (e.g., river-v_____) conditions. In the generate con-\ndition, they completed the second word in each pair during learning which\ninvolved effortful processing. The mood-state-dependent effect was four\ntimes greater in the generate condition.\nEvaluation\nSeveral effects of mood state on attention and memory have been estab-\nlished. Mood states involving high motivational intensity typically produce\nattentional narrowing, whereas mood states involving low motivational\nintensity produce attentional broadening. These effects on attention influ-\nence long-term memory. Positive affect often leads individuals to main-\ntain their current attentional strategy, whereas negative affect leads them\nto change that strategy. There is much evidence for mood congruity and\nFigure 15.11\n(a) Free and (b) cued recall as a function of mood state (happy\nor sad) at learning and at recall.\nBased on data in Kenealy (1997).\nCreated from usyd on 2022-02-17 03:28:58.",
    "738\nBroadening horizons\nmood-state-dependent memory, and both effects can often be explained by\nthe encoding specificity principle. Finally, we have an increasingly detailed\nunderstanding of the brain networks associated with the memory- enhancing\neffects of emotion.\nWhat are the limitations of research in this area? First, the notion\nthat attentional narrowing or broadening has direct effects on long-term\nmemory is only partially correct. Second, there is less evidence for mood\ncongruity and mood-state-dependent memory with negative mood states\nthan positive ones. Third, the reasons why stronger mood-state memory\neffects are found with some memory tasks than others are not fully\nunderstood.\nAFFECT AND COGNITION: JUDGEMENT AND\nDECISION-MAKING\nJudgement and decision-making are discussed in Chapter 13. Decision-\nmaking involves choosing among various options varying between the\ntrivial (e.g., what am I going to drink?) and the hugely important (e.g.,\nwhich career path will I follow?). Judgement is an important compo-\nnent of decision-making. It involves assessing the probability of various\nevents occurring and then deciding how we would feel if each one\nhappened.\nThis section is concerned with the effects\nof affect on judgement and decision- making.\nThis is an important area of research. As\nLerner et al. (2015, p. 801) pointed out, “Many\npsychological scientists assume that emotions\nare . . . the dominant driver of most meaning-\nful decisions in life.” Below we start by con-\nsidering how emotions influence what, in the\nreal world, are life-and-death issues.\nMoral dilemma: emotion vs\ncognition (reason)\nIt is commonly believed emotion leads us to\nmake fast relatively “automatic” decisions\nwhereas cognition (reason) produces slower,\nmore considered decisions. For example,\nconsider Greene et al.’s (2008) dual-process\nmodel of decisions made with moral dilem-\nmas. They distinguished between two systems:\n(1) a fast, automatic and affective system; and\n(2) a slower, effortful and more “cognitive”\nsystem.\nThis model has been investigated using\nvarious moral dilemmas. For example, the\ntrolley problem poses a moral dilemma. You\nmust decide whether to divert a runaway\ntrolley threatening the lives of five people\nFigure 15.12\nTwo well-known moral dilemma problems: (a) the trolley\nproblem; and (b) the footbridge problem.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n739\nKEY TERMS\nDeontological\njudgements\nJudgements based\non moral rules and/\nor obligations when\nresolving moral\ndilemmas; see utilitarian\njudgements.\nUtilitarian judgements\nJudgements based on\npractical and pragmatic\nconsiderations when\nresolving moral dilemmas;\nsee deontological\njudgements.\nonto a side-track where it will kill only one person (see Figure 15.12a). The\nfootbridge problem also poses a moral dilemma. You must decide whether\nto push a fat person over a bridge causing that person’s death but saving\nfive people’s lives (see Figure 15.12b).\nWhat did you decide? Research indicates 90% of people decide to\ndivert the trolley (trolley problem) but only 10% decide to push the person\noff the footbridge (footbridge problem). Greene et al. (2008) argued the\nfootbridge problem is a personal moral dilemma because we might directly\nharm one or more individuals through our actions. In contrast, the trolley\nproblem is an impersonal dilemma because any harm is only indirectly due\nto our actions.\nWith personal moral dilemmas, those making deontological judge-\nments based on moral rules or obligations (e.g., do not kill) respond mainly\nbased on the first, affective system. Deontological judgements are very\ncommon with the footbridge dilemma. In contrast, those making practi-\ncal or utilitarian judgements based on maximising the consequences (e.g.,\nsaving as many lives as possible) use the second, cognitive system.\nUtilitarian judgements are very common with the trolley problem. In crude\nterms, you can use your heart (deontological judgements) or your  head\n(utilitarian judgements) to resolve moral dilemmas (Greene, 2014).\nDifferent brain areas are associated with the two systems (see\nFigure  15.13). The dorsolateral prefrontal cortex (DLPFC; BA9/46) is\ninvolved in cognitive control. In contrast, the ventromedial prefrontal\ncortex (VMPFC; BA10/11) is involved in emotion generation.\nFindings\nAccording to the dual-process model, individuals making utilitarian judge-\nments should have more activity in the dorsolateral prefrontal cortex\nthan those making deontological judgements. This finding was reported\nby Greene et al. (2004). Tassy et al. (2012)\napplied repetitive transcranial magnetic stim-\nulation (rTMS; see Glossary) to the DLPFC\nto inhibit its functioning. This reduced utili-\ntarian judgements with moral dilemmas of\nhigh emotional intensity.\nPatients with damage to the ventrome-\ndial prefrontal cortex (VMPFC) have reduced\nemotional responsiveness and so should be\nless influenced than healthy controls by emo-\ntional factors. As predicted, they make more\nutilitarian judgements than controls (Thomas\net al., 2011).\nIt is assumed theoretically that deonto-\nlogical judgements depend much more on\nemotional processing than utilitarian ones\nonly with personal moral dilemmas. Perkins\net al. (2013) gave an anti-anxiety drug to par-\nticipants to reduce the impact of emotion on\njudgements. As predicted, anti-anxiety drugs\nFigure 15.13\nThe dorsolateral prefrontal cortex is located approximately in\nBrodmann areas 9 and 46; the ventromedial prefrontal cortex\nis located approximately in Brodmann areas 10 and 11.\nFrom Ward (2010).\nCreated from usyd on 2022-02-17 03:28:58.",
    "740\nBroadening horizons\nincreased utilitarian judgements (and reduced deontological ones) only\nwith personal moral dilemmas.\nAccording to Greene’s theoretical approach, utilitarian judgements are\nregarded as reflecting concern for the greater good. However, Kahane et al.\n(2015) obtained evidence apparently inconsistent with that approach. They\nfound antisocial individuals (e.g., those with psychopathic tendencies) were\nmore likely to produce utilitarian judgements with personal moral dilem-\nmas than were other people.\nConway et al. (2018) replicated the above findings when participants\nwere forced to choose between utilitarian and deontological judgements.\nHowever, they pointed out that such findings are  ambiguous  – they\nmay reflect increased utilitarian inclinations in antisocial individuals\nand/or reduced deontological inclinations. When they used more sen-\nsitive  measures, Conway et al. discovered antisocial individuals had\nreduced deontological inclinations rather than increased utilitarian incli-\nnations. These findings are broadly consistent with Greene’s theoretical\napproach.\nConsequences (C), moral norms (N) and preference for\ninaction (I): CNI model\nGawronski and Beer (2017) also argued that forcing participants to\ndecide between utilitarian and deontological judgements provides ambig-\nuous information. Accepting the killing of one person to save the lives\nof five other people on the trolley dilemma may reflect a utilitarian\nmoral judgement. However, it could also indicate a lack of aversion\nto harming others. Deciding not to push the person off the footbridge\non the footbridge problem may indicate either a deontological moral\njudgement or a general preference for inaction regardless of any moral\nnorms.\nGawronski et al. (2017) argued we can resolve such ambiguities by\nmanipulating factors relevant to utilitarian judgements (i.e., changing out-\ncomes or consequences) and those relevant to deontological judgements\n(i.e., changing moral norms). In addition, individual preferences for inac-\ntion or action can be assessed by including problems where moral norms\nprohibit action (e.g., using illegal torture methods to discover where chil-\ndren have been hidden). Accordingly, Gawronski et al. obtained separate\nmeasures of sensitivity to consequences or outcomes (utilitarian judge-\nments) and to moral norms (deontological judgements), and a general pref-\nerence for inaction vs action.\nGawronski et al. (2017) compared individuals high and low in psy-\nchopathy (antisocial tendencies). Those high in psychopathy had a greater\npreference than low scorers for action over inaction (see Figure 15.14).\nHowever, they had less sensitivity than low scorers to consequences and\nto moral norms. These findings seem more plausible than previous reports\n(e.g., Kahane et al., 2015) that high psychopathy is associated with an\nemphasis on utilitarian moral judgements.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n741\nFigure 15.14\nSensitivity to consequences\n(C), sensitivity to moral\nnorms (N) and preference\nfor inaction vs action as a\nfunction of psychopathy\n(low vs high).\nFrom Gawronski et al. (2017).\nIN THE REAL WORLD: DRIVERLESS CARS\nThe prospect that our roads may soon be full of driverless cars raises important moral issues.\nApproximately 75% of people argue driverless cars should be programmed to sacrifice one\npassenger rather than kill ten pedestrians (Bonnefon et al., 2016). This is a utilitarian moral\ndecision. However, Bonnefon et al. (2016) found complex moral issues arose when they asked\nadditional questions. Support for the utilitarian judgement (morality of sacrifice) was lower when\npeople imagined they were in the driverless car alone, or with a co-worker or family member (see\nFigure 15.15). If you want to compare your moral decisions in such dilemmas, you can do so at the\nfollowing address: http://moralmachine.mit.edu.\nWhen deciding how likely they would be to buy a driverless car designed to minimise casualties\n(which might threaten their own lives) or one programmed to protect the passengers, their\nenthusiasm for the utilitarian approach was weak. As Bonnefon et al. concluded, “Although people\ntend to agree that everyone would be better off if [driverless cars] were utilitarian (in the sense of\nminimising casualties), these same people have a personal incentive to ride in [driverless cars] that\nwill protect them at all costs” (p. 1575).\nThe moral issues involved in programming driverless cars have often been compared to those\ninvolved in the trolley problem (discussed earlier, pp. 738–739). However, there are important\ndifferences (Nyholm, 2018). First, the outcomes of the possible decision choices are known\nwith certainty with the trolley problem but are much less clear-cut when considering most road-\ndriving conditions. For example, if a driverless car is programmed to mount the pavement where\npedestrians are walking, the harm that would be caused depends on numerous factors (e.g.,\nwhether the pedestrians are looking at the car; the mobility of the pedestrians).\nSecond, there are complexities associated with real-world driving absent from the trolley problem\n(Nyholm, 2018). For example, it could be argued that driverless cars should be programmed to\n1.0\nLow psychopathy\nHigh psychopathy\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\nC parameter\nParameter estimate\nN parameter\nI parameter\nCreated from usyd on 2022-02-17 03:28:58.",
    "742\nBroadening horizons\nattach more value to the lives of young children (whose entire lives are ahead of them) than to\nolder adults.\nThird, suppose that in the future driverless cars are much safer than cars driven by humans.\nShould the driverless cars be programmed to minimise lives lost (the utilitarian judgement)? The\n“natural” reaction is to answer “Yes”. However, the problem with that approach is that people\nwould be reluctant to buy cars that would not prioritise their own safety in the case of an accident.\nThus, programming driverless cars to use utilitarian judgements is generally regarded as morally\ndesirable. However, it would have the unfortunate consequence that fewer driverless cars would be\nbought. As a result, more people would die in car accidents using this morally desirable approach\nbecause fewer of the safe driverless cars would be bought!\nFigure 15.15\nAgreement with a utilitarian approach (morality of sacrifice and willingness to buy\na driverless car programmed to minimise casualties) or to protect passengers as a\nfunction of whether the person is alone in the car or with a co-worker or family member.\nFrom Bonnefon et al. (2015).\n20\nMorality\nof sacrifce\nBuy\nminimise\nBuy\nprotective\n40\nAgreement with morality\n(or) willingness to buy\n60\n80\nStudy 3\nAlone\nWith co-worker\nWith family\nEvaluation\nResearch on moral dilemmas focuses on complex emotional issues rele-\nvant to everyday life. Individuals confronting a moral dilemma can use fast\naffective processes and/or slow cognitive ones. The brain areas associated\nwith those two types of processes have been identified using neuroimaging\nstudies and studies on brain-damaged patients. The dual-process model is\nof relevance to many real-life situations (e.g., programming driverless cars).\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n743\nWhat are the dual-process model’s limitations? First, it is oversimpli-\nfied (as are the moral dilemmas typically used to test it). As Gawronski\net al. (2017, p. 21) pointed out, “The traditional [experimental] approach\nconflates sensitivity to consequences, sensitivity to norms, and general pref-\nerences for inaction in a single outcome measures.” In addition, the out-\ncomes of the decision choices on the trolley and footbridge problems are\nknown with certainty but this is generally not the case in the real world.\nSecond, little is known of the extent to which responses to hypothetical\ndilemmas predict responses to real-life dilemmas. Bostyn et al. (2018) found\nthat judgements in a real-life dilemma (administering an electric shock to\none mouse vs allowing five other mice to receive the shock) were not pre-\ndicted by judgements on hypothetical trolley-like problems. One possibility\nis that people are more likely to make what they regard as socially desira-\nble judgements in hypothetical situations.\nThird, according to the dual-process model, the processes underlying\ndeontological judgements occur more rapidly and with less effort than\nthose underlying utilitarian judgements. However, Bialek and De Neys\n(2017) found that participants making deontological judgements often pro-\ncessed information relevant to utilitarian judgements rapidly and in parallel\nwith information relevant to deontological judgements. Thus, the processes\nunderlying moral judgements are often more complex than assumed by\nGreene’s model.\nJudgement and decision-making: anxiety, sadness,\nanger and positive mood\nThere has recently been a dramatic increase in research considering the\nimpact of affect on judgement and decision-making. As discussed earlier,\nthere are numerous emotions and mood states. However, research has\nfocused mostly on four mood states (anxiety; sadness; anger; positive\nmood) and our coverage will reflect that focus.\nAngie et al. (2011) provided a research review of this area. They drew\ntwo general conclusions. First, major mood states have different effects on\njudgement and decision-making. Second, moods influence decision-making\nmore than judgement.\nWe will also consider the effects of personality on judgement and\ndecision-making because there are moderately strong links between person-\nality and mood. For example, individuals high in the personality dimen-\nsion of trait anxiety (see Glossary) are in an anxious mood state much\nmore often than those low in trait anxiety.\nWhat predictions might we make? First, we might expect mood valence\n(positive vs negative) to be important. More specifically, individuals experi-\nencing negative moods (e.g., fear; anger; sadness) should be pessimistic and\nrisk-averse, whereas those experiencing positive moods should be optimis-\ntic and willing to take risks. Second, we might expect any given mood state\nto be associated with risky or cautious decision-making regardless of the\nsituation or the nature of the decision. As we will see, both assumptions\nare only partially correct.\nLerner et al. (2015, p. 801) provided a useful overarching principle\nto explain the effects of emotions on decision-making: “Decisions can be\nCreated from usyd on 2022-02-17 03:28:58.",
    "744\nBroadening horizons\nviewed as a conduit through which emotions guide everyday attempts at\navoiding negative feelings (e.g., guilt and regret) and increasing positive\nfeelings (e.g., pride and happiness).”\nWe must distinguish between integral and incidental emotions (Lerner\net al., 2015). Integral emotions arise from the current judgement or choice.\nFor example, an individual deciding whether or not to gamble a lot of\nmoney on a risky project may experience anxiety. In contrast, incidental\nemotions are unrelated to the current task (judgement or decision-making).\nFor example, the positive affect you experience having passed an important\nexamination may influence your subsequent judgements and decisions on\ntotally different issues.\nMuch research has involved incidental emotions. For example, par-\nticipants describe an intensely emotional experience and then perform an\nunrelated task. In contrast, real-world judgement and decision-making\nvery often involve integral emotions (e.g., the emotions associated with\nthe choices available when making a crucial decision often influence our\ndecision).\nWhy is it important to distinguish between integral and inciden-\ntal emotions? One reason is that the effects of incidental emotion on\njudgement and decision-making are often weaker than those of integral\nemotion. For example, individuals high in emotional intelligence (including\nthe ability to understand emotions) are better able to identify the event\ncausing their emotions and so minimise the impact of incidental emotions\non decision-making (Yip & Côté, 2013). The effects of incidental emotion\non judgement are sometimes easy to eliminate.\nSchwarz and Clore (1983) studied the effects of mood produced by\nweather conditions on ratings of life satisfaction. These ratings were lower\non rainy than sunny days because the weather influenced people’s mood.\nHowever, the negative effect of bad weather on judged life satisfaction dis-\nappeared when people were led to attribute their bad mood to the weather.\nAnxiety\nFear or anxiety is consistently associated with pessimistic judgements about\nthe future. Lerner et al. (2003) carried out a study soon after the 9/11 terror-\nist attacks. Participants focused on aspects of the attacks that made them\nafraid, angry or sad. The estimated probability of future terrorist attacks\nwas higher in fearful participants than sad or angry ones.\nMost individuals have an optimism bias – they believe they are more\nlikely than others to experience positive events (e.g., career success) but less\nlikely to experience negative events (e.g., divorce; serious illness). Anxious\nindividuals exhibit less optimism bias than non-anxious ones. Lench and\nLevine (2005) asked college students to judge the likelihood of various\nevents (positive and negative) happening to them compared to the average\ncollege student. Those put into a fearful mood were more pessimistic than\nthose in a happy or neutral mood.\nHarris et al. (2008) reported similar findings. Individuals high in trait\nanxiety were less likely than non-anxious individuals to perceive others\nas more vulnerable than themselves to future risks (e.g., having a heart\nattack; getting divorced).\nKEY TERMS\nIntegral emotions\nEmotions experienced\nwhile engaged in making\na judgement or decision\nthat arise from the\njudgement or decision.\nIncidental emotions\nEmotions experienced\nwhile engaged in making\na judgement or decision\nthat are irrelevant to the\njudgement or decision.\nOptimism bias\nThe tendency to\nexaggerate our chances\nof experiencing\npositive events and to\nminimise our chances of\nexperiencing negative\nevents relative to other\npeople.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n745\nDecision-making\nAnxious individuals typically make less\nrisky decisions than non-anxious individuals\n(see Chapter 13). Lee et al. (2006) provided\nreal-world evidence. High-anxious individ-\nuals were much less likely than low-anxious\nones to die from accidental causes or suffer\nnon-fatal injuries because they were more\nrisk-averse. Raghunathan and Pham (1999)\nasked participants to decide whether to accept\njob A (high salary + low job security) or job\nB (average salary + high job security). Those\nin an anxious mood state were much less\nlikely than those in a neutral state to choose\nthe high-risk option (i.e., job A) (see Figure\n15.16).\nGambetti and Giusberti (2012) studied\nreal-life financial decision-making. Anxious\nindividuals made safer (more conservative)\nfinancial decisions. They were more likely to\nhave put their money into interest- bearing\naccounts but less likely to have invested large\nsums in stocks and shares. Oehler et al. (2018)\nfound that individuals with anxious personalities made less risky financial\ninvestment decisions than non-anxious ones.\nCharpentier et al. (2017) identified two potential reasons for find-\nings such as those discussed above. First, anxious individuals may be loss\naverse (aversion to negative outcomes). Second, anxious individuals may\nbe risk averse (avoiding uncertainty even when only gains are involved).\nTheir findings provide clear-cut support for the second reason.\nSadness\nSadness and anxiety are both negative emotional states. However, sadness\n(which becomes depression when intense) is more strongly associated\nwith an absence of positive affect (Clark & Watson, 1991; see later discus-\nsion, p. 755). As a result, sad individuals may be less optimistic than other\npeople.\nLench and Darbor (2014) found the perceived likelihood of risk from\nformaldehyde exposure was greater when participants were in a sad rather\nthan neutral mood. Waters (2008) reviewed research concerning mood\nstate and likelihood estimates of health hazards and life events. Sad or\ndepressed individuals had less optimism bias than non-depressed ones.\nDecision-making\nAs discussed earlier, Raghunathan and Pham (1999) found anxious individ-\nuals preferred a low-risk job to a high-risk one. In contrast, sad individuals\nchose the high-risk job (see Figure 15.16). According to Raghunathan and\nFigure 15.16\nEffects of mood manipulation (anxiety, sadness or neutral) on\npercentages of people choosing a high-risk job option.\nBased on data in Raghunathan and Pham (1999). With permission from\nElsevier.\nCreated from usyd on 2022-02-17 03:28:58.",
    "746\nBroadening horizons\nPham, sad individuals find the environment relatively unrewarding and so\nare especially motivated to obtain rewards.\nReal-life risk taking was studied by Langille et al. (2012). Depressed\nadolescents were much more likely than non-depressed ones to engage in\nmultiple sexual risk-taking forms of behaviour. Perhaps depressed individ-\nuals feel they have “little to lose”. Drivers exhibited riskier driving behav-\niour after being put into a sad mood state (Eherenfreund-Hager et al.,\n2017).\nCryder et al. (2008) found evidence for the misery-is-not-miserly\neffect – sad individuals paid more than others to obtain a given commod-\nity. More specifically, sad individuals (especially those high in self-focus)\nwere willing to pay almost four times as much those in a neutral mood for\na water bottle (see Figure 15.17). These findings suggest sadness increases\nthe motivation to acquire possessions to enhance the self (especially when\nsad individuals focus their attention on the self). Garg et al. (2018) con-\nducted a meta-analysis and reported reliable evidence for the misery-is-not-\nmiserly effect. They also found suggestive evidence the effect is partly due\nto the sense of helplessness associated with sadness.\nMany people believe in the “sadder-but-wiser” hypothesis – sad indi-\nviduals make wiser decisions. Lerner et al. (2013) tested this hypothesis\nby assessing the extent to which individuals prefer immediate rewards to\nlarger (but later) ones. Participants in a neutral mood required $56 imme-\ndiately to forego receiving $85 in 3-months’ time. However, those in a sad\nmood required only $37 immediately.\nHow can we explain the above findings? Lerner et al. (2013) argued\nthey indicated myopic misery – sad individuals have a sense of loss and\nso are impatient to obtain rewards to replace what has been lost. Sad indi-\nviduals were more likely than those in a neutral mood to have impatient\nthoughts and to focus on what they might buy with the money while decid-\ning whether to prefer an immediate or a delayed reward.\nIn sum, depressed individuals experience a combination of high neg-\native affect and low positive affect (Clark & Watson, 1991). Depressed\nindividuals often engage in risky decision-making because their motivation\nto enhance their low level of positive affect leads them to seek immediate\nrewards.\nFigure 15.17\nMean buying price for a\nwater bottle as a function of\nmood (neutral vs sad) and\nself-focus (low vs high).\nFrom Cryder et al. (2008).\n$3.00\nHigh self-focus\nLow self-focus\n$2.50\n$2.00\n$1.50\n$1.00\n$0.50\n$0\nNeutral\nBuying price\nSadness\nEmotion condition\nKEY TERMS\nMisery-is-not-miserly\neffect\nThe tendency for sad\nindividuals to be willing\nto pay more for some\nproduct than other\npeople.\nMyopic misery\nThe notion that misery\nor sadness leads to\nan excessive focus on\nreplacing lost rewards.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n747\nAnger\nAnger is typically regarded as a negative affect. However, it can be expe-\nrienced as relatively pleasant because it leads individuals to believe they\ncan control the situation and dominate those they dislike (and perhaps\nalso those they like) (Lerner & Tiedens, 2006). Schadenfreude (experiencing\npleasure at the misfortune of disliked others) is increased by anger (Hareli\n& Weiner, 2002).\nHow does anger influence judgement? There are striking differences\nbetween the effects of anger and other negative emotional states. Anger\nis associated with relatively optimistic judgements about the likelihood of\nnegative events whereas anxiety and sadness are both associated with pessi-\nmistic judgements (Waters, 2008). Angry individuals rate themselves as less\nat risk of severe negative life events (e.g., divorce; work problems; heart\ndisease) than other people even though they are actually more likely to\nexperience these events (Lerner & Keltner, 2001).\nWhy is anger associated with optimistic judgements rather than the\npessimistic ones associated with other negative mood states? Anger differs\nfrom other negative moods in being associated with a sense of certainty\nabout what has happened and with perceived control over the situation\n(Litvak et al., 2010; discussed further later, pp. 751–752). These unique\nfeatures of anger (especially high perceived control) explain why anger pro-\nduces optimistic judgements.\nAnger often causes judgements to be made using relatively shallow or\nheuristic processing. Ask and Granhag (2007) found angry police investi-\ngators processed witness statements more superficially than did sad ones.\nDecision-making\nSince angry individuals perceive themselves to have high control over sit-\nuations, we might expect them to make risky decisions. This prediction\nhas received support. Lerner and Keltner (2001) used the Asian disease\nproblem on which most people exhibit risk-averse decision-making\n(see Chapter 13). Fearful participants were risk-averse but angry ones were\nrisk-seeking. In a study by Gambetti and Giusberti (2012) discussed earlier\n(p. 745), individuals with angry personalities made riskier financial deci-\nsions (e.g., more likely to have invested money in stocks and shares) than\nnon-angry ones.\nOther research reveals complexities in the effects of anger on\ndecision-making. First, Kugler et al. (2012) found angry participants\non their own were much less risk-averse than happy or fearful ones on\na lottery task involving large real-money payoffs. However, only 7% of\nangry participants chose the risky option when the outcome depended on\nthe other person’s choice. These angry participants did not want to lose\ncontrol of the situation by being reliant on someone else.\nSecond, Ferrer et al. (2017) assessed risky decision-making on a task\nwhere money could be earned by pumping up balloons provided they did\nnot burst. Angry male participants engaged in riskier decision-making than\nsad or neutral participants, but angry female participants did not exhibit\nrisky behaviour. This gender difference was also found when Ferrer et al.\nCreated from usyd on 2022-02-17 03:28:58.",
    "748\nBroadening horizons\nFigure 15.18\nThe positive emotion\n“family tree” with the trunk\nrepresenting the neural\nreward system and the\nbranches representing\nnine semi-distinct positive\nemotions.\nFrom Shiota et al. (2017).\nconducted a meta-analysis of previous research. It may occur because\nanger is more associated with perceived control in men than women.\nAnger often impairs individuals’ decision-making. In the words of\nRalph Waldo Emerson, it “blows out the light of reason”. For example,\nconsider research on driving behaviour. As discussed earlier (p. 730),\nZhang and Chan (2016) found in a review that anger was associated with\naggressive and risky driving, and with driving errors. Techer et al. (2017)\ndiscovered the high arousal and mind-wandering caused by anger partly\nexplained the negative effects of anger on driving performance.\nWhy does anger impair decision-making? It can lead to shallow pro-\ncessing based on heuristics (rules of thumb) rather than systematic or\nanalytic processing (Litvak et al., 2010). For example, Coget et al. (2011)\nfound film directors mostly resorted to intuitive decision-making when\nmoderately or very angry, whereas moderate anxiety led to analytic pro-\ncessing. If angry individuals engage in little analytic processing, we would\nexpect their decision-making to be unaffected if they performed an addi-\ntional task designed to prevent analytic processing at the same time. That\nis precisely what Small and Lerner (2008) found.\nPositive mood\nCampos et al. (2013) argued there are at least eight different positive moods:\nawe, amusement, interest, pride, gratitude, joy, love and contentment. Their\napproach was developed by Shiota et al. (2017; see Figure 15.18). All positive\nemotions depend on a common neural reward system including the mesolim-\nbic pathway (linking the ventral tegmental areas and nucleus accumbens)\nSexual\ndesire\nNurturant\nlove\nPride\nSerotonin\nCannabinoids\nOpioids\nEnthusiasm\nDopaminergic\nreward system\nTestosterone\nOxytocin\nAwe\nAmusement\nAttachment\nlove\nContentment\nGratitude\nLiking/\npleasure\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n749\nand involving the neurotransmitter dopamine. As a result of evolution,\nhumans possess nine positive emotions that are elicited in  different situations\nand involve different combinations of neurotransmitters and hormones.\nIn spite of increasing evidence that we possess several positive emo-\ntions, there is a puzzling difference between research on negative and posi-\ntive affect. Three different kinds of negative affect (anxiety; sadness; anger)\nhave been emphasised in research on judgement and decision. However,\nuntil recently, the effects of only a single broad category of positive affect\non judgement and decision-making have been explored.\nMuch research on positive affect has focused on optimism bias (indi-\nviduals anticipate experiencing more positive and fewer negative events\nthan others). We would expect optimism bias to be stronger among those\nin a positive mood than those in a negative or neutral mood. Lench and\nLevine (2005) found individuals in a happy mood had greater optimism\nbias than fearful participants. However, they were no more optimistic than\nindividuals in a neutral mood.\nKoellinger and Treffers (2015) studied a related effect: overconfidence\nin one’s performance on a general knowledge quiz. Positive affect caused\nby unexpectedly receiving a gift (bear-shaped jelly sweets) produced over-\nconfidence when participants were unlikely to attribute their positive affect\nto the gift. In contrast, there was no overconfidence when they were aware\nof the source of their positive feelings. Thus, one reason why positive affect\nis often associated with optimistic judgements is because it is regarded as\nproviding positive feedback on their performance.\nDecision-making\nIn a review, Blanchette and Richards (2010) concluded positive mood states\nare typically associated with a risk-averse approach to decision-making.\nFor example, sex behaviour increasing the risk of HIV for gay men is less\ncommon among those with high positive affect (Mustanski, 2007) and indi-\nviduals in a positive mood make less risky decisions when betting on hypo-\nthetical horse races (Cahir & Thomas, 2010).\nDecision-making can vary depending on the specific form of posi-\ntive affect. Eherenfreund-Hager and Taubman-Ben-Ari (2016) compared\nthe effects of relaxed positive affect (produced by thinking of a calm and\npeaceful event) and aroused positive affect (produced by thinking of a\nhappy and exciting event). Only the former was associated with a reduced\nwillingness to drive recklessly. Thus, decision-making may typically be\nrisk-averse when individuals experience high positive affect but not when\npositive affect involves excitement.\nPositive affect is associated with increased use of heuristic or low-\neffort processing and decreased use of analytic processing. Suppose you\nmust choose repeatedly between two gambles: (1) 50% chance of winning\n1.20 euros and 50% chance of winning nothing; and (2) 50% chance of\nwinning 1.00 euro and 50% chance of winning nothing. Analytic thinking\nwould lead you to choose the first gamble on every trial. De Vries et al.\n(2012) found happy participants were less likely than sad ones to use ana-\nlytic thinking. They were more likely to engage in heuristic processing (e.g.,\nswitching gambles if the previous one proved unsuccessful).\nCreated from usyd on 2022-02-17 03:28:58.",
    "750\nBroadening horizons\nHolland et al. (2012) assessed participants’ explicit attitudes (involv-\ning analytic processing) towards apples and candy bars and their implicit\nattitudes (involving non-analytic or heuristic processing). Then the partici-\npants were asked to choose between an apple and a candy bar. For happy\nparticipants, their choice was predicted only by their implicit attitudes (see\nFigure 15.19). For sad participants, in contrast, their choice was predicted\nonly by their explicit attitudes (see Figure 15.19). Thus, decision-making\n(i.e., candy bar or apple?) was based on heuristic processing for happy\nindividuals but by analytic thinking for sad ones.\nGriskevicius et al. (2010) studied the effects of several positive mood\nstates on the ability to assess the persuasiveness of strong and weak argu-\nments. Participants experiencing three positive emotions (anticipatory\nenthusiasm; amusement; attachment love) exhibited heuristic or shallow\nprocessing. However, for reasons that are unclear, participants experienc-\ning two other positive emotions (awe; nurturant love) exhibited less heuris-\ntic processing than those in a neutral mood state.\nJUDGEMENT AND DECISION-MAKING:\nTHEORETICAL APPROACHES\nWe have now discussed the effects of several mood states on judgement\nand decision-making. Mood states differ in the pattern of effects (see\nFigure 15.20). Of theoretical importance, the pattern varies across the three\nnegative mood states of anxiety, sadness and anger.\nFigure 15.19\nProbability of selecting a\ncandy bar by participants in\na happy or sad mood as a\nfunction of implicit attitudes\non the Implicit Association\nTest (IAT) with higher scores\nindicating a preference for\ncandy bars.\nFrom Holland et al. (2012).\n100\nHappy mood\nSad mood\n80\n60\n40\n20\n0\nApple\nCandy\nPersonalised IAT\nProbability of choosing candy (in %)\nFigure 15.20\nEffects of mood states\non judgement and\ndecision-making.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n751\nHow can we make sense of Figure 15.20? Anxiety occurs in threat-\nening situations involving uncertainty and unpredictability. Accordingly,\nanxious individuals are motivated to reduce anxiety by increasing certainty\nand predictability, which can be achieved by minimising risk taking and\nchoosing non-risky options.\nIndividuals become sad or depressed when they discover a desired goal\nis unattainable. Sadness or depression leads individuals to abandon the\nunachievable goal and engage in extensive thinking (i.e., analytic  processing)\nto focus on new goals (Andrews & Thomson, 2009). This helps us to under-\nstand why sadness is the only mood state associated with analytic processing.\nAnger has the function of overcoming some obstacles to an important\ngoal by taking direct and aggressive action. This approach is most likely\nto be found when individuals feel they have personal control and are thus\noptimistic the goal can be achieved (Lerner & Tiedens, 2006). This percep-\ntion of personal control also persuades angry individuals to take risks to\nachieve their goals.\nAn important function of positive mood states is to maintain the\ncurrent mood (Oatley & Johnson-Laird, 1987). This leads happy individ-\nuals to engage in shallow or heuristic processing and to avoid taking risks\nthat might endanger their positive mood state.\nAppraisal-tendency framework\nThe appraisal-tendency framework (Lerner & Keltner, 2000) is relevant to\nunderstanding how moods influence judgement and decision-making. This\nframework (see Han et al., 2007) extends the appraisal-theory approach dis-\ncussed earlier (pp. 719–724). It is assumed each emotion results from certain\ncognitive appraisals. Emotions often alter cognitive processes to assist the\nindividual to respond appropriately to the situation triggering the emotion.\nOf crucial importance, it is assumed theoretically the effects of any given\nemotion on judgement and decision-making depend more on the appraisal\nprocesses associated with it than on its valence (positive or negative affect).\nFindings\nThe appraisal-tendency framework explains many findings discussed earlier.\nHere are two examples. According to the framework, emotions differ along\nthe appraisal continuum of uncertainty-certainty (i.e., the extent to which\nfuture events seem predictable). More specifically, anger and positive affect\n(happiness) are associated with high certainty whereas fear or anxiety and\nsadness are associated with low certainty.\nBagneux et al. (2013) used the Iowa Gambling Task (see Glossary) on\nwhich decision-making is generally superior when participants use  intuitive\nrather than deliberative processing. They predicted participants  experiencing\ncertainty-associated emotions would use intuitive processing based on\nemotional cues from previous outcomes. In contrast, those experiencing\nuncertainty-associated emotions would use deliberative processing. As pre-\ndicted, participants induced to feel certainty (anger; happiness; disgust) made\nsuperior decisions to those induced to feel uncertainty (fear; sadness). İyilikci\nand Amado (2018) replicated these findings for disgust, fear and sadness.\nCreated from usyd on 2022-02-17 03:28:58.",
    "752\nBroadening horizons\nAccording to the appraisal-tendency framework, anger differs from\nmost other mood states in being associated with high perceived control\nleading to risk-taking behaviour. Beisswingert et al. (2015) exposed partic-\nipants to a situation involving loss of control which they predicted would\nproduce anger and lead to risk-taking behaviour. The findings were as pre-\ndicted. Of particular importance, the impact of the situation on risk-taking\nbehaviour depended on the extent to which it caused anger.\nEmotion-imbued choice model\nYou are probably thinking the effects of affect on judgement and\ndecision-making are complex. If so, you are right! Much of this complex-\nity is included within Lerner et al.’s (2015) emotion-imbued choice model\n(Figure  15.21). We start with the solid lines. These indicate the major\nfactors included in traditional models of decision-making: decision-makers\nevaluate the available options by considering the expected outcomes asso-\nciated with each option. Characteristics of the options (e.g., probabilities;\ntime delays) and of the decision-maker (e.g., risk aversion; personality) are\nalso considered as is the notion that expected emotions influence the deci-\nsion process (line A).\nThe roles of emotion are shown by the green dotted lines. Current\nemotions are influenced by: (1) characteristics of the decision-maker (e.g.,\nchronic anxiety; line B’); (2) characteristics of the choice options (line C’);\n(3) predicted emotions (e.g., if you expect to be made anxious you may\nexperience anxiety now; line F); (4) contemplating the decision (especially\nif the options are nearly equally (un)attractive; line G’); and (5) incidental\nemotions (e.g., those caused by the weather; line H).\nCurrent emotions directly influence the evaluation of the outcomes\n(e.g., whether heuristic or analytic processing is used; which motivational\ngoals are active; line G). They also indirectly influence decision-making by\nFigure 15.21\nThe emotion-imbued choice\nmodel (see text for details).\nFrom Lerner et al. (2015).\nH\nG’\nC’\nB’\nG\nC\nIncidental\ninfuences\ne.g., mood, weather,\ncarry-over efects\nConscious and/or\nnon-conscious evaluation\nDecision\nB\nA\nD\nE\nCurrent emotions\ni.e., emotions felt at\ntime of decision\nCharacteristics of\ndecision-maker\ne.g., preferences,\npersonality\nCharacteristics of\noptions\ne.g., likelihood or\nprobability, time delay,\ninterpersonal outcomes\nExpected outcomes\n(including expected\nemotions)\nPaths included in traditional\nrational choice models\nPaths not included in traditional\nrational choice models\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n753\nchanging the predicted emotional reactions to different potential decision\nchoices (line I).\nIn sum, the emotion-imbued choice model provides the most com-\nprehensive account of the ways decision-making is influenced by emotion.\nWe can see earlier decision-making approaches (e.g., von Neumann and\nMorgenstern’s 1944 utility theory; see chapter 13) were more limited with\nreference to Figure 15.21. According to these approaches, each option\nduring decision-making is evaluated with respect to the three factors shown\nby the solid lines A, B and C.\nWhat are the limitations of the emotion-imbued choice model? First, it\nprovides a framework rather than a fully fledged theory or model. Second,\nit is oversimplified. As Lerner et al. (2015, p. 814) admitted, “It assumes\nthat the decision-maker faces a one-time choice between given options,\nwithout the possibility of seeking additional information or options.”\nANXIETY, DEPRESSION AND COGNITIVE BIASES\nMost research discussed above dealt with effects of mood manipulations\non cognitive processing and performance. We can also focus on cogni-\ntive processing in individuals who are generally in a given mood state\n(e.g., patients with an anxiety disorder or major depressive disorder).\nAlternatively, we can study healthy individuals having anxious or depres-\nsive personalities. For example, anxious individuals can be selected by\nusing questionnaires assessing trait anxiety (susceptibility to experiencing\nanxiety).\nImplementing the above research strategies is complicated because\nanxious individuals tend to be depressed and vice versa. Comorbidity is\nthe term indicating a patient has two or more mental disorders at the same\ntime. Comorbidity of anxiety and depressive disorders is found in 20% to\n40% of patients (Huppert, 2008). In similar fashion, anxiety and depression\nare moderated highly correlated in healthy individuals.\nIn spite of the overlap between anxiety and depression, there are\nimportant differences between them. Later we consider three major theo-\nretical approaches focusing on such differences.\nWhy is it important to study cognitive processes in anxious and\ndepressed individuals? Anxious and depressed patients differ from healthy\nindividuals in several ways (e.g., cognitively; behaviourally; physiologi-\ncally). Therapies differ in terms of the symptoms that are the central focus\nin treatment. Within this context, it is of major theoretical importance to\nestablish the role played by cognitive factors.\nMany theorists (e.g., Beck & Dozois, 2011) assume vulnerability to\nclinical anxiety and depressions partly depends on cognitive factors. It\nis also often assumed that one goal of cognitive therapy (and cognitive-\nbehavioural therapy) should be to reduce various cognitive biases.\nHere are four important cognitive biases:\n●\nAttentional bias: selective attention to emotionally negative stimuli\npresented at the same time as neutral stimuli; this can involve rapid\nattentional engagement with negative stimuli and/or slow attentional\ndisengagement.\nKEY TERMS\nTrait anxiety\nA personality dimension\nbased on individual\ndifferences in\nsusceptibility to anxiety.\nComorbidity\nThe state of affairs when a\npatient has two (or more)\nmental disorders at the\nsame time.\nAttentional bias\nSelective allocation of\nattention to emotionally\nnegative stimuli when\npresented simultaneously\nwith neutral stimuli.\nCreated from usyd on 2022-02-17 03:28:58.",
    "754\nBroadening horizons\n●\nInterpretive bias: the tendency to interpret ambiguous stimuli and sit-\nuations in a negative fashion.\n●\nExplicit memory bias: the tendency to retrieve mostly negative or\nunpleasant rather than positive or neutral information on memory\ntests involving conscious recollection.\n●\nImplicit memory bias: the tendency to exhibit superior performance\nfor negative than for positive or neutral information on memory tests\nnot involving conscious recollection.\nAn individual possessing all the above cognitive biases would attend exces-\nsively to negative environmental events, would interpret most ambiguous\nsituations negatively, and so would perceive themselves as having experi-\nenced numerous unpleasant events. As a consequence, it is assumed they\nwould be more likely than other people to develop an anxiety disorder\nor depression. However, a key issue here is causality: do cognitive biases\ntrigger anxiety and depression; do anxiety and depression enhance cognitive\nbiases; or is causality bidirectional?\nTheoretical approaches\nBelow we discuss major theoretical approaches to understanding the sim-\nilarities (and differences) between anxiety and depression. Note these\napproaches are not necessarily incompatible with each other (see Eysenck\n& Fajkowska, 2018; Eysenck & Holmes, in press).\nFunctional approach\nAnxiety and depression both have adaptive functions even though they\noften involve high short-term costs (Del Guidice & Ellis, 2015). Depression\nis typically caused by goal loss (Oatley & Johnson-Laird, 1987) and has\nthe adaptive function of leading to sustained thinking about disengaging\nfrom the lost goal and generating a new one. Anxiety is typically caused by\na threat to self-preservation (Oatley & Johnson-Laird, 1987) and has the\nfunction of increasing selective attention to potential environmental threats\nand rapid detection of danger (Eysenck, 1992).\nThe above functional approach implies depression is mostly associated\nwith a past orientation whereas anxiety is mostly associated with a future\norientation. Eysenck et al. (2006) asked healthy individuals to identify per-\nsonal events strongly associated with anxiety or depression. Anxious events\nrelated more to the future than the past. In contrast, depressive events were\nmuch more associated with the past.\nAdditional supportive evidence comes from research on worry and\nrumination. Worry and rumination both involve persistent, repetitive neg-\native thoughts. However, they differ because worry is typically triggered by\n“What if?” questions whereas rumination is triggered by “Why?” questions\n(Papageorgiou, 2006). Unsurprisingly, worry is associated with a greater\nfuture orientation than rumination whereas rumination is associated with\na greater past orientation (Watkins et al., 2005).\nOf relevance to the functional approach, rumination in the clinical\nliterature is mostly considered in the context of major depressive disorder\nKEY TERMS\nInterpretive bias\nThe tendency when\npresented with ambiguous\nstimuli or situations\nto interpret them in a\nnegative way.\nExplicit memory bias\nThe retrieval of relatively\nmore negative information\nthan positive or neutral\ninformation on tests of\nexplicit memory.\nImplicit memory bias\nRelatively better memory\nperformance for negative\nthan for neutral or positive\ninformation on tests of\nimplicit memory.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n755\n(a mental disorder involving low mood and reduced interest in pleasurable\nactivities). In contrast, worry is the central symptom of generalised anxiety\ndisorder (pervasive anxiety across several life domains).\nWilliams et al. (1997) made several specific predictions based on the\nfunctional approach. Before discussing these predictions, we must consider\ntheir distinction between perceptual and conceptual processes. Perceptual\nprocesses are stimulus-driven or bottom-up: they are often fast and “auto-\nmatic” and are used in basic attention and implicit memory.\nIn contrast, conceptual processes are top-down and are slower and more\ncontrolled than perceptual ones. They are involved in explicit memory and\ncan also be involved in some attentional processes and implicit memory.\nSince anxiety has the function of anticipating danger, it should facilitate\nthe perceptual processing of threat-related stimuli. In contrast, depression\nhas the function of replacing failed goals. As a result, “the conceptual pro-\ncessing of internally generated material related to failure or loss may be\nmore relevant to this function than perceptual vigilance” (Williams et al.,\n1997, p. 315).\nThe above assumptions generate several predictions:\n(1) Anxious individuals should have an attentional bias for threatening\nstimuli when perceptual processes are involved. Depressed individuals\nshould have an attentional bias only when conceptual processing is\ninvolved.\n(2) Anxious and depressed individuals should have an interpretive bias\nfor ambiguous stimuli and situations.\n(3) Depressed individuals should have an explicit memory bias, but\nanxious ones should not.\n(4) Anxious individuals should have an implicit memory bias, but\nde pr essed ones should not when only perceptual processes are\ninvolved.\nTripartite model\nClark and Watson’s (1991) tripartite model (developed by Watson, 2009)\nidentified major similarities and differences between anxiety and depression.\nThey resemble each other in that both are strongly associated with distress\nand other negative emotional states. They differ in two ways:\n(1) Positive emotionality (involving energy and pleasurable engagement)\nis lacking in depression but not anxiety.\n(2) Physiological hyperarousal is present in anxiety but not depression.\nIt follows that anxious and depressed individuals should differ in their pro-\ncessing of emotionally positive stimuli. Depressed (but not anxious) indi-\nviduals should have reduced responsiveness to such stimuli.\nAttentional bias\nVarious tasks assess attentional bias (Yiend et al., 2013). First, there is the\ndot-probe task (see Figure 15.22). Two stimuli are presented simultaneously\nCreated from usyd on 2022-02-17 03:28:58.",
    "756\nBroadening horizons\nFigure 15.22\nThe dot-probe task.\nParticipants initially focus\nthe central +, then view two\nstimuli varying in emotion\nand then respond rapidly to\na dot that replaces one of\nthe stimuli.\n© ZoneCreative/iStock.\nat different locations on a computer screen. In Figure 15.22, one stimulus is\nemotionally positive (e.g. smiling face) and the other is neutral. On critical\ntrials, however, one stimulus is emotionally negative (e.g., angry face) and\nthe other neutral (e.g., expressionless face). The participant’s allocation of\nattention is assessed by recording the speed of detection of a dot replac-\ning one stimulus. Attentional bias is indicated by shorter detection latencies\nwhen the dot replaces the negative stimulus.\nSecond, there is the emotional Stroop\ntask in which participants rapidly name the\ncolour in which words are printed (see Figure\n15.23). Some words are emotionally negative\nwhereas others are neutral. Attentional bias\nis defined by participants taking longer to\nname the colours of emotional than neutral\nwords or faces (but see below).\nFindings\nBar-Haim et al. (2007) carried out a meta-\nanalysis of attentional bias in anxious individ-\nuals. There was strong evidence of attentional\nbias across all anxiety disorders and in high\ntrait-anxious healthy individuals.\nWe can distinguish two aspects of biased\nattention: (1) speed of attentional engagement\nwith negative stimuli (attentional bias); and\n(2) subsequent attentional disengagement from\nsuch stimuli. Anxious patients have fast attentional engagement (dependent\non a largely “automatic” threat- detection mechanism) and slow disengage-\nment (mostly due to poor attentional control) (Cisler & Koster, 2010).\nThe dot-probe and emotional Stroop tasks provide only a snapshot of\nwhere attention is directed. In contrast, eye-tracking provides a fairly direct\nand continuous assessment of visual attention. Armstrong and Olatunji\nFigure 15.23\nThe emotional Stroop task. Participants name the colours in\nwhich emotional or neutral words are printed. Attentional\nbias is allegedly shown if participants take longer to name the\ncolours of emotional words than those of neutral words.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n757\n(2012) found in a review that anxious individuals had faster attentional\nengagement to (and slower disengagement from) negative stimuli. However,\nanxiety did not influence the time taken to fixate emotionally positive stimuli.\nThe evidence relating to attentional bias in depression is less consis tent.\nKircanski and Gotlib (2015) reported in a review that patients with major\ndepressive disorder did not show rapid engagement with negative stimuli but\nhad slow disengagement. In a meta-analysis, Winer and Salem (2016) found\nsignificant avoidance of emotionally positive stimuli in depressed individuals.\nThe tendency for attentional bias (fast engagement) to be stronger\nin anxious than depressed individuals is consistent with the functional\napproach and its assumption that anxious individuals focus on potential\nfuture threats (Eysenck & Fajkowska, 2018). The finding that depressed\nindividuals (but not anxious ones) avoid emotionally positive stimuli\nis partly consistent with the tripartite model which assumes they have a\nvery limited ability to exhibit positive emotion. However, that model does\nnot explain why depressed individuals avoid (rather than ignore) posi-\ntive stimuli. According to Winer and Salem (2016), depressed individuals\nactively inhibit rewarding stimuli.\nFinally, we turn to the effects of depression on engagement with emo-\ntionally negative stimuli. Most research has failed to obtain significant\nfindings. However, Peckham et al. (2010) reported that depressed individ-\nuals showed attentional bias with depression-relevant stimuli but not when\nphysically or socially threatening stimuli were used. These findings are con-\nsistent with the content-specific hypothesis (Beck, 1976; Beck & Dozois,\n2011). According to this hypothesis depressed individuals have very neg-\native beliefs about themselves, the world and the future, and attend to\nstimuli relevant to those beliefs.\nLimitations\nWhat are the limitations of research in this area? First, the two main para-\ndigms (i.e., dot-probe; emotional Stroop) provided limited information con-\ncerning the time course of attentional processing. However, more detailed\ninformation is available from eye-tracking studies.\nSecond, most findings indicate an association between anxiety or\ndepression and attentional bias. Such findings cannot clarify the causal-\nity issue. Later we discuss research showing that changes in attentional\nTABLE 15.1  EFFECTS OF ANXIETY AND DEPRESSION ON ATTENTIONAL BIAS\n(ENGAGEMENT AND DISENGAGEMENT)\nAttentional bias (fast engagement) and Attentional\nbias (slow disengagement)\nEmotionally negative stimuli\nAnxiety\nYES\nYES\nDepression\nNO (?)\nYES\nEmotionally positive stimuli\nAnxiety\nNO\n?\nDepression\nOPPOSITE BIAS\n?\nCreated from usyd on 2022-02-17 03:28:58.",
    "758\nBroadening horizons\nbias can produce changes in anxiety. Other research shows that changes\nin anxiety can produce changes in attentional bias. Van Bockstaele et al.\n(2014, p. 682) concluded their review as follows: “The relation between\nattentional bias and fear and anxiety is best described as a bidirectional,\nmaintaining or mutually reinforcing relation.”\nInterpretive bias\nWe often encounter ambiguous situations. For example, suppose someone\nwalks past you without acknowledging your presence. Perhaps they simply\nfailed to notice you or perhaps they actively dislike you. Individuals who\ngenerally interpret ambiguous situations in a negative way have an inter-\npretive bias.\nAnxious individuals have an interpretive bias. Eysenck et al. (1987)\nasked participants varying in trait anxiety to write down the spellings of\nauditorily presented words. Some were homophones (two words with the\nsame pronunciation but different spellings (e.g., die, dye; pain, pane). Trait\nanxiety correlated +.60 with the number of negative or threatening homo-\nphone interpretations.\nIndividuals high in trait anxiety do not have an interpretive bias for all\npotentially threatening situations. High trait anxiety is associated with an\ninterpretive bias for ambiguous situations potentially involving social or\nintellectual threat but not those involving physical or health threat (Walsh\net al., 2015). Thus, interpretive bias in high-anxious individuals is limited to\ninterpersonal threats (i.e., negative reactions of others to one’s behaviour).\nEysenck et al. (1991) studied patients with generalised anxiety  disorder\n(see Glossary) who heard ambiguous sentences such as the following:\n(1) At the refugee camp, the weak/week would soon be finished.\n(2) The doctor examined little Emma’s growth.\n(3) They discussed the priest’s convictions.\nGeneralised anxiety disorder patients were more likely than healthy con-\ntrols to interpret such sentences in a negative or threatening way. Thus,\nthey exhibited interpretive bias.\nEveraert et al. (2017b) obtained two main findings in a meta- analytic\nreview of interpretive bias in depression. First, there was a moderately\nstrong relationship between depression and interpretive bias for both\npatients with clinical depression and depressed healthy individuals. Second,\nthis relationship was stronger with self-referential material (i.e., making\nreference to the individual’s character and/or experience) than with mate-\nrial that was not self-referential.\nDoes interpretive bias depend mostly on rapid, “automatic” processes\nor on slower, strategic ones? Both processes are involved (Mathews, 2012).\nEvidence for strategic processes was reported by Calvo and Castillo (1997).\nHigh-anxious individuals had an interpretive bias for ambiguous sentences\n1,250 ms after the sentence but not at 500 ms.\nEvidence interpretive bias can occur fairly rapidly was reported by\nMoser et al. (2012). Participants satisfying the criteria for social anxiety\ndisorder (excessive fear of social situations) or major depressive disorder\nKEY TERM\nGeneralised anxiety\ndisorder\nA condition involving\nexcessive anxiety and\nworry across many areas\nof everyday life.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n759\n(see Glossary) showed more evidence than healthy controls of the develop-\nment of interpretive bias within approximately 400 ms.\nMemory biases\nWhy is it important to study memory biases in anxious and depressed indi-\nviduals? Such biases may well maintain negative mood states via conscious\nprocesses (explicit memory bias) or relatively automatic processes (implicit\nmemory bias). We start with explicit memory bias.\nThere is convincing evidence for an explicit memory bias associ-\nated with depression (Blaney, 1986). This memory bias was also found\nwhen research on autobiographical memory was reviewed (Holland &\nKensinger, 2010). A positive memory bias (i.e., enhanced memory for pos-\nitive versus neutral material) is sometimes absent in depressed individuals\n(Foland-Ross and Gotlib, 2012). This finding is consistent with the tripar-\ntite model’s assumption that depressed individuals have a limited ability to\nexhibit positive emotions.\nSeveral studies have focused on implicit memory bias in depression.\nPhillips et al. (2010) reported a small (but significant) relationship between\ndepression and implicit memory bias in a meta-analysis. Williams et al.\n(1997) argued this would not be found when perceptual processes were\ninvolved. However, Phillips et al. found evidence for an implicit memory\nbias associated with depression even when perceptual processing occurred\nat encoding or learning and retrieval.\nWhat are the effects of anxiety on memory biases? Herrera et al. (2017)\naddressed this issue in a meta-analytic review. They obtained three main\nfindings. First, there was an explicit memory bias in anxiety for free recall\n(see Glossary) but not cued recall (see Glossary) or recognition memory.\nMore extensive retrieval processes are required for free recall than for cued\nrecall or recognition, providing more scope for the involvement of emotion.\nSecond, there was no implicit memory bias associated with anxiety, which\nis directly contrary to the prediction of Williams et al. (1997).\nIn sum, the effects of depression and anxiety on memory biases differ;\nindeed, there are greater differences between depressed and anxious indi-\nviduals with respect to memory biases than attentional or interpretive\nbiases. Explicit memory bias is typically stronger and found across a\nwider range of memory tests in depressed individuals. Implicit memory\nbias is generally found in depressed individuals but is absent in anxious\nones. These findings are consistent with the notion that depression is more\nassociated than anxiety with an orientation towards the past (Eysenck\net al., 2006) and are partially consistent with the theoretical approach of\nWilliams et al. (1997).\nCombined cognitive biases hypothesis\nMost theorists have treated the various cognitive biases as if they were\nentirely separate from each other. Hirsch et al. (2006) challenged this\napproach. According to their combined cognitive biases hypothesis, cog-\nnitive biases often interact with each other. Suppose an anxious person\nattends selectively to the threatening aspects of a situation. This might lead\nCreated from usyd on 2022-02-17 03:28:58.",
    "760\nBroadening horizons\nto a threatening interpretation of that situation, and to a memory bias in\nwhich negative information is more accessible than positive information.\nThere is reasonable support for the above hypothesis. Consider a study\nby Amir et al. (2010) with socially anxious participants. Training to reduce\ninterpretive bias made it easier for participants to disengage attention from\nthreat. These findings suggest attentional and interpretive biases reflect (at\nleast in part) the operation of shared mechanisms.\nEveraert et al. (2014) conducted a study in which depressed and\nnon-depressed participants received a scrambled sentences task (e.g., “am\nwinner born loser a I”) and constructed sentences using all the words bar\none. Subsequently, the participants recalled their previously constructed\nsentences. Everaert et al. assessed attentional, interpretive and explicit\nmemory biases. The memory bias associated with depression was mediated\nby attentional and interpretive biases.\nCognitive or attentional control\nAnxious and depressed individuals may have the various cognitive biases\ndiscussed above primarily because they are sensitive to emotionally nega-\ntive or threatening information. However, more general processes also play\na part. For example, suppose anxious and depressed individuals have defi-\ncient cognitive or attentional control. As a consequence, they might have\nincreased attentional bias because they find it hard to disengage from neg-\native stimuli and increased interpretive bias because they cannot easily sup-\npress threatening interpretations.\nBooth et al. (2017) reported findings consistent with the notions above.\nThey assessed attentional and interpretive biases in individuals differing in\ntrait anxiety. In one condition, these biases were assessed while partici-\npants performed a secondary task restricting their ability to exercise cog-\nnitive control. The relationship between anxiety and both cognitive biases\nwas stronger when participants had limited use of cognitive control.\nTwo key cognitive control processes are inhibition and shifting (see\nChapter 6). Inhibition involves overriding dominant responses and resist-\ning distraction, whereas shifting involves switching flexibly between tasks.\nJoormann et al. (2007) proposed a theory based on the assumption depressed\nindividuals have impaired cognitive control. As you can see in Figure 15.24,\nthe theory predicts this impaired cognitive control causes problems in dis-\nengaging attention from negative information. Depressed individuals are\nlikely to elaborate on this information while attending to it. This can lead\nto enhanced memory for such information (i.e., a memory bias).\nJoormann & Tanovic (2015) reviewed research on depression and cog-\nnitive control. There was clear evidence depression is associated with diffi-\nculties in both inhibition and shifting. For example, Zetsche and Joormann\n(2012) found deficient inhibitory control was associated with a greater\nnumber of depressive symptoms and predicted the maintenance of depres-\nsive symptoms over the following six months. Joormann and Tanovic also\ndiscussed research suggesting the deficient inhibitory control of depressed\nindividuals is associated with their cognitive biases.\nImpaired cognitive control is also relevant to understanding the effects\nof anxiety on cognitive processing and biases. According to attentional\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n761\ncontrol theory (Eysenck et al., 2007), anxiety\nreduces the available capacity of working\nmemory. This impairs the efficiency of atten-\ntional or cognitive control (which depends\non working memory) in two ways. First, it\nimpairs inhibitory control including the ability\nto avoid processing task-irrelevant stimuli.\nSecond, it impairs the ability to shift atten-\ntion or cognitive control optimally within and\nbetween tasks. Eysenck and Derakshan (2011)\nreviewed research findings showing that high\ntrait anxiety is associated with inefficient\ninhibitory control and shifting.\nDerryberry and Reed (2002) found atten-\ntional or cognitive control was important in\ndetermining attention bias. Attentional bias\nwas weaker in high-anxious individuals with\nhigh attentional control than those with low\nattentional control. Taylor et al. (2016) found\nindividuals high in social anxiety showed slow\ndisengagement from social threat stimuli only if\nlow in the shifting form of attentional control.\nFinally, we consider why anxious and\ndepressed individuals spend much of their\ntime engaged in worry and/or rumination. In\nessence, their deficient  cognitive and atten-\ntional control makes it harder for them than\nfor other people to disengage from their nega-\ntive internal thoughts.\nIn sum, one reason why high-anxious and depressed individuals have\ncognitive biases is because they have deficient cognitive or attentional\ncontrol. Shortly we will discuss therapy for anxiety and depression based\non the attempt to enhance cognitive control. The success of such therapy\nsuggests deficient cognitive control maintains cognitive biases and high\nlevels of anxiety and depression.\nCOGNITIVE BIAS MODIFICATION AND BEYOND\nWe have seen anxiety and depression are both associated with various\ncognitive biases. The direction of causality is crucial – do cognitive biases\nmake individuals vulnerable to developing anxiety or depression or does\nbeing anxious or depressed lead to the development of cognitive biases? An\nappropriate method for addressing this issue is cognitive bias modifica-\ntion: “methods designed to modify cognitive factors that maintain psychiat-\nric conditions such as anxiety and depression” (Lau, 2015, p. 735).\nCognitive bias modification is a form of cognitive behavioural therapy,\nwhich involves using psychological methods to change unhelpful distorted\nor biased cognitions and behaviour. Thus, cognitive behavioural therapy\nencompasses numerous techniques in addition to those associated with\ncognitive bias modification.\nKEY TERM\nCognitive bias\nmodification\nTraining typically\ndesigned to reduce\nattentional bias and/\nor interpretive bias in\nanxious or depressed\nindividuals.\nFigure 15.24\nAccording to the impaired cognitive control account put\nforward by Joormann et al. (2007), depression is associated\nwith cognitive control impairments that lead to impaired\nattentional disengagement, elaborative processing and\nmemory biases.\nFrom Everaert et al. (2012). With permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:58.",
    "762\nBroadening horizons\nIN THE REAL WORLD: REDUCING ANXIETY AND DEPRESSION\nIf cognitive biases increase individuals’ vulnerability to anxiety and depression, then cognitive\nbias modification might be effective in reducing those negative emotional states. Cognitive bias\nmodification typically involves attempts to reduce attentional bias and/or interpretive bias. A\ncommon form of training to reduce attentional bias involves the dot-probe task (discussed earlier,\npp. 755–756). The task is altered so the dot always appears where the neutral stimulus had been\npresented, leading participants to learn to avoid attending to the threat-related stimulus.\nTraining to reduce interpretive bias often involves presenting ambiguous sentences that can\nbe  interpreted negatively or positively (e.g., “When some of your colleagues unexpectedly see\nyou, their reaction is one of . . .”). Each sentence is followed by a word fragment to be completed\nby the participant. The word fragment is selected to produce a positive sentence completion (e.g.,\npl _ _ sure producing pleasure).\nHow effective is cognitive bias modification? Liu et al. (2017) carried out a meta-analysis on the\nuse of cognitive bias modification to treat social anxiety disorder. Treatment reduced attentional\nbias and interpretive bias (especially interpretive bias). Both forms of bias modification produced\nmodest reductions in anxiety, with interpretive bias modification being more effective.\nCristea et al. (2015) conducted a meta-analysis to assess the effects of cognitive bias modification\non individuals high in anxiety or depression. Treatment reduced both anxiety and depression.\nHowever, the effects were typically fairly modest.\nWhy were the findings so modest? Grafton et al. (2017) pointed out that Cristea et al. (2015)\nfailed to differentiate between studies where attentional and/or interpretive bias were successfully\nreduced and those where these biases were not significantly reduced. Since the crucial theoretical\nassumption is that beneficial effects of cognitive bias modification on anxiety and depression are\nmediated by reducing cognitive biases, there should be no beneficial effects when such biases\nare not reduced. Grafton et al. re-analysed Cristea et al.’s data. There were moderately strong\nreductions in anxiety and depression in every study in which cognitive biases were successfully\nreduced but no reductions when they were not reduced.\nJones and Sharpe (2017) provided the most comprehensive account of the effectiveness of\ncognitive bias modification based on 12 meta-analyses. Cognitive bias modification was generally\nreasonably effective in the treatment of anxiety. However, its beneficial effects were weaker in the\ntreatment of depression.\nHow can we enhance cognitive bias modification? Lee et al. (2015) argued that the standard\napproach to reducing interpretive bias is limited because it only requires participants to provide\npositive interpretations of ambiguous sentences. Accordingly, they extended this approach by\nrequiring some participants to imagine a future positive event related to their interpretation of each\nambiguous sentence. This extended approach was more effective than the standard one perhaps\nbecause it made clearer the relevance of positive interpretations of ambiguous events for the future.\nCognitive control\nWe saw earlier that anxious and depressed individuals have impaired atten-\ntional or cognitive control and that this impaired control partially explains\ntheir various cognitive biases. A plausible inference from these findings is\nthat therapy designed to enhance cognitive control might prove effective in\ntreating anxious and depressed patients.\nCognitive bias modification of attentional bias may depend on improved\ntop-down attentional control or more specific processes (e.g.,  reduced\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n763\nsensitivity to threat-related stimuli). Booth et al. (2014) obtained evidence\nthat attentional control is important – cognitive bias modification of\nattentional bias in anxious individuals was ineffective when the conditions\nreduced participants’ ability to use attentional control. Sari et al. (2016)\nprovided training designed to enhance attentional control. Individuals\nexhibiting the largest gains in attentional control tended to show the great-\nest reductions in trait anxiety.\nKoster et al. (2017) carried out a meta-analytic review of research on\ncognitive control interventions in the treatment of depression. They con-\ncluded that “Most CCT [cognitive control training] studies have yielded\npromising effects in MDD [major depressive disorder] samples in terms of\nreducing cognitive vulnerability for depression” (p. 86).\nWe need to achieve a greater understanding of how cognitive control\nand cognitive biases interact to determine an individual’s level of anxiety\nor depression. Everaert et al. (2017a) addressed this issue by obtaining\nmeasures of cognitive control (e.g., inhibition; shifting), attentional and\ninterpretive biases and depressive symptoms. They obtained three main\nfindings:\n(1) There were no direct effects of deficient cognitive control on depres-\nsive symptoms.\n(2) Deficient cognitive control influenced depressive symptoms indirectly\nthrough its effects on attentional bias.\n(3) Deficient inhibitory control influenced interpretive bias which was in\nturn associated with depressive symptoms.\nEvaluation\nWhat are the strengths of research in this area? First, studies of cognitive\nbias modification have shown treatment effective in reducing attentional\nand interpretive biases generally leads to reductions in anxiety and depres-\nsion (especially anxiety). Thus, an important reason why many individuals\nhave high levels of anxiety and depression is because they have attentional\nand interpretive biases.\nSecond, other forms of treatment for anxiety and depression (e.g.,\ncognitive-behavioural therapy) involve several components. As a conse-\nquence, it is often unclear why a given form of treatment reduces clini-\ncal symptoms. In contrast, cognitive bias modification techniques are very\nfocused, making it easier to identify the underlying mechanisms.\nWhat are the limitations of cognitive bias modification techniques?\nFirst, the effects of these techniques on cognitive biases and on levels of\nanxiety and depression are somewhat variable. A major factor here is the\nrapid increase of studies in which modification techniques were presented\nonline via the internet under poorly supervised and controlled condi-\ntions. MacLeod and Clarke (2015) found attentional bias was successfully\nreduced in only 11% of online studies compared to 74% of studies con-\nducted in laboratory conditions.\nSecond, cognitive biases in anxiety and depression depend on general,\ntop-down control processes as well as on processes specific to processing\nemotionally loaded information. There is suggestive evidence that therapy\nCreated from usyd on 2022-02-17 03:28:58.",
    "764\nBroadening horizons\ndesigned to reduce these biases influences both general and specific pro-\ncesses. However, the relative importance of these two types of processes\nand how they interact remain unclear.\nThird, the assessment of symptomatology following cognitive bias\nmodification typically focuses only on self-report measures. Future studies\nshould use additional measures (e.g., physiological; behavioural) to iden-\ntify the full range of changes produced.\nCHAPTER SUMMARY\n•\nIntroduction. Moods typically last longer than emotions but are\nless intense. The brain mechanisms underlying emotions consist of\nlarge-scale networks not specific to any given emotion. Emotional\nexperience is determined by complex interactions between\nbottom-up and top-down processes.\n•\nAppraisal theories. Appraisal theories assume emotional\nexperience is mostly determined by cognitive appraisals of the\ncurrent situation. They also assume cognitive appraisal can involve\nautomatic processes as well as more controlled ones. Limitations\nof appraisal theories include: (1) the unwarranted assumption that\nsituational appraisal is always crucial in determining emotional\nexperience; (2) the de-emphasis of social factors in influencing our\nemotional reactions; and (3) the assumption there is a clear-cut\ndistinction between cognition and emotion.\n•\nEmotion regulation. Emotion regulation involves individuals\noverriding their initial emotional responses. Key emotion-\nregulation strategies are attention deployment, cognitive\nchange (e.g., reappraisal) and response modulation. Cognitive\nchange is generally the most effective strategy for reducing\nnegative affect and response modulation the least effective,\nbut strategy effectiveness depends on the precise situation.\nMany successful strategies are associated with prefrontal\nactivation leading to reduced amygdala activation. Effortful\nemotion-regulation strategies are most effective early in\nprocessing of negative emotional situations, whereas timing\nmatters less for relatively undemanding strategies. Emotion-\nregulation strategies can involve explicit and/or implicit\nprocesses.\n•\nAffect and cognition: attention and memory. Negative affect\noften produces attentional narrowing whereas positive affect\nproduces attentional broadening. However, emotional states\n(positive or negative) involving high motivational intensity are\nassociated with attentional narrowing, whereas those involving low\nmotivational intensity are associated with attentional broadening.\nIn addition, positive affect often causes individuals to maintain\nCreated from usyd on 2022-02-17 03:28:58.",
    "Cognition and emotion\n765\ntheir current attentional strategy whereas negative affect causes\nthem to change their attentional strategy. Mood states influence\nmemory through mood congruity and mood-state-dependent\nmemory; these effects are stronger with positive mood states. Two\nbrain networks (one mostly involved in memory and the other in\nattention and cognitive control) influence the memory-enhancing\neffects of mood or emotion. The amygdala is of importance within\nboth networks.\n•\nAffect and cognition: judgement and decision-making.\nAccording to the dual-process model, deontological judgements\nwith moral dilemmas are based on rapid affective processing,\nwhereas utilitarian ones are based on slower, cognitive\nprocessing. This model is oversimplified as is demonstrated\nby a model focusing on consequences, moral norms and\npreference for inaction vs action. Anxiety, sadness, anger\nand positive affect all have different patterns of effects on\njudgement and decision-making. Many effects can be explained\nby assuming anxiety increases the need to reduce uncertainty,\nsadness increases the need to rethink priorities, anger creates\na sense of personal control, and positive affect creates a\ndesire to maintain the current mood state. The emotion-\nimbued choice model provides a comprehensive account of\nthe main factors (e.g., current emotion; characteristics of the\ndecision-maker; nature of the task) influencing judgement and\ndecision-making.\n•\nAnxiety, depression and cognitive biases. Anxiety and\ndepression are associated with various cognitive biases such\nas: attentional bias; interpretive bias; explicit memory bias; and\nimplicit memory bias. Changes in one cognitive bias often produce\nchanges in other cognitive biases. Attentional bias tends to\nbe somewhat stronger in anxiety than depression, whereas the\nopposite is the case with memory biases. These differences are\nunderstandable given that anxiety has the function of anticipating\nfuture threat whereas depression replaces failed goals with new\nones. Anxious and depressed individuals have deficient cognitive\ncontrol (e.g., inhibition; shifting) and this deficient control plays a\nrole in the maintenance of their cognitive biases.\n•\nCognitive bias modification. When cognitive bias modification\ntechniques decrease attentional and/or interpretive bias, they are\ntypically successful in reducing anxiety and depression (especially\nanxiety). These techniques are very focused which makes it easier\nto identify the underlying mechanisms. More research is required\nto establish the extent to which the successful use of cognitive\nbias modification techniques depends on enhancing cognitive or\nattentional control.\nCreated from usyd on 2022-02-17 03:28:58.",
    "766\nBroadening horizons\nFURTHER READING\nBrownstein, L.M., Gross, J.J. & Ochsner, K.N. (2017). Explicit and implicit emotion\nregulation: A multi-level framework. Social Cognitive and Affective Neuroscience,\n12, 1545–1557. The authors provide a theoretical framework for categorising\nand understanding emotion regulation strategies based on implicit–explicit and\nautomatic–controlled dimensions.\nDolcos, F., Katsumi, Y., Weymar, M., Moore, M., Tsukiura, T. & Dolcos, S. (2017).\nEmerging directions in emotional episodic memory. Frontiers in Psychology, 8\n(Article 1867). This review article discusses thoroughly the neural mechanisms\nassociated with the enhancing effects of emotion on memory.\nEysenck, M.W. & Holmes, A. (in press). Anxiety, depression and cognitive dys-\nfunction. In P. Corr (ed.), The Cambridge Handbook of Personality Psychology\n(2nd edn). Cambridge: Cambridge University Press. Michael Eysenck and Mandy\nHolmes discuss the cognitive biases associated with anxiety and depression and\nthe use of cognitive bias modification techniques to reduce these biases.\nKuckertz, J.M. & Amir, N. (2017). Cognitive bias modification. In S. Hofmann\nand  G. Asmundson (eds), The Science of Cognitive Behavioural Therapy\n(pp.  463–491). London: Academic Press. Jennie Kuckertz and Nader Amir\ndiscuss the theoretical foundations of cognitive bias modification and review its\neffectiveness.\nLerner, J.S., Valdesolo, P. & Kassam, K.S. (2015). Emotion and decision-making.\nAnnual Review of Psychology, 66, 799–823. Jennifer Lerner and her colleagues\ndiscuss their model of the effects of emotion on decision-making. This model pro-\nvides the most comprehensive account in this area.\nScherer, K.R. & Moors, A. (2019). The emotion process: Event appraisal and com-\nponent differentiation. Annual Review of Psychology, 70, 719–745. Klaus Scherer\nand Agnes Moors discuss the role played by appraisal in emotion.\nSmith, R. & Lane, R.D. (2015). The neural basis of one’s own conscious and uncon-\nscious emotional states. Neuroscience and Biobehavioral Reviews, 57, 1–29. An\nintegrative model of emotion focusing on interactions among several appraisal\nmechanisms and bodily states is presented in this article. This model combines\ninsights from several previous appraisal and other theories.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\nINTRODUCTION\nWhat exactly is “consciousness”? There is an important distinction\nbetween conscious content and conscious level (Bor & Seth, 2012).\nConscious content refers to the information of which we are currently\naware. Consciousness in this sense is “characterised by the experience of\nperceptions, thoughts, feelings, awareness of the external world, and often\nin humans . . . self-awareness” (Colman, 2009, p. 164). This definition\nis limited because it leads us to ponder the exact meanings of the words\n“experience” and “self-awareness”.\nIn contrast, conscious level refers to the state of consciousness. It\nruns from the total unconsciousness of coma through to alert wakeful-\nness. These two aspects of consciousness are related – a non-zero con-\nscious level is required for individuals to experience conscious content\nor awareness. The notion of levels implies that different states of con-\nsciousness lie along a single dimension. Thus, for example, patients with\ndisorders of consciousness were traditionally categorised as having dif-\nferent levels of consciousness solely on the basis of behavioural meas-\nures (e.g., wakefulness; capacity for intentional behaviour). However,\nsome patients exhibit consciousness via their patterns of brain activity\nin spite of displaying no behavioural evidence of consciousness (Bayne\net al., 2017).\nThe above considerations indicate that states of consciousness differ\nfrom each other in several dimensions. For example, Bayne et al. (2016)\nidentified two separate dimensions: (1) the range of contents of conscious-\nness; and (2) functions of consciousness (e.g., attentional control; action\nselection). Thus, we need a multidimensional approach to understand-\ning consciousness rather than a uni-dimensional one based on levels of\nconsciousness.\nIn this chapter, we focus mostly on consciousness in the former sense\nof conscious awareness. For example, Block (e.g., 2012) distinguished\nbetween two forms of consciousness:\nChapter\n16\nCreated from usyd on 2022-02-17 03:28:58.",
    "768\nBroadening horizons\n(1)\nAccess consciousness can be reported and its contents are avail-\nable for use by other cognitive processes (e.g., attention; memory).\nIt “refers to the functions that can be associated with consciousness”\n(Fazekas & Overgaard, 2018, p. 1).\n(2)\nPhenomenal consciousness is our raw, private experience; it “refers\nto the experiential characteristics of consciousness” (Fazekas &\nOvergaard, 2018, p. 1).\nMost people believe their immediate conscious experience (phenomenal\nconsciousness) is much richer than the information about that experience\nwe can communicate to others (access consciousness).\nThere is scepticism regarding the above distinction. As Naccache\n(2018) pointed out, we only know about someone else’s phenomenal con-\nsciousness from their self-reports (e.g., “I can see the view very clearly”).\nHowever, that is very similar to the case with access consciousness (e.g.,\n“I can see two cows in that field”), which suggests the distinction is less\nimportant than often assumed. Another problem with phenomenal con-\nsciousness is that it is very hard to assess the accuracy (or otherwise) of its\nalleged contents.\nBaumeister and Masicampo (2010) proposed a different distinction.\nFirst, there is phenomenal consciousness, which “describes feelings, sensa-\ntions, and orienting to the present moment” (p. 945). It is a basic form of\nconsciousness. Second, there is a higher form of consciousness (conscious\nthought). It “involves the ability to reason, to reflect on one’s experiences,\nand have a sense of self” (p. 945). Pinker (1997) provided an example of\nthis form of consciousness: “I cannot only feel pain and see red, but think\nto myself, ‘Hey, here I am, Steve Pinker, feeling pain and seeing red!’”\nMuch progress has been by cognitive neuroscientists with respect to\nseveral issues relating to consciousness. These include our ability to: dis-\ncriminate and categorise stimuli; integrate information; access our own\ninternal states; and control our own behaviour. However, we still do not\nunderstand why “some neural mechanisms, but not others, should be\nassociated with consciousness” (Tononi et al., 2016, p. 450). This is what\nChalmers (2007) called the “hard problem” of consciousness.\nFUNCTIONS OF CONSCIOUSNESS\nWhat are the main functions of consciousness? Below are listed some of its\nproposed functions (although there is fierce ongoing controversy concern-\ning some of them):\n(1) It is associated with perceiving the environment.\n(2) It plays a key role in social communication and understanding what\nothers are thinking.\n(3) It plays a role in controlling our actions.\n(4) It allows us to think about events and issues far removed from the\npresent. People’s conscious thoughts wander away from their current\nactivity (thus displaying “stimulus independence” between 25% and\n50% of the time (Konishi & Smallwood, 2016). Such mind-wandering\nis very useful when planning for the future.\nKEY TERMS\nAccess consciousness\nA form of consciousness\nwhere its contents\nare available for use\nby processes such as\nattention and memory;\ninformation within\naccess consciousness\ncan be communicated\nto others; phenomenal\nconsciousness.\nPhenomenal\nconsciousness\nDirect conscious\nexperience; see access\nconsciousness.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n769\n(5) Tononi et al. (2016) argued that consciousness is remarkably informa-\ntive, and this has great functional value. In their own words,\nConscious brains may have evolved [because] the world is\nimmensely complex . . . and organisms with brains that can incor-\nporate statistical regularities that reflect the causal structure of\nthe environment into their own causal structure have an adaptive\nadvantage for prediction and control.\n(p. 458)\n(6) It is important with respect to bodily self-consciousness, which is\n“the experience of being the subject of a given experience” (Blanke\net al., 2015, p. 145).\nIf we want to understand the functions of consciousness, it is relevant to\nconsider the controversy concerning the functions and usefulness of uncon-\nscious processes. It has often been argued that unconscious processes are\ninflexible and of limited value (see Chapter 5). In contrast, Sigmund Freud\nfamously emphasised its massive power. In this book, we have seen many\nprocesses can occur without conscious awareness: perceptual processes\n(Chapter 2); learning (Chapter 6); memory (Chapter 7); and, possibly,\ndecision-making (Chapter 13).\nHassin (2013, p. 195) provocatively proposed the “Yes It Can” prin-\nciple: “Unconscious processes can carry out every fundamental high-level\n[cognitive] function that conscious processes can perform.” Hassin focused\non evidence that goal pursuit, cognitive control and reasoning can all occur\nbelow the conscious level. If his “Yes It Can” principle is correct, this\nwould devalue the importance of consciousness.\nMarien et al. (2012) obtained support for the “Yes It Can” principle.\nParticipants performed a proofreading task and the unconscious goal of\nsocialisation was induced in some of them by presenting socialisation-\nrelevant words (e.g., partying; celebrating) subliminally (below the level of\nconscious awareness). This unconscious socialisation goal impaired proof-\nreading performance in participants for whom socialisation was an impor-\ntant goal (see Figure 16.1). Related effects of subliminally presented stimuli\non behaviour have often been found, especially when important goals are\nactivated (see Weingarten et al., 2016, for a meta-analytic review).\nThere are two issues with Hassin’s (2013) principle. First, he did not\nconsider problems with establishing that findings supporting his principle\ndepended solely on the use of unconscious processes. Second, he ignored\nnumerous findings apparently inconsistent with his principle (Hesselmann\n& Moors, 2015). In sum, cognitive functions involving unconscious pro-\ncesses are probably much more limited in scope than those involving con-\nscious ones.\nConsciousness sometimes provides misleading interpretations or\nrationalisations of events after they have happened (Nisbett & Wilson,\n1977). Adriaanse et al. (2016) obtained relevant evidence in a study using\nparticipants low or high in emotional eating (i.e., the tendency to overeat\nin response to negative emotions). After they were told they had overeaten,\nonly those high in emotional eating incorrectly claimed their mood state\nKEY TERM\nBodily self-consciousness\nA form of self-\nconsciousness involving\nbody-centred perception\n(e.g., of the face, hand\nor trunk) based on\nintegration of bodily\nsignals from several\ndifferent sense modalities.\nCreated from usyd on 2022-02-17 03:28:58.",
    "770\nBroadening horizons\nwas negative before eating. Thus, their conscious belief they had eaten too\nmuch because they were sad was a mistaken explanation for overeating.\nWe turn now to a consideration of two major functions of conscious-\nness. Social communication is discussed first, followed by controlling\naction.\nSocial communication\nA crucial function of consciousness is to facilitate social communication.\nHumans have lived in social groups for tens of thousands of years and\nso have needed to predict, understand and manipulate others’ behaviour.\nThis is much easier to do if you can imagine yourself in their position.\nGraziano and Kastner (2011, p. 98) proposed a theory along those lines:\n“The machinery that computes information about other people’s awareness\nis the same machinery that computers information about our own aware-\nness” (p. 98). Within this theory, “Awareness . . . is one’s social intelligence\nperceiving one’s focus of attention” (p. 98).\nKey aspects of this theory are shown in Figure 16.2. Abel forms a\nmodel of Bill’s mental state (“Bill is aware of the cup”) using neuronal\nmachinery specialised for social perception. This machinery is also used for\nself-awareness. Awareness may originally have been developed to under-\nstand others with humans only later developing self-awareness.\nFigure 16.1\nMean scores for error detection on a proofreading task as a function of whether the goal\nof socialisation had been induced unconsciously (unconscious goal vs no-goal control)\nand the importance of the goal of socialisation to the participants (low vs high goal\nimportance). Scores closer to zero indicate better error-detection performance.\nFrom Marien et al. (2012). © American Psychological Association.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n771\nGraziano and Catmur (2011) argued this neural machinery (involv-\ning the ability to switch perspectives) depends crucially on the temporo-\nparietal junction (meeting of the temporal and parietal lobes). In support,\nattributing states of awareness to other people is associated with activation\nin the temporo-parietal junction (Graziano, 2016). In addition, transcranial\nmagnetic stimulation (TMS; see Glossary) applied to this area to inhibit its\nfunctioning impairs the ability to switch between representations of the self\nand another person (Sowden & Catmur, 2015).\nIf perceiving someone else’s awareness and self-awareness depend on\nthe same neuronal mechanisms, we might sometimes be confused as to the\nsource of our awareness. This is, indeed, the case with out-of-body expe-\nriences, which are “sensations in which a person’s consciousness seems to\nbecome detached from the body and take up a remote viewing position”\n(Blanke et al., 2002, p. 269). Bos et al. (2016) discussed the case of a female\npatient undergoing brain surgery. Electrical stimulation of part of the tem-\nporo-parietal junction caused her to feel “as if she was floating just below\nthe ceiling and saw her own body lying on the operating table” (p. 10).\nFinally, Baumeister et al. (2011, p. 74) identified another social func-\ntion of conscious thoughts: “Many investigators operationally define\nconscious thought as those thoughts the person can report to others . . .\nthe purpose of conscious thought is precisely for enabling people to tell\ntheir thoughts to one another.” Thus, much of conscious thinking is for\ntalking.\nControlling our actions?\nNumerous times every day we think of doing something followed by actu-\nally doing it. For example, “I will get myself a coffee” is followed by me\nfinding myself in a café drinking coffee. Such experiences suggest we have\nfree will: “the ability to make choices and to determine one’s own outcomes\nFigure 16.2\nAwareness as a social perceptual model of attention. Abel observes Bill and constructs\na model of Bill’s mental state using mechanisms specialised for social perception.\nThis model includes the notion that Bill is aware of the cup. The mechanisms of social\nperception used to perceive awareness in other people may be used to perceive\nawareness in ourselves.\nFrom Graziano & Kastner (2011).\nKEY TERMS\nOut-of-body experiences\nVivid feelings of being\noutside of (and detached\nfrom) one’s own body.\nFree will\nThe notion that we freely\nor voluntarily choose\nwhat to do from various\noptions.\nCreated from usyd on 2022-02-17 03:28:58.",
    "772\nBroadening horizons\nfree from constraints” (Aarts & van den Bos, 2011, p. 532). As Baumeister\net al. (2018, p. 2) argued, “It seems wildly implausible that human conscious\nthought evolved purely as a side effect, with no adaptive benefits depending\non its ability to guide behaviour.”\nOver the centuries, philosophers have debated whether humans possess\nfree will without resolving the issue. Many (probably most) psychologists\nare sceptical about free will. For example, Wegner (2003) claimed we have\nonly the illusion of free will. Our actions are actually caused by uncon-\nscious processes, but we mistakenly infer our actions are determined by\nour conscious intentions. He argued this illusion depends on the principles\nof priority, consistency and exclusivity:\nWhen a thought appears in consciousness just before an action (prior-\nity), is consistent with the action (consistency), and is not accompanied\nby conspicuous alternative causes of the action (exclusivity), we experi-\nence conscious will and ascribe authorship to ourselves for the action.\n(p. 67)\nMuch research apparently supports Wegner’s (2003) position that free will\nis an illusion. In a study by Wegner and Wheatley (1999), two participants\n(one genuine and the other the researcher’s confederate) placed their fingers\non a small board. When they moved the board, a cursor moved over a\nscreen showing pictures of objects. The participants were instructed to stop\nthe cursor every 30 seconds or so and indicate whether they had consciously\nintended the cursor to stop where it did. Both participants heard words\nreferring to objects through headphones. The confederate was instructed\nthrough headphones where to stop the cursor.\nGenuine participants tended to believe wrongly they had caused\nthe cursor to stop where it did (e.g. on a picture of a cat) if they had\nheard the word “cat” 1 or 5 seconds beforehand. Their mistaken belief\ncan be explained by the principles of priority, consistency and exclusivity.\nHowever, the findings are less impressive than they sound for two reasons.\nFirst, only 60% of participants believed their conscious intention caused\nthe cursor to stop even when all three principles applied. Second, the\nset-up was very artificial and designed to make it hard for participants to\nunderstand what was happening. By analogy, no one would argue visual\nperception is hopelessly fallible simply because we misidentify objects in a\nthick fog!\nVan der Weiden et al. (2013) conducted a similar study. Participants\nstopped a rapid sequence of words by pressing a response key to a stop\ncue. The sequence stopped at a word (e.g., glass) determined by the com-\nputer but the participants were not told this.\nParticipants believed they had caused the outcome when the stopped\nword matched their goal (i.e., it was the one they intended to stop at).\nThey also believed they had caused the outcome when the stopped word\nmatched an earlier prime word presented below the level of conscious\nawareness. Thus, there are various ways people can be misled into thinking\nthey have caused a given outcome.\nBelow we consider additional experimental evidence. We start with\nbehavioural research followed by cognitive neuroscience research.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n773\nFindings: behavioural evidence\nBaumeister et al. (2011) reviewed evidence suggesting individuals’ behav-\niour often depends crucially on their conscious thoughts even though\nthose thoughts may have been preceded by various unconscious pro-\ncesses. Strong evidence comes from research on implementation intentions\n(if-then plans designed to attain some goal; see Glossary; and Chapter 8).\nHere is an example of an implementation intention: “If I feel depressed,\nthen I will immediately become actively involved in some task”). Toli\net al. (2016) found in a meta-analysis (see Glossary) that implementation\nintentions had a large effect on goal attainment in individuals with mental\nhealth problems.\nImplementation intentions are effective because they produce strong\nassociations between the current situation (if part of the plan) and the\ngoal-related action (then part of the plan). It follows that relatively little\neffortful action control should be required for goal attainment. As pre-\ndicted, people have reduced activity in brain areas involved in effortful\ncontrol (e.g., dorsolateral prefrontal cortex) when their behaviour is con-\ntrolled by implementation intentions (Wieber et al., 2015).\nMuch behavioural research has focused on individuals’ sense of\nagency – the “feeling of being in the driving seat when it comes to our\nactions” (Moore, 2016, p. 1). It would pose some problems for the notion\nof free will if individuals sometimes have a sense of agency when it is not\nwarranted and lack a sense of agency when it is warranted.\nOlson et al. (2015) produced a mistaken sense of agency in participants\nusing a simple card trick. A professional magician riffled rapidly through a\npack of cards having asked participants to choose one. One card (the target\ncard) was shown for longer than the others. The findings were clear-cut.\nAlmost all (98%) the participants chose the target card. Even though their\nchoice of card had been forced by the magician, 91% of participants felt\nthey had had a free choice. Thus, there was a strong dissociation between\nparticipants’ beliefs and reality.\nOlson et al. (2016) obtained evidence people can mistakenly believe\nthey lack agency. Participants inside a mock brain scanner chose arbitrary\nnumbers. In a mind-reading task, the scanner apparently guessed their\nchosen number, and in a mind-influencing task it apparently influenced\ntheir choice of numbers. As predicted, participants performing the latter\ntask had a reduced sense of agency – they reported lower levels of inter-\nnal voluntary control over their choices. Among their comments was the\nfollowing (p. 21): “I feel like it’s a voice . . . dragging me from the number\nthat already exists in my mind.”\nWe can explain the above findings with reference to Wegner’s (2003)\nexclusivity principle – being consciously aware of a single apparently exter-\nnal thought led participants to attribute their choices of numbers to the\nmock scanner. A related phenomenon occurs in schizophrenic patients\nwith delusions of control causing loss of a sense of agency. Here is what\nwas said by a schizophrenic patient (cited by Gallagher & Trigg, 2016,\np. 4): “They inserted a computer in my brain. It makes me turn to the left\nor right. It’s just as if I were being steered around, by who or what I don’t\nknow.”\nKEY TERM\nSense of agency\nThe belief we are\ndetermining our own\nactions.\nCreated from usyd on 2022-02-17 03:28:58.",
    "774\nBroadening horizons\nFindings: cognitive neuroscience\nIn a famous (or notorious!) study, Libet et al. (1983) asked participants to\ndecide when to bend their wrist and fingers and to indicate when they were\nconsciously aware of their intention to perform those movements. They also\nrecorded event-related potentials (ERPs; see Glossary) to assess the readi-\nness potential (reflecting preplanning of a bodily movement). Surprisingly,\nthe readiness potential occurred 350 ms before participants reported con-\nscious awareness of the intention to bend their wrist and fingers and 550 ms\nbefore the actual hand movement.\nSuperficially, Libet et al.’s (1983) findings suggest much processing\nrelating to the intention to make a movement occurs before conscious\nawareness. However, there are various problems with their study. For\nexample, they focused on the late stage of motor preparation rather than\non earlier high-level decision processes. In addition, they studied only when\ndecisions (when shall I move my hand? and ignored what decisions (e.g.,\nwhat movement shall I make?)).\nBode et al. (2011) addressed these limitations. They assessed brain\nactivity in the anterior fronto-polar cortex (associated with decision-\nmaking) while participants decided whether to respond with their left or\nright index finger. Their key finding was that participants’ decisions could\nFigure 16.3\n(a) Region in left fronto-\npolar cortex for which\ndecoding of upcoming\nmotor decisions was\npossible. (b) Decoding\naccuracy of these decisions\n(times preceding conscious\nawareness of the intention\nare labelled as negative\nnumbers). Chance\nperformance = 50%.\nFrom Bode et al. (2011).\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n775\nbe predicted on the basis of brain activity up to 7½ seconds before they\nwere consciously aware oftheir decision (see Figure 16.3).\nFor various reasons, Bode et al.’s (2011) findings do not cast doubt on\nthe existence of free will. First, predicting accurately participants’ decisions\nfrom their preceding brain activity was rarely above 55% (chance = 50%)\nexcept very shortly before the conscious decision. Thus, conscious process-\ning may have strongly influenced participants’ actions.\nSecond, the requirement to make unpredictable and random responses\nreduced any pre-decision conscious processing to a minimum by encour-\naging participants to use “automatic tie-breaking mechanisms” (Mele,\n2013, p. 781). In contrast, most people make extensive use of conscious\nthinking prior to important decisions (e.g., shall I marry X?). Third, as\nNachmias (2015, p. 78) wittily pointed out, if our decisions are made\nseveral seconds before we act, “we would all have died in car crashes by\nnow!”.\nFried et al. (2017) reviewed research indicating that frontal and\nparietal areas are of crucial importance with respect to conscious plan-\nning, decision-making and a sense of agency. For example, Rens et al.\n(2017) found there was much greater activation in the fronto-parietal\nnetwork (associated with cognitive control) when participants made vol-\nuntary choices than when they were instructed which choice to make.\nMore generally, a key aspect of human decision-making is our ability\nto use conscious processes to think ahead and plan goal-directed action\n(Fried et al.).\nEvaluation\nVarious strands of behavioural and cognitive neuroscience research appar-\nently cast doubt on the notion of free will. Behavioural research has shown\nwe can have a mistaken sense of agency when we are not responsible for\nsome action and we can also lack a sense of agency even when we are\nresponsible for an action. Such findings are interesting and potentially\nimportant. However, they are often obtained in rather artificial situations –\nin everyday life our actions probably often depend on a mixture of con-\nscious and unconscious processes.\nCognitive neuroscience research casts less doubt on human free will\nthan sometimes claimed. For example, researchers’ ability to predict par-\nticipants’ decisions from their preceding brain activity in the Bode et al.\n(2011) study was only slightly above chance. Thus, participants’ actions in\nthat study probably depended in part on processes associated with early\nbrain activity but this does not rule out a strong involvement of conscious\nprocessing. There is much evidence that conscious planning within frontal\nand parietal areas is of considerable importance in influencing goal- directed\naction (Fried et al., 2017).\nASSESSING CONSCIOUSNESS AND CONSCIOUS\nEXPERIENCE\nHow can we assess (and understand) conscious experience? Unsurprisingly,\nthe most popular answer is that we should use behavioural or introspective\nCreated from usyd on 2022-02-17 03:28:58.",
    "776\nBroadening horizons\nmeasures. For example, we could decide whether individuals have conscious\nexperience of an object by asking them to provide verbal reports of their\nvisual experience. Alternatively, they could make yes/no decisions concern-\ning the presence of a target object.\nLamme (2006, 2018) argued that our actual conscious experience\nis often much richer than our report of that experience. Why is that?\nAccording to Lamme (2006, p. 499), “You cannot know whether you have\na conscious experience without resorting to cognitive functions such as\nattention, memory or inner speech.” Thus, reports of our conscious expe-\nrience may be limited due to processes intervening between the experience\nand its report rather than limitations in the experience itself.\nAnother problem is that different behavioural or self-report measures\noften produce different answers. For example, consider research on sublim-\ninal perception (see Glossary; and Chapter 2). Observers sometimes show\n“awareness” of visual stimuli when making forced-choice decisions about\nthem (objective threshold) but not when reporting their experience (subjec-\ntive threshold).\nUnder-reporting of conscious experience?\nSuppose you look briefly at a photograph of a social event and then imme-\ndiately describe your conscious experience. You would probably refer to\nthe main individuals in the photograph. However, you would probably\nnot mention the size of the photograph, whether it is matt or gloss, or the\ndistances between the individuals. Research evidence indicating we often\nunder-report our conscious experience was reported by Sperling (1960; see\nChapter 6). He presented a visual array consisting of three rows of four\nletters each for 50 ms. Participants typically reported only four to five\nletters but claimed to have seen many more.\nSperling (1960) assumed this under-reporting occurred because rele-\nvant visual information faded before it could be reported. He tested this\nassumption by asking participants to recall only part of the information\npresented (e.g., the second row). As predicted, part recall was high provided\nthe to-be-recalled information was cued very shortly after the offset of the\nvisual display.\nMuch subsequent experimentation supports Sperling’s (1960) find-\nings. Two object arrays are presented several seconds apart, and observers\ndecide whether a given object has changed between arrays (see Lamme,\n2010). Performance was poor when this object was cued at the same time\nas the second array was presented. However, it was very good when the\ncue was presented some time ahead of the second array. Such findings\nsuggest observers have access to considerable information for some time\nfollowing the offset of the first array.\nThere are two possible interpretations of the above findings (Gross,\n2018). First, our conscious experience “overflows” our capacity to report it.\nIn the terms used by Block (2012; discussed earlier, pp. 767–768), phenom-\nenal consciousness (our private experience) is richer and more extensive\nthan our access consciousness (experience we can report). This approach\nis probably consistent with most people’s introspections, but that provides\nvery weak evidence.\nCase study:\nTowards a true neural\nstance\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n777\nSecond, some letters or objects may be represented consciously with\nmost (or all) of the remainder being represented unconsciously. Under\nsome circumstances, cueing can make observers consciously aware of\nthese unconscious representations which are then reported. Evidence we\ncan exaggerate the richness of our conscious experience was reported by\nde Gardelle et al. (2009) using a modified version of the Sperling task.\nParticipants expected letters to be presented but sometimes pseudo-letters\n(real letters rotated and flipped) were presented instead. Participants rarely\ndetected the presence of pseudo-letters. Thus, their conscious experience\nwas less accurate and detailed than they thought it was.\nOver-reporting of conscious experience?\nFurther evidence our conscious experience is less accurate than we believe\ncomes from research on change blindness (see Glossary; and Chapter 4).\nMost people substantially overestimate their ability to avoid change blind-\nness (Levin et al., 2002).\nYou can obtain some sense of what is going on here by looking out\nof the window and taking note of what you perceive. Your conscious per-\nception probably suggests you can see the entire view clearly. In fact, that\nis an illusion because peripheral vision is much more limited than central\nvision (Rosenholtz, 2016).\nFreeman and Simoncelli (2011) reported relevant evidence. Observers\nsaw an original undistorted photograph followed by distorted versions of\nthat photograph (see Figure 16.4). The observers could not distinguish\nbetween the original undistorted photographs and those with gross periph-\neral distortions. Why isn’t our conscious perception of the world blurred?\nWe use top-down processes (e.g., expectations) to fill in the gaps in the\ninformation available to us. Thus, as Cohen et al. (2016, p. 324) concluded,\n“We see far less than we think we see.”\nFigure 16.4\nUndistorted photograph of the Brunnen der Lebensfreude in Rostock, Germany (left-hand picture) and distorted versions\nof it (middle and right-hand pictures). With rapid presentation and fixation at the centre (red dot), the two distorted\nversions appeared nearly identical to each other and to the undistorted photograph.\nFrom Freeman and Simoncelli (2011). Reproduced with permission from Nature Publishing Group.\nCreated from usyd on 2022-02-17 03:28:58.",
    "778\nBroadening horizons\nConsciousness in brain-damaged patients\nThree stages of degraded consciousness have been identified in brain-\ndamaged patients. The most severe stage is coma – there is no conscious\nawareness and no wakefulness. The next stage is a vegetative state; patients\nin this state “appear to be awake but show no external evidence of aware-\nness” (De Salvo et al., 2015, p. 237). The third stage is a minimally conscious\nstate, involving wakefulness and some evidence of consciousness. This cat-\negorisation implies that states of consciousness differ along a single dimen-\nsion. In fact, conscious states differ from each other with respect to several\ndimensions (Bayne et al., 2016, 2017; discussed earlier, p. 767).\nHow can we explain differences between patients in a vegetative state\nand those in a minimally conscious state? Chen et al. (2018b) provided\nan answer. Conscious awareness in healthy individuals depends in part on\nconnections from brainstem arousal systems and cortical areas. These con-\nnections are impaired in patients in a minimally conscious state but totally\nlacking in vegetative state patients.\nMuch research interest has focused on vegetative state patients.\nBehavioural measures (e.g., responsiveness to external stimuli) provide\nno evidence such patients have conscious awareness whereas neuroimag-\ning research indicates some vegetative state patients have partial conscious\nawareness (see Box).\nKEY TERMS\nVegetative state\nA brain-damaged\ncondition in which\npatients exhibit\nwakefulness but lack\nconscious awareness.\nMinimally conscious\nstate\nA condition in which\npatients exhibit partial\npreservation of conscious\nawareness.\nIN THE REAL WORLD: VEGETATIVE STATE PATIENTS AND\nCONSCIOUSNESS\nWhat tasks would reveal whether some vegetative state patients have conscious awareness? Active\ntasks where participants generate the responses themselves by responding to commands are of\nspecial value (Owen, 2013). For example, Monti et al. (2010) gave a vegetative state patient various\nyes-or-no questions (e.g., “Is your father’s name Thomas?”). He was told to imagine playing tennis\nfor “Yes” answers and to imagine navigating his house for “No” answers. The patient’s patterns of\nbrain activity corresponded to the correct answers.\nCruse et al. (2011) reported interesting findings on 16 vegetative state patients instructed\nto respond to two commands (“squeeze your right hand”; “squeeze your toes”). In healthy\nparticipants, these commands produce activation in the hand and toe motor areas, respectively.\nThree patients showed very similar patterns of brain activation (see Figure 16.5). These findings are\nimpressive: successful task performance requires sustained attention, language comprehension (of\nthe task instructions) and response selection.\nMonti et al. (2013) studied a patient with a severe disorder of consciousness. He was presented\nwith superimposed pictures of faces and houses and instructed to shift his attention between the\nfaces and the houses. His changing patterns of brain activation indicated the patient’s intentions\nwere successful in changing his attentional focus.\nKondziella et al. (2016) argued the demanding nature of active tasks may mean that conscious\nawareness in vegetative state patients is underestimated. Accordingly, they compared evidence of\nconscious awareness in active tasks and passive ones (responses were not required) by assessing\nfunctional cortical connectivity in networks associated with conscious awareness. Here are their\nmain findings. First, 14% of vegetative state patients and 32% of minimally conscious state patients\nshowed signs of consciousness on active tasks. Second, 26% of vegetative state patients and 55%\nof minimally conscious patients showed signs of consciousness on passive tasks.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n779\nIn sum, the above research indicates the value of using cognitive neuroscience techniques to\nassess consciousness in vegetative state patients. Of importance, behavioural measures consistently\nindicate that conscious experience is absent in such patients.\nWhat are the limitations of research in this area? First, it is hard to interpret the differences between\nactive and passive tasks reported by Kondziella et al. (2016). As they concluded, “Unresolved\ndilemmas include the lack of a gold standard for [assessing] consciousness” (p.  7). Second, it is\nalso hard to assess consciousness in patients because it often fluctuates over time (Kondziella\net al.). Third, we have only limited understanding of the conscious experience of vegetative state\npatients exhibiting signs of consciousness (Owen, 2013). In addition, most vegetative patients\nshow no signs of consciousness and we do not know the extent to which this reflects insensitivity\nof assessment.\nFigure 16.5\nModulation of the\nappropriate frequency\nbands of the EEG signal\nassociated with motor\nimagery in one healthy\ncontrol and three patients.\nRed colours show values\nmore than zero, while\nblue colours show values\nless than zero. There are\nclear focal areas over\nthe hand and toe motor\nareas (directly relevant\nto the task) for all four\nparticipants.\nFrom Cruse et al. (2011).\nReprinted with permission\nfrom Elsevier.\nNeural correlates of consciousness\nWe have seen that relying solely on self-report measures to assess conscious\nawareness is limited. Alternatively, we could focus on the neural corre-\nlates of consciousness: “the minimum neural mechanisms jointly sufficient\nCreated from usyd on 2022-02-17 03:28:58.",
    "780\nBroadening horizons\nfor any one specific conscious experience” (Koch et al., 2016, p. 307). This\napproach typically involves relating behavioural measures of conscious\nawareness to associated patterns of brain activity. This approach has two\nadvantages. First, it is theoretically important to compare behavioural and\nneuroimaging measures to identify their similarities and differences. Second,\nneuroimaging measures may assess consciousness more directly than behav-\nioural measures if uncontaminated by additional processes such as atten-\ntion and memory (discussed above, p. 776).\nSeveral reviews on the neural correlates of consciousness are available\n(e.g., Koch et al., 2016). Here we will focus on two issues. First, prob-\nlems in establishing the neural correlates of consciousness are discussed.\nSecond, we discuss the role of recurrent processing in conscious awareness.\nFindings of direct theoretical relevance are discussed in the next section.\nMajor problems\nIn studies on the neural correlates of consciousness, several brain regions\nare typically activated. We cannot assume all these brain regions are neces-\nsarily associated with conscious experience. Consider a study where visual\nstimuli are presented very briefly to observers, who indicate whether they\nsaw each stimulus and try to identify it. The observers will use several\ncognitive processes (e.g., attention; monitoring their conscious awareness;\nremembering what they have seen; reporting what they have seen) addi-\ntional to conscious experience itself. As a consequence, it can be very hard\nto disentangle which neural activity is associated with conscious awareness\nand which neural activity is associated with other task-related processes\n(Storm et al., 2017).\nRelevant evidence was reported by Frässle et al. (2014) in a study on\nbinocular rivalry (see Glossary). In one condition, observers indicated by\nbutton presses which stimulus they saw (active condition). In the other\ncondition, observers simply observed changes in which stimulus they per-\nceived without responding (passive condition).\nWhat did Frässle et al. (2014) find? Occipital and parietal areas were\nactivated in both active and passive conditions (see Figure 16.6). However,\nfrontal areas (including dorsolateral prefrontal cortex) were much more\nactivated in the active condition. If the researchers had used only the\nactive condition, we might have mistakenly exaggerated the association\nbetween frontal activation and conscious awareness. In fact, that activa-\ntion mostly reflected processes relating to making behavioural reports (e.g.,\nself- monitoring) rather than directly to conscious experience.\nAnother problem is that of establishing the relationship between a given\npattern of neural activity and consciousness. Neural activity may directly\nreflect conscious awareness. Alternatively, the observed neural activity may\nprecede and influence conscious awareness or may occur merely as a conse-\nquence of conscious awareness (de Graaf et al., 2012).\nAnother problem is that most research is limited in scope. There\nhas been a strong emphasis on the neural correlates of visual conscious\nawareness to currently presented visual stimuli. Why is that? We can easily\ncontrol the conditions (e.g., by altering exposure time) to ensure observers\nare (or are not) consciously aware of any given visual stimulus.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n781\nAs a result of this emphasis, relatively little is known about the\nneural processes associated with conscious awareness of past or future\nevents. More generally, cognitive neuroscientists have rarely studied what\nBaumeister and Masicampo (2010; discussed earlier, p. 768) called con-\nscious thought.\nFeedforward processing and recurrent processing\nLamme (2018) provided an account of the various stages of visual process-\ning (see Figure 16.7) in the most recent version of his recurrent processing\ntheory:\n(1) Fast processing starts in early visual cortex and proceeding to higher\nlevels (Figure 16.7a); this feedforward sweep takes approximately\n150–200 ms. Feedforward processing is not accompanied by conscious\nexperience.\n(2) Recurrent or top-down processing starts approximately 100 ms after\nstimulus presentation and occurs between low-level visual areas\n(Figure 16.7b); it involves phenomenal consciousness (direct  conscious\nexperience).\n(3) Recurrent or top-down processing spreads throughout the brain\n(including prefrontal areas) (Figure 16.7c); it involves access con-\nsciousness (its contents can be communicated to other people).\nWhy is conscious experience associated with recurrent processing rather\nthan the feedforward sweep? First, the feedforward sweep involves\nfragmented processing of different kinds of information (e.g., shape;\ncolour), whereas recurrent processing is integrated. Second, conscious\nvisual experience is typically coherent even when the available visual\ninformation is ambiguous. Top-down processes (e.g., expectations) asso-\nciated with  recurrent processing are important in producing this coherence\n(O’Reilly et al., 2013).\nHow can we prevent (or reduce) recurrent processing to assess its impor-\ntance for conscious perception? Masking is one method. Backward masking\nFigure 16.6\nActivation patterns on a binocular-rivalry task when observers (a) reported what they\nperceived or (b) passively experienced rivalry.\nFrom Frässle et al. (2014).\nKEY TERM\nBackward masking\nSuppression of the\nprocessing (and conscious\nperception of) a stimulus\nby presenting a second,\nmasking stimulus very\nshortly thereafter.\nCreated from usyd on 2022-02-17 03:28:58.",
    "782\nBroadening horizons\ninvolves blocking the processing and perception of a stimulus by following\nit rapidly with a second, masking stimulus. Alternatively, we can use tran-\nscranial magnetic TMS (see Glossary). TMS can be applied to early visual\ncortex to disrupt recurrent processing but not the feedforward sweep.\nFinally, we can study brain activation in brain-damaged patients with\nlimited or no conscious awareness.\nKoivisto et al. (2011) used TMS to disrupt recurrent processing while\nobservers decided whether natural scenes contained animals. As predicted,\nconscious visual perception was impaired. This finding suggests conscious\nvisual perception partly depends on recurrent processing.\nBoly et al. (2011) found feedforward processes were comparable in\nvegetative state patients, minimally conscious patients and healthy controls\nwhen presented with expected and unexpected tones. However, only the\nvegetative state patients had impaired top-down connectivity from frontal\nto temporal areas indicative of reduced recurrent processing. These  findings\nare consistent with other research on vegetative state patients (discussed\nearlier).\nFigure 16.7\nThree successive stages of visual processing following stimulus presentation. Feedforward processing is shown by green\nlines and recurrent processing by red lines. See text for a full account.\nFrom Lamme (2018).\naction\nconfict\ncontrol\nface\nobject\nShape\nmotion\ndepth\ncolour\ngist\nFeedforward sweep: unconscious\n(a)\naction\nconfict\ncontrol\nface\nobject\nshape\nmotion\ndepth\ncolour\ngist\nGlobal ignition: A-conscious\n(c)\nt = 436 ms\nfrontoparietal\nP300–400\n2 x10–8\n1\n0\n–200 0 200400 600\nx10–8\n0.5\n1.0\n0\n–200 0 200\ninferior frontal\n400 600\naction\nconfict\ncontrol\nface\nobject\nshape\nmotion\ndepth\ncolour\ngist\nRecurrent processing: P-conscious\n(b)\nVAN\nGround\nFigure\nV1 ConMod\nfMRI PPI\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n783\nKoivisto et al. (2014) presented photo-\ngraphs briefly followed by backward masking\nto prevent recurrent processing. Accurate cat-\negorisation of photographs as showing or not\nshowing animals was comparable with and\nwithout masking (86% vs 88%, respectively).\nHowever, participants reported less conscious\nawareness of what was shown on each pho-\ntograph under masked conditions (see Figure\n16.8). These findings suggest conscious visual\nperception can occur without recurrent pro-\ncessing with easy visual tasks. Similar findings\nalso using backward masking were reported\nby Koivisto and Rientamo (2016).\nRecurrent processing is not always asso-\nciated with conscious awareness. Observers\ndetecting white vowels in a stream of black\nand white letters were occasionally presented\nwith unexpected square figures (Scholte et al.,\n2006). These figures produced recurrent pro-\ncessing but 50% of observers did not perceive\nthem consciously. The figures were consistently\nseen only when there was widespread  recurrent\nprocessing. Thus, conscious awareness can be\nlacking when inattention to unexpected stimuli\nis combined with limited recurrent processing.\nIn sum, conscious visual perception is typically associated with the\noccurrence of recurrent processing, whereas feedforward processing\nwithout recurrent processing generally does not lead to conscious percep-\ntion. Recurrent processing may play an important role in producing the\nwidespread integrated activity across the brain strongly associated with\nconscious awareness (discussed further below). However, simple visual\ndiscrimination (e.g., animal vs non-animal) can occur without recurrent\nprocessing, and recurrent processing of unattended stimuli is not always\nassociated with conscious experience. Thus, there is not a direct one-to-one\nrelationship between conscious awareness and recurrent processing.\nGLOBAL WORKSPACE AND GLOBAL NEURONAL\nWORKSPACE THEORIES\nMany theories of consciousness have been put forward. Here we will focus\non a theoretical approach that successfully relates cognitive factors to neu-\nroscience. Global workspace theory was proposed by Baars (1988) and a\nsimilar global neuronal workspace theory was developed by Dehaene and\nChangeux (2011). Initially, global workspace theory emphasised behav-\nioural data whereas global neuronal workspace theory focused more on\nidentifying the main brain areas associated with conscious awareness.\nHowever, Baars et al. (2013) expanded global workspace theory by con-\nsidering the role of the cortex and thalamus in conscious experience. Both\nversions of global workspace theory have been highly influential.\nFigure 16.8\nPercentage of trials on which participants reported awareness\nof the content of photographs under masked and unmasked\nconditions for animal and non-animal (e.g., landscapes;\nvehicles) photographs.\nFrom Koivisto et al. (2014). © Massachusetts Institute of Technology, by\npermission of the MIT Press.\nCreated from usyd on 2022-02-17 03:28:58.",
    "784\nBroadening horizons\nHere we focus on the main common assumptions of the two theories.\nFirst, it is argued early stimulus processing involves numerous special-\npurpose unconscious processors operating in parallel. These processors are\ndistributed across numerous brain areas with each processor carrying out a\nspecialised function (e.g., colour or motion processing; see Chapter 2). This\nearly unconscious processing should be very similar regardless of whether a\nstimulus is subsequently consciously perceived.\nSecond, it is assumed consciousness is associated with integrating infor-\nmation from these special-purpose processors relatively late in processing.\nMore specifically, a combination of bottom-up processing and top-down\ncontrol produces “ignition” leading to synchronised activity across large\nareas of the brain. This makes information globally available and corre-\nsponds to conscious experience.\nThird, it is assumed the brain areas associated with consciousness\nvary as a function of the content of conscious experience (e.g., visual areas\nwith awareness of visual but not auditory stimuli). However, some brain\nareas are consistently activated during conscious awareness. For example,\nDehaene and Changeux (2011, p. 210) emphasised the role of “prefrontal,\ncingulate, and parietal regions” in conscious experience.\nFourth, it is assumed conscious awareness is typically determined by\nprior selective attention. Consider a sentence such as “I look in order to\nsee”. The word look refers to attention whereas the word see refers to\nconsciousness. In other words, attention resembles choosing a television\nchannel and consciousness resembles what is presented on the screen.\nThere are several other views concerning the relationship between\nattention and conscious awareness. Webb and Graziano (2015) identified\nfive different hypotheses about that relationship (see Figure 16.9). The\nglobal (neuronal) workspace theoretical approach is most like (C). Webb\nand Graziano favoured hypothesis (E). According to this hypothesis, there\ncan be attention with or without awareness. In the latter case, however,\nattention is under less control. Note that it is assumed within Lamme’s\n(2018) recurrent processing theory (discussed earlier, pp. 781–783), that\nconscious perception can occur in the absence of prior attention. More\nspecifically, phenomenal consciousness can occur without prior attention,\nbut access consciousness typically requires prior attention (see Figure 16.7).\nIntegrated information theory\nTononi (e.g., Tononi et al., 2016) proposed an integrated information\ntheory. The theory starts with the key features of conscious experience. It\nthen makes assumptions about the characteristics of the brain substrate\nrequired to support such experience. It is assumed conscious experience\nincludes the following features: (1) intrinsic existence (accessible only to\noneself); (2) composition (it has structure); (3) specificity (different from\nother experiences); and (4) unitary (content is integrated within a unitary\nconsciousness). These key features of conscious experience mean it is typi-\ncally very rich and informative.\nWhat is the relationship between conscious experience and the underly-\ning neural substrate? According to integrated information theory, the brain\nprocesses associated with conscious experience are often extraordinarily\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n785\ncomplex. As a consequence, it is impossible for us (with our limited pro-\ncessing capacity) to access all the information associated with those brain\nprocesses.\nIn sum, integrated information theory has clarified the main features\nof conscious experience. Of most relevance here, the theory assumes the\nrichness of conscious experience depends crucially on integrated activa-\ntion within large brain networks. This assumption is entirely consistent\nwith global workspace theory (although the theories differ in many other\nways). Note that the findings discussed below all relate to global work-\nspace theory although some are also of relevance to integration informa-\ntion theory.\nFindings: early processing\nThe first theoretical assumption is that early stimulus processing is\nun affected by whether or not an object is subsequently consciously\nFigure 16.9\n(a) Awareness and attention\nare the same thing;\n(b) awareness precedes\nattention; (c) attention\nprecedes awareness;\n(d) awareness and attention\nare independent processes;\n(e) attention is possible\nwithout awareness, but is\nunder less control.\nFrom Webb and Graziano\n(2015).\n(a)\n(b)\n(c)\n(d)\n(e)\nAwareness\n=\nAttention\nAwareness\nAttention\nAwareness\nAwareness\nAttention\nAttention\nAttention\nAwareness\nCreated from usyd on 2022-02-17 03:28:58.",
    "786\nBroadening horizons\nperceived. Much research supports this assumption. For example, Lamy\net al. (2009) asked observers to indicate the location of a stimulus and indi-\ncate whether they had conscious awareness of its presence. Event-related\npotentials (ETPS; see Glossary) were recorded.\nThe amplitude of early ERP components was unaffected by whether or\nnot there was conscious awareness (see Figure 16.10). However, conscious\nawareness was associated with a late wave of activity (P3) between 400 and\n600 ms after stimulus onset. The bottom part of Figure 16.10 shows brain\npositivity was far more widespread in the presence (rather than absence) of\nconscious awareness.\nKoivisto and Grassini (2016) used more sensitive stimuli and analyses\nand found the N200 (180–280 ms) was greater on trials when there was\nconscious awareness. Their findings suggest the N200 is directly associated\nwith visual awareness whereas the P3 reflects additional conscious process-\ning following awareness.\nMelloni et al. (2011) argued the time taken for visual awareness to\noccur might be reduced if a stimulus is expected. As predicted, differences\nbetween the ERPs to seen and unseen stimuli started 100 ms earlier for\nexpected stimuli than unexpected ones. Of importance, the early stages\nof processing were very similar for seen and unseen stimuli regardless of\nwhether these stimuli were expected.\nFigure 16.10\nEvent-related potential\n(ERP) waveforms in the\naware-correct, unaware-\ncorrect and unaware-\nincorrect conditions. The\ngreatest differences among\nthe conditions occurred for\nthe P3 component (shown\nin light grey). In the bottom\npart of the figure, the\nextent of brain positivity\nin the three conditions is\nshown in red.\nFrom Lamy et al. (2009). ©\nMassachusetts Institute of\nTechnology, by permission of\nthe MIT Press.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n787\nFindings: integrated brain functioning\nAs we have seen, several theorists assume integrated brain functioning is\ncrucial to conscious awareness. This assumption makes much sense given\nthat what we are consciously aware of is nearly always integrated infor-\nmation. For example, it is almost impossible to perceive an object while\nignoring its colour.\nMelloni et al. (2007) tested the above assumption. They presented\nwords that were hard to perceive and compared brain activity for those that\nwere or were not consciously perceived. Only consciously perceived words\nproduced synchronised (or integrated) neural activity involving frontal,\nparietal and occipital areas, especially between 40 and 182 ms (see\nFigure 16.11).\nKing et al. (2013b) used electroencephalography (EEG; see Glossary)\nto assess integrated brain functioning in response to auditory stimuli\nusing a measure known as weighted symbolic mutual information\n(wSMI). The four groups of participants had varying levels of conscious\nawareness:\n(1) patients in a vegetative state (no conscious awareness; see earlier in the\nchapter, p. 778);\n(2) minimally conscious state patients;\n(3) conscious patients with brain damage (often recovering from a vege-\ntative state or state of minimal consciousness);\n(4) healthy participants.\nFigure 16.11\nSynchronisation of neural activity across cortical areas (shown by connecting lines) for\nconsciously perceived words (visible condition) and non-perceived words (invisible\ncondition) during different time periods. 0 ms = stimulus onset.\nFrom Melloni et al. (2007). Republished with permission of The Society for Neuroscience. Permission\nCreated from usyd on 2022-02-17 03:28:58.",
    "788\nBroadening horizons\nWhat did King et al. (2013b) find? There were dramatic differences\nin the extent of integrated brain activity across these four groups (see\nFigure 16.12). As predicted, there was much more integrated brain activity\nin those groups having high levels of conscious awareness.\nResearch on anaesthesia-induced unconsciousness has produced\nsimilar findings to those obtained with brain-damaged patients (Mashour\n& Hudetz, 2018). For example, Randt et al. (2016) found that the anaes-\nthetic sevoflurane reduced connectivity within higher-level frontal networks\nbut not low-level sensory networks. There is evidence that disrupted infor-\nmation transfer at hubs (highly connected regions within prefrontal cortex)\nis especially important in unconsciousness produced by anaesthesia or\nbrain damage (Mashour & Hudetz).\nThe findings discussed in this section are clearly consistent with the\nglobal workspace and integrated information theories. However, there is a\ntricky issue concerning causality. Synchronised neural activity may directly\nreflect conscious awareness. However, it is also possible synchronised neural\nactivity precedes and influences conscious awareness or that it occurs merely\nas a consequence of conscious awareness (de Graaf et al., 2012).\nFindings: key brain areas (e.g., prefrontal cortex)\nThere is much support for the assumption the prefrontal cortex and related\nareas are especially likely to be associated with conscious awareness. For\nexample, Neghavi and Nyberg (2005) argued similar brain areas are asso-\nciated with consciousness, attention and working memory. They reported\nFigure 16.12\n(a) Overall information sharing or integration across the brain for vegetative state, minimally conscious and conscious\nbrain-damaged patients and healthy controls (blue = low integration; red/brown = high integration). (b) Information\nsharing (integration) across short, medium and long distances within the brain for the four groups.\nFrom King et al. (2013b). Reprinted with permission from Elsevier.\nInteractive feature:\nPrimal Pictures’ 3D atlas of\nthe brain\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n789\noverlaps among these functions were greatest in dorsolateral prefrontal\ncortex (BA6 and BA9) and parietal cortex (BA and BA40). These areas\nrepresent the fronto-parietal network often assumed to be of major impor-\ntance to attention and consciousness.\nGaillard et al. (2009) studied event-related potentials in response to\nvisual stimuli that were or were not consciously perceived. They used epi-\nleptic patients and so had the rare opportunity to record ERPs directly\nfrom the brain with electrodes implanted in the brain (rather than scalp\nelectrodes). Conscious awareness (from about 350 ms after stimulus pres-\nentation) was associated with much larger effects on activation in the\nfrontal cortex than any other brain region.\nThe above findings are correlational, and do not show activation of the\nprefrontal cortex is causally related to conscious awareness. For example,\nthe findings may indicate prefrontal processes are involved in attention\nas well as conscious awareness. One approach to this causality issue is\nto study brain-damaged patients. Del Cul et al. (2009) studied patients\nwith damage to the prefrontal cortex. It was harder for these patients to\nperceive a masked number than healthy controls, and the magnitude of\nthis effect was greater in patients having the most damage to prefrontal\ncortex.\nAnother approach to the causality issue is to apply transcranial mag-\nnetic stimulation (TMS) to prefrontal cortex to inhibit its functioning.\nRounis et al. (2010) found disrupting prefrontal processing via TMS made\nparticipants less aware of the quality of their information processing.\nKoch et al. (2016) argued the role of prefrontal cortex (or the\nfronto-parietal network) in conscious awareness has been exaggerated. For\nexample, Markowitsch and Kessler (2000, p. 94) studied a young female\npatient with “severe degeneration of the prefrontal cortex”. In spite of\nthat, the patient showed essentially intact conscious awareness.\nGoldberg et al. (2006) presented participants with pictures and audio\nclips. In one condition, they self-introspected about their emotional reac-\ntions to the stimuli; in a second condition, they categorised the stimuli\n(e.g., animal vs non-animal). Different brain regions were activated for\neach task. Of most relevance here, the prefrontal cortex was less important\nwhen stimuli were categorised than when conscious awareness involved\nself-related processes.\nVarious findings suggest visual awareness is associated with numerous\nbrain regions in addition to the prefrontal cortex and parietal regions.\nBisenius et al. (2015, p. 177) carried out a meta-analysis and concluded:\n“[There is] a subcortical-extrastriate-fronto-parietal network rather than a\nsingle region that constitutes the necessary NCC [neural correlates of con-\nsciousness].” Several frontal areas formed part of that extensive network.\nEvidence indicating the prefrontal cortex can be activated during\nunconscious as well as conscious processing was reported by van Gaal et al.\n(2010). Participants were instructed to inhibit responses to a visible stimu-\nlus when preceded by a white square. When this square was visible, partic-\nipants showed good inhibitory control associated with extensive prefrontal\nactivation. Of greater theoretical importance, participants responded more\nslowly and had some activation in the inferior frontal cortex when the\nsquare was presented subliminally.\nCreated from usyd on 2022-02-17 03:28:58.",
    "790\nBroadening horizons\nFindings: attention and consciousness\nWe turn now to the theoretical assumption that consciousness depends on\nprior selective attention. That probably sounds reasonable to you. However,\nseveral theorists have disagreed with that assumption. For example, Koch\nand Tsuchiya (2012) argued attention without consciousness and conscious-\nness without attention are both possible. As mentioned earlier, it is assumed\nwithin recurrent processing theory (Lamme, 2018) that conscious awareness\ncan occur without prior attention.\nAttention can influence behaviour in the absence of conscious aware-\nness. For example, Jiang et al. (2006) presented pictures of male and female\nnudes subliminally. Each trial was followed immediately by a task with\nvisible stimuli to assess direction of attention while the nudes were pre-\nsented. The invisible nude pictures influenced participants’ attentional pro-\ncesses. Heterosexual males attended to subliminal female nudes whereas\nheterosexual females attended to subliminal male nudes.\nHow can unseen emotional stimuli influence attention? Troiani et al.\n(2014) discovered that subliminal fearful faces produced increased amyg-\ndala activation (associated with emotional processing). This activation in\nturn was associated with activation of brain areas formed an attentional\nnetwork.\nThe assumption within the global workspace approach that conscious\nawareness is always preceded by attention has proved controversial (Pitts\net al., 2018, 2019). Of relevance are change blindness and inattentional\nblindness (see Glossary; see Chapter 4). These phenomena suggest that\nnovel objects (or changes to objects) within a visual scene are rarely (if\never) detected consciously in the absence of attention. However, it has\nbeen claimed various other phenomena show conscious awareness in the\nabsence of attention. Three are discussed below: (1) natural-scene percep-\ntion; (2) visual pop-out; and (3) iconic memory.\nWe seem to perceive the gist of natural scenes without attention.\nHowever, that may be illusory. In a study by Cohen et al. (2011), observ-\ners saw rapidly presented digits and letters against changing chessboard\nmasks and counted the number of digits. Unexpectedly, a natural scene\ncontaining an animal or vehicle replaced a mask. Only 23% of the partici-\npants could immediately identify the object in the scene and 50% reported\nno conscious perception of it. In contrast, when participants attended to\nthe background, they classified the natural scenes accurately 93% of the\ntime. Thus, attention seems necessary to have conscious perception of the\ngist of natural scenes.\nVisual pop-out occurs when a target stimulus is detected rapidly when\nit differs in some obvious way (e.g., colour; orientation) from surround-\ning distractor stimuli. It has often been assumed attention is not required\nto detect such target stimuli. However, Cohen et al. (2012) reviewed the\nevidence and concluded the pop-out effect typically fails to occur when\nobservers’ attention is focused on another task.\nFinally, we turn to iconic memory (very brief storage of visual infor-\nmation following stimulus offset; see Glossary) which is often assessed\nusing the Sperling (1960) task discussed earlier (p. 776). Iconic memory\nhas been assumed to be attention-free (see Chapter 6). This assumption\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n791\nwas challenged by Mack et al. (2016). Participants were presented with\nletters in the centre of a visual array (iconic memory task) and four circles\nsurrounding the letters (the task involved deciding whether all circles were\nthe same colour) but were only required to perform one task on each\ntrial.\nMack et al. (2016) found performance on the iconic memory task was\nmuch worse when the probability of having to perform it was only 10%\nrather than 90%. This happened because there was much less attention to\nthe letters in the former condition. Most strikingly, most participants failed\nto note that all the letters had been removed from the screen when their\nattention was strongly focused on the circle task. These findings indicate\nthat conscious awareness of information in iconic memory depends on\nprior attention.\nIn sum, most of the available evidence suggests consciousness depends\non prior attention (Pitts et al., 2018, 2019). However, this conclusion is\ndisputed (e.g., Lamme, 2018). Agreement will be hard to achieve given the\nvarying definitions of the terms “attention” and “consciousness” used by\ndifferent researchers.\nOverall evaluation\nThere is support for all the major assumptions of the global workspace\napproach. First, early processing of seen stimuli typically does not differ\nfrom that of unseen ones in patterns of brain activity during the first 200 ms\nor 300 ms after stimulus onset.\nSecond, conscious awareness is generally associated with widespread\nintegrated or synchronised brain activity. This integrated brain activity gen-\nerally (but not invariably) includes prefrontal cortex and parietal regions,\nand often the anterior cingulate. As predicted theoretically, anaesthetics\ninducing unconsciousness produce greatly impaired functional connectiv-\nity within prefrontal networks, and patients with limited or no conscious\nawareness have considerably less integrated brain activity than healthy\ncontrols (King et al., 2013b). Of importance, research on patients with dis-\norders of consciousness (e.g., vegetative state patients) indicates that recov-\nery of consciousness is typically associated with enhanced integrated brain\nactivity (Bodien et al., 2017).\nThird, the assumption that brain regions associated with conscious\nawareness reflect the content of such awareness has received support. For\nexample, Eriksson et al. (2006) found that conscious awareness of pictures\nof objects was associated with activation in visual areas whereas conscious\nawareness of object sounds was associated with activation in auditory\nareas.\nFourth, most evidence supports the assumption that conscious aware-\nness is always (or nearly always) preceded by selective attention (Pitts\net al., 2018). However, there may sometimes be rather limited conscious\nawareness of objects in the absence of prior selective attention. In addi-\ntion, the relationship between attention and conscious awareness is more\ncomplex than assumed theoretically. As well as effects of attention on con-\nscious awareness, there are effects in the opposite direction (e.g., Webb\net al., 2016b): conscious awareness increases attentional control.\nCreated from usyd on 2022-02-17 03:28:58.",
    "792\nBroadening horizons\nWhat are the limitations of the global workspace approach? First,\nits emphasis is on the neural correlates of conscious visual perception.\nDemertzi et al. (2013) drew a distinction between external awareness\n(awareness of the environment) and internal awareness (self-relevant think-\ning). External awareness is associated with activity in the dorsolateral\nprefrontal cortex and posterior parietal regions. In contrast (and not con-\nsidered by the global workspace approach), internal awareness is associ-\nated with activity in the posterior cingulate cortex, anterior cingulate and\nmedial prefrontal cortex.\nSecond, the assumption that prefrontal cortex plays a major role in\nconscious experience has attracted much research support. However, there\nare findings suggesting its role may have been exaggerated (Boly et  al.,\n2017).\nThird, much of the integrated brain functioning associated with\nconscious awareness is not necessarily the neural substrate of conscious\nawareness. Other possibilities are that integrated brain functioning is a pre-\nrequisite or consequence of conscious experience (de Graaf et al., 2012).\nFor example, prefrontal activation may reflect selective attention preceding\nconscious awareness.\nFourth, identifying the brain areas and patterns of brain activity\nassociated with conscious awareness is of value. However, this focus on\ncognitive neuroscience has led to a relative neglect of the associated psy-\nchological processes.\nFifth, there are complexities in interpreting the findings from studies\nof anaesthesia-induced unconsciousness and unconsciousness in brain-\ndamaged patients. For example, it is typically assumed in both cases that\nimpaired integrated brain activity reflects loss of consciousness. However,\nit may also depend in part on loss of attentional processes (Mashour &\nHudetz, 2018).\nIS CONSCIOUSNESS UNITARY?\nMost people assume they have a single, unitary consciousness although\na few are in two minds on the matter. This issue became controversial\nbecause of research on split-brain patients, who have few connections\nbetween the two brain hemispheres following surgery. In most cases, the\ncorpus callosum (bridge) between the two brain hemispheres was cut surgi-\ncally to contain epileptic seizures within one hemisphere. This structure is a\ncollection of 250 million axons connecting the two hemispheres.\nThe dramatic reduction in structural connectivity between the hemi-\nspheres in split-brain patients does not always produce an equivalent reduc-\ntion in functional connectivity (Uddin, 2013). Tyszka et al. (2011) studied\npatients lacking a corpus callosum because of developmental abnormali-\nties. Surprisingly, the patients had largely normal functional networks in\nboth hemispheres, probably because their brains had undergone extensive\nfunctional reorganisation early in life. Thus, they may differ importantly\nfrom patients lacking a corpus callosum due to surgery in adult life.\nIt was not realised initially that cutting the corpus callosum caused\nsignificant problems. The reason is that split-brain patients ensure environ-\nmental information reaches both hemispheres by moving their eyes around.\nKEY TERM\nSplit-brain patients\nPatients in whom most of\nthe direct links between\nthe two hemispheres\nof the brain have been\nsevered.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n793\nSplit-brain patients also use cross-cueing: one hemisphere supplies infor-\nmation to the other (Volz & Gazzaniga, 2017). For example, a patient, VP,\nwas presented with break to the right hemisphere and fast to the left hem-\nisphere. She started to say “bre-” as in brake, but then instantly corrected\nherself, saying “breck”. The left hemisphere used the auditory input from\nthe right hemisphere to produce the correct pronunciation.\nSplit-brain patients typically have intact verbal IQ and problem-\nsolving abilities. They also have the “illusion of unity”: “They report that\nthey experience a single consciousness” (Volz & Gazzaniga, 2017, p. 2059).\nHowever, split-brain patients exhibit impaired laboratory performance\nwhen visual stimuli are presented briefly to one hemisphere, so the infor-\nmation is unavailable to the other hemisphere.\nDo split-brain patients have two minds, each with its own conscious-\nness? Many psychologists subscribe to that viewpoint. Sperry (1968, p. 723)\nargued as follows: “The minor hemisphere [the right one] constitutes a\nsecond conscious entity that . . . runs along in parallel with the more dom-\ninant stream of consciousness in the major hemisphere [the left one]”. He\nregarded the left hemisphere as dominant because language processing is\ntypically centred there.\nTononi et al. (2016) argued in their integrated information theory\n(discussed earlier, pp. 784–785), that the physical basis of consciousness\ninvolves integrated or synchronised brain activity across relatively large\nbrain areas. When there is little connectivity between the two brain hem-\nispheres (as with split-brain patients), there are two separate regions of\nintegrated brain activity with the larger region in the left hemisphere.\nBayne (2010) agreed in his switch model that consciousness can occur\nin both hemispheres. However, he argued a single stream of consciousness\nswitches between the hemispheres. Which hemisphere experiences con-\nsciousness depends on the allocation of attentional resources. The switch\nmodel can also explain why there are relatively few disagreements between\nthe two hemispheres.\nHowever, there are considerable doubts whether split-brain patients have\na truly single stream of consciousness. One reason is because most experi-\nments are designed to ensure each hemisphere has access to (and processes)\ndifferent information. It is more likely patients have two distinct streams of\nactivity even if only one is accessible to consciousness at any given moment\n(Schechter, 2012). Another problem with the switch model is that split-brain\npatients would “experience radical and sudden changes in the character and\ncontent of their streams of consciousness” (Friesen, 2013, p. 96).\nGazzaniga argued that the major conscious system (the interpreter)\nis based in the left hemisphere (dominant for language). According to\nMarinsek and Gazzaniga (2016, p. 157), “Even though the left hemisphere\ndoes not have access to the information presented to the right hemi-\nsphere  . . . the interpreter will often provide an explanation for the right\nhemisphere’s behaviour.”\nFindings\nIt is relevant to consider the right hemisphere’s abilities in patients follow-\ning hemispherectomy – a procedure involving removal of an entire cerebral\nKEY TERM\nCross-cueing\nThe (often subtle)\ncommunication of\ninformation from one\nhemisphere to the other\nin split-brain patients.\nHemispherectomy\na radical surgical\nprocedure in which one of\nthe cerebral hemispheres\nis destroyed and\nremoved.\nCreated from usyd on 2022-02-17 03:28:58.",
    "794\nBroadening horizons\nhemisphere. Nearly all such patients have conscious experience following\nleft hemispherectomy (Blackmon, 2016).\nPatients following left hemispherectomy exhibit considerable plasticity –\nthe remaining hemisphere reorganises to reduce the adverse effects of\nremoval of the other hemisphere. If hemispherectomy of the left hemisphere\noccurs when the patient is a young child, there is typically good language\ndevelopment (de Bode et al., 2015). BL, a patient who had a left hemi-\nspherectomy at the age of five, had above-average intelligence (Vanlancker-\nSidtis, 2004). Of major importance, there is typically “widespread [brain]\nrewiring” (Sebastianelli et al., 2017, p. 1427) following hemispherectomy.\nAdditional evidence has been obtained from the Wada test – this\ninvolves injecting sodium amobarbital to anaesthetise one cerebral hemi-\nsphere. Meador et al. (1997) found basic aspects of consciousness seemed\nunaltered in 28% of patients when their left hemisphere was anaesthe-\ntised and in 41% of the same patients when their right hemisphere was\nanaesthetised.\nBefore proceeding, note that information from the left visual field goes\nto the right hemisphere and information from the right visual field goes\nto the left hemisphere (see Chapter 2). More generally, the left half of the\nbody is controlled by the right hemisphere and the right half by the left\nhemisphere. Note also that the typically limited language ability of the\nright hemisphere makes it hard to establish whether it has its own con-\nsciousness in split-brain patients.\nTwo streams\nWhat evidence supports Sperry’s view that split-brain patients have two\nstreams of consciousness? On that view, we might expect to find disagree-\nments between the two hemispheres. Such disagreements have been reported\noccasionally. Mark (1996, p. 191) discussed a patient having speech in both\nhemispheres: “She mentioned she did not have feelings in her left hand.\nWhen I echoed the statement, she said that she was not numb, and then the\ntorrent of alternating ‘Yes!’ and ‘No!’ replies ensued, followed by a despair-\ning, ‘I don’t know!’”.\nBaynes and Gazzaniga (2000) studied a female split-brain patient (VJ),\nwhose writing was controlled by the right hemisphere but whose speech\nwas controlled by the left hemisphere. According to Baynes and Gazzaniga\n(p. 1362), “She [VJ] is discomfited by the fluent writing of her left hand to\nunseen stimuli”, which is suggestive of limited dual consciousness.\nMore evidence the two hemispheres of split-brain patients can function\nsimultaneously and independently was reported by Schiffer et al. (1998).\nPatients with their hands hidden from view behind a screen responded at\nthe same time with each hand to emotionally sensitive questions. The right\nhemisphere produced more emotional answers.\nThe ability to recognise one’s own face generally indicates reasonable\nself-awareness. However, patients with face blindness or prosopagnosia (see\nGlossary) often fail to recognise their own face despite good self-awareness.\nUddin et al. (2005) found NG, a split-brain patient, recognised her own\nface equally well with each hemisphere. This suggests both hemispheres\nhave basic self-awareness.\nKEY TERMS\nPlasticity\nChanges within the brain\noccurring as a result\nof brain damage or\nexperience.\nWada test\nA procedure in which one\ncerebral hemisphere is\nanaesthetised.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n795\nOne dominant stream\nGazzaniga (e.g., 2013) emphasised the importance of a stream of conscious-\nness (the interpreter) centred in the dominant left hemisphere. This view-\npoint is supported by the following observation: “No split-brain patient has\never woken up following callostomy [cutting of the corpus callosum] and felt\nas though his/her experience of self had fundamentally changed or that two\nselves now inhabited the same body” (Colvin & Gazzaniga, 2007, p. 189).\nThis observation also provides evidence against the notion that split-brain\npatients experience consciousness simultaneously in both hemispheres.\nGazzaniga and Ledoux (1978) studied Paul S, a split-brain patient. He\nhad unusually well-developed right-hemisphere language abilities making\nit easier to establish whether he had a separate consciousness in his right\nhemisphere. He showed some evidence of right-hemisphere consciousness\nby responding appropriately to questions using Scrabble letters with his\nleft hand. For example, he could spell his own name, that of his girlfriend,\nhis hobbies, his current mood and so on. There were some interesting dif-\nferences between Paul’s hemispheres. For example, his right hemisphere\nsaid he wanted to be a racing driver, whereas his left hemisphere wanted\nto be a draughtsman!\nGazzaniga (1992, 2013) discussed other studies on Paul S. He was pre-\nsented with a chicken claw to his left hemisphere and a snow scene to his\nright hemisphere. When asked to select relevant pictures from an array, he\nchose a chicken with his right hand (connected to the left hemisphere) and\na shovel with his left hand (connected to the right hemisphere).\nThe above findings may suggest Paul S had two separate conscious-\nnesses. However, here is how he explained his choices: “The chicken claw\ngoes with the chicken and you need a shovel to clean out the chicken shed”\n(Gazzaniga, 1992, p. 124). Thus, Paul S’s left hemisphere was interpret-\ning behaviour initiated by the right hemisphere with little right-hemisphere\ncontribution. Similarly, PS obeyed when his right hemisphere was given\nthe command to walk. However, his left hemisphere explained his behav-\niour by saying something such as that he wanted a Coke.\nVerleger et al. (2011) studied a male patient (GH) with anarchic-hand\nsyndrome. This is a condition where one hand (the left in GH’s case)\nsometimes counteracts the other (e.g., GH put money on a shop counter\nwith his right hand, but his left hand took it back). GH was slower and less\naccurate when responding to stimuli presented to his right hemisphere (and\nso requiring a left-hand response) suggesting he had “lost control over his\nright hemisphere” (p. 138).\nVerleger et al. (2011) found the P3 component of the event-related\npotential was much smaller to stimuli presented to GH’s right hemisphere.\nThis suggests his ability to attend to stimuli and control processing was\nmuch less in that hemisphere. Of relevance, GH’s experiences in everyday\nlife strongly suggested his consciousness resided within his left hemisphere.\nHesselmann et al. (2013) reported similar findings in a male patient\n(AC) with severe damage to his corpus callosum. Two stimuli (one to each\nhemisphere) were presented 100, 300 or 800 ms apart with instructions to\nrespond rapidly to both stimuli. We will focus on the ERP responses to the\nfirst stimulus. AC had a pronounced P3 component (reflecting attention\nKEY TERM\nAnarchic-hand syndrome\nComplex, goal-directed\nhand movements the\npatient does not initiate\nvoluntarily and cannot\ninterpret.\nCreated from usyd on 2022-02-17 03:28:58.",
    "796\nBroadening horizons\nand stimulus appraisal) to left-hemisphere stimuli but no P3 component to\nright-hemisphere stimuli (see Figure 16.13). These findings suggest AC had\nmuch greater conscious access to information about stimuli presented to\nthe left hemisphere.\nSummary and evaluation\nResearch has not fully resolved the issue of whether it is possible to have\ntwo separate consciousnesses. The commonest view is that split-brain\npatients have conscious experience in both hemispheres with the left hemi-\nsphere playing the dominant role. This occurs because language processing\nis typically centred in the left hemisphere and because it is the location of\nthe interpreter or self-supervisory system. This view is supported by find-\nings showing the left hemisphere overruling the right hemisphere and by the\npersistent failure to observe genuine inter-hemispheric dialogue.\nFigure 16.13\nEvent-related potentials (ERPs) in the left hemisphere (left-hand figure) and the right hemisphere (right-hand figure) to\nthe first of two stimuli by AC (a patient with severe corpus callosum damage). The time course of the ERPs is shown on\nthe horizontal axis in seconds. The second stimulus was presented 100 ms (red line), 300 ms (green line) or 800 ms (blue\nline) after the first stimulus (SOA = stimulus onset asynchrony).\nFrom Hesselmann et al. (2013). Reprinted with permission from Elsevier.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n797\nIn contrast, the right hemisphere engages in various processing activi-\nties (e.g., basic self-awareness; emotional processing; aspects of visual and\ntouch perception). Consciousness within the right hemisphere is hard to\nassess fully because of its very limited language abilities. However, research\nusing event-related potentials supports the view there is much less con-\nscious awareness in the right hemisphere, a view supported by research\nusing the Wada test (see Glossary) on healthy individuals. However, the\nright hemisphere can develop impressive language and other abilities, and\nfull conscious awareness in the absence of the left hemisphere, especially if\nhemispherectomy occurs early in life.\nThe main limitation of research is that it is harder than might be\nthought to interpret many of the findings. We will consider a concrete\nexample. Pinto et al. (2017) studied two split-brain patients (DDV; DDC)\nwho had been operated on many years earlier. The patients decided whether\na circle had been presented briefly; if so, they indicated its location. They\nresponded using their left hand, their right hand or verbally. Note that the\nright hemisphere receives visual input from the left visual field and controls\nthe left hand. In contrast, the left hemisphere receives visual input from\nthe right visual field and controls the right hand and language processing.\nWhat would we predict? As Pinto et al. (2017) pointed out, the typical\nfinding is that split-brain patients only respond to left-field stimuli when\nusing their left hand and only respond to right-field stimuli when using\ntheir right hand or verbally. Such findings suggest such patients have a\nseparate consciousness in each hemisphere. In marked contrast, Pinto et\nal. found performance was very good for stimuli presented anywhere in the\nvisual field regardless of response type (see Figure 16.14). They concluded\nthat these patients show “unity of consciousness” (p. 1236).\nThere are two major interpretive problems with Pinto et al.’s (2017)\nfindings. First, the patients may have learned over the years to compen-\nsate for the lack of connections between the two hemispheres by means\nof cross-cueing (communication between the hemispheres). For example,\nFigure 16.14\nDetection and localisation\nof circles presented to\nleft visual field (LVF) or\nright visual field (RVF) by\ntwo patients (DDV; DDC)\nresponding verbally, with\nthe left hand or with the\nright hand.\nFrom Pinto et al. (2017).\nIndicate location\nPRESENT\nABSENT\nVerbal\nRight hand\nLocalise circles\nDDV\nDDC\nDetect circles\nDDV\nLVF\n1\n0\nFraction correct\nRVF\nLVF\nRVF\nDDC\nLeft hand\nLVF\n10\n0\nDistance error\nRVF\nLVF\nRVF\nCreated from usyd on 2022-02-17 03:28:58.",
    "798\nBroadening horizons\n“Subtle cues may be given by minimal movements of the eyes or facial\nmuscles, which . . . are capable of encoding . . . the location of a stimulus\nfor the hemisphere that did not see it” (Volz et al., 2018, p. 1). Second, the\npatients’ surprisingly good performance may reflect the involvement of a\nsubcortical system that connects the two hemispheres even in split-brain\npatients.\nCHAPTER SUMMARY\n•\nIntroduction. There is a distinction between conscious content\nand conscious level of consciousness. The notion of levels is\noversimplified because it implies different states of consciousness\nlie along a single dimension. There is another important distinction\nbetween phenomenal or basic consciousness and higher-level\nconsciousness (not restricted to the here-and-now).\n•\nFunctions of consciousness. The functions claimed for conscious\nawareness include perception, social communication, action\ncontrol, thinking beyond the here-and-now, and intensive\nintegration of information. The machinery used to compute\ninformation about other people’s awareness is also used to\ncompute information about our own awareness. Some behavioural\nevidence suggests perceived conscious control of action (sense\nof agency) is an illusion driven by the principles of priority,\nconsistency and exclusivity. However, this research mostly uses\nartificial situations. Cognitive neuroscience research suggests some\ndecision-relevant processing occurs prior to conscious awareness.\nHowever, the modest effects do not rule out a major role for\nconscious awareness.\n•\nAssessing consciousness and conscious experience. Our verbal\nreports of our conscious experience sometimes involve under-\nreporting because of our attentional and memory limitations.\nThese verbal reports can also involve over-reporting. For\nexample, visual perception is typically clear and distinct in spite\nof the deficiencies of peripheral vision because we use top-\ndown processes (e.g., expectations) to fill in the gaps in the\ninformation available to us. Patients in the vegetative state show\nno behavioural signs of consciousness. However, a few show\nevidence of conscious awareness based on neuroimaging data\nobtained while they respond to orders. Some vegetative state\npatients also show functional cortical connectivity in networks\nassociated with conscious awareness. There is evidence recurrent\nprocessing is typically required for conscious visual perception\nbecause it is associated with integrated processing within the\nbrain.\n•\nGlobal workspace and global neuronal workspace theories.\nAccording to global workspace theory, selective attention\nResearch activity:\nFrom intention to action\nCreated from usyd on 2022-02-17 03:28:58.",
    "Consciousness\n799\ninfluences the information of which we become consciously aware.\nAnother key assumption (also made by integrated information\ntheory) is that conscious awareness is associated with integrated,\nsynchronous activity preceded by parallel non-conscious\nprocessing in special-purpose processors. The activity associated\nwith consciousness involves many brain areas, especially the\nprefrontal cortex, the anterior cingulate and parts of the parietal\ncortex. There is reasonable support for all the major assumptions\nof global workspace theory. However, research focuses on\nconscious visual perception and de-emphasises consciousness\nbased on self-awareness and self-knowledge. Another issue is\nwhether integrated brain functioning is a prerequisite or merely a\nconsequence of conscious awareness. Finally, it has proved hard\nto disentangle the relationship between selective attention and\nconscious awareness.\n•\nIs consciousness unitary? Evidence from split-brain patients\nindicates they probably have separate consciousnesses in each\nhemisphere. However, the left hemisphere is dominant because\nlanguage is typically centred in that hemisphere and because it is\nthe site of an interpreter that makes sense of behaviour triggered\nby the right hemisphere. The limited language abilities of the\nright hemisphere make it hard to assess whether it is conscious.\nHowever, electrophysiological evidence from split-brain patients\nand the Wada test on healthy individuals indicate the right\nhemisphere has some conscious awareness. Interpreting findings\nfrom split-brain patients is complex.\nFURTHER READING\nBayne, T., Hohwy, J. & Owen, A.M. (2016). Are there levels of consciousness?\nTrends in Cognitive Sciences, 20, 405–413. Tim Bayne and colleagues discuss\nways of moving beyond simplistic accounts based on the notion of levels of\nconsciousness.\nDehaene, S. (2014). Consciousness and the Brain: Deciphering How the Brain Codes\nour Thoughts. New York: Viking Press. Stanislas Dehaene provides a detailed\nand authoritative account of consciousness from the perspective of cognitive\nneuroscience.\nHill, C.S. (2018). Unity of consciousness. Wiley Interdisciplinary Reviews – Cognitive\nScience, 9, e1465. Christopher Hill reviews theoretical views on the unity of con-\nsciousness with an emphasis on research involving split-brain patients.\nKondziella, D., Friberg, C.K., Frokjaer, V.G., Fabricius, M. & Møller, K. (2016).\nPreserved consciousness in vegetative and minimal conscious states: Systematic\nreview and meta-analysis. Journal of Neurology, Neurosurgery and Psychiatry, 87,\n485–492. The extent to which consciousness is present in patients in the minimal\nconscious state or vegetative state is evaluated in this meta-analytic review.\nPitts, M.A., Lutsyshyna, L.S. & Hillyard, S.A. (2018). The relationship between\nattention and consciousness: An expanded taxonomy and implications for\n“no-report” paradigms. Philosophical Transactions of the Royal Society B, 373\n(Article no. 21070348). Michael Pitts and colleagues compare two major theories\nCreated from usyd on 2022-02-17 03:28:58.",
    "800\nBroadening horizons\nof consciousness (global workspace theory and recurrent processing theory) in the\nlight of the relationship between attention and consciousness.\nTononi, G., Boly, M., Massimini, M. & Koch, C. (2016). Integrated information\ntheory: From consciousness to its physical substrate. Nature Reviews Neuroscience,\n17, 450–461. Giulio Tononi and his colleagues discuss their influential integrated\ninformation theory and the neural correlates of conscious experience.\nTroscianko, E. & Blackmore, S. (2018). Consciousness: An introduction (3rd edn).\nAbingdon, Oxon.: Routledge. Emily Troscianko and Susan Blackmore provide a\nvery readable account of all the main issues relating to consciousness.\nVolz, L.J. & Gazzaniga, M.S. (2017). Interaction in isolation: 50 years of insights\nfrom split-brain research. Brain, 140, 2051–2060. Lukas Voltz and Michael\nGazzaniga (a leading expert) discuss issues involved in trying to understand the\nconscious experience of split-brain patients.\nCreated from usyd on 2022-02-17 03:28:58.",
    "Glossary\naccess consciousness: a form of consciousness where its contents are avail-\nable for use by processes such as attention and memory; information\nwithin access consciousness can be communicated to others; see phe-\nnomenal consciousness.\naccommodation: a depth cue based on changes in optical power pro-\nduced by thickening of the eye’s lens when an observer focuses on close\nobjects.\nachromatopsia: a condition caused by brain damage in which there is very\nlimited colour perception, but form and motion perception are rela-\ntively intact.\nad hominem fallacy: discrediting an argument by attacking the person\nmaking the argument.\naffect: a general term referring to evaluative (positive or negative) reac-\ntions; it encompasses mood and emotion.\naffect heuristic: using one’s emotional responses to influence rapid judge-\nments or decisions.\naffective blindsight: the ability of brain-damaged patients to discriminate\namong different emotional stimuli in spite of the absence of conscious\nperception of those stimuli.\naffordances: the potential uses of an object, which Gibson claimed are per-\nceived directly.\nagrammatism: literally, “without grammar”; a condition in which speech\nproduction lacks grammatical structure and many function words and\nword endings are omitted; there are often also problems with language\ncomprehension.\nakinetopsia: a brain-damaged condition in which motion perception is\nseverely impaired even though stationary objects are perceived reason-\nably well.\nalgorithm: a computational procedure providing a specified set of steps to\nproblem solution; see heuristic.\nallocentric coding: visual or spatial coding of objects relative to each other;\nsee egocentric coding.\nallophones: variant forms of a given phoneme; for example, the phoneme\n/p/ is associated with various allophones (e.g., in pit and spit).\nAlzheimer’s disease: a disease in which general deterioration of the brain\nleads to progressive mental degeneration.\nCreated from usyd on 2022-02-18 03:51:20.",
    "802\nGlossary\namblyopia: a condition in which one eye sends an inadequate input to the\nvisual cortex; colloquially known as lazy eye.\nAmes room: a very distorted room that nevertheless looks normal under\ncertain viewing conditions.\namnesia: a condition caused by brain damage in which there is severe\nimpairment of long-term memory (mostly declarative memory).\namygdala: a small almond-shaped subcortical structure towards the front\nof the temporal lobe strongly associated with several emotions includ-\ning fear.\nanalogy: a comparison between two objects (or between a current and pre-\nvious problem) that emphasises similarities between them.\nanaphor: a word or phrase that refers back to a previous word or phrase\n(e.g., a pronoun may refer back to a given individual mentioned earlier).\nanarchic-hand syndrome: complex, goal-directed hand movements the\npatient does not initiate voluntarily and cannot interpret.\nanchoring-and-adjustment heuristic: when someone makes an initial esti-\nmate (the anchor) and then adjusts it to produce a final estimate, the\nadjustment is generally insufficient.\nanomia: a condition caused by brain damage in which there is an impaired\nability to name objects.\nanterior: towards the front of the brain.\nanterograde amnesia: reduced capacity for new learning (and subsequent\nremembering) after the onset of amnesia.\nAnton’s syndrome: a condition found in some blind people in which they\nmisinterpret their visual imagery as visual perception.\naphantasia: the inability to form mental images of objects when those\nobjects are not present.\naphasia: severe problems in the comprehension and/or production of lan-\nguage caused by brain damage.\napraxia: a condition caused by brain damage in which there is greatly\nreduced ability to perform purposeful or planned bodily movements in\nspite of the absence of muscular damage.\narticulatory suppression: Rapid repetition of a simple sound (e.g., “the the\nthe”), which uses the articulatory control process of the phonological\nloop.\nartificial intelligence: this involves developing computer programs that\nproduce intelligent outcomes.\nAsperger’s syndrome: an autism spectrum disorder involving problems\nwith social communication in spite of at least average intelligence and\nno delays in language development.\nassociation: the finding that certain symptoms or performance impair-\nments  are consistently found together in numerous brain-damaged\npatients.\nattentional bias: selective allocation of attention to emotionally negative\nstimuli when presented simultaneously with neutral stimuli.\naudience design: this involves speakers tailoring what they say to the\nspecific needs and knowledge of their audience.\nautism spectrum disorder (ASD): a disorder involving difficulties in social\ninteraction and communication, and repetitive patterns of behaviour\nand thinking.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n803\nautobiographical memory: long-term memory for the events of one’s own\nlife.\nautostereogram: a complex two-dimensional image perceived as three-\ndimensional when not focused on for a period of time.\navailability heuristic: the rule of thumb that the frequencies of events can\nbe estimated accurately by the subjective ease with which they can be\nretrieved.\nback-propagation: a learning mechanism in connectionist models based on\ncomparing actual responses to correct ones.\nbackward crosstalk effect: aspects of Task 2 influence response selection\nand performance speed on Task 1 in studies on the psychological\nrefractory period (PRP) effect.\nbackward masking: suppression of the processing (and conscious per-\nception of) a stimulus by presenting a second, masking stimulus very\nshortly thereafter.\nbase-rate information: the relative frequency of an event in a given\npopulation.\nBayesian inference: a form of statistical inference in which initial beliefs\n(prior probabilities) are modified by evidence or experience to produce\nposterior probabilities.\nbelief bias: in syllogistic reasoning, the tendency to accept invalid but\nbelievable conclusions and reject valid but unbelievable ones.\nbinding problem: the issue of integrating different types of information to\nproduce coherent visual perception.\nbinocular cues: cues to depth that require both eyes to be used together.\nbinocular disparity: a depth cue based on the slight disparity in the two\nretinal images when an observer views a scene; it is the basis for\nstereopsis.\nbinocular rivalry: when two different visual stimuli are presented one to\neach eye, only one stimulus is seen; the seen stimulus alternates over\ntime.\nblindsight: the ability to respond appropriately to visual stimuli in the\nabsence of conscious visual experience in patients with damage to the\nprimary visual cortex.\nbodily self-consciousness: a form of self-consciousness involving body-\ncentred perception (e.g., of the face, hand or trunk) based on integra-\ntion of bodily signals from several different sense modalities.\nbody size effect: an illusion in which misperception of one’s own bodily\nsize causes the perceived size of objects to be misjudged.\nBOLD: blood oxygen-level-dependent contrast; this is the signal measured\nby fMRI.\nbottom-up processing: processing directly influenced by environmental\nstimuli; see top-down processing.\nboundary extension: misremembering a scene as having a larger surround\narea than was actually the case.\nbounded rationality: the notion that people are as rational as the\nenvironment and their limited processing capacity permit.\nbridging inferences: inferences or conclusions drawn to increase coher-\nence between the current and preceding parts of a text; also known as\nbackward inferences.\nCreated from usyd on 2022-02-18 03:51:20.",
    "804\nGlossary\nBroca’s aphasia: a form of aphasia involving non-fluent speech and gram-\nmatical errors.\nCAPTCHA: a Completely Automated Turing test to tell Computers and\nHumans Apart involving distorted characters connected together is\noften used to establish that the user of an internet website is human\nrather than an automated system.\ncascade processing: later processing stages start before earlier processing\nstages have been completed when performing a task.\ncase-series study: a study in which several patients with similar cognitive\nimpairments are tested; this allows consideration of individual data and\nof variation across individuals.\ncategorical perception: a sound intermediate between two phonemes is\nperceived as being one or other of the phonemes; a similar phenome-\nnon is found in vision with colour perception.\ncategory-specific deficits: disorders caused by brain damage in which\nsemantic memory is disrupted for certain semantic categories.\ncentral coherence: the ability to make use of all the information when\ninterpreting an utterance or situation.\ncentral executive: a modality-free, limited capacity, component of working\nmemory.\nchange blindness: failure to detect various changes (e.g., in objects) in the\nvisual environment.\nchange blindness blindness: the tendency of observers to overestimate\ngreatly the extent to which they can detect visual changes and so avoid\nchange blindness.\nCharles Bonnet syndrome: a condition in which individuals with eye\ndisease form vivid and detailed visual hallucinations sometimes mis-\ntaken for visual perception.\nchild-directed speech: the short, simple, slowly spoken sentences used by\nparents and others when talking to young children.\nchromatic adaptation: changes in visual sensitivity to colour stimuli when\nthe illumination alters.\nchunks: stored units formed from integrating smaller pieces of information.\nclause: a group of words within a sentence that contains a subject and a\nverb.\nco-articulation: a speaker’s production of a phoneme is influenced by their\nproduction of the previous sound and by preparations for the next sound.\ncocktail party problem: the difficulties involved in attending to one voice\nwhen two or more people are speaking at the same time.\ncognitive architecture: comprehensive framework for understanding\nhuman cognition in the form of computer programs.\ncognitive bias modification: training typically designed to reduce atten-\ntional bias and/or interpretive bias in anxious or depressed individuals.\ncognitive miser: someone who is economical with their time and effort\nwhen performing a thinking task.\ncognitive neuroscience: an approach that aims to understand human\ncognition by combining information from behaviour and the brain.\ncognitive psychology: an approach that aims to understand human cog-\nnition by the study of behaviour; a broader definition also includes the\nstudy of brain activity and structure.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n805\nCognitive Reflection Test: a test assessing individuals’ tendencies to over-\nride intuitive (but incorrect) answers to problems.\ncolour constancy: the tendency for an object to be perceived as having the\nsame colour under widely varying viewing conditions.\ncommon ground: shared knowledge and beliefs possessed by a speaker and\na listener; its use facilitates communication.\ncomorbidity: the state of affairs when a patient has two (or more) mental\ndisorders at the same time.\ncomputational modelling: this involves constructing computer programs\nthat simulate or mimic human cognitive processes.\nconcepts: mental representations of categories of objects or items.\nconceptual priming: a form of priming in which there is facilitated process-\ning of stimulus meaning.\nconditional reasoning: a form of deductive reasoning based on if … then\npropositions.\nconfirmation bias: (1) a tendency for eyewitnesses’ memory to be distorted\nby their prior expectations; (2) in hypothesis testing, seeking evidence\nthat supports one’s beliefs.\nconjunction fallacy: the mistaken assumption that the probability of a\nconjunction of two events is greater than the probability of one of\nthem.\nconnectionist models: models in computational cognitive science consist-\ning of interconnected networks of simple units or nodes; the networks\nexhibit learning through experience and specific items of knowledge are\ndistributed across numerous units.\nconnectome: a comprehensive wiring diagram of neural connections within\nthe brain.\nconsolidation: a basic process within the brain involved in establishing\nlong-term memories; this process lasts several hours or more and newly\nformed memories are fragile.\nconverging operations: an approach in which several methods with differ-\nent strengths and limitations are used to address a given issue.\ncovert attention: attention to an object in the absence of an eye movement\ntowards it.\ncross-cueing: the (often subtle) communication of information from one\nhemisphere to the other in split-brain patients.\ncross-modal attention: the coordination of attention across two or more\nmodalities (e.g., vision and audition).\ncrosstalk: in dual-task conditions, the direct interference between the tasks\nthat is sometimes found.\ncrystallised intelligence: a form of intelligence that involves the ability to\nuse one’s knowledge and experience effectively.\ncued recall: a test of episodic memory in which previously presented\nto-be-remembered items are recalled in response to relevant cues.\ndecision-making: making a selection from various options; if full informa-\ntion is unavailable, judgement is required.\ndeclarative memory: a form of long-term memory that involves knowing\nsomething is the case; it involves conscious recollection and includes\nmemory for facts (semantic memory) and events (episodic memory);\nsometimes known as explicit memory.\nCreated from usyd on 2022-02-18 03:51:20.",
    "806\nGlossary\ndecoding: using the pattern of brain activity exhibited by an individual to a\nstimulus to work out the nature of that stimulus.\ndeductive reasoning: reasoning to reach a conclusion from a set of prem-\nises or statements where that conclusion follows necessarily from the\nassumption the premises are true; see inductive reasoning.\ndeep dyslexia: a condition in which reading unfamiliar words and non-words\nis impaired and there are semantic errors (e.g., reading missile as rocket).\ndeep dysphasia: a condition involving semantic errors when trying to\nrepeat spoken words and a generally poor ability to repeat spoken\nwords and non-words.\ndefault mode network: a network of brain regions that is active “by\ndefault” when an individual is not involved in a current task; it is asso-\nciated with internal processes including mind-wandering, remembering\nthe past and imagining the future.\ndeliberate practice: this form of practice involves the learner being pro-\nvided with informative feedback and having the chance to correct their\nerrors.\ndeontic rules: rules relating to obligation and permissibility.\ndeontological judgements: judgements based on moral rules and/or obli-\ngations when resolving moral dilemmas; see utilitarian judgements.\ndepictive representation: a representation (e.g., visual image) resembling a\npicture in that objects within it are organised spatially.\ndiaschisis: the disruption to distant brain areas caused by a localised brain\ninjury or lesion.\ndichotic listening task: a different auditory message is presented to each\near and attention has to be directed to one message.\ndichromacy: a deficiency in colour vision in which one of the three cone\nclasses is missing.\ndirected forgetting: reduced long-term memory caused by instructions to\nforget information that had been presented for learning.\ndirected retrospection: a technique in which individuals (e.g., writers) cat-\negorise their immediately preceding thoughts.\ndirect retrieval: effortless recall of autobiographical memories triggered by\na specific cue (e.g., being in the same place as the original event); see\ngenerative retrieval.\ndiscourse: language that is a minimum of several sentences in length; it\nincludes written text and connected speech.\ndiscourse markers: spoken words and phrases that do not contribute\ndirectly to the content of what is being said but still serve various func-\ntions (e.g., clarifying the speaker’s intentions).\ndistinctiveness: this characterises memory traces that are distinct or differ-\nent from other memory traces stored in long-term memory.\ndistraction: a strategy used in emotion regulation in which the individual\ndisengages attention from emotional processing and focuses on neutral\ninformation.\ndivided attention: a situation in which two tasks are performed at the same\ntime; also known as multi-tasking.\ndorsal: towards the top.\ndorsal stream: the part of the visual processing system most involved in\nvisually guided action.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n807\ndouble conjunction fallacy: a stronger form of the conjunction fallacy in\nwhich a conjunction of two statements is judged more likely than each\nof the statements judged separately.\ndouble dissociation: the finding that some brain-damaged individuals have\nintact performance on one task but poor performance on another task,\nwhereas other individuals exhibit the opposite pattern.\nDunning-Kruger effect: the finding that less skilled individuals over estimate\ntheir abilities more than those who are more skilled.\ndysexecutive agraphia: severely impaired writing abilities in individuals\nwith damage to the frontal lobes whose central executive functioning is\ngenerally impaired.\ndysexecutive syndrome: a condition in which damage to the frontal lobes\ncauses impairments to the central executive component of working\nmemory.\ndysgraphia: impaired ability to write (including spelling).\ndyslexia: impaired ability to read not attributable to low intelligence.\nechoic memory: a sensory store that holds auditory information for\nap proximately 2–3 seconds.\necological validity: the applicability (or otherwise) of the findings of labo-\nratory studies to everyday settings.\nefference copy: an internal copy of a motor command (e.g., to the eyes);\nit can be used to identify movement within the retinal image that is not\ndue to object movement in the environment.\negocentric coding: visual or spatial coding dependent on the position of\nthe observer’s body; see allocentric coding.\negocentric heuristic: a strategy used by listeners in which they interpret\nwhat they hear based on their own knowledge rather than knowledge\nshared with the speaker.\nelaborative inferences: inferences based on our knowledge of the world\nthat involve adding details to a text that is being read (or speech being\nlistened to).\nelectroencephalography (EEG): recording the brain’s electrical potentials\nthrough a series of scalp electrodes.\nemotion: a short-lived affective state typically triggered by a specific event.\nemotion generation: the immediate and spontaneous emotional response\nto a given situation; see emotion regulation.\nemotion regulation: the use of explicit (deliberate and effortful) processes\nor implicit (relatively automatic) processes to change the spontaneous\nemotional state (usually a negative one) produced by the emotion-\ngeneration process.\nencoding: the process by which information contained in external stimuli is\ntransformed into a representation that can be stored within the memory\nsystem.\nencoding specificity principle: the notion that retrieval depends on the\noverlap between the information available at retrieval and the informa-\ntion in the memory trace.\nendogenous spatial attention: attention to a stimulus controlled by\nintentions or goal-directed mechanisms.\nepisodic buffer: a component of working memory; it is essentially passive\nand stores integrated information briefly.\nCreated from usyd on 2022-02-18 03:51:20.",
    "808\nGlossary\nepisodic memory: a form of long-term memory concerned with personal\nexperiences or episodes occurring in a given place at a specific time.\nevent-related functional magnetic resonance imaging (efMRI): this is a\nform of functional magnetic resonance imaging in which patterns of\nbrain activity associated with specific events (e.g., correct vs incorrect\nresponses on a memory test) are compared.\nevent-related potentials (ERPs): the pattern of electroencephalographic\nactivity obtained by averaging the brain responses to the same stimulus\n(or very similar stimuli) presented repeatedly.\nevent-based prospective memory: a form of prospective memory that\ninvolves remembering to perform an intended action (e.g., buying gro-\nceries) when the circumstances are appropriate.\nexecutive functions: processes that organise and coordinate the workings\nof the cognitive system to achieve current goals; key executive functions\ninclude inhibiting dominant responses, shifting attention and updating\ninformation in working memory.\nexecutive processes: processes that organise and coordinate the function-\ning of the cognitive system to achieve current goals.\nexogenous spatial attention: attention to a given spatial location deter-\nmined by “automatic” processes.\nexpertise: the high level of knowledge and performance in a given domain\nthat an expert has achieved through years of systematic practice.\nexplicit\nmemory: memory that involves conscious recollection of\nin-formation.\nexplicit memory bias: the retrieval of relatively more negative information\nthan positive or neutral information on tests of explicit memory.\nextinction: a disorder of visual attention in which a stimulus pre-\nsented to  the  side opposite the brain damage is not detected when\nanother  stimulus is presented at the same time to the side of the brain\ndamage.\nface inversion effect: the finding that faces are much harder to recognise\nwhen presented upside down; the effect of inversion is less marked (or\nabsent) with other objects.\nfalsification: proposing hypotheses and then trying to falsify them by exper-\nimental tests; the logically correct means by which science should work,\naccording to Popper.\nfigurative language: language that is not intended to be taken literally;\nexamples include metaphor, irony and idiom.\nfigure-ground segmentation: the perceptual organisation of the visual\nfield into a figure (object of central interest) and a ground (less impor-\ntant background).\nflashbacks: intense emotional memories of traumatic events that are\nrecalled  involuntarily by patients suffering from post-traumatic stress\ndisorder.\nflashbulb memories: vivid and detailed personal memories of dramatic\nevents (e.g., 9/11).\nfluid intelligence: non-verbal reasoning ability applied to novel problems.\nfocal task: an ongoing task that involves similar processing to that involved\nin encoding the target on a prospective-memory task performed at the\nsame time; see non-focal task.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n809\nfocused attention: a situation in which individuals try to attend to only\none source of information while ignoring other stimuli; also known as\nselective attention.\nfocus of expansion: the point towards which someone in motion is moving;\nit does not appear to move.\nfovea: a small area within the retina, in the centre of the field of vision\nwhere visual acuity is greatest.\nframing effect: the finding that decisions can be influenced by situational\naspects (e.g., problem wording) irrelevant to optimal decision-making.\nfree recall: a test of episodic memory in which previously presented\nto-be-remembered items are recalled in any order.\nfree will: the notion that we freely or voluntarily choose what to do from\nvarious options.\nFreudian slip: a speech error that reveals the speaker’s (often unconscious)\nsexual desires.\nfunctional fixedness: the inflexible focus on the usual function(s) of an\nobject in problem solving.\nfunctional magnetic resonance imaging (fMRI): a technique based on\nimaging blood oxygenation using an MRI machine; it provides infor-\nmation about the location and time course of brain processes.\nfunctional specialisation: the assumption that each brain area or region is spe-\ncialised for a specific function (e.g., colour processing; face processing).\nfusiform face area: an area that is associated with face processing; the term\nis somewhat misleading given that the area is also associated with pro-\ncessing other categories of objects.\nGanong effect: the finding that perception of an ambiguous phoneme is\nbiased towards a sound that produces a word rather than a non-word.\ngene-environment correlation: genetic differences between individuals\npartly determine the different environments they experience.\ngene-environment interaction: individuals differing in their genetic\nmake-up respond in different ways to environmental variation.\ngeneralised anxiety disorder: a condition involving excessive anxiety and\nworry across many areas of everyday life.\ngenerative retrieval: deliberate or voluntary construction of autobio-\ngraphical memories based on an individual’s current goals; see direct\nretrieval.\ngrammar: the set of rules governing the structure of a language (especially\nsyntax and inflections).\ngrapheme: a small unit of written language corresponding to a phoneme\n(e.g., the ph in photo).\ngraphemic buffer: a store in which graphemic information about the indi-\nvidual letters in a word is held immediately prior to spelling the word.\ngyrus: prominent elevated area or ridge on the brain’s surface; (“gyri” is the\nplural).\nhallucinations: perceptual experiences that appear real even though the\nindividuals or objects perceived are not present.\nhaptic: relating to the sense of touch.\nhemifield: one half of the visual field; information from the left hemifield\nof each eye proceeds to the right hemisphere and information from the\nright hemifield proceeds to the left hemisphere.\nCreated from usyd on 2022-02-18 03:51:20.",
    "810\nGlossary\nhemispherectomy: a radical surgical procedure in which one of the  cerebral\nhemispheres is destroyed and removed.\nheuristic: rule of thumb that is cognitively undemanding and often pro-\nduces approximately accurate answers; see algorithm.\nhighly superior autobiographical memory (HSAM): exceptional ability to\nrecall autobiographical memories in detail, generally accompanied by\nonly average ability to recall other memories.\nhill climbing: a simple heuristic used by problem solvers in which they focus\non making moves that will apparently put them closer to the goal.\nhippocampal neurogenesis: the process of generating new neurons in the\nhippocampus during early development.\nholistic processing: processing that involves integrating information from\nan entire object (especially faces).\nhollow-face illusion: a concave face mask is misperceived as a normal face\nwhen viewed from several feet away.\nhomophones: words pronounced in the same way but that differ in their\nspellings (e.g., pain-pane; sale-sail).\nHoni phenomenon: the typical apparent size changes when an individual\nwalks along the rear wall of the Ames room are reduced when female\nobservers view a man to whom they are very close emotionally.\niconic memory: a sensory store that holds visual information for\napproximately 250–1000 milliseconds following the offset of a visual\nstimulus.\nill-defined problems: problems in which the problem is imprecisely speci-\nfied; for example, the initial state, goal state and the methods available\nto solve the problem may be unclear.\nilluminant: a source of light illuminating a surface or object.\nillusory conjunction: mistakenly combining features from two different\nstimuli to perceive an object that is not present.\nimpact bias: overestimation of the intensity and duration of negative emo-\ntional reactions to losses and positive emotional reactions to gains.\nimpasse: the experience of being blocked and not knowing how to proceed\nwhen engaged in problem solving.\nimplacable experimenter: the situation in experimental research in which\nthe experimenter’s behaviour is uninfluenced by the participant’s\nbehaviour.\nimplementation intentions: action plans designed consciously to achieve\nsome goal (e.g., healthier eating) based on specific information con-\ncerning where, when and how the goal will be achieved.\nimplicit learning: learning complex information without conscious aware-\nness of what has been learned.\nimplicit memory: memory that does not depend on conscious recollection.\nimplicit memory bias: relatively better memory performance for negative\nthan for neutral or positive information on tests of implicit memory.\ninattentional blindness: failure to detect an unexpected object appearing in\nthe visual environment.\nincidental emotions: emotions experienced while engaged in making a\njudgement or decision that are irrelevant to the judgement or decision.\nincremental validity: the ability of a new test to predict behaviour or other\noutcomes to a greater extent than existing tests.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n811\nincubation: a stage of problem solving in which the problem is put to one\nside for some time; it is claimed to facilitate problem solving.\ninductive reasoning: forming generalisations (that may be probable but\nare not certain) from examples or sample phenomena; see deductive\nreasoning.\ninfantile amnesia: the inability of adults to recall autobiographical memo-\nries from early childhood; also known as childhood amnesia.\ninferior: towards the bottom of the brain.\ninflections: grammatical changes to nouns or verbs (e.g., adding -s to a noun\nto indicate the plural; adding -ed to a verb to indicate the past tense).\ninformal reasoning: a form of reasoning based on one’s relevant knowledge\nand experience rather than logic.\ninhibition of return: a reduced probability of visual attention returning to a\nrecently attended location or object.\ninner scribe: according to Logie, the part of the visuo-spatial sketchpad\ndealing with spatial and movement information.\ninsight: the experience of suddenly realising how to solve a problem; some-\ntimes referred to as the “the Aha! experience”.\ninstrumental rationality: maximising the utility (subjective value) of one’s\nchoices or decision with respect to achieving task-related goals.\nintegral emotions: emotions experienced while engaged in making a judge-\nment or decision that arise from the judgement or decision.\ninteroception: sensitivity to bodily stimuli (especially emotion-relevant\nones) whether at the conscious or non-conscious level.\ninterpretive bias: the tendency when presented with ambiguous stimuli or\nsituations to interpret them in a negative way.\nintrospection: a careful examination and description of one’s own mental\nthoughts.\ninvariants: properties of the optic array that remain constant even though\nother aspects vary; part of Gibson’s theory.\nIowa gambling task: a task in which participants are presented with four\ndecks of cards; they are told some cards in each deck will produce\nfinancial rewards whereas other cards will produce financial losses; two\ndecks produce immediate high gains but larger losses in the long run\n(risky decks), whereas the other two decks have immediate low gains\nfollowed by smaller losses and produce an overall net gain.\njargon aphasia: a brain-damaged condition in which speech is reasonably\ncorrect, grammatically, but there are severe problems in accessing the\nappropriate words.\njudgement: an assessment of the probability of a given event occurring\nbased on incomplete information.\nknowledge effect: the tendency to assume others possess the same knowl-\nedge as us.\nknowledge-lean problems: problems that can be solved by individuals in\nthe absence of specific relevant prior knowledge.\nknowledge-rich problems: problems that can only be solved by those\nhaving considerable relevant background knowledge.\nKorsakoff’s syndrome: amnesia (impaired long-term memory) caused by\nchronic alcoholism.\nlateral: situated at the side of the brain.\nCreated from usyd on 2022-02-18 03:51:20.",
    "812\nGlossary\nlateral inhibition: reduction of activity in one neuron caused by activity in\na neighbouring neuron.\nlaw of Prägnanz: the notion that the simplest possible organisation of the\nvisual environment is perceived; proposed by the gestaltists.\nlemmas: abstract words possessing syntactic and semantic features but not\nphonological ones.\nlesion: damage within the brain resulting from injury or disease; it typically\naffects a restricted area.\nlexical access: accessing detailed information about a given word by enter-\ning the lexicon.\nlexical bias effect: the tendency for speech errors to form words rather\nthan non-words.\nlexical decision task: participants presented with a string of letters or audi-\ntory stimulus decide rapidly whether it forms a word.\nlexicalisation: the process of translating a word’s meaning into its sound\nrepresentation during speech production.\nlexical parafoveal-on-foveal effects: the finding that fixation duration on\nthe current word (word n) is influenced by lexical properties of the next\nword (word n+1).\nlexicon: an individual’s internal dictionary containing information about\nword meanings.\nlexigrams: symbols used to represent words in studies on communication.\nlife script: a schema based on cultural expectations concerning the nature\nand order of a typical person’s major life events.\nlimb apraxia: a condition caused by brain damage in which individuals have\nimpaired ability to make skilled, goal-directed movements towards\nobjects even though they possess the physical ability to perform them.\nlinguistic relativity: the notion that speakers of different languages think\ndifferently.\nlinguistic universals: features (e.g., preferred word orders; the distinction\nbetween nouns and verbs) found in the great majority of the world’s\nlanguages.\nlogical inferences: inferences that follow necessarily from the meanings of\nword (e.g., a bachelor is a man who is unmarried).\nlong-term working memory: used by experts to store relevant information\nrapidly in long-term memory and to access it through retrieval cues in\nworking memory.\nloss aversion: the finding that losses have a greater subjective impact on\nindividuals than gains of the same magnitude.\nluminance: the intensity of light reflected from a surface or object.\nmagneto-encephalography (MEG): a non-invasive brain-scanning tech-\nnique based on recording the magnetic fields generated by brain activ-\nity; it has good spatial and temporal resolution.\nmajor depressive disorder: a mental disorder characterised by depressed\nmood, tiredness and lack of pleasure and interest in various activities.\nmatching bias: the tendency on the Wason selection task to select cards\nmatching the items explicitly mentioned in the rule.\nMcGurk effect: a mismatch between spoken and visual (lip-based) informa-\ntion leads listeners to perceive a sound or word involving a blending of\nthe auditory and visual information.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n813\nmeans-ends analysis: a heuristic method for solving problems based on\ncreating a subgoal to reduce the difference between the current state\nand the goal state.\nmedial: situated in the middle of the brain.\nmentalising: the ability to perceive and interpret behaviour in terms of\nmental states (e.g., goals; needs).\nmental model: an internal representation of some possible situation or\nevent in the world having the same structure as that situation or event.\nmental set: the tendency to use a familiar problem-solving strategy that has\nproved successful in the past even when it is no longer appropriate; also\nknown as Einstellung.\nmeta-analysis: a form of statistical analysis based on combining the find-\nings from numerous studies on a given research topic.\nmeta-cognition: beliefs and knowledge concerning one’s own cognitive\nprocesses and likely level of performance.\nmeta-memory: beliefs and knowledge about one’s own memory including\nstrategies for learning and memory.\nmetaphor interference effect: the finding that it takes longer to judge\nwhether metaphorical sentences are literally true or false than control\nsentences.\nmeta-reasoning: monitoring processes that influence the time, effort and\nstrategies used during reasoning and problem solving.\nminimally conscious state: a condition in which patients exhibit partial\npreservation of conscious awareness.\nmirror neuron system: neurons that respond to actions whether performed\nby oneself or someone else; it is claimed these neurons assist in imitat-\ning (and understanding) the actions of others.\nmisery-is-not-miserly effect: the tendency for sad individuals to be willing\nto pay more for some products than other people.\nmisinformation effect: the distorting effect on eyewitness memory of mis-\nleading information presented after a crime or other event.\nmixed-error effect: a form of speech error in which the incorrect word\nspoken is related to the correct one in terms of both meaning and\nsound.\nmodularity: the assumption that the cognitive system consists of many\nfairly independent or separate modules or processors, each specialised\nfor a given type of processing.\nmonocular cues: cues to depth that can be used by one eye but can also be\nused by both eyes together.\nmood: state resembling emotion but generally longer lasting, less intense\nand of unknown cause.\nmood congruity: learning and memory of emotional material are better\nwhen the learner’s/rememberer’s mood state matches the affective value\nof the material than when it does not.\nmood-state-dependent memory: memory performance is better when the\nindividual’s mood state is the same at learning and retrieval than when\nit differs.\nmorphemes: the basic units of meaning; words consist of one or more\nmorphemes.\nmorphology: the study of words and how they are formed from morphemes.\nCreated from usyd on 2022-02-18 03:51:20.",
    "814\nGlossary\nmotion parallax: a depth cue based on movement in one part of the retinal\nimage relative to another.\nmulti-tasking: performing two or more tasks at the same time by switching\nrapidly between them.\nmutual illumination: the light reflected from the surface of an object\nimpinges on the surface of a second object.\nmyopic misery: the notion that misery or sadness leads to an excessive\nfocus on replacing lost rewards.\nmyside bias: in informal reasoning, the tendency to select and interpret\ninformation in terms of one’s own beliefs or to generate reasons or\narguments supporting those beliefs.\nnaming task: a task in which visually presented words are pronounced\naloud rapidly.\nnegative afterimages: the illusory perception of the complemen-\ntary  colour  to the one that has just been fixated; green is the\ncomplementary colour to red and blue is complementary to yellow.\nneglect: a disorder involving right-hemisphere damage (typically) in\nwhich the left side of objects and/or objects presented to the left visual\nfield are undetected; the condition resembles extinction but is more\nsevere.\nneologisms: made-up words produced by patients suffering from jargon\naphasia.\nneural decoding: using computer-based analyses of patterns of brain activ-\nity to work out which stimulus an individual is processing.\nneural network models: computational models in which processing\ninvolves the simultaneous activation of numerous interconnected\nnodes (basic units).\nnodes: the basic units within a neural network model.\nnon-declarative memory: forms of long-term memory that influence\nbehaviour but do not involve conscious recollection (e.g., priming;\nprocedural memory); also known as implicit memory.\nnon-focal task: an ongoing task that involves different processes to those\ninvolved in encoding the target on a prospective-memory task per-\nformed at the same time; see non-focal task.\nnormativism: the notion that human thinking should be regarded as\n“correct” or “incorrect” depending on how closely it follows certain\nnorms or standards (e.g., those of classical logic).\nobsessive-compulsive disorder (OCD): an anxiety disorder in which the\nsymptoms include unwanted thoughts (obsessions) and repetitive\nbehaviours (compulsions) in response to those thoughts.\noculomotor cues: cues to depth produced by muscular contractions of the\nmuscles around the eye; use of such cues involves kinaesthesia (also\nknown as the muscle sense).\nomission bias: a biased preference for risking harm through inaction com-\npared to risking harm through action.\nongoing task: a task performed at the same time as a prospective-memory\ntask in studies on prospective memory.\nopen-object illusion: the misperception that objects with missing  boundaries\nare larger than objects the same size without missing boundaries.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n815\noperation span: the maximum number of items (arithmetical questions +\nwords) for which an individual can recall all the words more than 50%\nof the time.\noptic array: the structural pattern of light falling on the retina.\noptic ataxia: a condition in which there are problems making visually\nguided movements in spite of reasonably intact visual perception.\noptic flow: the changes in the pattern of light reaching an observer when\nthere is movement of the observer and/or aspects of the environment.\noptimism bias: the tendency to exaggerate our chances of experiencing\npositive events and to minimise our chances of experiencing negative\nevents relative to other people.\northographic lexicon: part of long-term memory in which learned word\nspellings are stored.\northographic neighbours: with reference to a target word, the number of\nwords that can be formed by changing one of its letters.\northographic working memory: a store in which information about the\nindividual letters in a word (and their ordering) is held immediately\nprior to spelling the word.\northography: the study of letters and word spellings.\nother-race effect: the finding that recognition memory for same-race faces\nis generally more accurate than for other-race faces.\nout-of-body experiences: vivid feelings of being outside of (and detached\nfrom) one’s own body.\nown-age bias: the tendency for eyewitnesses to identify the culprit more\noften when they are of similar age to the eyewitness than when they are\nof a different age.\nparadigm specificity: the findings with a given experimental task or par-\nadigm are not replicated even when apparently very similar tasks or\nparadigms are used.\nparafovea: the area in the retina immediately surrounding the fovea.\nparallel processing: processing in which two or more cognitive processes\noccur at the same time.\nParkinson’s disease: a progressive disorder involving damage to the basal\nganglia (including the striatum); the symptoms include muscle rigidity,\nlimb tremor and mask-like facial expression.\nparsing: analysing the syntactical or grammatical structure of sentences.\npart-whole effect: the finding that a face part is recognised more\neasily when presented in the context of a whole face rather than on its\nown.\npattern recognition: the ability to identify or categorise two-dimensional\npatterns (e.g., letters; fingerprints).\nperceptual priming: a form of priming in which repeated presentations of\na stimulus facilitates its perceptual processing.\nperceptual span: the effective field of view in reading (letters to the left and\nright of fixation that can be processed).\npersonal semantics: aspects of one’s personal or autobiographical memory\nthat combine elements of episodic memory and semantic memory.\nphenomenal consciousness: direct conscious experience; see access\nconsciousness.\nCreated from usyd on 2022-02-18 03:51:20.",
    "816\nGlossary\nphonemes: the smallest units of sound that distinguish one word from\nanother and contribute to word meaning; the number and nature of\nphonemes varies across languages.\nphonemic restoration effect: the finding that listeners are unaware that a\nphoneme has been deleted and replaced by a non-speech sound (e.g.,\ncough) within a sentence.\nphonological dysgraphia: a condition caused by brain damage in which\nfamiliar words can be spelled reasonably well but unfamiliar words and\nnon-words cannot.\nphonological dyslexia: a condition in which familiar words can be read but\nthere is impaired ability to read unfamiliar words and non-words.\nphonological loop: a component of working memory in which speech-\nbased information is processed and stored briefly and subvocal articu-\nlation occurs.\nphonological neighbourhood: words are phonological neighbours if they\ndiffer in only one phoneme (e.g., wipe, pipe and tap are phonological\nneighbours of type).\nphonological output lexicon: it contains information about the spoken\nform of words (e.g., number of syllables) and is used in object naming\nand reading aloud.\nphonological similarity effect: the finding that immediate serial recall of\nverbal material is reduced when the items sound similar.\nphonology: the study of the sounds of words and parts of words.\nphrase: a group of words within a sentence expressing a single idea.\nplasticity: changes within the brain occurring as a result of brain damage or\nexperience.\npositron emission tomography (PET): a brain-scanning technique based on\nthe detection of positrons; it has reasonable spatial resolution but poor\ntemporal resolution.\nposterior: towards the back of the brain.\npragmatics: the study of the ways in which language is used and understood\nin the real world including a consideration of its intended meaning; in\ngeneral, the impact of contextual factors on meaning.\npredictive inferences: expectations concerning what will happen next (e.g.,\na new event) when reading text or listening to someone.\npreformulation: the production by speakers of phrases used frequently\nbefore; it reduces the demands of speech production.\npriming: facilitating the processing of (and response) to a target stimulus by\npresenting a stimulus related to it shortly beforehand.\nprinciple of truth: the notion that assertions are represented by\nforming mental models concerning what is true while ignoring what\nis false.\nproactive interference: disruption of memory by previous learning\n(especially of similar material).\nproblem space: an abstract description of all the possible states that can\noccur within a given problem.\nprocedural memory: this is memory concerned with knowing how and it\nincludes the knowledge required to perform skilled actions.\nprocess-dissociation procedure: on learning tasks, participants try to\nguess the next stimulus (inclusion condition) or avoid guessing the next\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n817\nstimulus accurately (exclusion condition); the difference between the\ntwo conditions indicates the amount of explicit learning.\nproduction rules: “IF … THEN or condition-action rules in which the\naction is carried out whenever the appropriate condition is present.\nproduction systems: these consist of very large numbers of “IF … THEN”\nproduction rules and a working memory containing information.\nproposition: a statement making an assertion or denial which can be true\nor false.\nproprioception: an individual’s awareness of the position and orientation\nof parts of their body.\nprosodic cues: features of spoken language such as stress, intonation,\npauses and duration making it easier for listeners to work out gram-\nmatical structure and meaning; similar cues are often present in texts\n(e.g., commas; semi-colons).\nprosopagnosia: a condition (also known as face blindness) in which there\nis a severe impairment in face recognition but much less impairment\nof object recognition; it is often the result of brain damage (acquired\nprosopagnosia) but can also be due to impaired development of\nface-recognition mechanisms (developmental prosopagnosia).\nprospective memory: remembering to carry out some intended action in\nthe absence of an explicit reminder to do so; see retrospective memory.\npseudo-neglect: a slight tendency in healthy individuals to favour the left\nside of visual space.\npseudowords: non-words consisting of strings of letters that can be pro-\nnounced (e.g., mantiness; fass).\npsychological refractory period (PRP) effect: the slowing of the response\nto the second of two stimuli when presented close together in time.\npure alexia: severe problems with reading but not other language skills;\ncaused by damage to brain areas involved in visual processing.\npure word deafness: a condition involving severely impaired speech per-\nception but intact speech production, reading, writing and perception\nof non-speech sounds.\nrationalisation: in Bartlett’s theory, errors in story recall that conform to\nthe rememberer’s cultural expectations.\nreading span: the largest number of sentences read for comprehension from\nwhich an individual can recall all the final words over 50% of the time.\nreappraisal: a strategy used in emotion regulation in which the individual\nelaborates emotional information from an event prior to changing its\nmeaning.\nreceptive field: the region of the retina in which light influences the activity\nof a particular neuron.\nrecognition heuristic: using the knowledge that only one out of two objects\nis recognised as the basis for making a judgement.\nreconsolidation: this is a new process of consolidation occurring when a\npreviously formed memory trace is reactivated; it allows that memory\ntrace to be updated.\nrecovered memories: childhood traumatic memories forgotten for several\nyears and then remembered in adult life.\nrecursion: turning simple sentences into longer and more complex ones by\nplacing one or more additional clauses within them.\nCreated from usyd on 2022-02-18 03:51:20.",
    "818\nGlossary\nreminiscence bump: the tendency of older people to recall a disproportion-\nate number of autobiographical memories from adolescence and early\nadulthood.\nRemote Associates Test: this involves finding a word that is related to\nthree given words (e.g., opera, hand and dish are all related to soap).\nrepetition enhancement: the finding that stimulus repetition sometimes\nleads to increased brain activity; however, stimulus repetition more\noften leads to repetition suppression.\nrepetition priming: the finding that processing of a stimulus is facilitated if\nit has been processed previously.\nrepetition suppression: the finding that stimulus repetition often leads\nto reduced brain activity (typically with enhanced performance via\npriming).\nrepetitive transcranial magnetic stimulation (rTMS): the administration of\ntranscranial magnetic stimulation several times in rapid succession.\nreplication: the ability to repeat a previous experiment and obtain the same\n(or similar) findings.\nrepresentativeness heuristic: the assumption that an object or individual\nbelongs to a specified category because it is representative (typical) of\nthat category.\nrepression: motivated forgetting of traumatic or other threatening events\n(especially from childhood).\nretinal flow field: the changing patterns of light on the retina produced by\nmovement of the observer relative to the environment as well as by eye\nand head movements.\nretinal ganglion cells: retinal cells providing the output signal from the retina.\nretinopy: the notion that there is mapping between receptor cells in the\nretina and points on the surface of the visual cortex.\nretroactive interference: disruption of memory for previously learned\ninformation by other learning or processing occurring during the reten-\ntion interval.\nretrograde amnesia: impaired ability of amnesic patients to remember\ninformation and events from the time period prior to the onset of\namnesia.\nretrospective memory: memory for events, people and so on experienced\nin the past; see prospective memory.\nreverse inference: as applied to functional neuroimaging, it involves\narguing backwards from a pattern of brain activation to the presence\nof a given cognitive process.\nrisk aversion: a preference for certain gains over potentially larger (but less\ncertain) gains.\nrostral: towards the front of the brain.\nsaccades: rapid eye movements separated by eye fixations lasting about 250\nms.\nsatisficing: simplifying the decision-making process by using heuristics and\nignoring some relevant information sources; the term represents a blend\nof the words satisfactory and sufficing.\nsavings method: a measure of forgetting introduced by Ebbinghaus\nin which the number of trials for relearning is compared against the\nnumber for original learning.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n819\nsaying-is-believing effect: tailoring a message about an event to suit a\ngiven audience causes subsequent inaccuracies in memory for that\nevent.\nschemas: organised packets of information about the world, events or\npeople stored in long-term memory.\nscript: a form of schema containing information about a sequence of events\n(e.g., events during a typical restaurant meal).\nsegmentation: dividing the almost continuous sounds of speech into sepa-\nrate phonemes and words.\nselective exposure: a preference for information that strengthens pre-ex-\nisting views and avoidance of information conflicting with those views.\nsemantic dementia: a condition involving damage to the anterior tempo-\nral lobes involving widespread loss of information about the meanings\nof words and concepts; however, episodic memory and executive func-\ntioning are reasonably intact initially.\nsemanticisation: the phenomenon of episodic memories changing into\nsemantic memories over time.\nsemantic memory: a form of long-term memory consisting of general\nknowledge about the world, concepts, language and so on.\nsemantic priming: the finding that word recognition is facilitated by the\nprior presentation of a semantically related word.\nsemantics: the study of the meaning conveyed by words, phrases and\nsentences.\nsense of agency: the belief we are determining our own actions.\nserial dependence: systematic bias of current visual perception towards\nrecent visual input.\nserial processing: processing in which one process is completed before the\nnext one starts; see parallel processing.\nserial reaction time task: participants on this task respond as rapidly as\npossible to stimuli typically presented in a repeating sequence; it is used\nto assess implicit learning.\nserial recall: a test of episodic memory in which previously presented\nto-be-remembered items must be recalled in the order of presentation.\nshadowing: repeating one auditory message word for word as it is pre-\nsented while a second auditory message is also presented; it is used on\nthe dichotic listening task.\nshooter bias: the tendency for unarmed black individuals to be more likely\nthan unarmed white individuals to be shot.\nsingle-unit recording: an invasive technique for studying brain function,\npermitting the study of activity in single neurons.\nsize constancy: objects are perceived to have a given size regardless of the\nsize of the retinal image.\nslippery slope argument: the claim that an innocuous first step will lead to\nan undesirable outcome; sometimes regarded as a fallacy.\nsocial cognition: an approach within social psychology in which the empha-\nsis is on the cognitive processing of information about other people and\nsocial situations.\nsolution aversion: a bias in reasoning in which individuals deny the exist-\nence of a problem (e.g., climate change) because they dislike the\nproposed solution (e.g., restricting damaging emissions).\nCreated from usyd on 2022-02-18 03:51:20.",
    "820\nGlossary\nspillover effect: any given word is fixated longer during reading when\npreceded by a rare word rather than a common one.\nsplit attention: allocation of attention to two (or more) non-adjacent\nregions of visual space.\nsplit-brain patients: patients in whom most of the direct links between the\ntwo hemispheres of the brain have been severed.\nspoonerism: a speech error in which the initial letter or letters of two words\n(typically close together) are switched to form two different words.\nspreading activation: activation of a node (corresponding to a word or\nconcept) in the brain causes some activation to spread to several related\nnodes or words.\nstatus quo bias: a preference for maintaining the status quo (present state)\nrather than acting to change their decision.\nstereopsis: depth perception based on the small discrepancy in the two\nretinal images when a visual scene is observed (binocular disparity).\nstimulus onset asynchrony (SOA): time interval between the start of two\nstimuli.\nstraw man fallacy: refuting an opponent’s views by misrepresenting them\nin some way.\nstriatum: it forms part of the basal ganglia and is located in the upper part\nof the brainstem and the inferior part of the cerebral hemispheres.\nStroop task: a task in which participants have to name the ink colours in\nwhich colour words are printed; performance is slowed when the to-be-\nnamed colour (e.g., green) conflicts with the colour word (e.g., red).\nsubadditivity effect: the judged probability of the whole is less than the\ncombined probabilities of its parts.\nsubliminal perception: perceptual processing occurring below the level of\nconscious awareness that can nevertheless influence behaviour.\nsulcus: a groove or furrow in the surface of the brain.\nsunk-cost effect: investing additional resources to justify a previous com-\nmitment that has so far proved unsuccessful.\nsuperior: towards the top.\nsuper-recognisers: individuals with an outstanding ability to recognise\nfaces.\nsurface dysgraphia: a condition caused by brain damage in which there is\nimpaired spelling of irregular words but reasonably accurate spelling of\nregular words and non-words.\nsurface dyslexia: a condition in which regular words and non-words can\nbe  read but there is impaired ability to read irregular or exception\nwords.\nsyllable: a unit of speech consisting of one vowel sound with or without one\nor more additional consonants (e.g., water has two syllables: wa and\nter).\nsyllogism: a type of problem used in deductive reasoning; there are two\nstatements or premises and a conclusion that may or may not follow\nlogically from the premises.\nsynaesthesia: the tendency for one sense modality to evoke another.\nsyndrome: the notion that symptoms that often co-occur have a common\norigin.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n821\nsyntactic priming: the tendency for a speaker’s utterances to have the same\nsyntactic structure as those they have heard shortly beforehand.\nsyntax: the set of rules concerning word order to create well-formed\nsentences.\ntangent point: from a driver’s perspective, the point on a road at which the\ndirection of its inside edge appears to reverse.\ntemplate: as applied to chess, an abstract schematic structure consisting\nof a mixture of fixed and variable information about chess pieces and\npositions.\ntemporal ventriloquism effect: misperception of the timing of a visual\nstimulus when an auditory stimulus is presented close to it in time.\ntesting effect: the finding that long-term memory is enhanced when some\nof the learning period is devoted to retrieving to-be-learned informa-\ntion rather than simply studying it.\ntexture gradient: the rate of change of texture density from the front to the\nback of a slanting object.\ntime-based prospective memory: a form of prospective memory, which\ninvolves remembering to carry out an intended action at the appropri-\nate time.\ntip-of-the-tongue state: the frustrating experience of being unable to find\nthe correct word to describe a given concept or idea.\ntop-down processing: stimulus processing that is influenced by factors\nsuch as the individual’s past experience and expectations.\ntrait anxiety: a personality dimension based on individual differences in\nsusceptibility to anxiety.\ntranscortical sensory aphasia: a condition in which spoken words can be\nrepeated but comprehension of spoken and written language is severely\nimpaired.\ntranscranial direct current stimulation (tDCS): a technique in which a very\nweak electrical current is passed through an area of the brain (often for\nseveral minutes); anodal tDCS often enhances performance, whereas\ncathodal tCDS often impairs it.\ntranscranial magnetic stimulation (TMS): a technique in which magnetic\npulses briefly disrupt the functioning of a given brain area. It is often\nclaimed that it creates a short-lived “lesion”. More accurately, TMS\ncauses interference when the brain area to which it is applied is involved\nin task processing as well as activity produced by the applied stimulation.\nunconscious inference: the tendency of eyewitnesses to misidentify a famil-\niar (but innocent) face as being the person responsible for a crime.\nunderadditivity: the finding that brain activation when tasks A and B are\nperformed at the same time is less than the sum of the brain activation\nwhen tasks A and B are performed separately.\nunderspecification: a strategy used to reduce processing costs in speech\nproduction by using simplified expressions.\nuniform connectedness: the notion that adjacent regions in the visual envi-\nronment having uniform visual properties (e.g., colour) are perceived as\na single perceptual unit.\nuniqueness point: the point in time in spoken word recognition at which\nthe available perceptual information is consistent with only one word.\nCreated from usyd on 2022-02-18 03:51:20.",
    "822\nGlossary\nUrbach-Wiethe disease: a disease in which the amygdala and adjacent\nareas are destroyed; patients with this disease have impaired emotional\nprocessing.\nutilitarian judgements: judgements based on practical and pragmatic\nconsiderations when resolving moral dilemmas; see deontological\njudgements.\nutility: how rewarding or satisfying a given outcome is perceived to be\nsubjectively.\nvalence: the positive or negative character of emotional experience.\nvegetative state: a brain-damaged condition in which patients exhibit\nwakefulness but lack conscious awareness.\nventral: towards the bottom.\nventral stream: the part of the visual processing system most involved in\nobject perception and recognition, and the formation of perceptual\nrepresentations.\nventriloquism effect: the mistaken perception that sounds are coming from\ntheir apparent source (as in ventriloquism).\nverb bias: an imbalance in the frequency with which a verb is associated\nwith different syntactic structures.\nvergence: a cue to depth based on the inward focus of the eyes with close\nobjects.\nvisual buffer: within Kosslyn’s theory, a short-term visual memory store\ninvolved in visual imagery and perception.\nvisual cache: according to Logie, the part of the visuo-spatial sketchpad\nthat stores information about visual form and colour.\nvisual crowding: the inability to recognise objects in peripheral vision due\nto the presence of neighbouring objects.\nvisual form agnosia: a condition in which there are severe problems in\nshape perception (what an object is) but apparently reasonable ability\nto produce accurate visually guided actions.\nvisual search: a task involving the rapid detection of a specified target stim-\nulus within a visual display.\nvisuo-spatial sketchpad: a component of working memory used to process\nvisual and spatial information and to store this information briefly.\nWada test: a procedure in which one cerebral hemisphere is anaesthetised.\nweapon focus effect: the finding that eyewitnesses pay so much attention\nto the presence of a weapon (e.g., gun) that they ignore other details\nand so cannot remember them subsequently.\nwell-defined problems: problems in which the initial state, the goal and the\nmethods available for solving them are clearly laid out.\nWernicke’s aphasia: a form of aphasia involving fluent speech with many\ncontent words missing and impaired comprehension.\nWhorfian hypothesis: the theoretical assumption that language influences\nperception, thinking and behaviour.\nword-length effect: the finding that verbal memory span decreases when\nlonger words are presented.\nword meaning deafness: a condition in which there is selective impairment\nof the ability to understand spoken (but not written) language.\nword superiority effect: a target letter is more readily detected in a letter\nstring when the string forms a word than when it does not.\nCreated from usyd on 2022-02-18 03:51:20.",
    "Glossary\n823\nworking memory: a limited-capacity system used in the processing and\nbrief holding of information.\nworking memory capacity: an assessment of how much information can be\nprocessed and stored at the same time; individuals with high capacity\nhave higher intelligence and more attentional control.\nCreated from usyd on 2022-02-18 03:51:20.",
    "826\nReferences\nAnderson, R.C. & Pichert, J.W. (1978). Recall of previously\nunrecallable information following a shift in perspective.\nJournal of Verbal Learning and Verbal Behavior, 17, 1–12.\nAnderson, R.C., Pichert, J.W. & Shirey, L.L. (1983). Effects\nof the reader’s schema at different points in time. Journal\nof Educational Psychology, 75, 271–279.\nAnderson, S.W., Rizzo, M., Skaar, N., Stierman, L., Cavaco,\nS., Dawson, J., et al. (2007). Amnesia and driving.\nJournal of Clinical and Experimental Neuropsychology,\n29, 1–12.\nAndrews, P.W. & Thomson, J.A. (2009). The bright side of\nbeing blue: Depression as an adaptation for analysing\ncomplex problems. Psychological Review, 116, 620–654.\nAndrews, S., Lo, S. & Xia, V. (2017). Individual differences\nin automatic semantic priming. Journal of Experimental\nPsychology: Human Perception and Performance, 43,\n1025–1039.\nAndrews-Hanna, J.R., Saxe, R. & Yarkoni, T. (2014).\nContributions of episodic retrieval and mentalising to\nautobiographical thought: Evidence from functional\nneuroimaging, resting-state connectivity, and fMRI\nmeta-analyses. NeuroImage, 91, 324–335.\nAngelone, B.L., Levin, D.T. & Simons, D.J. (2003). The\nrelation ship between change detection and recognition of\ncentrally attended objects in motion pictures. Perception,\n32, 947–962.\nAngie, A.D., Connelly, S., Waples, E.P. & Kligyte, V. (2011).\nThe influence of discrete emotions on judgment and\ndecision-making: A meta-analytic review. Cognition &\nEmotion, 25, 1393–1422.\nArdila, A. (2016). Some unusual neuropsychological syn-\ndromes: Somatoparaphrenia, akinetopsia, reduplica-\ntive paramnesia, autotopagnosia. Archives of Clinical\nNeuropsychology, 31, 456–464.\nArdila, A. & Surloff, C. (2006). Dysexecutive agraphia: A\nmajor executive dysfunction sign. International Journal\nof Neuroscience, 116, 653–663.\nArmstrong, T. & Olatunji, B.O. (2012). Eye tracking of atten-\ntion in the affective disorders: A meta-analytic review\nand synthesis. Clinical Psychology Review, 32, 704–723.\nAsk, K. & Granhag, P.A. (2007). Hot cognition in investiga-\ntive judgments: The differential influence of anger and\nsadness. Law and Human Behavior, 31, 537–551.\nAtkins, J.E., Fiser, J. & Jacobs, R.A. (2001). Experience-\ndependent visual cue integration based on consistencies\nbetween visual and haptic percepts. Vision Research, 41,\n449–461.\nAtkinson, A.P., Dittrich, W.H., Gemmell, A.J. & Young,\nA.W. (2004). Emotion perception from dynamic and\nstatic body expressions in point-light and full-light dis-\nplays. Perception, 33, 717–746.\nAtkinson, R.L., Atkinson, R.C., Smith, E.E. & Bem, D.J.\n(1993). Introduction to Psychology (11th edn). New York:\nHarcourt Brace.\nAtkinson, R.C. & Shiffrin, R.M. (1968). Human memory:\nA proposed system and its control processes. In K.W.\nSpence & J.T. Spence (eds), The Psychology of Learning\nand Motivation (Vol. 2; pp. 89–195). London: Academic\nPress.\nAuckland, M.E., Cave, K.R. & Donnelly, N. (2007). Non-\ntarget objects can influence perceptual processes during\nobject recognition. Psychonomic Bulletin & Review, 14,\n332–337.\nAugustine, A.A. & Hemenover, S.H. (2009). On the relative\nmerits of affect regulation strategies: A meta-analysis.\nCognition & Emotion, 23, 1181–1220.\nAvenanti, A., Paracampo, R., Annella, L., Tidoni, E. &\nAglioti, S.M. (2018). Boosting and decreasing action\nprediction abilities through excitatory and inhibitory\ntDCS of inferior frontal cortex. Cortex, 28, 1282–1296.\nAverell, L. & Heathcote, A. (2011). The form of the forgetting\ncurve and the fate of memories. Journal of Mathematical\nPsychology, 55, 25–35.\nAwasthi, B., Williams, M.A. & Friedman, J. (2016).\nExamining the role of red background in magnocellu-\nlar contribution to face perception. PeerJ, 4 (Article no.\ne1617).\nAwh, E. & Pashler, H. (2000). Evidence for split attentional\nfoci. Journal of Experimental Psychology: Human\nPerception and Performance, 26, 834–846.\nAxelrod, R. (2015). Structure of Decision: The cognitive maps\nof political elites. Princeton, NJ: Princeton University\nPress.\nAxelrod, V. & Yovel, G. (2015). Successful decoding of\nfamous faces in the fusiform face area. PLoS ONE, 10\n(Article no. e0117126).\nAydelott, J., Jamaluddin, Z. & Pearce, S.N. (2015). Semantic\nprocessing of unattended speech in dichotic listen-\ning. Journal of the Acoustical Society of America, 138,\n964–975.\nAzevedo, R.T., Garfinkel, S.N., Critchley, H.D. & Tsakiris,\nM. (2017). Cardiac afferent activity modulates the\nexpression of racial stereotypes. Nature Communications,\n8 (Article no. 13854).\nBaars, B.J. (1988). A Cognitive Theory of Consciousness.\nCambridge: Cambridge University Press.\nBaars, B.J., Franklin, S. & Ramsoy, T.Z. (2013). Global work-\nspace dynamics: Cortical “binding and propagation”\nenables conscious contents. Frontiers in Psychology, 4\n(Article no. 200).\nBaddeley, A.D. (1978). Trouble with levels: Re-examinatioin\nof Craik and Lockhart5’s framework for memory\nresearch. Psychological Review, 85, 139–152.\nBaddeley, A.D. (1996). Exploring the central executive.\nQuarterly Journal of Experimental Psychology, 49A, 5–28.\nBaddeley, A.D. (2000). The episodic buffer: A new compo-\nnent of working memory? Trends in Cognitive Sciences,\n4, 417–423.\nCreated from usyd on 2022-02-18 03:51:57.",
    "828\nReferences\nBaptista, M. (2012). On universal grammar, the bioprogram\nhypothesis and creole genesis. Journal of Pidgin and\nCreole Languages, 27, 351–376.\nBar, M., Kassam, K.S., Ghuman, A.S., Boshyan, J., Schmid,\nA.M., Dale, A.M., et al. (2006). Top-down facilitation of\nvisual recognition. Proceedings of the National Academy\nof Sciences, 103, 449–454.\nBarense, M.D., Ngo, L.H.T & Peterson, M.A. (2012).\nInteractions of memory and perception in amnesia:\nThe figure-ground perspective. Cerebral Cortex, 22,\n2680–2691.\nBar-Haim, Y., Lamy, D., Pergamin, L., Bakermans-\nKronenburg, M.J. & van IJzendoorn, M.H. (2007).\nThreat-related attentional bias in anxious and nonanx-\nious individuals: A meta-analytic study. Psychological\nBulletin, 133, 1–24.\nBarliya, A., Omlor, L., Giese, M.A., Berthoz, A. & Flash,\nT. (2013). Expression of emotion in the kinemat-\nics of locomotion. Experimental Brain Research, 225,\n159–176.\nBaronchelli,\nA.,\nChater,\nN.,\nPastor-Satorras,\nR.\n&\nChristiansen, M.H. (2012). The biological origin of lin-\nguistic diversity. PLoS ONE, 7 (Article no. e48029).\nBarrett, L.F. & Russell, J.A. (1998). Independence and\nbipolarity in the structure of current affect. Journal of\nPersonality and Social Psychology, 74, 967–984.\nBarreyro, J.P., Cevasco, J., Burin, D. & Marotto, C.M.\n(2012). Working memory capacity and individual dif-\nferences in the making of reinstatement and elabo-\nrative inferences. Spanish Journal of Psychology, 15,\n471–479.\nBarry, S. (2009). Fixing My Gaze. New York: Basic Books.\nBarsalou, L.W. (2009). Simulation, situated conceptualiza-\ntion, and prediction. Philosophical Transactions of the\nRoyal Society B: Biological Sciences, 364, 1281–1289.\nBarsalou, L.W. (2012). The human conceptual system. In\nM.J. Spivey, K. McRae & M.F. Joanisse, (eds), The\nCambridge Handbook of Psycholinguistics (pp. 239–258).\nCambridge: Cambridge University Press.\nBarsalou, L.W. (2016a). On staying grounded and avoiding\nquixotic dead ends. Psychonomic Bulletin & Review, 23,\n1122–1142.\nBarsalou, L.W. (2016b). Situated conceptualisation: Theory\nand applications. In Y. Coello & M.H. Fischer (eds),\nFoundations of Embodied Cognition (Vol 1): Perceptual\nand emotional embodiment (Vol 1; pp. 11–37). London:\nRoutledge.\nBarsalou, L.W., Dutriaux, L. & Scheepers, C. (2018). Moving\nbeyond the distinction between concrete and abstract\nconcepts. Philosophical Transactions of the Royal Society\nB, 373 (Article no. 2017.0144).\nBarth, M., Stahl, C. & Haider, H. (2019). Assumptions of the\nprocess-dissociation procedure are violated in implicit\nsequence learning. Journal of Experimental Psychology:\nLearning, Memory, and Cognition. Advance online publi-\ncation (19 July 2018), 641–676.\nBartlett, F.C. (1932). Remembering: An experimental and social\nstudy. Cambridge: Cambridge University Press.\nBartley, J.E., Boeving, E.R. Riedel, M.C., Bottenhorn, K.L.,\nSalo, T., Eickhoff, S.B., et al. (2018). Meta-analytic\nevidence for a core problem solving network across\nmultiple representational domains. Neuroscience and\nBiobehavioral Reviews, 92, 318–337.\nBartolo, A., Rossetti, Y., Revol, P., Urquizar, C., Pisella, L.\n& Coello, Y. (2018). Reachability judgement in optic\nataxia: Effect of peripheral vision on hand and target\nperception in depth. Cortex, 98, 102–113.\nBartolomeo, P. (2002). The relationship between visual per-\nception and visual mental imagery: A re-appraisal of the\nneuropsychological evidence. Cortex, 38, 357–378.\nBartolomeo, P. (2008). The neural correlates of visual mental\nimagery: An ongoing debate. Cortex, 44, 107–108.\nBartolomeo, P., Seidel-Malkinson, T. & De Vito, S. (2017).\nBotallo’s error, or the quandaries of the universality\nassumption. Cortex, 86, 176–185.\nBarton, J.J.S. & Corrow, S.L. (2016). Selectivity in acquired\nprosopagnosia: The segregation of divergent and conver-\ngent operations. Neuropsychologia, 83, 76–87.\nBartsch, M.V., Donohue, S.E., Strumpf, H., Schoenfeld,\nM.A. & Hopf, J.-M. (2018). Enhanced spatial focusing\nincreases feature-based selection in unattended locations.\nScientific Reports, 8 (Article no. 16132).\nBaruch, O., Kimchi, R. & Goldsmith, M. (2018). Attention to\ndistinguishing features in object recognition: An interac-\ntive-iterative framework. Cognition, 170, 228–244.\nBarzykowski, K. & Staugaard, S.R. (2016). Does retrieval\nintentionality really matter? Similarities and differences\nbetween involuntary memories and directly and gener-\natively retrieved voluntary memories. British Journal of\nPsychology, 107, 519–536.\nBasehore, Z. & Anderson, R.B. (2016). The simple life: New\nexperimental tests of the recognition heuristic. Judgment\nand Decision Making, 11, 301–309.\nBastin, C., Besson, G., Simon, J., Delhaye, E., Geurten, M.,\nWillems, S., et al. (2019). An integrative memory model\nof recollection and familiarity to understand memory\ndeficits. Behavioral and Brain Sciences, 1–66 (Epub 05\nFebruary 2019).\nBauer, A.J. & Just, M.A. (2017). A brain-based account of\n“basic-level” concepts. NeuroImage, 161, 196–205.\nBaumeister, R.F. & Masicampo, E.J. (2010). Conscious\nthought is for facilitating social and cultural interactions:\nHow mental simulations serve the animal-culture inter-\nface. Psychological Review, 117, 945–971.\nBaumeister, R.F., Lau, S., Maranges, H.M. & Clark, C.J.\n(2018). On the necessity of consciousness for sophist-\nicated human action. Frontiers in Psychology, 9 (Article\nno. 1925).\nCreated from usyd on 2022-02-18 03:51:57.",
    "830\nReferences\nsuppression of unwanted memories. NeuroImage, 48,\n726–737.\nBerisha, V., Wang, S., LaCross, A. & Liss, J. (2015). Tracking\ndiscourse complexity preceding Alzheimer’s disease diag-\nnosis: A case study comparing the press conferences of\nPresidents Ronald Reagan and George Herbert Walker\nBush. Journal of Alzheimer’s Disease, 45, 959–963.\nBerisha, V., Wang, S., LaCross, A., Liss, J. & Garcia-Filion,\nP. (2017). Longitudinal changes in linguistic complexity\namong professional football players. Brain & Language,\n169, 57–63.\nBerman, M.G., Jonides, J. & Lewis, R.L. (2009). In search of\ndecay in verbal short-term memory. Journal of Experi-\nmental Psychology: Learning, Memory, and Cognition,\n35, 317–333.\nBermúdez-Rattoni, F. & McGaugh, J.L. (2017). Memory\nreconsolidation and memory updating: Two sides of the\nsame coin? Neurobiology of Learning and Memory, 142,\n1–3.\nBerninger, V.W. & Abbott, R.D. (2010). Listening com-\nprehension, oral expression, reading comprehension,\nand written expression: Related yet unique language\nsystems in grades 1, 3, 5, and 7. Journal of Educational\nPsychology, 102, 635–651.\nBerntsen, D., Rubin, D.C. & Siegler, I.C. (2011). Two differ-\nent versions of life: Emotionally negative and positive\nlife events have different roles in the organisation of life\nstory and identity. Emotion, 11, 1190–1201.\nBerwick, R.C., Friederici, A.D., Chomsky, N. & Bolhuis, J.J.\n(2013). Evolution, brain, and the nature of language.\nTrends in Cognitive Sciences, 17, 89–98.\nBesson, G., Barragan-Jason, G., Thorpe, S.J., Fabre-Thorpe,\nM., Puma, S., Ceccaldi, M., et al. (2017). From face pro-\ncessing to face recognition: Comparing three different\nprocessing levels. Cognition, 158, 33–43.\nBeukema, P. & Verstynen, T. (2018). Predicting and binding:\nInteracting algorithms supporting the consolidation of\nsequential motor skills. Current Opinion in Behavioral\nSciences, 20, 98–103.\nBezdicek, O., Ballarini, T., Buschke, H., Ružička, F., Roth,\nJ., Albrecht, F., et al. (2019). Memory impairment in\nParkinson’s disease: The retrieval versus associative deficit\nhypothesis revisited and reconciled. Neuropsychology, 33,\n391–405.\nBezuidenhout, A. (2014). Reply to Brown-Schmidt and Heller.\nJournal of Pragmatics, 60, 285–290.\nBhatt, R.S. & Quinn, P.C. (2011). How does learning impact\ndevelopment in infancy? The case of perceptual organi-\nsation. Infancy, 16, 2–38.\nBialek, M. (2017). Not that neglected! Base rates influence\nrelated and unrelated judgements. Acta Psychologica,\n177, 10–16.\nBialek, M. & De Neys, W. (2017). Dual processes and moral\nconflict: Evidence for deontological reasoners’ intuitive\nutilitarian sensitivity. Judgment and Decision Making, 12,\n148–167.\nBickerton, D. (1984). The language bioprogram hypothesis.\nBehavioral and Brain Sciences, 7, 173–221.\nBidelman, G.M. & Walker, B.S. (2017). Attentional modula-\ntion and domain-specificity underlying the neural organ-\nisation of auditory categorical perception. European\nJournal of Neuroscience, 45, 690–699.\nBiederman, I. (1987). Recognition-by-components: A theory\nof human image understanding. Psychological Review,\n94, 115–147.\nBiederman, I. & Gerhardstein, P.C. (1993). Recognising\ndepth-rotated objects: Evidence for 3-D viewpoint\ninvariance. Journal of Experimental Psychology: Human\nPerception & Performance, 19, 1162–1182.\nBiedermann, B., Ruh, B., Nickels, L. & Coltheart, M.\n(2008). Information retrieval in tip-of-the-tongue states:\nNew data and methodological advances. Journal of\nPsycholinguistic Research, 37, 171–198.\nBier, N., Bottari, C., Hudon, C., Jobert, S., Paquette, G. &\nMacoir, J.L. (2013). The impact of semantic dementia\non everyday actions: Evidence from an ecological study.\nJournal of the International Neuropsychological Society,\n19, 162–172.\nBiggs, A.T. & Gibson, B.S. (2018). Opening the window: Size\nof the attentional window dominates perceptual load and\nfamiliarity in visual selection. Journal of Experimental\nPsychology: Human Perception and Performance, 44,\n1780–1798.\nBiggs, A.T., Brockmole, J.R. & Witt, J.K. (2013). Armed\nand attentive: Holding a weapon can bias attentional\npriorities in scene viewing. Attention, Perception &\nPsychophysics, 75, 1715–1724.\nBilalić, M. (2016). Revisiting the role of the fusiform face\narea in expertise. Journal of Cognitive Neuroscience, 28,\n1345–1357.\nBilalić, M., McLeod, P. & Gobet, F. (2008a). Inflexibility of\nexperts: Reality or myth? Quantifying the Einstellung\neffect in chess masters. Cognitive Psychology, 56, 73–102.\nBilalić, M., McLeod, P. & Gobet, F. (2008b). Why good\nthoughts block better ones: The mechanism of the perni-\ncious Einstellung effect. Cognition, 108, 652–661.\nBinder, E., Dovern, A., Hesse, M.D., Ebke, M., Karbe, H.,\nSaliger, J., et al. (2017). Lesion evidence for a human\nmirror neuron system. Cortex, 90, 125–137.\nBinder, J.R. & Desai, R.H. (2011). The neurobiology of\nsemantic memory. Trends in Cognitive Sciences, 15,\n527–536.\nBinder, J.R., Desai, R.H., Graves, W.W. & Conant, L.L.\n(2009). Where is the semantic system? A critical review\nand meta-analysis of 120 functional neuroimaging\nstudies. Cerebral Cortex, 19, 2767–2796.\nBindschaedler, C., Peter-Favre, C., Maeder, P., Hirsbrunner,\nT. & Clarke, S. (2011). Growing up with bilateral\nCreated from usyd on 2022-02-18 03:51:57.",
    "832\nReferences\nBorges, J.L. (1964). Labyrinths. London: Penguin.\nBorghesani, V. & Piazza, M. (2017). The neuro-cognitive\nrepresentations of symbols: The case of concrete words.\nNeuropsychologia, 105, 4–17.\nBorghesani, V., Buiatti, M., Eger, E. & Piazza, M. (2019).\nConceptual and perceptual dimensions of word meaning\nare recovered rapidly and in parallel during reading.\nJournal of Cognitive Neuroscience, 31, 95–108.\nBohrn, J.C., Altmann, U. & Jacobs, A.M. (2012). Looking\nat the brains behind figurative language. A quantitative\nmeta-analysis of neuroimaging studies on metaphor,\nidiom, and irony processing. Neuropsychologia, 50,\n2669–2683.\nBormann, T. & Weiller, C. (2012). “Are there lexicons?”\nA study of lexical and semantic processing in word-\nmeaning deafness suggests “yes”. Cortex, 48, 294–307.\nBormann, T., Wolfer, S., Hachmann, W., Neubauer, C. &\nKonieczny, L. (2015). Fast word reading in pure alexia:\n“Fast, yet serial”. Neurocase, 21, 251–267.\nBorst, J.P., Buwalda, T.A., van Rijn, H. & Taatgen, N.A.\n(2013). Avoiding the problem state bottleneck by stra-\ntegic use of the environment. Acta Psychologica, 144,\n373–379.\nBos, E.M., Spoor, J.K.H., Smits, M., Schouten, J.W. &\nVincent, A.J.P.E. (2016). Out-of-body experience during\nawake craniotomy. World Neurosurgery, 92 (Article no.\nUNSP 586.e9).\nBose, A. (2013). Phonological therapy in jargon aphasia:\nEffects on naming and neologisms. International\nJournal of Language & Communication Disorders, 48,\n582–595.\nBostyn, D.H., Sevenhant, S. & Roets, A. (2018). Of mice, men,\nand trolleys: Hypothetical judgement versus real-life\nbehaviour in trolley-style moral dilemmas. Psychological\nScience, 29, 1084–1093.\nBourke, L., Davies, S.J., Sumner, E. & Green, C. (2014).\nIndividual differences in the development of early writing\nskills: Testing the unique contribution of visuo-spatial\nworking memory. Reading and Writing, 27, 315–335.\nBourne, L.E., Kole, J.A. & Healy, A.F. (2015). Expertise:\nDefined, described, explained. Frontiers in Psychology, 5,\n211–213 (Article no. 186).\nBouvier, S.E. & Engel, S.A. (2006). Behavioural deficits and\ncortical damage loci in cerebral achromatopsia. Cerebral\nCortex, 16, 183–191.\nBowden, E.M., Jung-Beeman, M., Fleck, J. & Kounios, J.\n(2005). New approaches to demystifying insight. Trends\nin Cognitive Sciences, 9, 322–328.\nBowen, H.J., Kark, S.M. & Kensinger, E.A. (2018).\nNEVER forget: Negative emotional valence enhances\nrecapitulation. Psychonomic Bulletin & Review, 25,\n870–891.\nBower, G.H., Black, J.B. & Turner, T.J. (1979). Scripts in\nmemory for text. Cognitive Psychology, 11, 177–220.\nBowers, J.S. (2017a). Parallel distributed processing theory in\nthe age of deep networks. Trends in Cognitive Sciences,\n21, 950–961.\nBowers, J.S. (2017b). Grandmother cells and localist rep-\nresentations: A review of current thinking. Language,\nCognition and Neuroscience, 32, 257–273.\nBowers, J.S & Davis, C.J. (2012). Bayesian just-so stories in\npsychology and neuroscience. Psychological Bulletin,\n138, 389–414.\nBowles, B., Crupi, C., Pigott, S., Parrent, A., Wiebe, S.,\nJanzen, L., et al. (2010). Double dissociation of select ive\nrecollection and familiarity impairments following two\ndifferent surgical treatments for temporal-lobe  epilepsy.\nNeuropsychologia, 48, 2640–2647.\nBowles, B., O’Neil, E.B., Mirsattari, S.M., Poppenk, J. &\nKöhler, S. (2011). Preserved hippocampal novelty\nresponses following anterior temporal-lobe resection that\nimpairs familiarity but spares recollection. Hippocampus,\n21, 847–854.\nBrainard, D.H. & Maloney, L.T. (2011). Surface colour per-\nception and equivalent illumination models. Journal of\nVision, 11, 1–18.\nBrainerd, C.J. & Mojardin, A.H. (1998). Children’s sponta-\nneous memories for narrative statements: Long-term\npersistence and testing effects. Child Development, 69,\n1361–1377.\nBrainerd, C.J., Gomes, C.F.A. & Moran, R. (2014). The two\nrecollections. Psychological Review, 121, 563–599.\nBrainerd, C.J., Reyna, V.F. & Ceci, S.J. (2008). Developmental\nreversals in false memory: A review of data and theory.\nPsychological Bulletin, 134, 343–382.\nBramão, I. & Johansson, M. (2017). Benefits and costs of\ncontext reinstatement in episodic memory: An ERP\nstudy. Journal of Cognitive Neuroscience, 29, 52–64.\nBraňas-Garza, P., Kujal, P. & Lenkei, B. (2015). Cognitive\nreflection test: Whom, how, when. ESI Working Paper,\n15–25.\nBrandt, A., Gebrian, M. & Slevc, L.R. (2012). Music and\nearly language acquisition. Frontiers in Psychology,\n3 (Article no. 327).\nBrandt, K.R., Eysenck, M.W., Nilsen, M.K. & Von Oertzen,\nT.J. (2016). Selective lesion to the entorhinal cortex leads\nto an impairment in familiarity but not recollection.\nBrain and Cognition, 104, 82–92.\nBransford, J.D. & Johnson, M.K. (1972). Contextual prereq-\nuisites for understanding. Journal of Verbal Learning and\nVerbal Behavior, 11, 717–726.\nBransford, J.D., Barclay, J.R. & Franks, J.J. (1972). Sentence\nmemory: A constructive versus interpretive approach.\nCognitive Psychology, 3, 193–209.\nBrase, G.L. (2014). Behavioural science integration: A prac-\ntical framework of multi-level converging evidence for\nbehavioural science theories. New Ideas in Psychology,\n33, 8–20.\nCreated from usyd on 2022-02-18 03:51:57.",
    "834\nReferences\ndependent on between-task conflict? Psychological\nResearch, 82, 92–108.\nBruno, N. & Cutting, J.E. (1988). Mini-modularity and\nthe perception of layout. Journal of Experimental\nPsychology, 117, 161–170.\nBruno, N., Bernardis, P. & Gentilucci, M. (2008). Visually\nguided pointing, the Müller-Lyer illusion, and the\nfunctional interpretation of the dorsal-ventral split:\nConclusions from 33 independent studies. Neuroscience\nand Biobehavioral Reviews, 32, 4213–4437.\nBrunyé, T.T., Carney, P.A., Allison, K.H., Shapiro, L.G. &\nWeaver, D.L. (2014). Eye movements as an index of\npathologist visual expertise: A pilot study. PLoS ONE, 9\n(Article no. e103447).\nBrunyé, T.T., Taylor, H.A. & Rapp, D.N. (2008). Working\nmemory in developing and applying mental models from\nspatial descriptions. Journal of Memory and Language,\n58, 701–729.\nBrusovansky, M., Glickman, M. & Usher, M. (2018). Fast\nand effective: Intuitive processes in complex decisions.\nPsychonomic Bulletin & Review, 25, 1542–1548.\nBruyer, R. (2011). Configural face processing: A meta- analytic\nsurvey. Perception, 40, 1478–1490.\nBrysbaert, M. & Mitchell, D.C. (1996). Modifier attachment\nin sentence parsing: Evidence from Dutch. Quarterly\nJournal of Experimental Psychology, 49, 664–695.\nBuchanan, T.W., Tranel, D. & Adolphs, R. (2006). Memories\nfor emotional autobiographical events following uni-\nlateral damage to medial temporal lobe. Brain, 129,\n115–127.\nBuckley, M.J. & Mitchell, A.S. (2016). Retrosplenial cortical\ncontributions to anterograde and retrograde amnesia in\nthe monkey. Cerebral Cortex, 26, 2905–2918.\nBuckthought, A., Yoonessi, A. & Balker, C.L. (2017).\nDynamic perspective cues enhance depth perception\nfrom motion parallax. Journal of Vision, 17, 1–19.\nBuetler, K.A., Rodriguez, D.L., Leganaro, M., Műri, R.,\nSpierer, L. & Annoni, J.-M. (2014). Language context\nmodulates reading route: An electrical neuroimaging\nstudy. Frontiers in Human Neuroscience, 8 (Article no.\n83).\nBullmore, E. & Sporns, O. (2012). The economy of brain\nnetwork organisation. Nature Reviews Neuroscience, 13,\n336–349.\nBülthoff, I., Bülthoff, H. & Sinha, P. (1998). Top-down\ninfluences on stereoscopic depth-perception. Nature\nNeuroscience, 1, 254–257.\nBurdett, B.R.D., Charlton, S.G. & Starkey, N.J. (2018). Inside\nthe commuting driver’s wandering mind. Transportation\nResearch Part F, 57, 59–74.\nBurgess, P.W., Gilbert, S.J. & Dumontheil, I. (2007). Function\nand localisation within rostral prefrontal cortex (area\n10). Philosophical Transactions of the Royal Society B:\nBiological Sciences, 362, 887–899.\nBurgoyne, A.P., Sala, G., Gobet, F., Macnamara, B.N.,\nCampitelli, G. & Hambrick, D.Z. (2016). The relation-\nship between cognitive ability and chess skill: A compre-\nhensive meta-analysis. Intelligence, 59, 72–83.\nBürki, A., Sadat, J., Dubarry, A.-S. & Alario, F.-X. (2016).\nSequential processing during noun phrase production.\nCognition, 146, 90–99.\nBurnham, B.R., Sabia, M. & Langan, C. (2014). Components\nof working memory and visual selective attention.\nJournal of Experimental Psychology: Human Perception\nand Performance, 40, 391–403.\nBurns, B.D. (2004). The effects of speed on skilled chess per-\nformance. Psychological Science, 15, 442–447.\nBurns, B.D. & Wieth, M. (2004). The collider principle in\ncausal reasoning: Why the Monty Hall dilemma is so\nhard. Journal of Experimental Psychology: General, 133,\n434–449.\nBurton, A.M., Kramer, R.S.S., Ritchie, K.L. & Jenkins, R.\n(2016). Identity from variation: Representations of faces\nderived from multiple instances. Cognitive Science, 40,\n202–223.\nBusigny, T., Graf, M., Mayer, E. & Rossion, B. (2010a).\nAcquired prosopagnosia as a face-specific  disorder:\nRuling out the general visual similarity account. Neuro-\npsychologia, 48, 2051–2067.\nBusigny, T., Joubert, S., Felician, O., Ceccaldi, M. & Rossion,\nB. (2010b). Holistic perception of the individual face is\nspecific and necessary: Evidence from an extensive case\nstudy of acquired prosopagnosia. Neuropsychologia, 48,\n4057–4092.\nButterworth, B. (1985). Jargon aphasia: Processes and\nstrategies. In S. Newman & R. Epstein (eds), Current\nPerspectives in Dysphasia (pp. 61–96). Edinburgh:\nChurchill Livingstone.\nByrne, M.D. (2012). Unified theories of cognition. Wiley\nInterdisciplinary Reviews – Cognitive Science, 3, 431–438.\nCabeza, R., Stanley, M.L. & Moscovitch, M. (2018). Process-\nspecific alliances (PSAs) in cognitive neuroscience.\nTrends in Cognitive Sciences, 22, 996–1010.\nCaccappolo-van Vliet, E., Miozz, M. & Stern, Y. (2004).\nPhonological dyslexia: A test case for reading models.\nPsychological Science, 15, 583–590.\nCaharel, S., Ramon, M. & Rossion, B. (2014). Face famil-\niarity decisions take 200ms in the human brain:\nElectrophysiological evidence from a go/no-go speeded\ntask. Journal of Cognitive Neuroscience, 26, 81–95.\nCahill, L., Babinsky, R., Markowitsch, H.J. & McGaugh, J.L.\n(1995). Involvement of the amygdaloid complex in emo-\ntional memory. Nature, 377, 295–296.\nCahir, C. & Thomas, K. (2010). Asymmetric effects of positive\nand negative affect on decision making. Psychological\nReports, 106, 193–204.\nCai, Z.G., Gilbert, R.A., Davis, M.H., Gaskell, M.G., Farrar,\nL., Adler, S., et al. (2017). Accent modulates access to\nCreated from usyd on 2022-02-18 03:51:57.",
    "836\nReferences\nCeci, S.J. & Liker, J.K. (1986). A day at the races: A study\nof IQ, expertise, and cognitive complexity. Journal of\nExperimental Psychology: General, 115, 255–266.\nCeleghin, A., Bagnis, A., Diano, M., Méndez, C.A., Costa,\nT. & Tamietto, M. (2019). Functional neuroanat-\nomy of blindsight revealed by activation likelihood\nestimation\nmeta-analysis.\nNeuropsychologia,\n128,\n109–118.\nCeraso, J. & Provitera, A. (1971). Sources of error in syllogis-\ntic reasoning. Cognitive Psychology, 2, 400–410.\nCermak, L.S., Talbot, N., Chandler, K. & Wolharst, L.R.\n(1985). The perceptual priming phenomenon in amnesia.\nNeuropsychologia, 23, 615–622.\nChabanat, E., Jacquin-Courtois, S., Havé, L., Kihoulou, C.,\nTilikete, C., Mauguière, F., et al. (2019). Can you guess\nthe colour of this moving object? A dissociation between\ncolour and motion in blindsight. Neuropsychologia, 128,\n204–208.\nChallis, B.H., Velichkovsky, B.M. & Craik, F.I.M. (1996).\nLevels-of-processing effects on a variety of memory\ntasks: New findings and theoretical implications.\nConsciousness and Cognition, 5, 142–164.\nChalloner, J. (2009). 1,001 Inventions That Changed the World.\nHauppauge, NY: Barron’s Educational Series.\nChalmers, D. (2007). The hard problem of consciousness.\nIn M. Velmans & S. Schneider (eds), The Blackwell\nCompanion to Consciousness (pp. 225–235). Oxford:\nBlackwell.\nChamberlain, F. (2003). Review of “Behavioural Assessment\nof the Dysexecutive Syndrome (BADS)”. Journal of\nOccupational Psychology, 5, 33–37.\nChampod, C. (2015). Fingerprint identification: Advances\nsince the 2009 National Research Council report.\nPhilosophical Transactions of the Royal Society: B, 370,\n20140259.\nChan, E., MacPherson, S.E., Bozzali, M., Shallice, T. &\nCipolotti, L. (2018). The influence of fluid intelligence,\nexecutive functions and premorbid intelligence on\nmemory in frontal patients. Frontiers in Psychology, 9\n(Article no. 926).\nChan, J., Paletz, S.B.F. & Schunn, C.D. (2012). Analogy as a\nstrategy for supporting complex problem solving under\nuncertainty. Memory & Cognition, 40, 1352–1365.\nChan, J.C.K. & LaPaglia, J.A. (2013). Impairing existing\ndeclarative memory in humans by disrupting reconsoli-\ndation. Proceedings of the National Academy of Sciences,\n110, 9309–9313.\nChan, J.C.K., Manley, K.D. & Lang, K. (2017). Retrieval-\nenhanced suggestibility: A retrospective and a new inves-\ntigation. Journal of Applied Research in Memory and\nCognition, 6, 213–229.\nChang, H. & Rosenholtz, R. (2016). Search performance is\nbetter predicted by tileability than presence of a unique\nbasic feature. Journal of Vision, 16 (Article no. 13).\nChang, J.Y. & Lane, D.M. (2016). There is time for calcula-\ntion in speed chess, and calculation accuracy increases\nwith expertise. American Journal of Psychology, 129, 1–9.\nChaplin, T.A., Hagan, M.A., Allitt, B.J. & Lul, L.L. (2018).\nNeuronal correlations in MT and MST impair popu-\nlation decoding of opposite directions of random dot\nmotion. ENeuro, 5 (Article no. UNSP e0336–1.2018).\nCharness, N., Reingold, E.M., Pomplun, M. & Stampe,\nD.M. (2001). The perceptual aspect of skilled perform-\nance in chess: Evidence from eye movements. Memory &\nCognition, 29, 1146–1152.\nCharpentier, C.J., Aylward, J., Roiser, J.P. & Robinson, O.J.\n(2017). Enhanced risk aversion, but not loss aversion, in\nunmediated pathological anxiety. Biological Psychology,\n81, 1014–1022.\nCharpentier, C.J., De Neve, J.-E., Li, X., Roiser, J.P. &\nSharot, T. (2016). Models of affective decision making:\nHow do feelings predict choice? Psychological Science,\n27, 763–775.\nChater, N. & Christiansen, M.H. (2018). Language acqui-\nsition as skill learning. Current Opinion in Behavioral\nSciences, 21, 205–208.\nChater, N., McCauley, S.M. & Christiansen, M.H. (2016).\nLanguage as skill: Intertwining comprehension and pro-\nduction. Journal of Memory and Language, 89, 244–254.\nChee, Q.W. & Goh, W.D. (2018). What explains the von\nRestorff effect? Contrasting distinctive processing and\nretrieval cue efficacy. Journal of Memory and Language,\n99, 49–61.\nCheek, N.N. & Shwartz, B. (2016). On the meaning and\nmeasurement of maximisation. Judgment and Decision\nMaking, 11, 126–146.\nChekaf, M., Cowan, N. & Mathy, F. (2016). Chunk forma-\ntion in immediate memory and how it relates to data.\nCognition, 155, 96–107.\nChen, C.C. & Tyler, C.W. (2015). Shading beats binocular\ndisparity in depth from luminance gradients: Evidence\nagainst a maximum likelihood principle for cue combi-\nnation. PloS ONE, 10 (Article no. e0132658).\nChen, J., Lun, X., Guo, Y., Zhang, Y. & Gong, D. (2017). A\nsurvey on breaking techniques of text-based CAPTCHA.\nSecurity and Communication Networks, 2017 (Article no.\nUNSP 6898617).\nChen, J., Sperandio, I. & Goodale, M.A. (2018a).\nProprioceptive distance cues restore perfect size con-\nstancy in grasping, but not perception, when vision is\nlimited. Current Biology, 26, 927–932.\nChen, Q. & Mirman, D. (2012). Competition and cooperation\namong similar representations: Toward a unified account\nof facilitative and inhibitory effects of lexical neighbours.\nPsychological Review, 119, 417–430.\nChen, S., Wu, X., Wang, L., Wang, Y., Wu, B., Ge, M., et al.\n(2018b). Disrupted interactions between arousal and cor-\ntical awareness networks in MCS and VS/UWS patients:\nCreated from usyd on 2022-02-18 03:51:57.",
    "838\nReferences\nand individuating information. Journal of Personality\nand Social Psychology, 91, 205–217.\nChung, S. (2012). Are lexical categories universal? The view\nfrom Chamorro. Theoretical Linguistics, 38, 1–56.\nChurchland, P.S. & Sejnowski, T.J. (1988). Perspectives on\ncognitive neuroscience. Science, 242, 741–745.\nChuy, M., Scardamalia, M. & Bereiter, C. (2012).\nDevelopment of ideational writing through knowl-\nedge building: Theoretical and empirical bases. In E.L.\nGrigorenko, E. Mambrino & D. Preiss (eds), Writing:\nA mosaic of New Perspectives (pp. 175–190). Hove, UK:\nPsychology Press.\nCisler, J.M. & Koster, E.H.W. (2010). Mechanisms of atten-\ntional biases towards threat in anxiety disorders: An inte-\ngrative review. Clinical Psychology Review, 30, 203–216.\nClancy, S.A. & McNally, R.J. (2005/2006). Who needs repres-\nsion? Normal memory processes can explain “forgetting”\nof childhood sexual abuse. Scientific Review of Mental\nHealth Practice, 4, 66–73.\nClark, C.M., Lawlor-Savage, L. & Goghari, V.M. (2017).\nComparing brain activations associated with working\nmemory and fluid intelligence. Intelligence, 63, 66–77.\nClark, G.M., Lum, J.A.G. & Ullman, M.T. (2014). A\nmeta-analysis and meta-regression of serial reaction time\nperformance in Parkinson’s disease. Neuropsychology,\n28, 945–958.\nClark, I.A. & Maguire, E.A. (2016). Remembering pres-\nervation in hippocampal amnesia. Annual Review of\nPsychology, 67, 51–82.\nClark, L.A. & Watson, D. (1991). Tripartite model of anxiety\nand depression: Psychometric evidence and taxonomic\nimplications. Journal of Abnormal Psychology, 100,\n316–336.\nClarke, J. & Mack, A. (2015). Iconic memory for natural\nscenes: Evidence using a modified change-detection pro-\ncedure. Visual Cognition, 23, 917–938.\nClay, Z. & Genty, E. (2017). Natural communication in\nbonobos: Insights into social awareness and the evo-\nlution of language. In B. Hare & S. Yamamoto (eds),\nBonobos: Unique in mind, brain, and behaviour (pp. 105–\n122). Oxford: Oxford University Press.\nClifton, C., Ferreira, F., Henderson, J.M., Inhoff, A.W.,\nLiversedge, S.P., Reichle, E.D., et al. (2016). Eye\nmovements in reading and information processing:\nKeith Rayner’s 40 year legacy. Journal of Memory and\nLanguage, 86, 1–19.\nClore, G.L., Schiller, A.J. & Shaked, A. (2018). Affect\nand cognition: Three principles. Current Opinion in\nBehavioral Science, 19, 78–82.\nClose, J. & Pothos, E.M. (2012). “Object categorisation:\nReversals and explanations of the basic-level advan-\ntage” (Rogers & Patterson, 2007): A simplicity account.\nQuarterly Journal of Experimental Psychology, 65,\n1615–1632.\nCoch, D., Sanders, L.D. & Neville, H.J. (2005). An event-\nrelated potential study of selective auditory attention in\nchildren and adults. Journal of Cognitive Neuroscience,\n17, 606–622.\nCoco, M.I. & Keller, F. (2015). The interaction of visual and\nlinguistic saliency during syntactic ambiguity resolution.\nQuarterly Journal of Experimental Psychology, 68, 46–74.\nCoetzee, J.P. & Monti, M.M. (2018). At the core of reasoning:\nDissociating deductive and non-deductive load. Human\nBrain Mapping, 39, 1850–1861.\nCoget, J.-F., Haag, C. & Gibson, D.E. (2011). Anger and fear\nin decision-making: The case of film directors on set.\nEuropean Management Journal, 29, 476–490.\nCohen, L.R. (2002). The role of experience in the perception of\nbiological motion. Dissertation Abstracts International:\nSection B: The Sciences & Engineering, 63, 3049.\nCohen, M.A., Alvarez, G.A. & Nakayama, K. (2011).\nNatural-scene perception requires attention. Psycho-\nlogical Science, 22, 1165–1172.\nCohen, M.A., Cavanagh, P., Chun, M.M. & Nakayama, K.\n(2012). The attentional requirements of consciousness.\nTrends in Cognitive Sciences, 16, 411–417.\nCohen, M.A., Dennett, D.C. & Kanwisher, N. (2016). What\nis the bandwidth of perceptual experience? Trends in\nCognitive Sciences, 20, 324–335.\nColavita, F.B. (1974). Human sensory dominance. Perception\n& Psychophysics, 16, 409–412.\nCole, J. (2015). Prosody in context: A review. Language,\nCognition and Neuroscience, 30, 1–31.\nCollegio, A.J., Nah, J.C., Scott, P.S. & Schomstein, S. (2019).\nAttention scales according to inferred real-world object\nsize. Nature Human Behaviour, 3, 140–147.\nCollette, F., Van der Linden, M., Laureys, S., Delfiore, G.,\nDegueldre, C., Luxen, A., et al. (2005). Exploring the\nunity and diversity of the neural substrates of executive\nfunctioning. Human Brain Mapping, 25, 409–423.\nCollin, G., Sporns, O., Mandl, R.C.W. & van den Heuvel,\nM.P. (2014). Structural and functional aspects relat-\ning to costs and benefit of rich club organisation in the\nhuman cerebral cortex. Cerebral Cortex, 24, 2258–2267.\nCollins, A.M. & Loftus, E.F. (1975). A spreading-activation\ntheory of semantic processing. Psychological Review, 82,\n407–428.\nCollins, W.M. & Daniel, F. (2018). The impact of reading at\nrapid rates on inference generation. Journal of Research\nin Reading, 41, 564–581.\nColman, A.M. (2015). Oxford Dictionary of Psychology (4th\nedn). Oxford: Oxford University Press.\nColomb, C. & Ginet, M. (2012). The cognitive interview\nfor use with adults: An empirical test of an alternative\nmnemonic and of a partial protocol. Applied Cognitive\nPsychology, 26, 35–47.\nColombo, L., Fudio, S. & Mosna, G. (2009). Phonological\nand working memory mechanisms involved in written\nCreated from usyd on 2022-02-18 03:51:57.",
    "840\nReferences\ncomprehension? A study of executive processs and\nsemantic knowledge in dementia. Neuropsychology, 20,\n307–318.\nCoste, C.P. & Kleinschmidt, A. (2016). Cingulo-opercular\nnetwork activity maintains alertness. NeuroImage, 128,\n264–272.\nCostello, F.J. & Keane, M.T. (2000). Efficient creativity:\nConstraint-guided conceptual combination. Cognitive\nScience, 24, 299–349.\nCowen, A.S. & Keltner, D. (2017). Self-report captures 27 dis-\ntinct categories of emotion bridged by continuous gra-\ndients. Proceedings of the National Academy of Sciences,\n114, E7900–E7909.\nCowen, A.S. & Keltner, D. (2018). Clarifying the concep-\ntualization, dimensionality, and structure of emotion:\nResponse to Barrett and colleagues. Trends in Cognitive\nSciences, 22, 274–276.\nCowley, M.B. (2015). Hypothesis falsification in the 2-4-6\nnumber sequence test: Introducing imaginary counter-\nparts. Philosophy of Mind eJournal, 8, 3–44.\nCowley, M.B. & Byrne, R.M.J. (2005). When falsification\nis the only path to truth. In B.G. Bara, L. Barsalou &\nM. Bucciarelli (eds), Proceedings of the Twenty-Seventh\nAnnual Conference of the Cognitive Science Societ\n(pp. 512–517). Mahwah, NJ: Erlbaum.\nCowley, S.J. & Harvey, M.I. (2016). The illusion of common\nground. New Ideas in Psychology, 42, 56–63.\nCox, W.T.L. & Devine, P.G. (2016). Experimental research\non shooter bias: Ready (or relevant) for application in\nthe courtroom? Journal of Applied Research in Memory\nand Cognition, 5, 236–238.\nCraik, F.I.M. (2002). Levels of processing: Past, present . . .\nand future? Memory, 10, 305–318.\nCraik, F.I.M. & Lockhart, R.S. (1972). Levels of processing:\nA framework for memory research. Journal of Verbal\nLearning and Verbal Behavior, 11, 671–684.\nCraik, F.I.M. & Tulving, E. (1975). Depth of processing and\nthe retention of words in episodic memory. Journal of\nExperimental Psychology: General, 104, 268–294.\nCrawford, J.R., Smith, G., Maylor, E.A., Della Sala, S. &\nLogie, R.H. (2003). The Prospective and Retrospective\nMemory Questionnaire (PRMQ): Normative data and\nlatent structure in a large non-clinical sample. Memory,\n11, 261–275.\nCraycraft, N.N. & Brown-Schmidt, S. (2018). Compensating\nfor an inattentive audience. Cognitive Science, 42,\n1509–1528.\nCreem, S.H. & Proffitt, D.R. (2001). Grasping objects by their\nhandles: A necessary interaction between cognition and\naction. Journal of Experimental Psychology: Human\nPerception and Performance, 27, 218–228.\nCrescentini, C., Seyed-Allaei, S., Vallesi, A. & Shallice, T.\n(2012). Two networks involved in producing and realis-\ning plans. Neuropsychologia, 50, 1521–1535.\nCrible, L. (2017). Discourse markers and (dis)fluencies in\nEnglish and French: Variation and combination in\nthe DisFrEn corpus. International Journal of Corpus\nLinguistics, 22, 242–269.\nCrisp, J., Howard, D. & Lambon Ralph, M.A. (2011). More\nevidence for a continuum between phonological and\ndeep dyslexia: Novel data from three measures of direct\northography-to-phonology translation. Aphasiology, 25,\n615–641.\nCristea, I.A., Kok, R.N. & Cuijpers, P. (2015). Efficacy of\ncognitive bias modification interventions in anxiety and\ndepression: Meta-analysis. British Journal of Psychiatry,\n206, 7–16.\nCroskerry, P. (2018). Medical decision making. In L.J. Ball &\nV.A. Thompson (eds), Routledge International Handbook\nof Thinking and Reasoning (pp. 109–129). Abingdon,\nOxon.: Routledge.\nCrupi, V., Elia, F., Aprà, F. & Tentori, K. (2018). Double\nconjunction fallacies in physicians’ probability judge-\nment. Medical Decision Making, 38, 756–760.\nCruse, D., Chennu, S., Chatelle, C., Bekinschtein, T.A.,\nFernandez-Espejo, D., Pickard, J.D., et al. (2011).\nBedside detection of awareness in the vegetative state.\nLancet, 378, 2088–2094.\nCryder, C.E., Lerner, J.S., Gross, J.J. & Dahl, R.E. (2008).\nMisery is not miserly: Sad and self-focused individuals\nspend more. Psychological Science, 19, 525–530.\nCrystal, D. (1997). A Dictionary of Linguistics and Phonetics\n(4th edn). Cambridge, MA: Blackwell.\nCrystal, D. (2005). Speaking of writing and writing of speak-\ning. Longman’s Language Review, 1, 5–8.\nCuriel, J.M. & Radvansky, G.A. (2014). Spatial and char-\nacter situation model updating. Journal of Cognitive\nPsychology, 26, 205–212.\nCurot, J., Busigny, T., Valton, L., Denuelle, M., Vignal, J.-P.,\nMaillard, L., et al. (2017). Memory scrutinized through\nelectrical brain stimulation: A review of 80 years of\nexperiential phenomena. Neuroscience and Biobehavioral\nReviews, 78, 161–177.\nCutler, A. & Butterfield, S. (1992). Rhythmic cues to speech\nsegmentation: Evidence from juncture misperception.\nJournal of Memory and Language, 31, 218–236.\nCuttler, C. & Graf, P. (2009a). Checking-in on the memory\ndeficit and meta-memory deficit theories of com-\npulsive checking. Clinical Psychology Review, 29,\n393–409.\nCuttler, C. & Graf, P. (2009b). Sub-clinical compulsive check-\ners show impaired performance on habitual, event- and\ntime-cued episodic prospective memory tasks. Journal of\nAnxiety Disorders, 23, 813–823.\nCvejic, E., Kim, J. & Davis, C. (2012). Recognising prosody\nacross modalities, face areas and speakers: Examining\nperceivers’ sensitivity to variable realisations of visual\nprosody. Cognition, 122, 442–453.\nCreated from usyd on 2022-02-18 03:51:57.",
    "842\nReferences\nde Gardelle, V., Sackur, J. & Kouider, S. (2009). Perceptual\nillusions in brief visual presentations. Consciousness and\nCognition, 18, 569–577.\nde Gardelle, V., Waszczuk, M., Egner, T. & Summerfield,\nC. (2013). Concurrent repetition enhancement and sup-\npression responses in extrastriate visual cortex. Cerebral\nCortex, 23, 2235–2244.\nDegno, F., Loberg, O., Zang, C.L., Zhang, M.M., Donnelly,\nN. & Liversedge, S.P. (2019). Parafoveal previews and\nlexical frequency in natural reading: Evidence from eye\nmovements and fixation-related potentials. Journal of\nExperimental Psychology: General, 148, 453–473.\nde Graaf, T.A., Hsieh, P.-J. & Sack, A.T. (2012). The “corre-\nlates” in neural correlates of consciousness. Neuroscience\nand Biobehavioral Reviews, 16, 191–197.\nDe Groot, A.D. (1965). Thought and Choice in Chess. The\nHague, Netherlands: Mouton.\nde Haan, E.H.F., Jackson, S.R. & Schenk, T. (2018). Where\nare we now with “what” and “how”? Cortex, 98, 1–7.\nde Haan, B., Karnath, H.-O. & Driver, J. (2012). Mechanisms\nand anatomy of unilateral extinction after brain injury.\nNeuropsychologia, 50, 1045–1053.\nDehaene, S. & Changeux, J.P. (2011). Experimental and the-\noretical approaches to conscious processing. Neuron, 70,\n200–227.\nDelaney, P.F., Ericsson, K.A. & Knowles, M.E. (2004).\nImmediate and sustained effects of planning in a problem-\nsolving task. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 30, 1219–1234.\nde la Rosa, S., Schillinger, F.L., Bülthoff, H.H., Schultz,\nJ. & Uludag, K. (2016). fMRI adapation between\naction observation and action execution reveals corti-\ncal areas with mirror neuron properties in human BA\n44/45. Frontiers in Human Neuroscience, 10 (Article\nno. 78).\nDel Cul, A., Dehaene, S., Reyes, P., Bravo, E. & Slachevsky,\nA. (2009). Causal role of prefrontal cortex in the thresh-\nold for access to consciousness. Brain, 132, 2531–2540.\nDel Guidice, M. & Ellis, B.J. (2015). Evolutionary foundations\nof developmental psychopathology. In D. Ciccetti (ed.),\nDevelopmental Psychopathology, Vol. 2: Developmental\nneuroscience (3rd edn) (pp. 1–58). New York: Wiley.\nDell, G.S. (1986). A spreading-activation theory of retrieval in\nsentence production. Psychological Review, 93, 283–321.\nDell, G.S. (2013). Cascading and feedback in interactive\nmodels of production: A reflection of forward model-\nling? Behavioral and Brain Sciences, 36, 351–352.\nDell, G.S. & Caramazza, A. (2008). Introduction to special\nissue on computational modelling in cognitive neuropsy-\nchology. Cognitive Neuropsychology, 25, 131–135.\nDell, G.S. & Oppenheim, G.M. (2015). Insights for speech\nproduction planning from errors in inner speech. In\nM.A. Redford (ed.), The Handbook of Speech Production\n(pp. 404–418). Hoboken, NJ: Wiley-Blackwell.\nDell, G.S., Burger, L.K. & Svec, W.R. (1997). Language pro-\nduction and serial order: A functional analysis and a\nmodel. Psychological Review, 104, 123–147.\nDell, G.S., Nozari, N. & Oppenheim, G.M. (2014). Word\nproduction: Behavioural and computational considera-\ntions. In M. Goldrick, V. Ferreira & M. Miozzo (eds),\nThe Oxford Handbook of Language Production. Oxford:\nOxford University Press.\nDell, G.S., Oppenheim, G.M. & Kitttredge, A.K. (2008).\nSaying the right word at the right time: Syntagmatic\nand paradigmatic interference in sentence production.\nLanguage and Cognitive Processes, 23, 583–608.\nDeLong, K.A., Urbach, T.P. & Kutas, M. (2005).\nProbabilisltic word activation during language compre-\nhension inferred from electrical brain activity. Nature\nNeuroscience, 8, 1117–1121.\nDeLucia, P.R. (2013). Effects of size on collision perception\nand implications for perceptual theory and transporta-\ntion safety. Current Directions in Psychological Science,\n22, 199–204.\ndel Prete, F., Hanczakowski, M., Bajo, M.T. & Mazzoni, G.\n(2015). Inhibitory effects of thought substitution in the\nthink/no-think task: Evidence from independent cues.\nMemory, 23, 507–517.\nde Manzano, O. & Ullén, F. (2018). Same genes, different\nbrains: Neuroanatomical differences between mono-\nzygotic twins discordant for musical training. Cerebral\nCortex, 28, 387–394.\nDe Martino, B., Camerer, C.F. & Adolphs, R. (2010).\nAmydala damage eliminates monetary loss aversion.\nProceedings of the National Academy of Sciences, 107,\n3788–3792.\nDemertzi, A., Soddu, A. & Laureys, S. (2013). Consciousness\nsupporting networks. Current Opinion in Neurobiology,\n23, 239–244.\nDeMiguel, V., Garlappi, L. & Budescu, D.V. (2009). Optimal\nversus naïve diversification: How inefficient is the 1/N\nportfolio strategy? Review of Financial Studies, 22,\n1915–1953.\nDemiray, B. & Janssen, S.M.J. (2015). The self-enhancement\nfunction of autobiographical memory. Applied Cognitive\nPsychology, 29, 49–60.\nDe Neys, W. (2006). Dual processing in reasoning: Two\nsystems but one reasoner. Psychological Science, 17,\n428–433.\nDe Neys, W. (2012). Bias and conflict: A case for logical intui-\ntions. Perspectives on Psychological Science, 7, 28–38.\nDe Neys, W. (2014). Conflict detection, dual processes,\nand logical intuitions: Some clarifications. Thinking &\nReasoning, 20, 169–187.\nDe Neys, W., Cromheeke, S. & Osman, M. (2011). Feeling\nwe’re biased: Autonomic arousal and reasoning con-\nflict. Cognitive, Affective & Behavioral Neuroscience, 12,\n123–130.\nCreated from usyd on 2022-02-18 03:51:57.",
    "844\nReferences\nDismukes, R.K. (2012). Prospective memory in workplace and\neveryday situations. Current Directions in Psychological\nScience, 21, 215–220.\nDismukes, R.K. & Nowinski, J.L. (2006). Prospective\nmemory, concurrent task management, and pilot\nerror. In A. Kramer, D. Wiegmann & A. Kirlik (eds),\nAttention: From theory to practice (pp. 223–238). Oxford:\nOxford University Press.\nDi Stasi, L.L. & Guardini, P. (2007). Perceiving affordances\nin virtual environments: Visual guidance of virtual stair\nclimbing. Perception, 36 (Suppl. S), 186.\nDitto, P.H., Scepansky, J.A., Munro, G.D., Apanovitch,\nA.M. & Lockhart, L.K. (1998). Motivated sensitiv-\nity to preference inconsistent information. Journal of\nPersonality and Social Psychology, 75, 53–69.\nDodhia, R.M. & Dismukes, K.R. (2009). Interruptions create\nprospective memory tasks. Applied Cognitive Psychology,\n23, 73–89.\nDöhring, J., Stoldt, A., Witt, K., Schönfeld, R., Deuschl, G.,\nBorn, J., et al. (2017). Motor skill learning and offline-\nchanges in TGA patients with acute hippocampal CA1\nlesions. Cortex, 89, 156–168.\nDolcos, F., Katsumi, Y., Weymar, M., Moore, M., Tsukiura,\nT. & Dolcos, S. (2017). Emerging directions in emotional\nepisodic memory. Frontiers in Psychology, 8 (Article no.\n1867).\nDomeier, M., Sachse, P. & Schäfer, B. (2018). Motivational\nreasons for biased decisions: The sunk-cost effect’s\ninstrumental rationality. Frontiers in Psychology, 9\n(Article no. 815).\nDomini, F., Shah, R. & Caudek, C. (2011). Do we  perceive\na flattened world on the monitor screen? Acta Psycho-\nlogica, 138, 359–366.\nDomurat, A., Kowalczuk, O., Idzikowska, K., Borzymowska,\nZ. & Nowak-Przygodzka, M. (2015). Bayesian proba-\nbility estimates are not necessary to make choices satis-\nfying Bayes’ rule in elementary situations. Frontiers in\nPsychology, 6, 1–14.\nDonovan, I., Pratt, J. & Shomstein, S. (2017). Spatial atten-\ntion is necessary for object-based attention: Evidence\nfrom temporal-order judgements. Attention, Perception\n& Psychophysics, 79, 753–764.\nDoré,\nB.P.,\nSilvers,\nJ.A.\n&\nOchsner,\nK.N.\n(2016).\nToward a personalized science of emotion regula-\ntion. Social and Personality Psychology Compass, 10,\n171–187.\nDosenbach, N.U.F., Fair, D.A., Cohen, A.L., Schlaggar, B.L.\n& Petersen, S.E. (2008). A dual-networks architecture\nof top-down control. Trends in Cognitive Sciences, 12,\n99–105.\nDouglass, A.B. & Steblay, N.K. (2006). Memory distortion in\neyewitnesses: A meta-analysis of the post- identification\nfeedback effect. Applied Cognitive Psychology, 20,\n859–869.\nDowning, P.E., Chan, A.W.Y., Peelen, M.V., Dodds, C.M.\n& Kanwisher, N. (2006). Domain specificity in visual\ncortex. Cerebral Cortex, 16, 1453–1461.\nDoyon, J., Gabitov, E., Vahdat, S., Lungu, O. & Boutin, A.\n(2018). Current issues related to motor sequence learning\nin humans. Current Opinion in Behavioral Sciences, 20,\n89–97.\nDreyer, F.R., Frey, D., Arana, S., von Saldern, S., Picht,\nT., Vajkoczy, P., et al. (2015). Is the motor system\nnecessary for processing action and abstract emotion\nwords? Evidence from focal brain lesions. Frontiers in\nPsychology, 6 (Article no. 1661).\nDronkers, N.F., Ivanova, M.V. & Baldo, J.V. (2017). What\ndo language disorders reveal about brain-language rela-\ntionships? From classic models to network approaches.\nJournal of the International Neuropsychological Society,\n23, 741–754.\nDror, I.E., Charlton, D. & Péron, A.E. (2006). Contextual\ninformation renders experts vulnerable to making erro-\nneous identifications. Forensic Science International, 156,\n74–78.\nDror, I.E., Wertheim, K., Fraser-Mackenzie, P. & Walajtys,\nJ. (2012). The impact of human-technology co- operation\nand distributed cognition in forensic science: Biasing\neffects of AFIS contextual information on human\nexperts. Journal of Forensic Sciences, 57, 343–352.\nDrummond, L. & Shomstein, S. (2010). Object-based atten-\ntion: Shifting or uncertainty? Attention, Perception &\nPsychophysics, 72, 1743–1755.\nDrury, J.E., Baum, S.R., Valertote, H. & Steinhauer, K.\n(2016). Punctuation and implicit prosody in silent\nreading: An ERP study investigating English garden-\npath sentences. Frontiers in Psychology, 7 (Article\nno. 1375).\nDubarry, A.-S., Llorens, A., Trébuchon, A., Carron, R.,\nLiégeois-Chauvel, C., Bénar, C.-G., et al. (2017).\nEstimating parallel processing in a language task using\nsingle-trial\nintracerebral\nelectroencephalography.\nPsychological Science, 28, 414–426.\nDuchaine, B. & Yovel, G. (2015). A revised neural framework\nfor face processing. Annual Review of Vision Science, 1,\n393–416.\nDudai, Y. & Edelson, M.G. (2016). Personal memory: Is it\npersonal, is it memory? Memory Studies, 9, 275–283.\nDudukovic, N.M., Marsh, E.J. & Tversky, B. (2004). Telling\na story or telling it straight: The effects of entertaining\nversus accurate retellings on memory. Applied Cognitive\nPsychology, 18, 125–143.\nDuffau, H. (2017). A two-level model of inter-individual\nanatomo-functional variability of the brain and its impli-\ncations for neurosurgery. Cortex, 86, 303–313.\nDuffy, S.A. & Pisoni, D.B. (1992). Comprehension of syn-\nthetic speech produced by rule: A review and theoretical\ninterpretation. Language and Speech, 35, 351–389.\nCreated from usyd on 2022-02-18 03:51:57.",
    "846\nReferences\nEimer, M., Gosling, A. & Duchaine, B. (2012). Electro-\nphysiological markers of covert face recognition in\ndevelopmental prosopagnosia. Brain, 135, 542–554.\nEinstein, G.O. & McDaniel, M.A. (2005). Prospective\nmemory: Multiple retrieval processes. Current Directions\nin Psychological Science, 14, 286–290.\nEkroll, V., Sayim, B., Van der Hallen, R. & Wagemans, J.\n(2016). Illusory visual completion of an object’s invisi-\nble backside can make your finger feel shorter. Current\nBiology, 26, 1029–1033.\nEkroll, V., Sayim, B. & Wagermans, J. (2017). The other side\nof magic: The psychology of perceiving hidden things.\nPerspectives on Psychological Science, 12, 91–106.\nEldar, E., Niv, Y. & Cohen, J.D. (2016). Neural gain\nand breadth versus focus in perceptual processing.\nPsychological Science, 27, 1632–1643.\nElder, J.H. & Goldberg, R.M. (2002). Ecological statistics of\nGestalt laws for the perceptual organisation of contours.\nJournal of Vision, 2, 324–353.\nElliott, D., Lyons, J., Hayes, S.J., Burkitt, J.J., Roberts, J.W.,\nGrierson, L.E.M., et al. (2017). The multiple process\nmodel of goal-directed reaching revisited. Neuroscience\nand Biobehavioral Reviews, 72, 95–110.\nEllis, A.W. & Young, A.W. (1988). Human Cognitive\nNeuropsychology. Hove, UK: Psychology Press.\nEllis, J.J., Glaholt, M.G. & Reingold, E.M. (2011). Eye\nmovements reveal solution knowledge prior to insight.\nConsciousness and Cognition, 20, 768–776.\nElqayam, S. (2018). The new paradigm in psychology of rea-\nsoning. In L.J. Ball & V.A.Thompson (eds), Routledge\nInternational Handbook of Thinking and Reasoning\n(pp. 130–150). Abingdon, Oxon.: Routledge.\nElqayam, S. & Evans, J.St.B.T. (2011). Subtracting “ought”\nfrom “is”: Descriptivism versus normatism in the study\nof human thinking. Behavioral and Brain Sciences, 34,\n233–248.\nElsey, J.W.B., van Ast, V.A. & Kindt, M. (2018). Human\nmemory reconsolidation: A guiding framework and crit-\nical review of the evidence. Psychological Bulletin, 144,\n797–848.\nElward, R.L. & Vargha-Khadem, F. (2018). Semantic memory\nin developmental amnesia. Neuroscience Letters, 680,\n23–30.\nEndres, T. & Renkl, A. (2015). Mechanisms behind the testing\neffect: An empirical investigation of retrieval practice in\nmeaningful learning. Frontiers in Psychology, 6 (Article\nno. 1054).\nEndress, A.D. & Potter, M.C. (2014). Large capacity tempo-\nrary visual memory. Journal of Experimental Psychology:\nGeneral, 143, 548–565.\nEndress, A.D. & Szabó, S. (2017). Interference and memory\ncapacity limitations. Psychological Review, 124, 551–571.\nEngbert, R., Nuthmann, A., Richter, E.M. & Kliegl,\nR. (2005). SWIFT: A dynamical model of saccade\ngeneration during reading. Psychological Review, 112,\n777–813.\nEngel, P.J.H. (2008). Tacit knowledge and visual expertise in\nmedical diagnostic reasoning: Implications for medical\neducation. Medical Teacher, 30, e184–e188.\nEngel, S., Shapiro, L.P. & Love, T. (2018). Proform-\nantecedent linking in individuals with agrammatic\naphasia: A test of the intervener hypothesis. Journal of\nNeurolinguistics, 48, 79–94.\nEngle, R.W. & Kane, M.J. (2004). Executive attention, wor-\nking memory capacity and a two-factor theory of cogni-\ntive control. In B. Ross (ed.), The Psychology of Learning\nand Motivation (pp. 145–199). New York: Elsevier.\nEngstrom, J., Markkula, G., Victor, T. & Merat, N. (2017).\nEffects of cognitive load on driving performance:\nThe cognitive control hypothesis. Human Factors, 59,\n734–764.\nEnz, K.F., Pillemer, D.B. & Johnson, K.M. (2016). The relo-\ncation bump: Memories of middle adulthood are organ-\nised around residential moves. Journal of Experimental\nPsychology: General, 145, 935–940.\nErez, J., Cusack, R., Kendall, W. & Barense, M.D. (2016).\nConjunctive coding of complex object features. Cerebral\nCortex, 26, 2271–2282.\nEricsson, K.A. (2017). Expertise and individual differences:\nThe search for the structure and acquisition of experts’\nsuperior performance. Wiley Interdisciplinary Reviews:\nCognitive Science, 8, 1–6.\nEricsson, K.A. & Chase, W.G. (1982). Exceptional memory.\nAmerican Scientist, 70, 607–615.\nEricsson, K.A. & Kintsch, W. (1995). Long-term working\nmemory. Psychological Review, 102, 211–245.\nEriksen, C.W. & St. James, J.D. (1986). Visual attention\nwithin and around the field of focal attention: A zoom\nlens model. Perception & Psychophysics, 40, 225–240.\nEriksson, J., Larsson, A., Ahlströn, K.R. & Nyberg, L.\n(2006). Similar frontal and distinct posterior cortical\nregions mediate visual and auditory perceptual aware-\nness. Cerebral Cortex, 17, 760–765.\nEsteves-Sorenson, C. & Perretti, F. (2012). Micro-costs:\nInertia in television viewing. The Economic Journal, 122,\n867–902.\nEtchells, D.B., Brooks, J.L. & Johnston, R.A. (2017).\nEvidence for view-invariant face recognition units\nin unfamiliar face learning. Quarterly Journal of\nExperimental Psychology, 70, 874–889.\nEtkin, A. & Schatzberg, A.F. (2011). Common abnormalities\nand disorder-specific compensation during implicit reg-\nulation of emotional processing in generalised anxiety\nand major depressive disorders. American Journal of\nPsychiatry, 168, 968–978.\nEtkin, A., Büchel, C. & Gross, J.J. (2015). The neural basis\nof emotion regulation. Nature Reviews Neuroscience, 16,\n693–700.\nCreated from usyd on 2022-02-18 03:51:57.",
    "848\nReferences\nFarah, M.J. (1991). Cognitive neuropsychology: Patterns\nof co-occurrence among the associative agnosias:\nImplications for visual object representation. Cognitive\nNeuropsychology, 8, 1–19.\nFarah, M.J. (1994). Specialisations within visual object\nrecognition: Clues from prosopagnosia and alexia.\nIn  M.J. Farah & G. Ratcliff (eds), The Neuro-\npsychology of High-Level Vision: Collected Tutorial\nEssays (pp. 133–146). Hillsdale, NJ: Lawrence Erlbaum\nAssociates.\nFarmer, C.M., Klauer, S.G., McClafferty, J.A. & Guo, F.\n(2015). Relationship of near-crash/crash risk to time\nspent on a cell phone while driving. Traffic Injury\nPrevention, 16, 792–800.\nFarmer, G.D., Janssen, C.P., Nguyen, A.T. & Brumby,\nD.P. (2018). Dividing attention between tasks: Testing\nwhether explicit payoff functions elicit optimal dual-task\nperformance. Cognitive Science, 42, 820–849.\nFarmer, M.E. & Klein, R.M. (1995). The evidence for a tem-\nporal processing deficit linked to dyslexia: A review.\nPsychonomic Bulletin & Review, 2, 460–493.\nFaroqui-Shah, Y. & Friedman, L. (2015). Production of\nverb tense in agrammatic aphasia: A meta-analysis\nand further data. Behavioural Neurology, (Article no.\nID983870).\nFatania, J. & Mercer, T. (2017). Non-specific retroactive\ninterference in children and adults. Advances in Cognitive\nPsychology, 13, 314–322.\nFath, A.J., Lind, M. & Bingham, G.P. (2018). Perception of\ntime to contact of slow- and fast-moving objects using\nmonocular and binocular motion information. Attention,\nPerception & Psychphysics, 80, 1584–1590.\nFawcett, J.M., Peace, K.A. & Greve, A. (2016). Looking\ndown the barrel of a gun: What do we know about the\nweapon focus effect? Journal of Applied Research in\nMemory and Cognition, 5, 257–263.\nFawcett, J.M., Russell, E.J., Peace, K.A. & Christie, J.\n(2013). Of guns and geese: A meta-analytic review of the\n“weapon focus” literature. Psychology, Crime & Law, 19,\n35–66.\nFazekas, P. & Overgaard, M. (2018). Perceptual conscious-\nness and cognitive access: An introduction. Philosophical\nTransactions of the Royal Society B, 373 (Article no.\n201170340).\nFazio, L.K., Brashier, N.M., Payne, B.K. & Marsh, E.J.\n(2015). Knowledge does not protect against illusory\ntruth. Journal of Experimental Psychology: General, 144,\n993–1002.\nFecher, B., Friesike, S. & Hebing, M. (2015). What drives\nacademic data sharing? PLoS ONE, 10 (Article no.\ne0118053).\nFedor, A., Szathmáry, E. & Őllinger, M. (2015). Problem\nsolving stages in the five square problem. Frontiers in\nPsychology, 6 (Article no. 1050).\nFedorenko, E., Scott, T.L., Brunner, P., Coon, W.G.,\nPritchett, B., Schalk, G., et al. (2016). Neural correlate\nof the construction of sentence meaning. Proceedings of\nthe National Association of Sciences, 113, E6256–E6262.\nFedzechkina, M., Chu, B. & Jaeger, T.F. (2018). Human\ninformation\nprocessing\nshapes\nlanguage\nchange.\nPsychological Science, 29, 72–82.\nFeeser, M., Prehn, K., Kazzer, P., Mungee, A. & Bajhouj, M.\n(2014). Transcranial direct current stimulation enhances\ncognitive control during emotion regulation. Brain\nStimulation, 7, 105–112.\nFeinstein, J.S. (2013). Lesion studies of human emotion and\nfeeling. Current Opinion in Neurobiology, 23, 304–309.\nFeist, G.J. (2008). The Psychology of Science and the Origins\nof the Scientific Mind. New Haven, CT: Yale University\nPress.\nFeldman, A.G. (2016). Active sensing without efference\ncopy: Referent control of perception. Journal of\nNeurophysiology, 116, 960–976.\nFeldman, G. & Albarracín, D. (2017). Norm theory and the\naction-effect: The role of social norms in regret follow-\ning action and inaction. Journal of Experimental Social\nPsychology, 69, 111–120.\nFeldman, J. (2013). The neural binding problem(s). Cognitive\nNeurodynamics, 7, 1–11.\nFelleman, D.J. & Van Essen, D.C. (1991). Distributed hierar-\nchical processing in the primate cerebral cortex. Cerebral\nCortex, 1, 1–47.\nFerber, R. (1995). Reliability and validity of slip-of-the-\ntongue corpora: A methodological note. Linguistics, 33,\n1169–1190.\nFerbinteanu, J. (2019). Memory systems 2018 – Towards a\nnew paradigm. Neurobiology of Learning and Memory,\n157, 61–78.\nFernandez, K.C., Jazaieri, H. & Gross, J.J. (2016). Emotion\nregulation: A transdiagnostic perspective on a new RDoC\ndomain. Cognitive Therapy and Research, 40, 426–440.\nFerrari, P.F., Gerbella, M., Coudé, G. & Rozzi, S. (2017a).\nTwo different mirror neuron networks: The sensori-\nmotor (hand) and limbi (face) pathways. Neuroscience,\n358, 300–315.\nFerrari, V., Codispoti, M. & Bradley, M.M. (2017b).\nRepetition and ERPs during emotional scene pro-\ncessing: A selective review. International Journal of\nPsychophysiology, 111, 170–177.\nFerreira, F. (2003). The misinterpretation of non-canonical\nsentences. Cognitive Psychology, 47, 164–203.\nFerreira, F. & Lowder, M.W. (2016). Prediction, informa-\ntion structure, and good-enough language processing.\nPsychology of Learning and Motivation, 65, 217–247.\nFerreira, F. & Swets, B. (2002). How incremental is language\nproduction? Evidence from the production of utterances\nrequiring the computation of arithmetic sums. Journal of\nMemory and Language, 46, 57–84.\nCreated from usyd on 2022-02-18 03:51:57.",
    "850\nReferences\nForster, S. & Lavie, N. (2008). Failures to ignore entirely\nirrelevant distractors: The role of load. Journal of\nExperimental Psychology: Applied, 14, 73–83.\nFossett, T.R.D., McNeil, M.R., Pratt, S.R., Tompkins,\nC.A. & Shuster, L.I. (2016). The effect of speaking rate\non serial-order sound-level errors in normal healthy\ncontrols and persons with aphasia. Aphasiology, 30,\n74–95.\nFoster, D.H. (2011). Colour constancy. Vision Research, 51,\n674–700.\nFoster, D.H. (2018). The Verriest lecture: Colour vision in\nan uncertain world. Journal of the Optical Society of\nAmerica, 35, B192–B201.\nFoster, D.H. & Nascimento, S.M.C. (1994). Relational\ncolour constancy from invariant cone-excitation ratios.\nProceedings of the Royal Society of London Series B –\nBiological Sciences, 257, 115–121.\nFoster, J.D., Reidy, D.E., Misra, T.A. & Goff, J.S. (2011).\nNarcissism and stock market investing: Correlates and\nconsequences of cocksure investing. Personality and\nIndividual Differences, 50, 816–821.\nFoulsham, T. (2015). Eye movements and their functions in\neveryday tasks. Eye, 29, 196–199.\nFoulsham, T. & Kingstone, A. (2017). Are fixations in static\nnatural scenes a useful predictor of attention in the real\nworld? Canadian Journal of Experimental Psychology,\n71, 172–181.\nFowlkes, C.C., Martin, D.R. & Malik, J. (2007). Local\nfigure-ground cues are valid for natural images. Journal\nof Vision, 7 (Article no. 2).\nFox, C.J., Hanif, H.M., Iaria, G., Duchaine, B.C. & Barton,\nJ.J.S. (2011). Perceptual and anatomic patterns of selec-\ntive deficits in facial identity and expression processing.\nNeuropsychologia, 49, 3188–3200.\nFrank, M.C., Everett, D.L., Fedorenko, E. & Gibson, E.\n(2008). Number as a cognitive technology: Evidence\nfrom Pirahã language and cognition. Cognition, 108,\n819–824.\nFranklin, S., Turner, J., Lambon Ralph, M.A., Morris, J. &\nBailey, P.J. (1996). A distinctive case of word meaning\ndeafness? Cognitive Neuropsychology, 13, 1139–1162.\nFranz, V.H. & Gegenfurtner, K.R. (2008). Grasping visual\nillusions: Consistent data and no dissociation. Cognitive\nNeuropsychology, 25, 920–950.\nFraser H. (2018a). Thirty years is long enough: It’s time to\ncreate a process that ensures covert recordings used as\nevidence in court are interpreted reliably and fairly.\nJournal of Judicial Administration, 27, 95–104.\nFraser, H. (2018b). “Assisting” listeners to hear words that\naren’t here: Dangers in using police transcripts of indis-\ntinct covert recordings. Australian Journal of Forensic\nSciences, 50, 129–139.\nFrässle, S., Summer, J., Jansen, A., Naber, M. & Einhäuser,\nW. (2014). Binocular rivalry: Frontal activity relates to\nintrospection and action but not to perception. Journal\nof Neuroscience, 34, 1738–1747.\nFrauenfelder, U.H., Segui, J. & Dijkstra, T. (1990). Lexical\neffects in phonemic processing: Facilitatory or inhib-\nitory? Journal of Experimental Psychology: Human\nPerception & Performance, 16, 77–91.\nFrazier, L. & Rayner, K. (1982). Making and correcting errors\nduring sentence comprehension: Eye movements in the\nanalysis of structurally ambiguous sentences. Cognitive\nPsychology, 14, 178–210.\nFrazier, L., Carlson, K. & Clifton, C. (2006). Prosodic phras-\ning is central to language comprehension. Trends in\nCognitive Sciences, 10, 244–249.\nFrederick, S. (2005). Cognitive reflection and decision making.\nJournal of Economic Perspectives, 19, 25–42.\nFredrickson, B.L. & Branigan, C. (2005). Positive emotions\nbroaden the scope of attention and thought-action rep-\nertoires. Cognition & Emotion, 19, 313–332.\nFreed, E.M., Hamilton, S.T. & Long, D.L. (2017).\nComprehension in proficient readers: The nature of indi-\nvidual variation. Journal of Memory and Language, 97,\n135–153.\nFreeman, J. & Simoncelli, E.P. (2011). Metamers of the\nventral stream. Nature Neuroscience, 14, 1195–1201.\nFreud, E., Culham, J.C., Plaut, D.C. & Behrmann, M.\n(2017a). The large-scale organisation of shape processing\nin the ventral and dorsal pathways. ELIFE, 6 (Article\nno. e27576).\nFreud, E., Ganel, T., Shelef, I., Hammer, M.D., Avidan, G.\n& Behrmann, M. (2017b). Three-dimensional representa-\ntions of objects in dorsal cortex are dissociable from\nthose in ventral cortex. Cerebral Cortex, 27, 422–434.\nFreud, E., Plaut, D.C. & Behrmann, M. (2016). “What”\nis happening in the dorsal visual pathway. Trends in\nCognitive Sciences, 20, 773–784.\nFreuenberger, D. & Roeham, D. (2017). The costs of being\ncertain: Brain potential evidence for linguistic preac-\ntivation in sentence processing. Psychophysiology, 54,\n824–832.\nFrick-Horbury, D. & Guttentag, R.E. (1998). The effects of\nrestricting hand gesture production on lexical retrieval\nand free recall. American Journal of Psychology, 111,\n43–62.\nFried, I., Haggard, P., He, B.J. & Schurger, A. (2017). Volition\nand action in the human brain: Processes, pathologies,\nand reasons. Journal of Neuroscience, 37, 10842–10847.\nFriedman, N.P. & Miyake, A. (2017). Unity and diversity of\nexecutive functions: Individual differences as a window\non cognitive structure. Cortex, 86, 186–204.\nFriedman, N.P., Miyake, A., Young, S.E., DeFries, J.C.,\nCorley, R.P. & Hewitt, J.K. (2008). Individual differ-\nences in executive functions are almost entirely genetic\nin origin. Journal of Experimental Psychology: General,\n137, 201–225.\nCreated from usyd on 2022-02-18 03:51:57.",
    "852\nReferences\nof Experimental Psychology: Human Perception and\nPerformance, 44, 848–855.\nGarcea, F.E. & Mahon, B.Z. (2012). What is in a tool concept?\nDissociating manipulation knowledge from function\nknowledge. Memory & Cognition, 40, 1303–1313.\nGardiner, J.M., Brandt, K.R., Baddeley, A.D., Vargha-\nKhadem, F. & Mishkin, M. (2008). Charting the acqui-\nsition of semantic knowledge in a case of developmental\namnesia. Neuropsychologia, 46, 2865–2868.\nGarg, N., Williams, L.A. & Lerner, J.S. (2018). The misery-\nis-not-miserly effect revisited: Replication despite oppor-\ntunities for compensatory consumption. PLoS ONE, 13\n(Article no. e199433).\nGarner, K.G. & Dux, P.E. (2015). Training conquers mul-\nti-tasking costs by dividing task representations in the\nfronto-parietal-subcortical system. Proceedings of the\nNational Academy of Sciences, 112, 14372–14377.\nGarrard, P., Carroll, E., Vinson, D. & Vigliocco, G. (2004).\nDissociation of lexical syntax and semantics: Evidence\nfrom focal cortical degeneration. Neurocase, 10, 353–362.\nGarrard, P., Maloney, L.M., Hodges, J.R. & Patterson, K.\n(2005). The effects of very early Alzheimer’s disease on\nthe characteristics of writing by a renowned author.\nBrain, 128, 250–260.\nGarrett, B. (2011). Convicting the Innocent: Where crimi-\nnal prosecutions go wrong. Cambridge, MA: Harvard\nUniversity Press.\nGarrett, M. (1980). Levels of processing in sentence pro-\nduction. In B. Butterworth (ed.), Language Production\n(pp. 177–220). London: Academic Press.\nGarrod, S. & Terras, M. (2000). The contribution of lexical\nand situational knowledge to resolving discourse\nroles: Bonding and resolution. Journal of Memory and\nLanguage, 42, 526–544.\nGarson, J. (2016). Connectionism. In E.N. Zalta (ed.), The\nStanford Encyclopedia of Philosophy (online). Stanford,\nCA: Metaphysics Research Lab, Stanford University.\nGaskell,\nM.G.\n&\nMarslen-Wilson,\nW.D.\n(2002).\nRepresentation and competition in the perception of\nspoken words. Cognitive Psychology, 45, 220–266.\nGathercole, S.E. & Baddeley, A.D. (1993). Phonological\nworking memory: A critical building-block for reading\ndevelopment and vocabulary acquisition. European\nJournal of Psychology of Education, 8, 259–272.\nGauld, A. & Stephenson, G.M. (1967). Some experiments\nrelating to Bartlett’s theory of remembering. British\nJournal of Psychology, 58, 39–50.\nGauthier, I. & Tarr, M.J. (2016). Visual object recognition:\nDo we (finally) know more now than we did? Annual\nReview of Vision Science, 2, 377–396.\nGauvin, H.S., De Baene, W., Brass, M. & Hartsuiker, R.J.\n(2016). Conflict monitoring in speech processing: An\nfMRI study of error detection in speech production and\nperception. NeuroImage, 126, 96–105.\nGavilán, J.M., Rivera, D., Guasch, M., Demestre, J. &\nGarcia-Albea, J.E. (2017). Exploring the effects of visual\nframe and matching direction on the vertical-horizontal\nillusion. Perception, 46, 1339–1355.\nGawronski, B. & Beer, J.S. (2017). What makes moral\ndilemma judgements “utilitarian” or “deontological”?\nSocial Neuroscience, 12, 626–632.\nGawronski, B., Armstrong, J., Conway, P., Friesdorf, R. &\nHütter, M. (2017). Consequences, norms, and gener-\nalised inaction in moral dilemmas: The CNI model of\nmoral decision making. Journal of Personality and Social\nPsychology, 112, 343–376.\nGazzaniga, M.S. (1992). Nature’s Mind. London: Basic Books.\nGazzaniga, M.S. (2013). Shifting gears: Seeking new\napproaches for mind/brain mechanisms. Annual Review\nof Psychology, 64, 1–20.\nGazzaniga, M.S. & Ledoux, J.E. (1978). The Integrated Mind.\nLondon: Basic Books.\nGazzaniga, M.S., Ivry, R.B. & Mangun, G.R. (2008).\nCognitive Neuroscience: The biology of the mind (3rd\nedn). New York: W.W. Norton.\nGegenfurtner, A., Kok, E., van Geel, K., de Bruin, A.,\nJarodzka, H., Szulewski, A., et al. (2017). The challenges\nof studying visual expertise in medical image diagnosis.\nMedical Education, 51, 97–104.\nGegenfurtner, A., Lehtinen, E. & Säljö, R. (2011). Expertise\ndifferences in the comprehension of visualisations: A\nmeta-analysis of eye-tracking research in professional\ndomains. Educational Psychology Review, 23, 523–552.\nGeiselman, R.E. & Fisher, R.P. (1997). Ten years of cogni-\ntive interviewing. In D.G. Payne & F.G. Conrad (eds),\nIntersections in Basic and Applied Memory Research\n(pp.  291–310). Mahwah, NJ: Lawrence Erlbaum\nAssociates.\nGeisler, W.S., Perry, J.S., Super, B.J. & Gallogly, D.P.\n(2001).  Edge co-occurrence in natural images predicts\ncontour grouping performance. Vision Research, 41,\n711–724.\nGelbard-Sagiv, H., Faivre, N., Mudrik, L. & Koch, C. (2016).\nLow-level awareness accompanies “unconscious” high-\nlevel processing during continuous flash suppression.\nJournal of Vision, 16, 1–16.\nGeng, J.J., DiQuattro, N.E. & Helm, J. (2017). Distractor\nprobability changes the shapes of attentional template.\nJournal of Experimental Psychology: Human Perception\nand Performance, 43, 1993–2007.\nGenon, S., Reid, A., Langner, R., Amunts, K. & Eickhoff,\nS.B. (2018). How to characterise the function of a brain\nregion. Trends in Cognitive Sciences, 22, 350–364.\nGenty, E., Neumann, C. & Zuberbühler, K. (2015). Bonobos\nmodify communication signals according to recipient\nfamiliarity. Scientific Reports, 5 (Article no. 16442).\nGeorge, T. & Wiley, J. (2016). Forgetting the literal: The\nrole of inhibition in metaphor comprehension. Journal\nCreated from usyd on 2022-02-18 03:51:57.",
    "854\nReferences\nGlover, S. (2004). Separate visual representations in the\nplanning and control of action. Behavioral and Brains\nSciences, 27, 3–78.\nGlover, S., Wall, M.B. & Smith, A.T. (2012). Distinct corti-\ncal networks support the planning and online control\nof reaching-to-grasp in humans. European Journal of\nNeuroscience, 35, 909–915.\nGobet, F. (2016). Understanding Expertise: A multi-\ndisciplinary approach. London: Palgrave.\nGobet, F. & Clarkson, G. (2004). Chunks in expert memory:\nEvidence for the magical number four … or is it two?\nMemory, 12, 732–747.\nGobet, F. & Ereku, M.H. (2014). Checkmate to deliber-\nate practice: The case of Magnus Carlsen. Frontiers in\nPsychology, 5 (Article no. 878).\nGobet, F. & Lane, P. (2015). Human problem solving: Beyond\nNewell, Shaw, and Simon’s (1958) theory of human\nproblem solving. In M.W. Eysenck & D. Groome (eds),\nCognitive Psychology: Revisiting the classic studies (pp.\n133–145). London: Sage.\nGobet, F. & Simon, H.A. (2000). Five seconds or sixty?\nPresentation time in expert memory. Journal of Experi-\nmental Psychology: Learning, Memory and Cognition, 29,\n1082–1094.\nGobet, F. & Waters, A.J. (2003). The role of constraints in\nexpert memory. Journal of Experimental Psychology:\nLearning, Memory & Cognition, 29, 1082–1094.\nGodden, D.R. & Baddeley, A.D. (1975). Context depend-\nent memory in two natural environments: On land and\nunder water. British Journal of Psychology, 66, 325–331.\nGodden, D.R. & Baddeley, A.D. (1980). When does context\ninfluence recognition memory? British Journal of\nPsychology, 71, 99–104.\nGodefroy, O., Azouvi, P., Robert, P., Roussel, M., LeGall,\nD. & Meulemans, T. (2010). Dysexecutive syndrome:\nDiagnostic criteria and validation study. Annals of\nNeurology, 68, 855–864.\nGodwin, D., Barry, R.L. & Marois, R. (2015). Breakdown of\nthe brain’s functional network modularity with aware-\nness. Proceedings of the National Academy of Sciences of\nthe United States of America, 112, 3799–3804.\nGoel, V. (2010). Neural basis of thinking: Laboratory prob-\nlems versus real-world problems. Wiley Interdisciplinary\nReviews – Cognitive Science, 1, 613–621.\nGoel, V. & Grafman, J. (1995). Are the frontal lobes impli-\ncated in “planning” functions? Interpreting data from\nthe Tower of Hanoi. Neuropsychologia, 33, 623–642.\nGoel, V. & Grafman, J. (2000). The role of the right prefron-\ntal cortex in ill-structured problem solving. Cognitive\nNeuropsychology, 17, 415–436.\nGoel, V. & Waechter, R. (2018). Inductive and deductive rea-\nsoning: Integrating insights from philosophy, psychol-\nogy, and neuroscience. In L.J. Ball & V.A. Thompson\n(eds), Routledge International Handbook of Thinking\nand  Reasoning (pp. 218–247). Abingdon, Oxon.:\nRoutledge.\nGoel, V., Tierney, M., Sheesley, L., Bartolo, A., Vartanian,\nO. & Grafman, J. (2007). Hemispheric specialisation in\nhuman prefrontal cortex for resolving certain and uncer-\ntain inferences. Cerebral Cortex, 17, 2245–2250.\nGoel, V., Vartanian, O., Bartolo, A., Hakim, L., Ferraro,\nA.M., Isella, V., et al. (2013). Lesions to the right pre-\nfrontal cortex impair real-world planning through pre-\nmature commitments. Neuropsychologia, 51, 713–724.\nGoh, W.D. & Lu, S.H.X. (2012). Testing the myth of encod-\ning-retrieval match. Memory & Cognition, 40, 28–39.\nGoldberg, A., Russell, M. & Cook, A. (2003). The effect of\ncomputers on student writing: A meta-analysis of studies\nfrom 1992 to 2002. Journal of Technology, Learning, and\nAssessment, 2, 1–52.\nGoldberg, I.I., Harel, M. & Malach, R. (2006). When the\nbrain loses its self: Prefrontal inactivation during senso-\nrimotor processing. Neuron, 50, 329–339.\nGoldenberg, G., Mullbacher, W. & Nowak, A. (1995).\nImagery without perception: A case study of anosog-\nnosia for cortical blindness. Neuropsychologia, 33,\n1373–1382.\nGoldinger, S.D. & Azuma, T. (2003). Puzzle-solving science:\nThe quixotic quest for units in speech perception.\nJournal of Phonetics, 31, 305–320.\nGoldrick, M. (2006). Limited interaction in speech produc-\ntion: Chronometric, speech error, and neuropsycho-\nlogical evidence. Language and Cognitive Processes, 21,\n817–855.\nGoldrick, M., Keshet, J., Gustafson, E., Heller, J. & Needle,\nJ. (2016). Automatic analysis of slips of the tongue:\nInsights into the cognitive architecture of speech produc-\ntion. Cognition, 148, 31–39.\nGoldstein, D.G. & Gigerenzer, G. (2002). Models of ecolog-\nical rationality: The recognition heuristic. Psychological\nReview, 109, 75–90.\nGollwitzer, P. (2014). Weakness of the will: Is a quick fix pos-\nsible? Motivation and Emotion, 38, 305–322.\nGolumbic, E.Z., Cogan, G.B., Schroeder, C.E. & Poeppel, D.\n(2013). Visual input enhances selective speech envelope\ntracking in auditory cortex at a “cocktail party”. Journal\nof Neuroscience, 33, 1417–1426.\nGómez, A.T., Lupón, N., Cardna, G. & Aznar-Casanova,\nJ.A. (2012). Visual mechanisms governing the percep-\ntion of autostereograms. Clinical and Experimental\nOptometry, 95, 146–152.\nGomulicki, B.R. (1956). Recall as an abstractive process. Acta\nPsychologica, 12, 77–94.\nGong, L., Wang, J., Yang, X., Li, X., Gu, C., Wang, M.,\net al. (2016). Dissociation between conceptual and per-\nceptual implicit memory: Evidence from patients with\nfrontal and occipital lobe lesions. Frontiers in Human\nNeuroscience, 9 (Article no. 722).\nCreated from usyd on 2022-02-18 03:51:57.",
    "856\nReferences\nGroopman, J. (2007). How Doctors Think. New York:\nHoughton Mifflin.\nGross, J.J. (2015). Emotion regulation: Current status and\nfuture prospects. Psychological Inquiry, 26, 1–26.\nGross, J.J. & Thompson, R.A. (2007). Emotion regulation:\nConceptual foundations. In J.J. Gross (ed.), Handbook\nof Emotion Regulation (pp. 3–24). New York: Guilford\nPress.\nGross, S. (2018). Perceptual consciousness and cognitive\naccess from the perspective of capacity-unlimited\nworking memory. Philosophical Transactions of the\nRoyal Society B, 373 (Article no. 2017.0343).\nGrossman, E.D., Battelli, L. & Pascual-Leone, A. (2005).\nRepetitive TMS over STSp disrupts perception of bio-\nlogical motion. Vision Research, 45, 2847–2853.\nGrossnickle, E.M., Dumas, D., Alexander, P.A. & Baggetta,\nP. (2016). Individual differences in the process of\nrelational reasoning. Learning and Instruction, 42,\n141–159.\nGrot, S., Leclerc, M.-E. & Luck, D. (2018). Examining the\nneural correlates of active and passive forms of ver-\nbal-spatial binding in working memory. Biological\nPsychology, 136, 67–75.\nGuan, C.Q., Ye, F., Wagner, R.W., Meng, W. & Leary, C.K.\n(2014). Text comprehension mediates morphological\nawareness, syntactic processing, and working memory\nin predicting Chinese written composition perform ance.\nJournal of Educational Psychology, 106, 779–798.\nGueliaï, B., Langus, A. & Nespor, M. (2014). Prosody in the\nhands of the speaker. Frontiers in Psychology, 5 (Article\nno. 700).\nGuida, A., Gobet, F. & Nicolas, S. (2013). Functional cerebral\nreorganisation: A signature of expertise? Re-examining\nGuida, Gobet, Tardieu, and Nicolas’ (2012) two-stage\nframework. Frontiers in Human Neuroscience, 7 (Article\nno. 590).\nGuida, A., Gobet, F., Tardieu, H. & Nicolas, S. (2012). How\nchunks, long-term working memory and templates\noffer a cognitive explanation for neuroimaging data on\nexpertise acquisition: A two-stage framework. Brain and\nCognition, 79, 221–244.\nGüllich, A. (2017). International medallists’ and non-\nmedallists’ developmental sport activities – A matched-\npairs analysis. Journal of Sports Sciences, 35, 2281–2288.\nGustavson, D.E., Miyake, A., Hewitt, J.K. & Friedman, N.P.\n(2015). Understanding the cognitive and genetic under-\npinnings of procrastination: Evidence for shared genetic\ninfluences with goal management and executive function\nabilities. Journal of Experimental Psychology: General,\n144, 1063–1079.\nGutchess, A.H. & Park, D.C. (2006). The fMRI environment\ncan impair memory performance in young and elderly\nadults. Brain Research, 1099, 133–140.\nGutierrez-Sigut, E., Vergara-Martínez, M. & Perea, M.\n(2017). Early use of phonological codes in deaf readers:\nAn ERP study. Neuropsychologia, 106, 261–279.\nGvion, A. & Friedmann, N. (2016). A principled relation\nbetween reading and naming in acquired and develop-\nmental anomia: Surface dyslexia following impairment in\nthe phonological output lexicon. Frontiers in Psychology,\n7 (Article no. 340).\nGwilliams, L., Linzen, T., Poeppel, D. & Marantz, A. (2018).\nIn spoken word recognition, the future predicts the past.\nJournal of Neuroscience, 38, 7585–7599.\nHaak, K.V. & Beckmann, C.F. (2018). Objective analysis of\nthe topological organisation of the human cortical visual\nconnectome suggests three visual pathways. Cortex, 98,\n73–83.\nHaber, R.N. & Levin, C.A. (2001). The independence of\nsize perception and distance perception. Perception &\nPsychophysics, 63, 1140–1152.\nHafenbrädl, S., Waeger, D., Marewski, J.N. & Gigerenzer,\nG. (2016). Applied decision making with fast-and- frugal\nheuristics. Journal of Applied Research in Memory and\nCognition, 5, 215–231.\nHagoort, P. (2017). The core and beyond in the language-\nready brain. Neuroscience and Biobehavioral Reviews, 81,\n194–204.\nHagoort, P., Hald, L., Bastiaansen, M. & Petersson, K.M.\n(2004). Integration of word meaning and world\nknowledge in language comprehension. Science, 304,\n438–441.\nHahn, B., Ross, T.J. & Stein, E.A. (2006). Neuroanatomical\ndissociations between bottom-up and top-down pro-\ncesses of visuospatial selective attention. NeuroImage,\n32, 842–853.\nHahn, S., Andersen, G.J. & Saidpour, A. (2003). Static scene\nanalysis for the perception of heading. Psychological\nScience, 14, 543–548.\nHahn, U. (2014). The Bayesian boom: Good thing or bad?\nFrontiers in Psychology, 5 (Article no. 765).\nHahn, U. & Hornikx, J. (2016). A normative framework\nfor argument quality: Argumentation schemes with a\nBayesian foundation. Synthese, 193, 1833–1873.\nHahn, U. & Oaksford, M. (2007). The rationality of informal\nargumentation: A Bayesian approach to reasoning falla-\ncies. Psychological Review, 114, 704–732.\nHahn, U. & Oaksford, M. (2014). The Fallacies Explained.\nOxford: Oxford University Press.\nHaider, H., Eichler, A. & Lange, T. (2011). An old problem:\nHow can we distinguish between conscious and uncon-\nscious knowledge acquired in an implicit learning task?\nConsciousness and Cognition, 20, 658–672.\nHaigh, M., Wood, J.S. & Stewart, A.J. (2016). Slippery slope\narguments imply opposition to change. Memory &\nCognition, 44, 819–836.\nCreated from usyd on 2022-02-18 03:51:57.",
    "858\nReferences\nHarrison, T.L., Shipstead, Z. & Engle, R.W. (2015). Why is\nworking memory capacity related to matrix reasoning\ntasks? Memory & Cognition, 43, 389–396.\nHart, W., Albarracin, D., Eagly, A.H., Brechan, I., Lindberg,\nM.J. & Merrill, L. (2009). Feeling validated versus being\ncorrect: A meta-analysis of selective exposure to infor-\nmation. Psychological Bulletin, 135, 555–588.\nHartwigsen, G. (2018). Flexible redistribution in cognitive\nnetworks. Trends in Cognitive Sciences, 22, 687–698.\nHarvey, L.O. (1986). Visual memory: What is remembered?\nIn F. Klix & H. Hagendorf (eds), Human Memory\nand Cognitive Capabilities (pp. 179–186). The Hague,\nNetherlands: Elsevier.\nHaskell, T.R., Thornton, R. & MacDonald, M.C. (2010).\nExperience and grammatical agreement: Statistical learn-\ning shapes number agreement production. Cognition,\n114, 151–164.\nHassabis, D., Kumaran, D., Vann, S.D. & Maguire, E.A.\n(2007). Patients with hippocampal amnesia cannot\nimagine new experiences. Proceedings of the National\nAcademy of Sciences, USA, 104, 1726–1731.\nHassin, R.R. (2013). Yes it can: On the functional abilities of\nthe human unconscious. Perspectives on Psychological\nScience, 8, 195–207.\nHasson, U., Egidi, G., Marelli, M. & Willems, R.M. (2018).\nGrounding the neurobiology of language in first princi-\nples: The necessity of non-language-centric explanations\nfor language comprehension. Cognition, 180, 135–157.\nHata, K. (2016). On the importance of the multimodal\napproach to discourse markers: A pragmatic view.\nInternational Review of Pragmatics, 8, 36–54.\nHauk, O., Johnsrude, I. & Pulvermüller, F. (2004).\nSomatotopic representation of action words in human\nmotor and premotor cortex. Neuron, 41, 301–307.\nHäuser, K.I., Titone, D.A. & Baum, S.R. (2016). The role\nof the ventro-lateral prefrontal cortex in idiom com-\nprehension: An rTMS study. Neuropsychologia, 91,\n360–370.\nHayes, J.R. (2012). Modelling and remodelling writing.\nWritten Communication, 29, 369–388.\nHayes, J.R. & Bajzek, D. (2008). Understanding and reducing\nthe knowledge effect: Implications for writers. Written\nCommunication, 25, 104–118.\nHayes, J.R. & Chenoweth, N. (2006). Is working memory\ninvolved in the transcribing and editing of texts? Written\nCommunication, 23, 135–141.\nHayes, J.R. & Flower, L.S. (1980). Identifying the organ-\nisation of writing processes. In L.W. Gregg & E.R.\nSteinberg\n(eds),\nCognitive\nProcesses\nin\nWriting\n(pp.  3–30). Mahwah, NJ: Erlbaum.\nHayes, J.R. & Flower, L.S. (1986). Writing research and the\nwriter. American Psychologist, 41, 1106–1113.\nHayes, J.R., Flower, L.S., Schriver, K., Stratman, J. & Carey,\nL. (1985). Cognitive Processes in Revision (Technical\nReport No. 12). Pittsburgh, PA: Carnegie Mellon\nUniversity.\nHayward, W.G. & Tarr, M.J. (2005). Visual perception II:\nHigh-level vision. In K. Lamberts & R.L. Goldstone\n(eds), The Handbook of Cognition (pp. 43–70). London:\nSage.\nHeck, D.W. & Erdfelder, E. (2017). Linking process and\nmeasurement models of recognition-based decisions.\nPsychological Review, 124, 442–471.\nHegdé, J. (2008). Time course of visual perception: Coarse-\nto-fine processing and beyond. Progress in Neurobiology,\n84, 405–439.\nHegdé, J. (2018). Neural mechanisms of high-level vision.\nComprehensive Physiology, 8, 902–953.\nHegdé, J. & Van Essen, D.C. (2000). Selectivity for\ncomplex shapes in primate visual area V2. Journal of\nNeuroscience, 20, RC61.\nHeimler, B., Weisz, H. & Collignon, O. (2014). Revisiting the\nadaptive and maladaptive effects of cross-modal plas-\nticity. Neuroscience, 283, 44–63.\nHeld, R.T., Cooper, E.A. & Banks, M.S. (2012). Blur and\ndisparity are complementary cues to depth. Current\nBiology, 22, 426–431.\nHeller, D., Parisien, C. & Stevenson, S. (2016). Perspective-\ntaking behaviour as the probabilistic weighing of multi-\nple domains. Cognition, 149, 104–120.\nHellmann, J.H., Echterhoff, G., Kopietz, R., Niemeier, S. &\nMemon, A. (2011). Talking about visually perceived\nevents: Communication effects on eyewitness memory.\nEuropean Journal of Social Psychology, 41, 658–671.\nHenderson, E.N. (1903). A study of memory for connected\ntrains of thought. Psychological Review, Series of\nMonograph Supplements, 5, 1–93.\nHenderson, J.M. & Hollingworth, A. (1999). High-level scene\nperception. Annual Review of Psychology, 50, 243–271.\nHenke, K. (2010). A model for memory systems based on pro-\ncessing modes rather than consciousness. Nature Reviews\nNeuroscience, 11, 523–532.\nHenry, M.L., Beeson, P.M., Alexander, G.E. & Rapcsak,\nS.Z. (2012). Written language impairments in primary\nprogressive aphasia: A reflection of damage to central\nsemantic and phonological processes. Journal of\nCognitive Neuroscience, 24, 261–275.\nHenry, M.L., Wilson, S.M., Babiak, M.C., Mandelli, M.L.,\nBeeson, P.M., Miller, Z.A., et al. (2016). Phonological\nprocessing in primary progressive aphasia. Journal of\nCognitive Neuroscience, 28, 210–222.\nHepner, C., McCloskey, M. & Rapp, B. (2017). Do reading\nand\nspelling\nshare\northographic\nrepresentations?\nEvidence from developmental dysgraphia. Cognitive\nNeuropsychology, 34, 119–143.\nHerholz, S.C. & Zatorre, R.J. (2012). Musical training as a\nframework for brain plasticity, behaviour, function, and\nstructure. Neuron, 76, 486–502.\nCreated from usyd on 2022-02-18 03:51:57.",
    "860\nReferences\nfunctional imaging studies. Human Brain Mapping, 37,\n1953–1969.\nHodgson, C. & Lambon Ralph, M.A. (2008). Mimicking\naphasic semantic errors in normal speech production:\nEvidence from a novel experimental paradigm. Brain and\nLanguage, 104, 89–101.\nHofer, F. & Schwaninger, A. (2005). Using threat image\nprojection\ndata\nfor\nassessing\nindividual\nscreen-\ners  performance. WIT Transactions on the Built\nEnvironment, 82, 417–426.\nHoffman, P., Lambon Ralph, M.A. & Woollams, A.M.\n(2015). Triangulation of the neurocomputational archi-\ntecture underpinning reading aloud. Proceedings of the\nNational Academy of Sciences, 112, E3719–E3728.\nHoffrage, U., Hafenbrädle, S. & Marewski, J.N. (2018). The\nfast-and-frugal heuristics programme. In L.J. Ball &\nV.A. Thompson (eds), Routledge International Handbook\nof Thinking and Reasoning (pp. 325–345). Abingdon,\nOxon.: Routledge.\nHoffrage, U., Krauss, S., Martignon, L. & Gigerenzer, G.\n(2015). Natural frequencies improve Bayesian reason-\ning in simple and complex inference tasks. Frontiers in\nPsychology, 6 (Article no. 1473).\nHolan, A.D. (2015). All politicians lie, some lie more than\nothers. New York Times, 11 December.\nHolland, A.C. & Kensinger, E.A. (2010). Emotion and auto-\nbiographical memory. Physics of Life Reviews, 7, 88–131.\nHolland, R.W., de Vries, M., Hermsen, B. & van Knippenberg,\nA. (2012). Mood and the attitude- behaviour link:\nThe happy act on impulse, the sad think twice. Social\nPsychological and Personality Science, 3, 356–364.\nHoller, J. & Wilkin, K. (2011). An experimental investiga-\ntion of how addressee feedback affects co-speech ges-\ntures accompanying speakers’ responses. Journal of\nPragmatics, 43, 3622–3536.\nHollingworth, A. & Henderson, J.M. (2002). Accurate visual\nmemory for previously attended objects in natural\nscenes. Journal of Experimental Psychology: Human\nPerception & Performance, 28, 113–136.\nHollingworth, A., Maxcey-Richard, A.M. & Vecera, S.P.\n(2012). The spatial distribution of attention within and\nacross objects. Journal of Experimental Psychology:\nHuman Perception and Performance, 38, 135–151.\nHolmes, V.M. (1988). Hesitations and sentence planning.\nLanguage and Cognitive Processes, 3, 323–361.\nHolyoak, K.J. & Stamenković, D. (2018). Metaphor com-\nprehension: A critical review of theories and evidence.\nPsychological Bulletin, 144, 641–671.\nHolzgrefe, J., Wellmann, C., Petrone, C., Truckenbrodt, H.,\nHohle, B. & Wartenburger, I. (2013). Brain response to\nprosodic boundary cues depends on boundary position.\nFrontiers in Psychology, 4 (Article no. 421).\nHommel, B. (1998). Automatic stimulus-response transla-\ntion in dual-task performance. Journal of Experimental\nPsychology: Human Perception and Performance, 24,\n1368–1384.\nHornikx, J., Harris, A.J.L. & Boekema, J. (2018). How many\nlaypeople holding a popular opinion are needed to\ncounter an expert opinion? Thinking & Reasoning, 24,\n117–128.\nHortensius, R., Terburg, D., Morgan, B., Stein, D.J., van\nHonk, J. & de Gelder, B. (2017). The dynamic conse-\nquences of amygdala damage on threat processing in\nUrbach-Wiethe disease: A commentary on Pishamazi\net al. (2016). Cortex, 88, 192–197.\nHorton, C., D’Zmura, M. & Srinivasan, R. (2013).\nSuppression of competing speech through entrainment\nof cortical oscillations. Journal of Neurophysiology, 109,\n3082–3093.\nHorton, W.S. & Gerrig, R.J. (2005). Conversational common\nground and memory processes in language production.\nDiscourse Processes, 40, 1–35.\nHorton, W.S. & Gerrig, R.J. (2016). Revisiting the mem-\nory-based processing approach to common ground.\nTopics in Cognitive Science, 8, 780–795.\nHorton, W.S. & Keysar, B. (1996). When do speakers take\ninto account common ground? Cognition, 59, 91–117.\nHosking, S.G. & Crassini, B. (2010). The effects of familiar\nsize and object trajectories on time-to-contact judg-\nments. Experimental Brain Research, 203, 541–552.\nHoudé, O. & Borst, G. (2015). Evidence for an inhibitory-\ncontrol theory of the reasoning brain. Frontiers in\nHuman Neuroscience, 9 (Article no. 148).\nHouston,\nA.I.,\nFawcdett,\nT.W.,\nMallpress,\nJ.M.\n&\nMcNamara, J.M. (2014). Clarifying the relationship\nbetween prospect theory and risk-sensitive foraging\ntheory. Evolution and Human Behavior, 35, 502–507.\nHoward, R.W. (2009). Individual differences in expertise\ndevelopment over decades in a complex intellectual\ndomain. Memory & Cognition, 37, 194–209.\nHowe, M.L. (2019). Unravelling the nature of early (autobio-\ngraphical) memory. Memory, 27, 115–121.\nHowe, M.L. & Courage, M.L. (1997). The emergence\nand early development of autobiographical memory.\nPsychological Review, 104, 499–523.\nHowe, P.D.L. & Carter, O.L. (2016). Hallucinations and\nmental imagery demonstrate top-down effects on visual\nperception. Behavioral and Brain Sciences, 39 (Article no.\ne248).\nHowe, P.D. & Leiserowitz, A. (2013). Who remembers a\nhot summer or a cold winter? The asymmetric effects\nof beliefs about global warming on perceptions of local\nconditions in the U.S. Global Environmental Change, 23,\n1488–1500.\nHowe, P.D.L. & Webb, M.E. (2014). Detecting unidentified\nchanges. PLoS ONE, 9 (Article no. e84490).\nHowes, A., Warren, P.A., Farmer, G., El-Deredy, W. &\nLewis, R.L. (2016). Why contextual preference reversals\nCreated from usyd on 2022-02-18 03:51:57.",
    "862\nReferences\nlifetime and its dependence on handedness and gender.\nNeuroImage, 19, 1061–1075.\nIpser, A., Agolli, B., Bajraktari, A., Al-Alawi, F., Djaafara,\nN. & Freeman, E.D. (2017). Sight and sound persist-\nently out of synch: Stable individual differences in audio-\nvisual synchronization revealed by implicit measures of\nlip-voice integration. Scientific Reports, 7 (Article no.\n46413).\nIrish, M. & Piguet, O. (2013). The pivotal role of semantic\nmemory in remembering the past and imagining the\nfuture. Frontiers in Behavioral Neuroscience, 7 (Article\nno. 27).\nIrish, M. & Piolino, P. (2016). Impaired capacity for\nprospection in the dementias – Theoretical and clinical\nimplications. British Journal of Clinical Psychology, 55,\n45–68.\nIrish, M., Bunk, S., Tu, S.C., Kamminga, J., Hodges,\nJ.R., Hornberger, M., et al. (2016). Preservation of\nepisodic memory in semantic dementia: The impor-\ntance of regions beyond the medial temporal lobes.\nNeuropsychologia, 81, 50–60.\nIshibashi, R., Mima, T., Fukuyama, H. & Pobric, G. (2018).\nFacilitation of function and manipulation knowledge of\ntools using transcranial direct current stimulation (tDCS).\nFrontiers of Integrative Neuroscience, 11 (Article no. 37).\nItkonen, T., Pekkanen, J. & Lappi, O. (2015). Driver gaze\nbehaviour is different in normal curve driving and when\nlooking at the tangent point. PLoS One, 10 (Article no.\ne0135505).\nIttelson, W.H. (1951). Size as a cue to distance: Static localisa-\ntion. American Journal of Psychology, 64, 54–67.\nItzhak, I. & Baum, S.R. (2015). Misleading bias-driven expec-\ntations in referential processing and the facilitative\nrole of contrastive accent. Journal of Psycholinguistic\nResearch, 44, 623–650.\nIyilikci, E.A. & Amado, S. (2018). The uncertainty appraisal\nenhances the prominent deck in the Iowa gambling task.\nMotivation and Emotion, 42, 1–16.\nIzard, C.E. (2007). Basic emotions, natural kinds, emotion\nschemas, and a new paradigm. Perspectives on Psycho-\nlogical Science, 2, 260–280.\nJaarsma, T., Jarokzka, H., Nap, M., van Merrienboer, J.J.G.\n& Boshuizen, H.P.A. (2014). Expertise under the micro-\nscope: Processing histopathological slides. Medical\nEducation, 48, 292–300.\nJack, F. & Hayne, H. (2010). Childhood amnesia: Empirical\nevidence for a two-stage phenomenon. Memory, 18,\n831–844.\nJack, F., MacDonald, S., Reese, E. & Hayne, H. (2009).\nMaternal reminiscing style during early childhood pre-\ndicts the age of adolescents’ earliest memories. Child\nDevelopment, 80, 496–505.\nJacobs, A., Pinto, J. & Shiffrar, M. (2004). Experience,\ncontext, and the visual perception of human movement.\nJournal of Experimental Psychology: Human Perception\nand Performance, 30, 833–835.\nJacobs, R.A. (2002). What determines visual cue reliability?\nTrends in Cognitive Sciences, 6, 345–350.\nJacoby, L.L., Bishara, A.J., Hessels, S. & Toth, J.P. (2005).\nAging, subjective experience, and cognitive control:\nDramatic false remembering by older adults. Journal of\nExperimental Psychology: General, 134, 131–148.\nJacoby, L.L., Debner, J.A. & Hay, J.F. (2001). Proactive\ninterference, accessibility bias, and process dissociations:\nValid subjective reports of memory. Journal of Experi-\nmental Psychology: Learning, Memory, and Cognition,\n27, 686–700.\nJacoby, L.L., Wahlheim, C.N. & Kelley, C.M. (2015).\nMemory consequences of looking back to notice\nchange: Retroactive and proactive facilitation. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 41, 1282–1297.\nJacquemot, C., Dupoux, E. & Bachoud-Lévi, A.-C. (2011).\nIs the word-length effect linked to subvocal rehearsal?\nCortex, 47, 484–493.\nJaeger, T.F. & Snider, N.E. (2013). Alignment as a conse-\nquence of expectation adaptation: Syntactic priming is\naffected by the prime’s prediction error given both prior\nand recent experience. Cognition, 127, 57–83.\nJain, A.K. & Duin, R.P.W. (2004). Pattern recognition. In\nR.L. Gregory (ed.), The Oxford Companion to the Mind\n(pp. 698–703). Oxford: Oxford University Press.\nJäkel, F., Singh, M., Wichmann, F.A. & Herzog, M.H. (2016).\nAn overview of quantitative approaches in Gestalt per-\nception. Vision Research, 126, 3–8.\nJalbert, A., Neath, I., Bireta, T.J. & Surprenant, A.M. (2011).\nWhen does length cause the word length effect? Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 37, 338–353.\nJames, D., Friedman, D., Louie, C. & O’Meara, T. (2018).\nDissecting the Monty Hall anomaly. Economic Inquiry,\n56, 1817–1826.\nJames, E.L., Lau-Zhu, A., Clark, I.A., Visser, R.M.,\nHagenaars, M.A. & Holmes, E.A. (2016). The trauma\nfilm paradigm as an experimental psychopathology\nmodel of psychological trauma: Intrusive memories and\nbeyond. Clinical Psychology Review, 47, 106–142.\nJames, K.H. (2017). The importance of handwriting experi-\nence on the development of the literate brain. Current\nDirections in Psychological Science, 26, 502–508.\nJames, T.W., Culham, J., Humphrey, G.K., Milner, A.D. &\nGoodale, M.A. (2003). Ventral occipital lesions impair\nobject recognition but not object-directed grasping: An\nfMRI study. Brain, 126, 2463–2475.\nJames, W. (1890). The Principles of Psychology. New York:\nHolt, Rinehard & Winston.\nJanczyk, M., Renas, S. & Durst, M. (2018). Identifying\nthe locus of compatibility-based backward crosstalk:\nCreated from usyd on 2022-02-18 03:51:57.",
    "864\nReferences\nunfamiliar faces. Quarterly Journal of Experimental\nPsychology, 70, 906–918.\nJongman, S.R., Roelofs, A. & Scheper, A.R. (2017). Picture\nnaming in typically developing and language-impaired\nchildren: The role of sustained attention. International\nJournal of Language & Communication Disorders, 52,\n323–333.\nJonides, J., Lewis, R.L., Nee, D.E., Lustig, C., Berman, M.G.\n& Moore, K.S. (2008). The mind and brain of short-term\nmemory. Annual Review of Psychology, 59, 193–224.\nJoormann, J. & Tanovic, E. (2015). Cognitive vulnerability\nto depression: Examining cognitive control and emotion\nregulation. Current Opinion in Psychology, 4, 86–92.\nJoormann, J., Yoon, K.L. & Zetsche, U. (2007). Cognitive\ninhibition\nin\ndepression.\nApplied\n&\nPreventive\nPsychology, 12, 128–139.\nJosselyn, S.A. & Frankland, P.W. (2012). Infantile amnesia: A\nneurogenic hypothesis. Learning & Memory, 19, 423–433.\nJoyce, J. (1922/1960). Ulysses. London: Bodley Head.\nJun, S.A. (2010). The implicit prosody hypothesis and overt\nprosody in English. Language and Cognitive Processes,\n25, 1201–1233.\nJuphard, A., Vidal, J.R., Perrone-Bertolotti, M., Minotti, L.,\nKahane, P., Lachaux, J.-P., et al. (2011). Direct  evidence\nfor two different neural mechanisms for reading famil-\niar and unfamiliar words: An intra-cerebral EEG study.\nFrontiers in Human Neuroscience, 5 (Article no. 101).\nJust, M.A. & Carpenter, P.A. (1992). A capacity theory of\ncomprehension. Psychological Review, 114, 678–703.\nJust, M.A., Carpenter, P.A., Keller, T.A., Emery, L.,\nZajac, H. & Thlborn, K.R. (2001). Interdependence of\nnon-overlapping cortical systems in dual cognitive tasks.\nNeuroImage, 14, 417–426.\nJuskenaite, A., Quinette, P., Laisney, M., Eustache, M.L.,\nDesgranges, B., Viader, F., et al. (2016). Preserved\nself- evaluation in amnesia supports access to the self\nthrough introspective computation. Frontiers in Human\nNeuroscience, 10 (Article no. 462).\nKaakinen, J.K. & Hyönä, J. (2007). Perspective effects in\nrepeated reading: An eye movement study. Memory &\nCognition, 35, 1323–1336.\nKahan, D.M. (2012). Why we are poles apart on climate\nchange. Nature, 488, 255.\nKahan, D.M. (2015). Climate-science communication and the\nmeasurement problem. Advances in Political Psychology,\n36, 1–43.\nKahan, D.M., Peters, E., Wittlin, M., Slovic, P., Ouellette,\nL.L., Braman, D., et al. (2012). The polarising impact\nof science literacy and numeracy on perceived climate\nchange risks. Nature Climate Change, 2, 732–735.\nKahane, G., Everett, J.A.C., Earp, B.D., Farias, M. &\nSavulescu, J. (2015). “Utilitarian” judgments in sacrifi-\ncial moral dilemmas do not reflect impartial concern for\nthe greater good. Cognition, 134, 193–209.\nKahneman, D. (2003). A perspective on judgment and choice:\nMapping bounded rationality. American Psychologist,\n58, 697–720.\nKahneman, D. (2011). Thinking, Fast and Slow. New York:\nFarrar, Strauss and Giroux.\nKahneman, D. & Tversky, A. (1972). Subjective probability –\nJudgment of representativeness. Cognitive Psychology, 3,\n430–454.\nKahneman, D. & Tversky, A. (1973). On the psychology of\nprediction. Psychological Review, 80, 237–251.\nKahneman, D. & Tversky, A. (1979). Prospect theory: An anal-\nysis of decision under risk. Econometrica, 47, 263–291.\nKahneman, D. & Tversky, A. (1984). Choices, values and\nframes. American Psychologist, 39, 341–350.\nKaiser, E., Runner, J.T., Sussman, R.S. & Tanenhaus, M.K.\n(2009). Structural and semantic constraints on the res-\nolution of pronouns and reflexives. Cognition, 112,\n55–80.\nKaiser, D. & Cichy, R.M. (2018). Typical visual field loca-\ntions facilitate access to awareness for everyday objects.\nCognition, 180, 118–122.\nKaland, N., Moller-Nielsen, A., Smith, L., Mortensen, E.L.,\nCallesen, K. & Gotlien, D. (2005). The Strange Stories\ntest: A replication study of children and adolescents\nwith Asperger syndrome. European Child & Adolescent\nPsychiatry, 14, 73–82.\nKandasamy, N., Garfinkel, S.N., Page, L., Hardy, B.,\nCritchley, H.D., Gurnell, M., et al. (2016). Interoceptive\nability predicts survival on a London trading floor.\nScientific Reports, 6 (Article no. 32986).\nKandil, F.I., Rotter, A. & Lappe, M. (2009). Driving is\nsmoother and more stable when using the tangent point.\nJournal of Vision, 9, 1–11.\nKane, J. & Webster, G.A. (2013). Heuristics and biases that\nhelp and hinder scientists: Toward a psychology of sci-\nentific judgement and decision making. In G. Feist & M.\nGorman (eds), Handbook of the Psychology of Science\n(pp. 437–459). New York: Springer.\nKanizsa, G. (1976). Subjective contours. Scientific American,\n234, 48–52.\nKanwisher, N., McDermott, J. & Chun, M.M. (1997). The\nfusiform face area: A module in human extrastri-\nate cortex specialised for face perception. Journal of\nNeuroscience, 17, 4302–4311.\nKaplan, S., Bekhor, S. & Shiftan, Y. (2011). Development\nand estimation of a semi-compensatory choice model\nbased on explicit choice protocols. Annals of Regional\nScience, 47, 51–80.\nKarimi, H. & Ferreira, F. (2016). Good-enough linguis-\ntic representations and online cognitive equilibrium in\nlanguage processing. Quarterly Journal of Experimental\nPsychology, 69, 1013–1040.\nKarlen, Y. (2017). The development of a new instrument to\nassess metacognitive strategy knowledge about academic\nCreated from usyd on 2022-02-18 03:51:57.",
    "866\nReferences\nKhemlani, S.S., Orenes, I. & Johnson-Laird, P.N. (2012).\nNegation: A theory of its meaning, representation, and\nuse. Journal of Cognitive Psychology, 24, 541–559.\nKidd, E., Donnelly, S. & Christiansen, M.H. (2018).\nIndividual differences in language acquisition and pro-\ncessing. Trends in Cognitive Sciences, 22, 154–169.\nKilpatrick, F.P. & Ittelson, W.H. (1953). The size-distance\ninvariance hypothesis. Psychological Review, 60, 223–231.\nKim, D., Stephens, J.D.W. & Pitt, M.A. (2012). How does\ncontext play a part in splitting words apart: Production\nand perception of word boundaries in casual speech.\nJournal of Memory and Language, 66, 509–529.\nKim, E.J., Suh, M.K., Lee, B., Park, K.C., Ku, B.D., Chung,\nC.S., et al. (2009). Transcortical sensory aphasia follow-\ning a left frontal lobe infarction probably due to anom-\nalously represented language areas. Journal of Clinical\nNeuroscience, 16, 1482–1485.\nKim, H. (2017a). Brain regions that show repetition sup-\npression and enhancement: A meta-analysis of 137\nneuroimaging experiments. Human Brain Mapping, 38,\n1894–1913.\nKim, N.-G. (2017b). A binocular information source for size\nperception. Frontiers in Psychology, 8 (Article no. 2078).\nKim, N.-G. (2018). Independence of size and distance in\nbinocular vision. Frontiers in Psychology, 9 (Article no.\n988).\nKim, P.Y. & Mayhorn, C.B. (2008). Exploring students’ pro-\nspective memory inside and outside the lab. American\nJournal of Psychology, 121, 241–254.\nKim, S. & Voss, J.L. (2019). Large-scale network interactions\nsupporting item-context memory formation. PloS ONE,\n14 (Article no. e0210167).\nKim, S., Carello, C. & Turvey, M.T. (2016). Size and dis-\ntance are perceived independently in an optical tunnel:\nEvidence for direct perception. Vision Research, 125,\n1–11.\nKimchi, R., Yeshurun, Y., Spehar, B. & Pirkner, Y. (2016).\nPerceptual organisation, visual attention, and object-\nhood. Vision Research, 126, 34–51.\nKing, B.R., Fogel, S.M., Albouy, G. & Doyon, J. (2013a).\nNeural correlates of the age-related changes in motor\nsequence learning and motor adaptation in older adults.\nFrontiers in Human Science, 7 (Article no. 142).\nKing, J.-R., Sitt, J.D., Faugeras, F., Rohaut, B., El Karoui,\nI., Cohen, L., et al. (2013b). Information sharing in\nthe brain indexes consciousness in non-communicative\npatients. Current Biology, 23, 1914–1919.\nKingston, J., Levy, J., Rysling, A. & Staub, A. (2016). Eye\nmovement evidence for an immediate Ganong effect.\nJournal of Experimental Psychology: Human Perception\nand Performance, 42, 1969–1988.\nKintsch, W. (1988). The role of knowledge in discourse\ncomprehension:\nA\nconstruction-integration\nmodel.\nPsychological Review, 95, 163–182.\nKintsch, W. (1992). A cognitive architecture for compre-\nhension. In H.L. Pick, P. van den Broek & D.C. Knill\n(eds), Cognition: Conceptual and methodological issues\n(pp. 143–163). Washington, DC: American Psychological\nAssociation.\nKintsch, W. (1998). Comprehension: A Paradigm for\nCognition. New York: Cambridge University Press.\nKintsch, W. (2000). Metaphor comprehension: A computa-\ntional theory. Psychonomic Bulletin & Review, 7, 257–266.\nKintsch, W., Welsch, D., Schmalhofer, E. & Zimny, S. (1990).\nSentence memory: A theoretical analysis. Journal of\nMemory and Language, 29, 133–159.\nKircanski, K. & Gotlib, I.H. (2015). Processing of emotional\ninformation in major depressive disorder: Toward a\ndimensional understanding. Emotion Review, 7, 256–264.\nKizilirmak, J.M., Sarrger, V., Kehl, J., Őllinger, M., Folta-\nSchoofs, K. & Richardson-Klavehn, A. (2018). Feelings-\nof-warmth increase more abruptly for verbal riddles\nsolved with in contrast to without Aha! experience.\nT.W., Mendez, M.F., Frontiers in Psychology, 9 (Article\nno. 1404).\nKlargaard, S.K., Starrfelt, R. & Gerlach, C. (2018). Inversion\neffects for faces and objects in developmental prosop-\nagnosia: A case series analysis. Neuropsychologia, 113,\n52–60.\nKlauer, K.C., Beller, S. & Hütter, M. (2010). Conditional rea-\nsoning in context: A dual-source model of probabilistic\ninference. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 36, 298–323.\nKlauer, K.C. & Zhao, Z. (2004). Double dissociations in\nvisual and spatial short-term memory. Journal of\nExperimental Psychology: General, 133, 355–381.\nKlauer, K.C., Musch, J. & Naumer, B. (2000). On belief bias in\nsyllogistic reasoning. Psychological Review, 107, 852–884.\nKlaus, J., Mädebach, A., Oppermann, F. & Jeseniak, J.D.\n(2017). Planning sentences while doing other things\nat the same time: Effects of concurrent verbal and\nvisuo-spatial working memory load. Quarterly Journal of\nExperimental Psychology, 70, 811–831.\nKlein, C. (2014). Reliability in cognitive neuroscience: A meta-\nmeta analysis. Philosophical Psychology, 28, 606–613.\nKlein, G. (1998). Sources of Power: How people make deci-\nsions. Cambridge, MA: MIT Press.\nKlein, G. (2008). Naturalistic decision making. Human\nFactors, 50, 456–460.\nKlein, G., Calderwood, R. & Clinton-Cirocco, A. (2010).\nRapid decision making on the fire ground: The original\nstudy plus a postscript. Journal of Cognitive Engineering\nand Decision Making, 4, 186–209.\nKliegl, O. & Bäuml, K-H.T. (2016). Retrieval practice can insu-\nlate items against intralist interference: Evidence from\nthe list-length effect, output interference, and retrieval-\ninduced forgetting. Journal of Experimental Psychology:\nLearning, Memory and Cognition, 42, 202–214.\nCreated from usyd on 2022-02-18 03:51:57.",
    "868\nReferences\nKoppenol-Gonzalez, G.V., Bouwmeester, S. & Boonstra,\nA.M. (2010). Understanding planning ability measured\nby the Tower of London: An evaluation of its internal\nstructure by latent variable modelling. Psychological\nAssessment, 22, 923–934.\nKornell, N., Bjork, R.A. & Garcia, M.A. (2011). Why tests\nappear to prevent forgetting: A distribution-based bifur-\ncation model. Journal of Memory and Language, 65,\n85–97.\nKosslyn, S.M. (1994). Image and Brain: The resolution of the\nimagery debate. Cambridge, MA: MIT Press.\nKosslyn, S.M. (2005). Mental images and the brain. Cognitive\nNeuropsychology, 22, 333–347.\nKosslyn, S.M. & Thompson, W.L. (2003). When is early\nvisual cortex activated during visual mental imagery?\nPsychological Bulletin, 129, 723–746.\nKoster, E.H.W., Hoorelbeke, K., Onraedt, T., Owens, M.\n& Derakshan, N. (2017). Cognitive control interven-\ntions for depression: A systematic review of findings\nfrom training studies. Clinical Psychology Review, 53,\n79–92.\nKotseruba, I. & Tsotsos, J. (2018). A review of 40 years of\ncognitive architecture research: Core cognitive abilities\nand practical applications. Artificial Intelligence Review,\n1–78.\nKouider, S., de Gardelle, V., Sackur, J. & Dupoux, E. (2010).\nHow rich is consciousness? The partial awareness\nhypothesis. Trends in Cognitive Sciences, 14, 301–307.\nKounios, J. & Beeman, M. (2014). The cognitive neuroscience\nof insight. Annual Review of Psychology, 65, 71–93.\nKourtzi, Z. & Connor, C.E. (2011). Neural representations\nfor object perception: Structure, category, and adaptive\ncoding. Annual Reviews of Neuroscience, 34, 45–67.\nKovacs, G. & Schweinberger, S.R. (2016). Repetition suppres-\nsion – An integrative view. Cortex, 80, 1–4.\nKovacs, K. & Conway, A.R.A. (2016). Process overlap\ntheory: A unified account of the general factor of intelli-\ngence. Psychological Inquiry, 27, 151–177.\nKovera, M.B., Bull, M. & Evelo, A.J. (2017). The case for\ndouble-blind lineup administration. Psychology, Public\nPolicy and Law, 23, 421–437.\nKraft, J.M. & Brainard, D.H. (1999). Mechanisms of colour\nconstancy under nearly natural viewing. Proceedings of\nthe National Academy of the United States of America,\n96, 307–312.\nKragel, J.E. & Polyn, S.M. (2016). Decoding episodic\nretrieval processes: Fronto-parietal and medial tempo-\nral lobe contributions to free recall. Journal of Cognitive\nNeuroscience, 28, 125–139.\nKraus, N. & Slater, J. (2016). Beyond words: How humans\ncommunicate through sound. Annual Review of Psycho-\nlogy, 67, 83–103.\nKrauss, S. & Wang, X.T. (2003). The psychology of the\nMonty\nHall\nproblem:\nDiscovering\npsychological\nmechanisms for solving a tenacious brain teaser. Journal\nof Experimental Psychology: General, 132, 3–22.\nKravitz, D.J. & Behrmann, M. (2011). Space-, object-, and\nfeature-based attention interact to organise visual scenes.\nAttention, Perception & Psychophysics, 73, 2434–2447.\nKravitz, D.J., Saleem, K.S., Baker, C.I., Ungerleider, L.G.\n& Mishkin, M. (2013). The ventral visual pathway: An\nexpanded neural framework for the processing of object\nquality. Trends in Cognitive Sciences, 17, 26–49.\nKrawczyk, D.C. (2012). The cognition and neuroscience of\nrelational reasoning. Brain Research, 1428, 13–23.\nKrawczyk D.C., Morrison, R.G., Viskontas, I., Holyoak,\nK.J., Chow, T.W., Mendez, M.F., et al. (2008).\nDistraction during relational reasoning: The role of pre-\nfrontal cortex in interference control. Neuropsychologia,\n46, 2020–2032.\nKretz, D. & Krawczyk, D.C. (2014). Expert analogy use in\na naturalistic setting. Frontiers in Psychology, 5 (Article\nno. 1333).\nKriengwatana, B., Terry, J., Chládková, K. & Escudero, P.\n(2016). Speaker and accent are handled differently:\nEvidence in native and non-native listeners. PLoS ONE,\n11 (Article no. e0156870).\nKróliczak, G., Heard, P., Goodale, M.A. & Gregory, R.L.\n(2006). Dissocations of perception and action unmasked\nby the hollow-face illusion. Brain Research, 1080, 9–16.\nKroll, J.F. & Navarro-Torres, C. (2018). Bilingualism. In\nJ.T. Wixted & S.L. Thompson-Schill (eds), Stevens’\nHandbook of Experimental Psychology and Cognitive\nNeuroscience, Vol. 3: Language and thought (4th edn)\n(pp. 245–274). New York: Wiley.\nKruger, J.M. & Dunning, D. (1999). Unskilled and unaware\nof it: How difficulties in recognising one’s own incom-\npetence lead to inflated self-assessments. Journal of\nPersonality and Social Psychology, 77, 1121–1134.\nKruglanski, A.W. & Gigerenzer, G. (2011). Intuitive and\ndeliberate judgments are based on common principles.\nPsychological Review, 118, 97–109.\nKrupinski, E.A., Graham, A.R. & Weinstein, R.S. (2013).\nCharacterising the development of visual search exper-\ntise in pathology residents viewing whole slide images.\nHuman Pathology, 44, 357–364.\nKrynski, T.R. & Tenenbaum, J.B. (2007). The role of causality\nin judgment under uncertainty. Journal of Experimental\nPsychology: General, 136, 430–450.\nKubricht, J.R., Lu, H. & Holyoak, K.J. (2017). Individual dif-\nferences in spontaneous analogical transfer. Memory &\nCognition, 45, 576–588.\nKugler, T., Connolly, T. & Ordonez, L.D. (2012). Emotion,\ndecision and risk: Betting on gambles versus betting\non people. Journal of Behavioral Decision Making, 25,\n123–134.\nKuhn, G. & Findlay, J.M. (2010). Misdirection, attention\nand awareness: Inattentional blindness reveals temporal\nCreated from usyd on 2022-02-18 03:51:57.",
    "870\nReferences\nCom ments on “Case series investigations in cogni-\ntive neuro psychology” by Schwartz and Dell (2010).\nCognitive Neuropsychology, 28, 466–474.\nLamme, V.A.F. (2006). Towards a true neural stance on con-\nsciousness. Trends in Cognitive Sciences, 10, 494–501.\nLamme, V.A.F. (2010). How neuroscience will change our\nview on consciousness. Cognitive Neuroscience, 1,\n204–240.\nLamme, V.A.F. (2018). Challenges for theories of conscious-\nness: Seeing or knowing, the missing ingredient and how\nto deal with panpsychism. Philosophical Transactions of\nthe Royal Society B, 373 (Article no. 2017.0344).\nLamy, D., Salti, M. & Bar-Haim, Y. (2009). Neural correlates\nof subjective awareness and unconscious processing:\nAn ERP study. Journal of Cognitive Neuroscience, 21,\n1435–1446.\nLand, E.H. (1986). Recent advances in retinex theory. Vision\nResearch, 26, 7–21.\nLand, M. (2009). Lee’s tau operator. Perception, 38, 853–854.\nLand, M.F. & Lee, D.N. (1994). Where we look when we\nsteer. Nature, 369, 742–744.\nLandin-Romero, R., Tan, R., Hodges, J.R. & Kufor, F. (2016).\nAn update on semantic dementia: Genetics, imaging, and\npathology. Alzheimer’s Research & Therapy, 8, 1–9.\nLandy, M.S., Banks, M.S. & Knill, D.C. (2011). Ideal-observer\nmodels of cue utilisation. In J. Trommershäuser, J.\nKörding & M.S. Landy (eds), Sensory Cue Integration\n(pp. 5–29). Oxford: Oxford University Press.\nLangenburg, G., Champod, C. & Wertheim, P. (2009).\nTesting for potential contextual bias during the verifica-\ntion stage of the ACE-V methodology when conducting\nfingerprint comparisons. Journal of Forensic Sciences,\n54, 571–582.\nLanger, M.S. & Siciliano, R.A. (2015). Are blur and dispar-\nity complementary cues to depth? Vision Research, 107,\n15–21.\nLangille, D., Asbridge, M., Kisely, S. & Wilson, K. (2012).\nRisk of depression and multiple sexual risk-taking\nbehaviours in adolescents in Nova Scotia, Canada. Sex\nHealth, 9, 254–260.\nLappi, O. & Mole, C.D. (2018). Visuo-motor control, eye\nmovements, and steering: A unified approach for incor-\nporating feedback, feedforward, and internal models.\nPsychological Bulletin, 144, 981–1001.\nLappi, O., Pekkanen, J. & Itkonen, T.H. (2013). Pursuit\neye-movements in curve driving differentiate between\nfuture path and tangent point models. PloS ONE, 8\n(Article no. e68326).\nLappi, O., Rinkkala, P. & Pekkanen, J. (2017). Systematic\nobservation of an expert driver’s gaze strategy – An\non-road case study. Frontiers in Psychology, 8 (Article\nno. 620).\nLasaponara, S., D’Onofrio, M., Pinto, M., Dragone, A.,\nMenicagli, D., Bueti, D., et al. (2018). EEG correlates of\npreparatory orienting, contextual updating, and inhibi-\ntion of sensory processing in left spatial neglect. Journal\nof Neuroscience, 38, 3792–3808.\nLatorella, K.A. (1998). Effects of modality on interrupted\nflight deck performance: Implications for data link.\nProceedings of the Human Factors and Ergonomics Society\n42nd Annual Meeting, Vols. 1 and 2, 87–91. Chicago, IL.\nLau, J.Y.F. (2015). Commentary: A glass half full or half\nempty? Cognitive bias modification for mental health\nproblems in children and adolescents – Reflections on\nthe meta-analysis by Cristea et al. (2015). Journal of\nChild Psychology and Psychiatry, 56, 735–737.\nLaukkonen, R.E. & Tangen, J.M. (2018). How to detect\ninsight moments in problem solving experiments.\nFrontiers in Psychology, 9 (Article no. 282).\nLaunder, D. & Perry, C. (2014). A study identifying factors\ninfluencing decision making in dynamic emergencies like\nurban fire and rescue settings. International Journal of\nEmergency Services, 3, 144–161.\nLavie, N. (2005). Distracted and confused? Selective attention\nunder load. Trends in Cognitive Sciences, 9, 75–82.\nLavie, N. (2010). Attention, distraction, and cognitive control\nunder load. Current Directions in Psychological Science,\n19, 143–148.\nLawrence, A., Thomas, R.P. & Dougherty, M.R. (2018).\nIntegrating fast and frugal heuristics with a model of\nmemory-based cue generation. Journal of Behavioral\nDecision Making, 31, 487–507.\nLawson, R.R., Gayle, J.O. & Wheaton, L.A. (2017). Novel\nbehavioural indicator of explicit awareness reveals tem-\nporal course of fronto-parietal neural network facilita-\ntion during motor learning. PLoS ONE, 12 (Article no.\ne0175176).\nLe, X., Lancvashire, I., Hirst, G. & Jokel, R. (2011).\nLongitudinal detection of dementia through lexical\nand syntactic changes in writing: A case study of three\nBritish novelists. Literary and Linguistic Computing, 26,\n435–461.\nLeach, F.R. & Plaks, J.E. (2009). Regret for errors of com-\nmission in the distant term versus near term: The role of\nlevel of abstraction. Personality and Social Psychology\nBulletin, 35, 221–229.\nLeding, J.K. & Toglia, M.P. (2018). Adaptive memory:\nSurvival processing and social isolation. Evolutionary\nPsychology, 16, 1–9.\nLee, C.Y., Tsai, J.-L., Su, E.C.-I., Tzeng, O.J.L. & Hung, D.\n(2005). Consistency, regularity, and frequency effects in\nnaming Chinese characters. Language and Linguistics, 6,\n75–107.\nLee, D.N. (1976). A theory of visual control of braking based\non information about time-to-collision. Perception, 5,\n1497–1501.\nLee, D.N. (2009). General tau theory: Evolution to date.\nPerception, 38, 837–850.\nCreated from usyd on 2022-02-18 03:51:57.",
    "872\nReferences\nLevin, D.T., Drivdahl, S.B., Momen, N. & Beck, M.R.\n(2002). False predictions about the detectability of visual\nchanges: The role of beliefs about attention, memory,\nand the continuity of attended objects in causing change\nblindness blindness. Consciousness & Cognition, 11,\n507–527.\nLevin, I.P. & Gaeth, G.J. (1988). How consumers are affected\nby the framing of attribute information before and after\nconsuming the product. Journal of Consumer Research,\n15, 374–378.\nLevine, D.N., Calvanio, R. & Popovics, A. (1982). Language\nin the absence of inner speech. Word, 15, 19–44.\nLevine, L.J. & Edelstein, R.S. (2009). Emotion and memory\nnarrowing: A review and goal-relevance approach.\nCognition & Emotion, 23, 833–875.\nLevis, J. & Barriuso, T.A. (2011). Non-native speakers’\npronunciation errors in spoken and read English.\nProceedings of Pronunciation in Second Language\nLearning and Teaching, 3, 187–194.\nLeviston, Z., Walker, I. & Morwinski, S. (2013). Your opinion\non climate change might not be as common as you think.\nNature Climate Change, 3, 334–337.\nLewis, P.A., Critchley, H.D., Smith, A.P. & Dolan, R.J.\n(2005). Brain mechanisms for mood congruent memory\nfacilitation. NeuroImage, 25, 1214–1223.\nLevy, C.M. & Ransdell, S. (1995). Is writing as difficult as it\nseems? Memory & Cognition, 23, 767–779.\nLevy, D.A., Stark, C.E.L. & Squire, L.R. (2004). Intact con-\nceptual priming in the absence of declarative memory.\nPsychological Science, 17, 228–235.\nLi, O., Jackson, T. & Chen, H. (2011). Attentional and\nmemory biases among weight dissatisfied young women:\nEvidence from a dichotic listening paradigm. Cognitive\nTherapy and Research, 35, 9312–9314.\nLi, P., Dunham, Y. & Carey, S. (2009). Of substance: The\nnature of language effects on entity construal. Cognitive\nPsychology, 58, 487–524.\nLiberman, A.M., Cooper, F.S., Shankweiler, D.S. & Studdert-\nKennedy, M. (1967). Perception of the speech code.\nPsychological Review, 74, 431–461.\nLibet, B., Gleason, C.A., Wright, E.W. & Pearl, D.K. (1983).\nTime of conscious intention to act in relation to onset of\ncerebral activity (readiness potential): The unconscious\ninitiation of a freely voluntary act. Brain, 106, 623–642.\nLichtenstein, S., Slovic, P., Fischhoff, B., Layman, M. &\nCoombs, J. (1978). Judged frequency of lethal events.\nJournal of Experimental Psychology: Human Learning\nand Memory, 4, 551–578.\nLiden, C., Krüger, O., Schwarz, L., Erb, M., Karatzki, B.,\nScheffler, K., et al. (2016). Neurobiology of know ledge\nand misperception of lyrics. NeuroImage, 134, 12–21.\nLiebenthal, E. & Möttönen, R. (2018). An interactive\nmodel of auditory-motor speech perception. Brain and\nLanguage, 187, 33–40.\nLieberman, P. (1963). Some effects of semantic and grammat-\nical context on the production and perception of speech.\nLanguage & Speech, 6, 172–187.\nLief, H. & Fetkewicz, J. (1995). Retractors of false memories:\nThe evolution of pseudo-memories. Journal of Psychiatry\n& Law, 23, 411–436.\nLieto, A., Lebiere, C. & Oltramari, A. (2018). The knowledge\nlevel in cognitive architectures: Current limitations and\npossible developments. Cognitive Systems Research, 48,\n39–55.\nLimpo, T. & Alves, R.A. (2018). Effects of planning strategies\non writing dynamics and final texts. Acta Psychologica,\n188, 97–109.\nLin, S., Keysar, B. & Epley, N. (2010). Reflexively mindblind:\nUsing theory of mind to interpret behaviour requires\neffortful attention. Journal of Experimental Social\nPsychology, 46, 551–556.\nLindholm, T. & Christianson, S.A. (1998). Intergroup biases\nand eyewitness testimony. Journal of Social Psychology,\n138, 710–723.\nLindquist, K.A., Gendron, M., Barrett, L.F. & Dickerson,\nB.C. (2014). Emotion perception, but not affect percep-\ntion, is impaired with semantic memory loss. Emotion,\n14, 375–387.\nLindquist, K.A., Satpute, A.B., Wager, T.D., Weber, J. &\nBarrett, L.F. (2016). The brain basis of positive and\nnegative affect: Evidence from a meta-analysis of the\nhuman neuroimaging literature. Cerebral Cortex, 26,\n1910–1922.\nLindquist, K.A., Wager, T.D., Kober, H., Bliss-Moreau, E.\n& Barrett, L.F. (2012). The brain basis of emotion: A\nmeta-analytic review. Behavioral and Brain Sciences, 35,\n121–143.\nLindsay, D.S., Allen, B.P., Chan, J.C.K. & Dahl, L.C.\n(2004). Eyewitness suggestibility and source similarity:\nIntrusions of details from one event into memory reports\nof another event. Journal of Memory and Language, 50,\n96–111.\nLingnau, A. & Petris, S. (2013). Action understanding within\nand outside the motor system: The role of task difficulty.\nCerebral Cortex, 23, 1342–1350.\nLinhares, A., Freitas, A.E.T.A., Mendes, A. & Silva, J.S.\n(2012). Entanglement of perception and reasoning in the\ncombinatorial game of chess: Differential errors of strate-\ngic reconstruction. Cognitive Systems Research, 13, 72–86.\nLinkovski, O., Kalanthroff, E., Henik, A. & Anholt, G. (2013).\nDid I turn off the stove? Good inhibitory control can\nprotect from influences of repeated checking. Journal\nof Behavior Therapy and Experimental Psychiatry, 44,\n30–36.\nLinnell, K.J. & Caparos, S. (2011). Perceptual and cognitive\nload interact to control the spatial focus of attention.\nJournal of Experimental Psychology: Human Perception\nand Performance, 37, 1643–1648.\nCreated from usyd on 2022-02-18 03:51:57.",
    "874\nReferences\nLuchins, A.S. (1942). Mechanisation in problem solving:\nThe effect of Einstellung. Psychological Monographs, 54\n(Article no. 248).\nLudwig, K., Sterzer, P., Kathmann, N. & Hesselmann, G.\n(2016). Differential modulation of visual object process-\ning in dorsal and ventral stream by stimulus visibility.\nCortex, 83, 113–123.\nLuk, K.K.S., Xiao, W.S. & Cheung, H. (2012). Cultural\neffects on perspective taking in Chinese-English bilin-\nguals. Cognition, 124, 350–355.\nLuke, S.G. (2018). Influences on and consequences of par-\nafoveal preview in reading. Attention, Perception, &\nPsychophysics, 80, 1675–1682.\nLuke, S.G. & Christianson, K. (2016). Limits on lexical pre-\ndiction during reading. Cognitive Psychology, 88, 22–60.\nLupyan, G. (2016). Not even wrong: The “It’s just X” fallacy.\nBehavioral and Brain Sciences, 39, 40–41.\nLupyan, G. (2017). Changing what you see by changing what\nyou know: The role of attention. Frontiers in Psychology,\n8 (Article no. 553).\nLuria, A.R. (1968). The Mind of a Mnemonist. New York:\nBasic Books.\nLustig, C., Konkel, A. & Jacoby, L.L. (2004). Which route\nto recovery? Controlled retrieval and accessibility bias\nin retroactive interference. Psychological Science, 15,\n729–735.\nLyn, H., Greenfield, P.M., Savage-Rumbaugh, S., Gillespie-\nLynch, K. & Hopkins, W.D. (2011). Nonhuman pri-\nmates do declare! A comparison of declarative symbol\nand gesture use in two children, two bonobos and a\nchimpanzee. Language & Communication, 31, 63–74.\nLyn, H., Russell, J.L., Leevens, D.A., Bard, K.A., Boysen,\nS.T., Schaeffer, J.A., et al. (2014). Apes communi-\ncate about absent and displaced objects: Methodology\nmatters. Animal Cognition, 17, 85–94.\nMcClain, R. & Goldrick, M. (2018). The neurocognitive\nmechanisms of speech production. In S.L. Thompson-\nSchill\n(ed.),\nStevens’\nHandbook\nof\nExperimental\nPsychology and Cognitive Neuroscience, Vol. 3: Language\nand thought: Developmental and social psychology (4th\nedn; pp. 319–356). New York: Wiley.\nMacDonald, M.C. (2013). How language production\nshapes language form and comprehension. Frontiers in\nPsychology, 4 (Article no. 226).\nMacDonald, M.C. (2016). Speak, act, remember: The lan-\nguage-production basis of serial order and maintenance\nin verbal memory. Current Directions in Psychological\nScience, 25, 47–53.\nMacDonald, M.C., Just, M.A. & Carpenter, P.A. (1992).\nWorking memory constraints on the processing of syn-\ntactic ambiguity. Cognitive Psychology, 24, 56–98.\nMacDonald, M.C., Pearlmutter, N.J. & Seidenberg, M.S.\n(1994). The lexical nature of syntactic ambiguity resolu-\ntion. Psychological Review, 101, 676–703.\nMace, J.H. (2003). Study-test awareness can enhance priming\non an implicit memory task: Evidence from a word-\ncompletion task. American Journal of Psychology, 116,\n257–279.\nMacerollo, A., Bose, S., Ricciardi, L., Edwards, M.J. &\nKilner, J.M. (2015). Linking differences in action\nperception\nwith\ndifferences\nin\naction\nexecution.\nSocial, Cognitive and Affective Neuroscience, 10,\n1121–1127.\nMacGregor, J.N., Ormerod, T.C. & Chronicle, E.P. (2001).\nInformation processing and insight: A process model\nof performance on the nine-dot and related problems.\nJournal of Experimental Psychology: Learning, Memory,\nand Cognition, 27, 176–201.\nMack, A., Erol, M., Clarke, J. & Bert, J. (2016). No iconic\nmemory without attention. Consciousness and Cognition,\n40, 1–8.\nMacLeod, A.K. (2016). Prospection, well-being and memory.\nMemory Studies, 9, 266–274.\nMacLeod, C. & Clarke, P. (2015). The attentional bias mod-\nification approach to anxiety intervention. Clinical\nPsychological Science, 3, 58–78.\nMacnamara, B.N., Hambrick, D.Z. & Oswald, F.L. (2014).\nDeliberate practice and performance in music, games,\nsports, education, and professions: A meta-analysis.\nPsychological Science, 25, 1608–1618.\nMacnamara, B.N., Hambrick, D.Z. & Moreau, D. (2016a).\nHow important is deliberate practice? Perspectives on\nPsychological Science, 11, 355–358.\nMacnamara, B.N., Moreau, D. & Hambrick, D.Z. (2016b).\nThe relationship between deliberate practice and per-\nformance in sports: A meta-analysis. Perspectives on\nPsychological Science, 11, 333–350.\nMcNeil, M.R., Hula, W.D. & Sung, J.E. (2010). The role of\nmemory and attention in aphasic language perform ance.\nIn J. Guendouzi, F. Loncke & M. Williams (eds), The\nHandbook of Psycholinguistics and Cognitive Processes:\nPerspectives in communication disorders (pp. 567–592).\nHove, UK: Psychology Press.\nMacoir, J. & Bernier, J. (2002). Is surface dysgraphia tied to\nsemantic impairment? Evidence from a case of semantic\ndementia. Brain and Cognition, 48, 452–457.\nMacPherson, S.E. (2018). Definition: Dual-tasking and multi-\ntasking. Cortex, 106, 313–314.\nMãdebach, A., Jescheniak, J.D., Schriefers, H. & Oppermann,\nF. (2011). Ease of processing constrains the activation\nflow in the conceptual-lexical system during speech plan-\nning. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 37, 649–660.\nMadore, K.P., Szpunar, K.K., Addis, D.R. & Schacter, D.L.\n(2016). Episodic specificity induction impacts activity in\na core brain network during construction of imagined\nfuture experiences. Proceedings of the National Academy\nof Sciences, 113 (Article no. 38).\nCreated from usyd on 2022-02-18 03:51:57.",
    "876\nReferences\nMarques, L.M., Lapenta, O.M., Costa, T.L. & Boggio, P.S.\n(2016). Multisensory integration processes underlying\nspeech perception as revealed by the McGurk illusion.\nLanguage, Cognition and Neuroscience, 31, 1115–1129.\nMarr, D. (1982). Vision: A computational investigation into the\nhuman representation and processing of visual informa-\ntion. San Francisco: W.H. Freeman.\nMarrero, H., Gámez, E. & Díaz, J.M. (2016). Do people\nreason when they accept tricky offers? A case of\napproach and avoidance motivated reasoning. Journal of\nEconomic Psychology, 57, 26–38.\nMarsh, E.J. & Roediger, H.L. (2012). Episodic and autobio-\ngraphical memory. In A.F. Healy & R.W. Proctor (eds),\nHandbook of Psychology, Vol. 4: Experimental psychol-\nogy (2nd edn; pp. 472–494). New York: Wiley.\nMarslen-Wilson, W.D. (1987). Functional parallelism in\nspoken word-recognition. Cognition, 25, 71–102.\nMarslen-Wilson, W.D. (1990). Activation, competition, and\nfrequency in lexical access. In G.T.M. Altmann (ed.),\nCognitive Models of Speech Processing (pp. 148–172).\nCambridge, MA: MIT Press.\nMarslen-Wilson, W.D. & Tyler, L.K. (1980). The temporal\nstructure of spoken language comprehension. Cognition,\n6, 1–71.\nMartin, C.D., Branzi, F.M. & Bar, M. (2018). Prediction is\nproduction: The missing link between language produc-\ntion and comprehension. Scientific Reports, 8 (Article\nno. 1079).\nMartin, D.H. & Barry, C. (2012). Writing nonsense: The\ninteraction between lexical and sublexical knowledge in\nthe priming of non-word spelling. Psychonomic Bulletin\n& Review, 19, 691–698.\nMartin, R.C., Miller, M. & Vu, H. (2004). Lexical-semantic\nretention and speech production: Further evidence from\nnormal and brain-damaged participants for a phrasal\nscope of planning. Cognitive Neuropsychology, 21,\n625–644.\nMartinez, A., Anilo-Vento, L., Sereno, M.I., Frank, L.R.,\nBuxton, R.B., Dubowitz, D.J., et al. (1999). Involvement\nof striate and extrastriate visual cortical areas in spatial\nattention. Nature Neuroscience, 2, 364–369.\nMashour, G.A. & Hudetz, A.G. (2018). Neural correlates of\nunconsciousness in large-scale brain networks. Trends in\nNeurosciences, 41, 150–160.\nMather, G. (2009). Foundations of Sensation and Perception\n(2nd edn). Hove, UK: Psychology Press.\nMather, G. (2015). Computational approaches to percep-\ntion: Beyond Marr’s (1982) computational approach to\nvision. In M.W. Eysenck & D. Groome (eds), Cognitive\nPsychology: Revisiting the classic studies (pp. 38–46).\nLondon: Sage.\nMather, M., Cacioppo, J.T. & Kanwisher, N. (2013). How\nfMRI can inform cognitive theories. Perspectives on\nPsychological Science, 8, 108–113.\nMathews, A. (2012). Effects of modifying the interpretation of\nemotional ambiguity. Journal of Cognitive Psychology,\n24, 92–105.\nMathy, F. & Feldman, J. (2012). What’s magic about magic\nnumbers: Chunking and data compression in short-term\nmemory. Cognition, 122, 346–362.\nMattys, S.L. (2004). Stress versus co-articulation: Toward\nan integrated approach to explicit speech segmentation.\nJournal of Experimental Psychology: Human Perception\nand Performance, 30, 397–408.\nMattys, S.L., Brooks, J. & Cooke, M. (2009). Recognising\nspeech under a processing load: Dissociating energetic\nfrom informational factors. Cognitive Psychology, 59,\n203–243.\nMattys, S.L., Davis, M.H., Bradlow, A.R. & Scott, S.K.\n(2012). Speech recognition in adverse conditions: A\nreview. Language and Cognitive Processes, 27, 953–978.\nMattys, S.L., White, L. & Melhorn, J.F. (2005). Integration of\nmultiple speech segmentation cues: A hierarchical frame-\nwork. Journal of Experimental Psychology: General, 134,\n477–500.\nMaule, A.J. & Hodgkinson, G.P. (2002). Heuristics, biases\nand strategic decision making. The Psychologist, 15,\n69–71.\nMauss, I.B., Cook, C.L., Cheng, J.Y.J. & Gross, J.J.\n(2007). Individual differences in cognitive reappraisal:\nExperiential and physiological responses to an anger\nprovocation. International Journal of Psychophysiology,\n66, 116–124.\nMayberry, E.J., Sage, K. & Lambon Ralph, M.A. (2011). At\nthe edge of semantic space: The breakdown of coherent\nconcepts in semantic dementia is constrained by typical-\nity and severity but not modality. Journal of Cognitive\nNeuroscience, 23, 2240–2251.\nMayer, K.M., Vuong, G.C. & Thornton, I.M. (2015). Do\npeople “pop out”? PLoS ONE, 10 (Article no. e0139618).\nMayor, J., Gomez, P., Chang, F. & Lupyan, G. (2014).\nConnectionism coming of age: Legacy and future chal-\nlenges. Frontiers in Psychology, 5 (Article no. 187).\nMazzi, C., Bagattini, C. & Savazzi, S. (2016). Blind-sight vs.\ndegraded-sight: Different measures tell a different story.\nFrontiers in Psychology, 7 (Article no. 901).\nMcBride, P.M. & Workman, R.A. (2017). Is prospective\nmemory unique? A comparison of prospective and\nretrospective memory. Psychology of Learning and\nMotivation, 67, 213–238.\nMcCabe, D.P., Roediger, H.L., McDaniel, M.A., Balota,\nD.A. & Hambrick, D.Z. (2010). The relationship\nbetween working memory capacity and executive func-\ntioning: Evidence for a common executive attention con-\nstruct. Neuropsychology, 24, 222–243.\nMcCaffrey, T. (2012). Innovation relies on the obscure: A key\nto overcoming the classic problem of functional fixed-\nness. Psychological Science, 23, 215–218.\nCreated from usyd on 2022-02-18 03:51:57.",
    "878\nReferences\nMcNerney, M.W., Goodwin, K.A. & Radvansky, G.A.\n(2011). A novel study: A situation model analysis of\nreading times. Discourse Processes, 48, 453–474.\nMcQueen, J.M. & Huettig, F. (2012). Changing only the prob-\nability that spoken words will be distorted changes how\nthey are recognised. Journal of the Acoustical Society of\nAmerica, 131, 509–517.\nMcQueen, J.M. (1991). The influence of the lexicon on pho-\nnetic categorisation: Stimulus quality in word-final\nambiguity. Journal of Experimental Psychology: Human\nPerception & Performance, 17, 433–443.\nMcRae, K., Jacobs, S.E., Ray, R.D., John, O.P. & Gross,\nJ.J. (2012). Individual differences in reappraisal ability:\nLinks to reappraisal frequency, well-being, and cognitive\ncontrol. Journal of Research in Personality, 46, 2–7.\nMcVay, J.C. & Kane, M.J. (2012). Drifting from low to\n“D’oh!”: Working memory capacity and mind wander-\ning predict extreme reaction times and executive control\nerrors. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 38, 525–549.\nMeador, K.J., Loring, D.W., Lee, G.P., Nichols, M.E., Moore,\nE.E. & Figueroa, R.E. (1997). Level of consciousness and\nmemory during the intracarotid sodium amobarbital pro-\ncedure. Brain and Cognition, 33, 178–188.\nMedimorec, S. & Risko, E.F. (2017). Pauses in written com-\nposition: On the importance of where writers pause.\nReading and Writing, 30, 1267–1285.\nMeehan, T.P., Bressler, S.L., Tang, W., Astafiev, S.V.,\nSylvester, C.M., Shulman, G.L., et al. (2017). Top-down\ncortical interactions in visuo-spatial attention. Brain\nStructure and Function, 222, 3127–3145.\nMegreya, A.M., Sandford, A. & Burton, A.M. (2013).\nMatching face images taken on the same day or months\napart: The limitations of photo ID. Applied Cognitive\nPsychology, 27, 700–706.\nMeiser, T. (2011). Much pain, little gain? Paradigm-specific\nmodels and methods in experimental psychology.\nPerspectives on Psychological Science, 6, 183–191.\nMelby-Lervåg, A., Lyster, S.-A.H. & Hulme, C. (2012).\nPhonological skills and their role in learning to read:\nA meta-analytic review. Psychological Bulletin, 138,\n322–352.\nMelinger, A., Branigan, H.P. & Pickering, M.J. (2014).\nParallel processing in language production. Language,\nCognition and Neuroscience, 29, 663–683.\nMelloni, L., Molina, C., Pena, M., Torres, D., Singer, W. &\nRodriguez, E. (2007). Synchronisation of neural activity\nacross cortical areas correlates with conscious percep-\ntion. Journal of Neuroscience, 27, 2858–2865.\nMelloni, L., Schwiedrzik, C.M., Muller, N., Rodriguez,\nE. & Singer, W. (2011). Expectations change the sig-\nnatures and timing of electrophysiological correlates\nof perceptual awareness. Journal of Neuroscience, 31,\n1386–1396.\nMelnikoff, D.E. & Bargh, J.A. (2018). The mythical number\ntwo. Trends in Cognitive Sciences, 22, 280–293.\nMelo, M., Scarpin, D.J., Amaro, E., Passos, R.B.D., Sato,\nJ.R., Friston, K.J., et al. (2012). How doctors generate\ndiagnostic hypotheses: A study of radiological diagno-\nsis with functional magnetic resonance imaging. PLoS\nONE, 6 (Article no. e28752).\nMély, D.A., Kim, J., McGill, M., Guo, Y. & Serre, T. (2016).\nA systematic comparison between visual cues for bound-\nary detection. Vision Research, 120, 93–107.\nMemon, A., Meissner, C.A. & Fraser, J. (2010). The cognitive\ninterview: A meta-analytic review and study space anal-\nysis of the past 25 years. Psychology, Public Policy and\nLaw, 16, 340–372.\nMenneer, T., Cave, K.R. & Donnelly, N. (2009). The cost of\nsearch for multiple targets: Effects of practice and target\nsimilarity. Journal of Experimental Psychology: Applied,\n15, 125–139.\nMennin, D.S., Fresco, D.M., Ritter, M. & Heimberg, R.G.\n(2015). An open trial of emotion regulation therapy for\ngeneralised anxiety disorder and co-occurring depres-\nsion. Depression and Anxiety, 32, 614–623.\nMercier, H. (2016). The argumentative theory: Predictions\nand empirical evidence. Trends in Cognitive Sciences, 20,\n689–700.\nMercier, H. (2018). A related proposal: An interactionist per-\nspective on reason. Behavioral and Brain Sciences, 41\n(Article no. e53).\nMercier, H., Boudry, M., Paglieri, F. & Trouche, E. (2017).\nNatural-born arguers: Teaching how to make the best\nof our reasoning abilities. Educational Psychologist, 52,\n1–16.\nMesgarani, N. & Chang, E.F. (2012). Selective cortical rep-\nresentation of attended speaker in multi-talker speech\nperception. Nature, 485, 233–237.\nMessina, I., Sambin, M., Beschoner, P. & Viviani, R. (2016).\nChanging views of emotion regulation and neurobiologi-\ncal models of the mechanism of action of psychotherapy.\nCognitive, Affective and Behavioral Neuroscience, 16,\n571–587.\nMesulam, M.M., Wieneke, C., Hurley, R., Rademaker, A.,\nThompson, C.K., Weintraub, S., et al. (2013). Words\nand objects at the tip of the left temporal lobe in primary\nprogressive aphasia. Brain, 136, 601–618.\nMetcalfe, J. & Wiebe, D. (1987). Intuition in insight and\nnoninsight problem solving. Memory & Cognition, 15,\n238–246.\nMetzner, P., von der Malsberg, T., Vasishth, S. & Rösler, F.\n(2017). The importance of reading naturally: Evidence\nfrom combined recordings of eye movements and elec-\ntric brain potentials. Cognitive Science, 41, 1232–1263.\nMeyer, A.S. & Damian, M.F. (2007). Activation of distrac-\ntor names in the picture-picture interference paradigm.\nMemory & Cognition, 35, 494–503.\nCreated from usyd on 2022-02-18 03:51:57.",
    "880\nReferences\ncomplex “frontal lobe” tasks: A latent variable analysis.\nCognitive Psychology, 41, 49–100.\nMohamed, T. & Clifton, C. (2011). Processing temporary syn-\ntactic ambiguity: The effect of contextual bias. Quarterly\nJournal of Experimental Psychology, 64, 1797–1820.\nMoisala, M., Salmela, V., Hietajärvi, L., Salo, E., Carlson, S.,\nSalonen, O., et al. (2016). Media multitasking is associ-\nated with distractibility and increased prefrontal activ-\nity in adolescents and young adults. NeuroImage, 134,\n113–121.\nMole, C.D., Jersakova, R. & Kountouriotis, G.K. (2018).\nMetacognitive judgements of perceptual-motor steer-\ning performance. Quarterly Journal of Experimental\nPsychology, 71, 2223–2234.\nMole, C.D., Kountouriotis, G., Billington, J. & Wilkie,\nR.M. (2016). Optic flow speed modulates guidance level\ncontrol: New insights into two-level steering. Journal\nof Experimental Psychology: Human Perception and\nPerformance, 42, 1818–1838.\nMolenberghs, P., Sale, M.V. & Mattingley, J.B. (2012). Is\nthere a critical lesion site for unilateral spatial neglect?\nA meta-analysis using activation likelihood estimation.\nFrontiers in Human Neuroscience, 6 (Article no. 78).\nMomma, S. & Phillips, C. (2018). The relationship between\nparsing and generation. Annual Review of Linguistics, 4,\n233–254.\nMonahan, P.J. (2018). Phonological knowledge and speech\ncomprehension. Annual Review of Linguistics, 4,\n421–447.\nMonti, M.M., Pickard, J.D. & Owen, A.M. (2013). Visual\ncognition in disorders of consciousness: From V1 to top-\ndown attention. Human Brain Mapping, 34, 1245–1253.\nMonti, M.M., Vanhaudenhuyse, A., Coleman, M.R., Boly,\nM., Pickard, J.D., Tshibanda, L., et al. (2010). Wilful\nmodulation of brain activity in disorders of con-\nsciousness. New England Journal of Medicine, 362,\n579–589.\nMoore, A.T. & Schwitzgebel, E. (2018). The experience of\nreading. Consciousness and Cognition, 62, 57–68.\nMoore, J.W. (2016). What is the sense of agency and does it\nmatter? Frontiers in Psychology, 7 (Article no. 1272).\nMoore, R. (2015). A common intentional framework for\nape and human communication. Current Anthropology,\n56, 70.\nMoore-Berg, S., Karpinski, A. & Plant, E.A. (2017). Quick to\nthe draw: How suspect race and socioeconomic status\ninfluences shooting decisions. Journal of Applied Social\nPsychology, 47, 482–491.\nMoors, A. (2016). Automaticity: Componential, causal, and\nmechanistic explanations. Annual Review of Psychology,\n67, 263–287.\nMoors, A. & De Houwer, J. (2006). Automaticity: A theoret-\nical and conceptual analysis. Psychological Bulletin, 132,\n297–326.\nMorawetz, C., Holz, P., Bauedwig, J., Treue, S. & Dechent,\nP. (2007). Split of attentional resources in human visual\ncortex. Visual Neuroscience, 24, 817–826.\nMorcom, A.M. (2016). Mind over memory: Cuing the aging\nbrain. Current Directions in Psychological Science, 25,\n143–150.\nMorewedge, C.K. & Kahneman, D. (2010). Associative\nprocesses in intuitive judgement. Trends in Cognitive\nSciences, 14, 435–440.\nMoray, N. (1959). Attention in dichotic listening: Affective\ncues and the influence of instructions. Quarterly Journal\nof Experimental Psychology, 11, 56–60.\nMorey, C.C. (2018). The case against specialised visual-\nspatial short-term memory. Psychological Bulletin, 144,\n849–883.\nMorgan, C.A., Southwik, S., Steffian, G., Hazlett, G.A.\n& Loftus, E.F. (2013). Misinformation can influence\nmemory for recently experienced, highly stressful events.\nInternational Journal of Law and Psychiatry, 36, 11–17.\nMorgan, P.H. & Patrick, J. (2013). Paying the price works:\nIncreasing goal-state access cost improves problem\nsolving and mitigates the effect of interruption. Quarterly\nJournal of Experimental Psychology, 66, 160–178.\nMoro, V., Berlucchi, G., Lerch, J., Tomaiuolo, F. & Aglioti,\nS.M. (2008). Selective deficit of mental visual imagery\nwith intact primary visual cortex and visual perception.\nCortex, 44, 109–118.\nMorris, C.D., Bransford, J.D. & Franks, J.J. (1977). Levels of\nprocessing versus transfer appropriate processing. Journal\nof Verbal Learning and Verbal Behavior, 16, 519–533.\nMorrison, R.G., Holyoak, K.J. & Truong, B. (2001).\nWorking-memory modularity in analogical reasoning.\nIn J.D. Moore & K. Stenning (eds), Proceedings of the\nTwenty-third Annual Conference of the Cognitive Science\nSociety (pp. 663–668). Mahway, NJ: Lawrence Erlbaum\nAssociates.\nMoscovitch, M. (2008). Commentary: A perspective on pro-\nspective memory. In M. Kliegel, M.A. McDaniel &\nG.O. Einstein (eds), Prospective Memory: Cognitive,\nneuroscience, developmental, and applied perspectives\n(pp.  309–320). New York: Lawrence Erlbaum Associates.\nMoscovitch, M., Cabeza, R., Winocur, G. & Nadel, L.\n(2016). Episodic memory and beyond: The hippocam-\npus and neocortex in transformation. Annual Review of\nPsychology, 67, 105–134.\nMoscovitch, M., Winocur, G. & Behrmann, M. (1997). What\nis special about face recognition? Nineteen experi-\nments on a person with visual object agnosia and dys-\nlexia but normal face recognition. Journal of Cognitive\nNeuroscience, 9, 555–604.\nMoser, J.S., Huppert, J.D., Foa, E.B. & Simons, R.F. (2012).\nInterpretation of ambiguous social scenarios in social\nphobia and depression: Evidence from event-related\nbrain potentials. Biological Psychology, 89, 387–397.\nCreated from usyd on 2022-02-18 03:51:57.",
    "882\nReferences\nNairne, J.S. (2015a). Encoding and retrieval: Beyond Tulving\nand Thomson’s (1973) encoding specificity. In M.W.\nEysenck & D. Groome (eds), Cognitive Psychology:\nRevisiting the classic studies (pp. 117–132). London: Sage.\nNairne, J.S. (2015b). The three “Ws” of episodic memory:\nWhat, when, and where. American Journal of Psychology,\n128, 267–279.\nNairne, J.S., Thompson, S.R. & Pandeirada, J.N.S. (2007).\nAdaptive memory: Survival processing enhances reten-\ntion. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 33, 263–273.\nNamdar, G., Tzelgov, J., Algom, D. & Ganel, T. (2014).\nGrasping numbers: Evidence for automatic influence\nof numerical magnitude on grip aperture. Psychonomic\nBulletin & Review, 21, 830–835.\nNardo, D., Holland, R., Leff, A.P., Price, C.J. & Crinion,\nJ.T. (2018). Less is more: Neural mechanisms underly-\ning anomia treatment in chronic aphasic patients. Brain,\n140, 3039–3054.\nNascimento, S.M.C., de Almeida, V.M.N., Fiadeiro, P.T. &\nFoster, D.H. (2004). Minimum-variance cone- excitation\nratios and the limits of relational colour constancy.\nVisual Neuroscience, 21, 337–340.\nNascimento, S.M.C., Amano, K. & Foster, D.H. (2016).\nSpatial distributions of local illumination colour in\nnatural scenes. Vision Research, 120, 39–44.\nNaselaris, T., Olman, C.A., Stansbury, D.E., Ugurbil, K. &\nGallant, J.L. (2015). A voxel-wise encoding model for\nearly visual areas decodes mental images of remembered\nscenes. NeuroImage, 105, 215–228.\nNavarrete, G. & Mandel, D.R. (eds) (2016). Improving\nBayesian reasoning: What works and why? Frontiers in\nPsychology, 6, 1–207.\nNavarro, D.J. & Perfors, A.F. (2011). Hypothesis genera-\ntion, sparse categories, and the positive test strategy.\nPsychological Review, 118, 120–134.\nNavon, D. (1977). Forest before trees: The precedence\nof global features in visual perception. Cognitive\nPsychology, 9, 353–383.\nNavon, D. & Miller, J. (2002). Queuing or sharing? A criti-\ncal evaluation of the single-bottleneck notion. Cognitive\nPsychology, 44, 193–251.\nNee, D.E., Brown, J.W., Askren, M.K., Berman, M.G.,\nDemiralp, E., Krawitz, A., et al. (2013). A meta-analysis\nof executive components of working memory. Cerebral\nCortex, 23, 264–282.\nNeely, J.H. (1977). Semantic priming and retrieval from lexical\nmemory: Roles of inhibitionless spreading activation\nand limited capacity attention. Journal of Experimental\nPsychology: General, 106, 226–254.\nNeghavi, H.R. & Nyberg, L. (2005). Common fronto-parietal\nactivity in attention, memory, and consciousness: Shared\ndemands on integration? Consciousness and Cognition,\n14, 390–425.\nNeisser, U. (1996). Remembering as doing. Behavioral and\nBrain Sciences, 19, 203–204.\nNelson, L.D., Simmons, J. & Simonsohn, U. (2018).\nPsychology’s renaissance. Annual Review of Psychology,\n69, 511–534.\nNeumann, M.F., End, A., Luttmann, S., Scheweinberger, S.R.\n& Wiese, H. (2015). The own-age bias in face memory\nis unrelated to differences in attention – Evidence\nfrom event-related potentials. Cognitive, Affective &\nBehavioral Neuroscience, 15, 180–194.\nNewell, A. & Simon, H.A. (1972). Human Problem Solving.\nEnglewood Cliffs, NJ: Prentice Hall.\nNewell, A., Shaw, J.C. & Simon, H.A. (1958). Elements of a\ntheory of human problem solving. Psychological Review,\n65, 151–166.\nNewell, B.R. (2015). Decision making under risk: Beyond\nKahneman and Tversky’s (1979) prospect theory.\nIn M.W. Eysenck & D. Groome (eds), Cognitive\nPsychology: Revisiting the classic studies (pp. 162–178).\nLondon: Sage.\nNewell, B.R. (2011). Recognising the recognition heuristic\nfor what it is (and what it’s not). Judgment and Decision\nMaking, 6, 409–412.\nNewell, B.R., Weston, N.J. & Shanks, D.R. (2003). Empirical\ntests of a fast and frugal heuristic: Not everyone “takes-\nthe-best”. Organizational Behavior and Human Decision\nProcesses, 91, 82–96.\nNewman, I.R., Gibb, M. & Thompson, V.A. (2017). Rule-\nbased reasoning is fast and belief-based reasoning can be\nslow: Challenging current explanations of belief-bias and\nbase-rate neglect. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 43, 1154–1170.\nNewman-Toker, D.E., Kerber, K.A., Hsieh, Y.-H., Pula,\nJ.H., Omron, R., Tehrani, A.S.S., et al. (2013). HINTS\noutperforms ABCD2 to screen for stroke in acute con-\ntinuous vertigo and dizziness. Academic Emergency\nMedicine, 20, 987–996.\nNewsome, M.R. & Johnson-Laird, P.N. (2006). How falsity\ndispels fallacies. Thinking & Reasoning, 12, 214–234.\nNewstead, S.E., Handley, S.J. & Buck, E. (1999). Falsifying\nmental models: Testing the predictions of theories\nof  syllogistic reasoning. Memory & Cognition, 27,\n344–354.\nNguyen, K. & McDaniel, M.A. (2016). The JOIs of text\ncomprehension: Supplementing retrieval practice to\nenhance inference performance. Journal of Experimental\nPsychology: Applied, 22, 59–71.\nNicolle, A., Fleming, S.M., Bach, D.R., Driver, J. & Dolan,\nR.J. (2011). A regret-induced status quo bias. Journal of\nNeuroscience, 31, 3320–3327.\nNiebergall, R., Khayat, P.S., Treue, S. & Martinez-Trujillo,\nJ.C. (2011). Multifocal attention filters targets from dis-\ntractors within and beyond primate MT neurons’ recep-\ntive field boundaries. Neuron, 72, 1067–1079.\nCreated from usyd on 2022-02-18 03:51:57.",
    "884\nReferences\nTest (RAST). Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 23, 441–458.\nOatley, K. & Johnson-Laird, P.N. (1987). Towards a cognitive\ntheory of emotions. Cognition and Emotion, 1, 29–50.\nOberauer, K., Lewandowsky, S., Awh, E., Brown, G.D.A.,\nConway, A., Cowan, N., et al. (2018). Benchmarks\nfor models of short-term and working memory.\nPsychological Bulletin, 144, 885–958.\nO’Brien, E.J. & Cook, A.E. (2014). Knowledge activation,\nintegration, and validation during narrative text compre-\nhension. Discourse Processes, 51, 26–49.\nO’Brien, E.J. & Cook, A.E. (2016). Coherence threshold and\nthe continuity of processing: The RI-Val model of com-\nprehension. Discourse Processes, 53, 326–338.\nO’Brien, G.E., McCloy, D.R., Kubota, E.C. & Yeatman, J.D.\n(2018). Reading ability and phoneme categorisation.\nScientific Reports, 8 (Article no. 16842).\nOchsner, K.N., Ray, R.R., Hughes, B., McRae, K., Cooper,\nJ.C., Weber, J., et al. (2009). Bottom-up and top-down\nprocesses in emotion generation: Common and dis-\ntinct neural mechanisms. Psychological Science, 20,\n1322–1331.\nO’Craven, K., Downing, P. & Kanwisher, N. (1999). fMRI\nevidence for objects as the units of attentional  selection.\nNature, 401, 584–587.\nOdinot, G., Wolters, G. & van Koppen, P.J. (2009).\nEyewitness memory of a supermarket robbery: A case\nstudy of accuracy and confidence after 3 months. Law\nand Human Behavior, 33, 506–514.\nOeberst, A. & Blank, H. (2012). Undoing suggestive influence\non memory: The reversibility of the eyewitness misinfor-\nmation effect. Cognition, 125, 141–159.\nOehler, A., Wendt, S., Wedlich, F. & Horn, M. (2018).\nInvestors’ personality influences investment decisions:\nExperimental evidence on extraversion and neuroticism.\nJournal of Behavioral Finance, 19, 30–48.\nOh, H., Beck, J.M., Zhu, P., Sommer, M.A., Ferrari, S. &\nEgner, T. (2016). Satisficing in split-second decision\nmaking is characterised by strategic cue discounting.\nJournal of Experimental Psychology: Learning, Memory,\nand Cognition, 42, 1937–1956.\nOhlsson, S. (1992). Information processing explanations\nof insight and related phenomena. In M.T. Keane &\nK.J.  Gilhooly (eds), Advances in the Psychology\nof Thinking (Vol. 1; pp. 1–44). London: Harvester\nWheatsheaf.\nOhlsson, S. (2011). Deep Learning: How the mind overrides\nexperience. Cambridge: Cambridge University Press.\nOlguin, A., Bekinschtein, T.A. & Bozic, M. (2018). Neural\nencoding of attended continuous speech under different\ntypes of interference. Journal of Cognitive Neuroscience,\n30, 1606–1619.\nOlive, T. (2012). Writing and working memory: A summary of\ntheories and findings. In E.L. Grigorenko, E. Mambrino\n& D.D. Preiss (eds), Writing: A mosaic of perspectives\n(pp. 125–140). Hove, UK: Psychology Press.\nOlive, T. (2014). Toward a parallel and cascading model of\nthe writing system: A review of research on writing pro-\ncesses’ co-ordination. Journal of Writing Research, 6,\n173–194.\nOlive, T., Kellogg, R.T. & Piolat, A. (2008). Verbal, visual,\nand spatial working memory demands during text com-\nposition. Applied Psycholinguistics, 29, 669–687.\nOlive, T. & Passerault, J.-M. (2012). The visuospatial dimen-\nsion of writing. Written Communication, 29, 326–344.\nOliveri, M. & Caltagirone, C. (2006). Suppression of extinc-\ntion with TMS in humans: From healthy controls to\npatients. Behavioural Neurology, 17, 163–167.\nOlkoniemi, H., Ranta, H. & Kaakinen, J.K. (2016). Individual\ndifferences in the processing of written sarcasm and\nmetaphor: Evidence from eye movements. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 42, 433–450.\nÖllinger, M., Jones, G. & Knoblich, G. (2014). The dynamics\nof search, impasse, and representational change provide\na coherent explanation of difficulty in the nine-dot\nproblem. Psychological Research, 78, 266–275.\nOlson, A., Halloran, E. & Romani, C. (2015a). Target/error\noverlap in jargonaphasia: The case for a one-source\nmodel, lexical and non-lexical summation, and the\nspecial status of correct responses. Cortex, 73, 158–179.\nOlson, J.A., Amlani, A.A., Raz, A. & Rensink, R.A. (2015b).\nInfluencing choice without awareness. Consciousness and\nCognition, 37, 225–236.\nOlson, J.A., Landry, M., Appourchaux, K. & Raz, A. (2016).\nSimulated thought insertion: Influencing the sense of\nagency using deception and magic. Consciousness and\nCognition, 43, 11–26.\nOpen Science Collaboration (2015). Estimating the reproduc-\nibility of psychological science. Science, 349 (Article no.\naac4716).\nOphir, E., Nass, C. & Wagner, A.D. (2009). Cognitive control\nin media multitaskers. Proceedings of the National\nAssociation of Sciences, 106, 15583–15587.\nOppenheimer, D.M. (2004). Spontaneous discounting of\navailability in frequency judgment tasks. Psychological\nScience, 15, 100–105.\nOppenheimer, D.M. & Monin, B. (2009). Investigations in spo-\nntaneous discounting. Memory & Cognition, 37, 608–614.\nOrchard-Mills, E., Van der Burg, E. & Alais, D. (2016). Cross-\nmodal correspondence between auditory pitch and visual\nelevation affects temporal ventriloquism. Perception, 45,\n409–424.\nO’Reilly, R.C., Wyatte, D., Herd, S., Mingus, B. & Jilk, D.J.\n(2013). Recurrent processing during object recognition.\nFrontiers in Psychology, 4 (Article no. 124).\nOrtega, J., Montañes, P., Barnhart, A. & Kuhn, G. (2018).\nExploiting failures in metacognition through magic:\nCreated from usyd on 2022-02-18 03:51:57.",
    "886\nReferences\nParketny, J., Towler, J. & Eimer, M. (2015). The  activation\nof visual face memory and explicit face recogni-\ntion are delayed in developmental prosopagnosia.\nNeuropsychologia, 75, 538–547.\nParkinson, B. (2001). Putting appraisal in context. In K.R.\nScherer, A. Schorr & T. Johnstone (eds), Appraisal\nProcesses in Emotion: Theory, methods, research. Oxford:\nOxford University Press.\nParkinson, B. (2011). How social is the social psychology\nof emotion? British Journal of Social Psychology, 50,\n405–413.\nParkinson, B. (2015). Pushing and pulling the boundaries\nof emotion regulation. Psychological Inquiry, 26, 93–98.\nParkinson, B. & Manstead, A.S.R. (2015). Current emotion\nresearch in social psychology: Thinking about emotions\nand other people. Emotion Review, 7, 371–380.\nParks, C.M. (2013). Transfer-appropriate processing in rec-\nognition memory: Perceptual and conceptual effects on\nrecognition memory depend on task demands. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 39, 1280–1286.\nPashler, H. (1994). Dual-task interference in simple tasks:\nData and theory. Psychological Bulletin, 116, 220–244.\nPastötter, B. & Bäuml, K-H.T. (2016). Reversing the testing\neffect by feedback: Behavioural and electrophysiologi-\ncal evidence. Cognitive and Affective Neuroscience, 16,\n473–488.\nPatal, E.Z., Gadian, D.G., Cooper, J.M., Dziecial, A.M.,\nMishkin, M. & Vargha-Khadem, F. (2015). Extent of\nhippocampal atrophy predicts degree of deficit in recall.\nProceedings of the National Academy of Sciences, 112,\n12830–12833.\nPatihis, L., Frenda, S.J., LePort, A.K.R., Petersen, N.,\nNichols, R.M., Stark, C.E.L., et al. (2013). False memo-\nries in highly superior autobiographical memory individ-\nuals. Proceedings of the National Academy of Sciences,\n110, 20947–20952.\nPatsenko, E.G. & Altmann, E.M. (2010). How planful is\nroutine behaviour? A selective-attention model of perfor-\nmance in the Tower of Hanoi. Journal of Experimental\nPsychology: General, 139, 95–116.\nPattamadilok, C., Perre, L. & Ziegler, J.C. (2011). Beyond\nrhyme or reason: ERPs reveal task-specific activation of\northography on spoken language. Brain and Language,\n116, 116–124.\nPatterson, K. & Lambon Ralph, M.A. (1999). Selective dis-\norders of reading? Current Opinion in Neurobiology, 9,\n235–239.\nPatterson, K. & Plaut, D.C. (2009). “Shallow draughts intox-\nicate the brain”: Lessons from cognitive science for cog-\nnitive neuropsychology. Topics in Cognitive Science, 1,\n39–58.\nPatterson, K., Nestor, P.J. & Rogers, T.T. (2007). Where\ndo you know what you know? The representation of\nsemantic knowledge in the human brain. Nature Reviews\nNeuroscience, 8, 976–987.\nPatterson, R., Fournier, L., Pierce, B., Winterbottom, M.\n& Tripp, L. (2009). Modelling the dynamics of rec-\nognition-primed decision making. Proceedings of the\n9th International Conference on Naturalistic Decision\nMaking. London, June.\nPauker, E., Itzhak, I., Baum, S.R. & Steinhauer, K. (2011).\nEffects of cooperating and conflicting prosody in spoken\nEnglish garden path sentences: ERP evidence for the\nboundary deletion hypothesis. Journal of Cognitive\nNeuroscience, 23, 2731–2751.\nPaulo, R.M., Albuquerque, P.B. & Bull, R. (2016). The\nenhanced cognitive interview: Expressions of uncer-\ntainty, motivation and its relation with report accuracy.\nPsychology, Crime & Law, 22, 366–381.\nPaulo, R.M., Albuquerque, P.B., Vitorino, F. & Bull, R.\n(2017). Enhancing the cognitive interview with an alter-\nnative procedure to witness-compatible questioning:\nCategory clustering recall. Psychology, Crime & Law, 23,\n967–982.\nPavan, A., Ghin, F., Donato, R., Campana, G. & Mather,\nG. (2017). The neural basis of form and form-motion\nintegration from static and dynamic translational Glass\npatterns: A rTMS investigation. NeuroImage, 157,\n555–560.\nPavlova, M.A., Erb, M., Hagberg, G.E., Loureiro, J., Sokolov,\nA.N. & Scheffer, K. (2017). “Wrong way up”: Temporal\nand spatial dynamics of the networks for body motion\nprocessing at 9.4 T. Cerebral Cortex, 27, 5318–5330.\nPayne, B.K. (2006). Weapon bias: Split-second decisions\nand unintended stereotyping. Current Perspectives in\nPsychological Science, 15, 287–291.\nPayne, J. (1976). Task complexity and contingent process-\ning in decision making: An information search and\nprotocol analysis. Organizational Behavior and Human\nPerformance, 16, 366–387.\nPayne, S.J. & Duggan, G.B. (2011). Giving up problem\nsolving. Memory & Cognition, 39, 902–913.\nPaynter, C.A., Kotovsky, K. & Reder, L.M. (2010). Problem-\nsolving without awareness: An ERP investigation.\nNeuropsychologia, 48, 3137–3144.\nPearson, J. & Kosslyn, S.M. (2015). The heterogeneity of\nmental representation: Ending the imagery debate.\nProceedings of the National Association of Sciences, 112,\n10089–10092.\nPearson, J., Clifford, C.W.G. & Tong, F. (2008). The func-\ntional impact of mental imagery on conscious  perception.\nCurrent Biology, 18, 982–986.\nPeckham, A.D., McHugh, R.K. & Otto, M.W. (2010). A\nmeta-analysis of the magnitude of biased attention in\ndepression. Depression and Anxiety, 27, 1135–1142.\nPedrazzini, E., Schnider, A. & Ptak, R. (2017). A neuro-\nanatomical model of space-based and object-centred\nCreated from usyd on 2022-02-18 03:51:57.",
    "888\nReferences\nin jargon aphasia. Frontiers in Human Neuroscience, 11\n(Article no. 225).\nPilz, K.S., Roggeveen, A.B., Creighton, S.E., Bennett, P.J.\n& Sekuler, A.B. (2012). How prevalent is object-based\nattention? PloS ONE, 7 (Article no. e30693).\nPinker, S. (1997). How the Mind Works. New York: W.W.\nNorton.\nPinna, D., Porcheddu, D. & Deiana, K. (2016). From group-\ning to coupling: A new perceptual organisation in vision,\npsychology, and biology. Frontiers in Psychology, 7\n(Article no. 1051).\nPinto, J. (2006). Developing body representations: A review\nof infants’ responses to biological-motion displays. In\nG. Knoblich, M. Grosjean, J. Thornton & M. Shiffrar\n(eds), Perception of the Human Body from the Inside Out\n(pp. 305–322). Oxford: Oxford University Press.\nPinto, Y., Neville, D.A., Otten, M., Corballis, P.M., Lamme,\nV.A.F., de Haan, E.H.F., et al. (2017). Split brain:\nDivided perception but undivided consciousness. Brain,\n140, 1231–1237.\nPirogovsky-Turk, E., Filoteo, J.V., Litvan, I. & Harrington,\nD.L. (2015). Structural MRI correlates of episodic\nmemory processes in Parkinson’s disease without mild\ncognitive impairment. Journal of Parkinson’s Disease, 5,\n971–981.\nPisella, L., Binkofski, F., Lasek, K., Toi, L. & Rossetti, Y.\n(2006). No double dissociation between optic ataxia\nand visual agnosia: Multiple sub-streams for multi-\nple visuo-manual integrations. Neuropsychologia, 44,\n2734–2748.\nPitts, M.A., Lutsyshyna, L.A. & Hillyard, S.A. (2018). The\nrelationship between attention and consciousness: An\nexpanded taxonomy and implications for no-report par-\nadigms. Philosophical Transactions of the Royal Society\nB, 373 (Article no. 21070348).\nPitts, M.A., Lutsyshyna, L.A. & Hillyard, S.A. (2019). Reply\nto Montemayor and Halajian. Philosophical Transactions\nof the Royal Society B, 374 (Article no. 20190003).\nPlait, P. (2016). A fantastic optical illusion: Just another brick\nin the wall? Retrieved from www.slate.com/blogs/bad_\nastronomy/2016/05/18/sometimes_a_cigar_isn_t_just_\na_cigar.html.\nPlanton, S., Jucla, M. Roux, F.-E. & Démonet, J.-F. (2013).\nThe “handwriting brain”: A meta-analysis of neuroim-\naging studies of motor versus orthographic processes.\nCortex, 49, 2772–2787.\nPlanton, S., Longcamp, M., Péran, P., Démonet, J.-F. &\nJucla, M. (2017). How specialised are writing-specific\nbrain regions? An fMRI study of writing, drawing and\noral spelling. Cortex, 88, 66–80.\nPlaut, D.C., McClelland, J.L., Seidenberg, M.S. & Patterson,\nK.E. (1996). Understanding normal and impaired word\nreading: Computational principles in quasi-regular\ndomains. Psychological Review, 103, 56–115.\nPleskac, T.J. (2012). Comparability effects in probability judg-\nments. Psychological Science, 23, 848–854.\nPobric, G., Jefferies, E. & Lambon Ralph, M.A. (2010a).\nAmodal semantic representations depend on both ante-\nrior temporal lobes: Evidence from repetitive transcranial\nmagnetic stimulation. Neuropsychologia, 48, 1336–1342.\nPobric, G., Jefferies, E. & Lambon Ralph, M.A. (2010b).\nCategory-specific\nversus\ncategory-general\nsemantic\nimpairment induced by transcranial magnetic stimula-\ntion. Current Biology, 20, 964–968.\nPoeppel, D. & Monahan, P.J. (2011). Feedforward and feed-\nback in speech perception: Revisiting analysis by synthe-\nsis. Language and Cognitive Processes, 26, 935–951.\nPohl, R.F., Michalkiewicz, M., Erdfelder, E. & Hilbig, B.E.\n(2017). Use of the recognition heuristic depends on the\ndomain’s recognition validity, not on the recognition\nvalidity of selected sets of objects. Memory & Cognition,\n45, 776–791.\nPoldrack, R.A. & Yarkoni, T. (2016). From brain maps to cog-\nnitive ontologies: Informatics and the search for mental\nstructure. Annual Review of Psychology, 67, 587–612.\nPoldrack, R.A., Baker, C., Durnez, J., Gorgolewski, K.J.,\nMatthews, P.M., Munafo, M.R., et al. (2017). Scanning\nthe horizon: Towards transparent and reproducible neu-\nroimaging research. Nature Reviews Neuroscience, 18,\n115–126.\nPope, D.G. & Schweitzer, M.E. (2011). Is Tiger Woods loss\naverse? Persistent bias in the face of experience, compe-\ntition, and high stakes. American Economic Review, 101,\n129–157.\nPope, S.M., Meguerditchian, A. & Hopkins, W.D. (2015).\nBaboons (Papio papio), but not humans, break cogni-\ntive set in a visuo-motor task. Animal Cognition, 18,\n1339–1346.\nPopov, V., Ostarek, M. & Tenison, C. (2018). Practices and\npitfalls in inferring neural representations. NeuroImage,\n174, 340–351.\nPopper, K.R. (1968). The Logic of Scientific Discovery.\nLondon: Hutchinson.\nPosner, M.I. (1980). Orienting of attention. The VIIth\nSir Frederic Bartlett lecture. Quarterly Journal of\nExperimental Psychology, 32A, 3–25.\nPostle, B.R. (2006). Working memory as an emergent prop-\nerty of the mind and brain. Neuroscience, 139, 23–38.\nPourtois, G., Vanlessen, N., Bakic, J. & Paul, K. (2017).\nModulatory effects of positive mood on cognition:\nLessons from attention and error monitoring. Current\nDirections in Psychological Science, 26, 495–501.\nPower, M. & Dalgleish, T. (2008). Cognition and Emotion:\nFrom order to disorder (2nd edn). Hove, UK: Psychology\nPress.\nPozzulo, J.D., Crescini, C. & Panton, T. (2008). Does meth-\nodology matter in eyewitness identification research?\nThe effect of live versus video exposure on eyewitness\nCreated from usyd on 2022-02-18 03:51:57.",
    "890\nReferences\nRakow, T. & Sylark, W.J. (2018). Judgement heuris-\ntics. In L.J. Ball & V.A. Thompson (eds), Routledge\nInternational Handbook of Thinking and Reasoning\n(pp. 451–471). Abingdon, Oxon.: Routledge.\nRamsey, L.E., Siegel, J.S., Baldassarre, A., Metcalf, N.V.,\nZinn, K., Shulman, G.L., et al. (2016). Normalisation\nof network connectivity in hemispatial neglect recovery.\nAnnals of Neurology, 80, 127–141.\nRamsey, R. (2018). What are reaction time indices of auto-\nmatic imitation measuring? Consciousness and Cognition,\n65, 240–254.\nRanft, A., Golkowski, D., Kiel, T., Riedl, V., Kohl,\nP., Rohrer, G., et al. (2016). Neural correlates of\nsevoflurance- induced\nunconsciousness\nidentified\nby\nsimultaneous functional magnetic resonance imaging\nand\nelectroencephalography.\nAnesthesiology,\n125,\n861–872.\nRao, K.V. & Baddeley, A. (2013). Raven’s matrices and\nworking memory: A dual-task approach. Quarterly\nJournal of Experimental Psychology, 66, 1881–1887.\nRaposo, A. & Marques, J.F. (2013). The contribution of fron-\nto-parietal regions to sentence comprehension: Insights\nfrom the Moses illusion. NeuroImage, 83, 431–437.\nRapp, B. & Lipka, K. (2011). The literate brain: The relation-\nship between spelling and reading. Journal of Cognitive\nNeuroscience, 23, 1180–1197.\nRapp, B., Epstein, C. & Tainturier, M.-J. (2002). The\nintegration of information across lexical and sublexical\nprocesses in spelling. Cognitive Neuropsychology, 19,\n1–29.\nRapp, B., Fischer-Baum, S. & Miozzo, M. (2015). Modality\nand morphology: What we write may not be what we\nsay. Psychological Science, 26, 892–902.\nRashal, E., Yeshurun, Y. & Kimchi, R. (2017). Attentional\nrequirements in perceptual grouping depend on the pro-\ncesses involved in the organisation. Attention, Perception\n& Psychophysics, 79, 2073–2087.\nRastle, K. & Brysbaert, M. (2006). Masked phonologi-\ncal priming effects in English: Are they real? Do they\nmatter? Cognitive Psychology, 53, 97–145.\nRaven, J., Raven, C. & Court, J.H. (1998). Manual for Raven’s\nProgressive Matrices and Vocabulary Scales. Section 4:\nThe advanced progressive matrices. San Antonio, TX:\nHarcourt Assessment.\nRay, C. & Huntsinger, J.R. (2017). Feeling and thinking:\nAn affect-as-cognitive feedback account. Social and\nPersonality Psychology Compass, 11 (Article no. e12314).\nRayner, K. & Clifton, C. (2009). Language processing in\nreading and speech perception is fast and incremen-\ntal: Implications for event related potential research.\nBiological Psychology, 80, 4–9.\nRayner, K., Li, X.S. & Pollatsek, A. (2007). Extending the\nE-Z model of eye-movement control to Chinese readers.\nCognitive Science, 31, 1021–1033.\nRayner, K., Pollatsek, A., Ashby, J. & Clifton, C. (2012).\nPsychology of Reading (2nd edn). Hove, UK: Psychology\nPress.\nRayner, K., White, S.J., Johnson, R.L. & Liversedge, S.P.\n(2006). Reading words with jubmled lettres – There is a\ncost. Psychological Science, 17, 192–193.\nReber, A.S. (1993). Implicit Learning and Tacit Knowledge:\nAn essay on the cognitive unconscious. Oxford: Oxford\nUniversity Press.\nReber, P.J. (2013). The neural basis of implicit learning\nand memory: A review of neuropsychological and\nneuroimaging research. Neuropsychologia, 51, 2026–2042.\nReber, P.J., Knowlton, J.R. & Squire, L.R. (1996).\nDissociable properties of memory systems: Differences in\nthe flexibility of declarative and non-declarative knowl-\nedge. Behavioral Neuroscience, 110, 861–871.\nRecanzone, G.H. & Sutter, M.L. (2008). The biological basis\nof audition. Annual Review of Psychology, 59, 119–142.\nRedelmeier, C., Koehler, D.J., Liberman, V. & Tversky, A.\n(1995). Probability judgment in medicine: Discounting\nunspecified alternatives. Medical Decision Making, 15,\n227–230.\nRedfern, A.S. & Benton, C.P. (2017). Expressive faces confuse\nidentity. i-Perception, 8 (Article no. 2041669517731115).\nRees, G. (2007). Neural correlates of the contents of visual\nawareness in humans. Philosophical Transactions of the\nRoyal Society B – Biological Sciences, 362, 877–886.\nReeves, A.J., Amano, K. & Foster, D.H. (2008). Colour\nconstancy: Phenomenal or projective? Perception &\nPsychophysics, 70, 219–228.\nRegier, T. & Xu, Y. (2017). The Sapir-Whorf hypothesis\nand inference under uncertainty. Wiley Interdisciplinary\nReviews – Cognitive Science, 8 (Article no. UNSP e1440).\nRego, S., Avantes, J. & Magalhães, P. (2018). Is there a\nsunk-cost effect in committed relationships? Current\nPsychology, 37, 508–519.\nReichle, E.D. (2015). Computational models of reading: A\nprimer. Language and Linguistics Compass, 9, 271–284.\nReichle, E.D., Pollatsek, A., Fisher, D.L. & Rayner, K.\n(1998). Towards a model of eye movement control in\nreading. Psychological Review, 105, 125–157.\nReingold, E.M., Reichle, E.D., Glaholt, M.G. & Sheridan,\nH. (2012). Direct lexical control of eye movements in\nreading: Evidence from a survival analysis of fixation\ndurations. Cognitive Psychology, 65, 177–206.\nReingold, E.M., Sheridan, H. & Reichle, E.D. (2015). Direct\nlexical and non-lexical control of fixation duration in\nreading. In A. Pollatsek & R. Treiman (eds), Oxford\nHandbook of Reading (pp. 261–276). Oxford: Oxford\nUniversity Press.\nReiss, J.P., Campbell, D.W., Leslie, W.D., Paulus, M.P.,\nStroman, P.W., Polimeni, J.O., et al. (2005). The role of\nthe striatum in implicit learning: A functional magnetic\nresonance imaging study. NeuroReport, 16, 1291–1295.\nCreated from usyd on 2022-02-18 03:51:57.",
    "892\nReferences\nRobin, J. & Moscovitch, M. (2017). Details, gist and schema:\nHippocampal-neocortical interactions underlying recent\nand remote episodic and spatial memory. Current\nOpinion in Behavioral Sciences, 17, 114–123.\nRobin, J., Wynn, J. & Moscovitch, M. (2016). The spatial\nscaffold: The effects of spatial context on memory for\nevents. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 42, 308–315.\nRobinson, B.L. & McAlpine, D. (2009). Gain control mech-\nanisms in the auditory pathway. Current Opinion in\nNeurobiology, 19, 402–407.\nRobinson, G.A., Butterworth, B. & Cipolotti, L. (2015).\n“My mind is doing it all”: No “brake” to stop speech\ngeneration in jargon aphasia. Cognitive and Behavioral\nNeurology, 28, 229–241.\nRobison, M.W. & Unsworth, N. (2018). Cognitive and\ncontextual correlates of spontaneous and deliberate\nmind-wandering. Journal of Experimental Psychology:\nLearning, Memory and Cognition, 44, 85–98.\nRock, P.B., Harris, M.G. & Yates, T. (2006). A test of\nthe tau-dot hypothesis of braking control. Journal\nof Experimental Psychology: Human Perception and\nPerformance, 32, 1479–1484.\nRodriguez, L.-F., Gutierrez-Garcia, J.O. & Ramos, F. (2016).\nModelling the interaction of emotion and cognition\nin autonomous agents. Biologically Inspired Cognitive\nArchitectures, 17, 57–70.\nRoediger, H.L. (2008). Relativity of remembering: Why the\nlaws of memory vanished. Annual Review of Psychology,\n59, 225–254.\nRoediger, H.L. (2010). Reflections on intersections between\ncognitive and social psychology: A personal exploration.\nEuropean Journal of Social Psychology, 40, 189–205.\nRoediger, H.L. & McDermott, K.B. (2013). Two types of\nevent memory. Proceedings of the National Academy of\nSciences, 110, 20856–20857.\nRoediger, H.L. & Gallo, D.A. (2001). Levels of processing:\nSome unanswered questions. In M. Naveh-Benjamin,\nM. Moscovitch & H.L. Roediger (eds), Perspectives on\nHuman Memory and Cognitive Aging (pp. 28–47). New\nYork: Psychology Press.\nRogers, B. (2016). Revisiting motion parallax as a source of\n3-D information. Perception, 45, 1267–1278.\nRogers, B. & Graham, M.E. (1979). Motion parallax as an\nindependent cue for depth perception. Perception, 8,\n125–134.\nRogers, T.T. & Patterson, K. (2007). Object categorisations:\nReversals and explanations of the basic-level advan-\ntage. Journal of Experimental Psychology: General, 136,\n451–469.\nRohde, H. & Ettlinger, M. (2012). Integration of pragmatic\nand phonetic cues in spoken word recognition. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 38, 967–983.\nRohde, M., van Dam, L.C.J. & Ernst, M.O. (2016).\nStatistically optimal multisensory cue integration: A\npractical tutorial. Multisensory Research, 29, 279–317.\nRolls, E.T. & Mills, W.P.C. (2018). Non-accidental properties,\nmetric invariance, and encoding by neurons in a model\nof ventral stream visual object recognition, VisNet.\nNeurobiology of Learning and Memory, 152, 20–31.\nRorden, C., Hjaltason, H., Fillmore, P., Fridriksson, J.,\nKjartansson, O., Magnusdottir, S., et al. (2012).\nAllocentric neglect strongly associated with egocentric\nneglect. Neuropsychologia, 50, 1151–1157.\nRosch, E., Mervis, C.B., Gray, W.D., Johnson, D.M.\n& Boyes-Braem, P. (1976). Basic objects in natural\ncategories. Cognitive Psychology, 8, 382–439.\nRose, N.S., Craik, F.I.M. & Buchsbaum, B.R. (2015). Levels\nof processing in working memory: Differential involve-\nment of fronto-temporal networks. Journal of Cognitive\nNeuroscience, 27, 522–532.\nRose, S.B., Aristei, S., Melinger, A. & Abdel Rahman, R.\n(2019). The closer they are, the more they interfere:\nSemantic similarity of word distractors increases com-\npetition in language production. Journal of Experimental\nPsychology: Learning, Memory, and Cognition, 45,\n753–763.\nRosenbaum, R.S., Kõhler, S., Schacter, D.L., Moscovitch,\nM., Westmacott, R., Black, S.E., et al. (2005). The case\nof KC: Contributions of a memory-impaired person to\nmemory theory. Neuropsychologia, 43, 989–1021.\nRosenbloom, P.S., Laird, J.E. & Lebiere, C. (2017). Précis of\n“A standard model of the mind”. Advances in Cognitive\nSystems, 5, 1–4.\nRosenholtz, R. (2016). Capabilities and limitations of\nperipheral vision. Annual Review of Vision Science, 2,\n437–457.\nRosenholtz, R. (2017a). What modern vision science reveals\nabout the awareness puzzle: Summary-statistic encoding\nplus decision limits underlie the richness of visual per-\nception and its quirky failures. Vision Sciences Society\nSymposium on Summary Statistics and Awareness, St.\nPete Beach, FL, preprint arXiv:1706.02764.\nRosenholtz, R. (2017b). Capacity limits and how the\nvisual  system copes with them. Electronic Imaging, 14,\n8–23.\nRosenholtz, R., Huang, J. & Ehinger, K.A. (2012). Rethinking\nthe role of top-down attention in vision: Effects attrib-\nutable to a lossy representation in peripheral vision.\nFrontiers in Psychology, 3 (Article no. 13).\nRosenholtz, R., Sharan, L. & Park, E. (2016). Why don’t we\nsee the gorilla? Looking in the wrong places, attending\nto the wrong stuff, or doing the wrong task? Journal of\nVision, 16, 43.\nRosenthal, G., Sporns, O. & Avidan, G. (2017). Stimulus-\ndependent dynamic reorganisation of the human face\nprocessing network. Cerebral Cortex, 27, 4823–4834.\nCreated from usyd on 2022-02-18 03:51:57.",
    "894\nReferences\nRusting, C.L. & DeHart, T. (2000). Retrieving positive mem-\nories to regulate negative mood: Consequences for\nmood-congruent memory. Journal of Personality and\nSocial Psychology, 78, 737–752.\nRuthruff, E., Johnston, J.C. & Remington, R.W. (2009). How\nstrategic is the central bottleneck: Can it be overcome\nby trying harder? Journal of Experimental Psychology:\nHuman Perception and Performance, 35, 1368–1384.\nRyskin, R., Futrell, R., Kiran, S. & Gibson, E. (2018).\nComprehenders model the nature of noise in the envi-\nronment. Cognition, 181, 141–150.\nRyu, J. & Lee, S.-H. (2018). Stimulus-tuned structure of cor-\nrelated fMRI activity in human visual cortex. Cerebral\nCortex, 28, 693–712.\nSabri, M., Humphries, C., Verber, M., Mangalathu, J.,\nDesai, A., Binder, J.R., et al. (2013). Perceptual demand\nmodulates activation of human auditory cortex in\nresponse to task-irrelevant sounds. Journal of Cognitive\nNeuroscience, 25, 1553–1562.\nSadeh, T., Ozubko, J.D., Winocur, G. & Moscovitch, M.\n(2016). Forgetting patterns differentiate between two\nforms of memory representation. Psychological Science,\n27, 810–820.\nSadeh, T., Shohamy, D., Levy, D.R., Reggev, N. & Maril, A.\n(2011). Cooperation between the hippocampus and the\nstriatum during episodic encoding. Journal of Cognitive\nNeuroscience, 23, 1597–1608.\nSaenen, L., Heyvaert, M., van Dooren, W. & Onghena, P.\n(2015). Inhibitory control in a notorious brain teaser:\nThe Monty Hall dilemma. ZDN Mathematics Education,\n47, 837–848.\nSævland, W. & Norman, E. (2016). Studying different tasks\nof  implicit learning across multiple test sessions con-\nducted on the web. Frontiers in Psychology, 7 (Article\nno. 808).\nSakreida, K., Effnert, I., Thill, S., Menz, M.M., Jirak, D.,\nEickhoff, C.R., et al. (2016). Affordance process-\ning in  segregated parieto-frontal dorsal stream sub-\npathways. Neuroscience and Biobehavioral Reviews, 69,\n80–112.\nSala, G. & Gobet, F. (2017). Experts’ memory superiority for\ndomain-specific random material generalizes across fields\nof expertise: A meta-analysis. Memory & Cognition, 45,\n183–193.\nSala, G., Foley, J.P. & Gobet, F. (2017). The effects of chess\ninstruction on pupils’ cognitive and academic skills:\nState of the art and theoretical challenges. Frontiers in\nPsychology, 8 (Article no. 238).\nSalvucci, D.D. & Taatgen, N.A. (2008). Threaded cogni-\ntion: An integrated theory of concurrent multitasking.\nPsychological Review, 115, 101–130.\nSalvucci, D.D. & Taatgen, N.A. (2011). Toward a unified\nview of cognitive control. Topics in Cognitive Science, 3,\n227–230.\nSampson, M. & Faroqui-Shah, Y. (2011). Investigation\nof self-monitoring in fluent aphasia with jargon.\nAphasiology, 25, 505–528.\nSamuel, A.G. (2011). Speech perception. Annual Review of\nPsychology, 62, 49–72.\nSamuelson, W. & Zeckhauser, R.J. (1988). Status quo bias\nin decision making. Journal of Risk and Uncertainty, 1,\n7–59.\nSanbonmatsu, D.M., Posavac, S.S., Behrends, A.A., Moore,\nS.M. & Uchino, B.N. (2015). Why a confirmation strat-\negy dominates psychological science. PLoS ONE, 10\n(Article no. e01138197).\nSanbonmatsu, D.M., Strayer, D.L., Biondi, F., Behrends,\nA.A. & Moore, S.M. (2016a). Cell-phone use diminishes\nself-awareness of impaired driving. Psychonomic Bulletin\n& Review, 23, 617–623.\nSanbonmatsu, D.M., Strayer, D.L., Biondi, F., Behrends,\nA.A., Ward, N. & Watson, J.M. (2016b). Why drivers\nuse cell phones and support legislation to restrict this\npractice. Accident Analysis and Prevention, 92, 22–33.\nSanborn, A.N. & Chater, N. (2016). Bayesian brains\nwithout  probabilities. Trends in Cognitive Sciences, 20,\n883–893.\nSand, K., Habekost, T., Petersen, A. & Starrfelt, R. (2016).\nThe word superiority effect in central and peripheral\nvision. Visual Cognition, 24, 293–303.\nSandberg, K., Timmermans, B., Overgaard, M. & Cleeremans,\nA. (2010). Measuring consciousness: Is one measure\nbetter than the others? Consciousness and Cognition, 19,\n1069–1078.\nSandler, W., Meir, I., Padden, C. & Aronoff, M. (2005). The\nemergence of grammar: Syntactic structure in a new lan-\nguage. Proceedings of the National Academy of Sciences\nof the United States of America, 102, 2661–2665.\nSanocki, T., Bowyer, K.W., Heath, M.D. & Sarkar, S. (1998).\nAre edges sufficient for object recognition? Journal\nof Experimental Psychology: Human Perception &\nPerformance, 24, 340–349.\nSantangelo, V., Cavallina, C., Colucci, P., Santori, A., Macri,\nS., McGaugh, J.L. & Campolongo, P. (2018). Enhanced\nbrain activity associated with memory access in highly\nsuperior autobiographical memory. Proceedings of the\nNational Academy of Sciences, 115, 7795–7800.\nSaposnik, G., Redelmeier, D., Ruff, C.C. & Tobler, P.N.\n(2016). Cognitive biases associated with medical deci-\nsions: A systematic review. BMC Medical Informatics\nand Decision Making, 16 (Article no. 138).\nSari, D.A., Koster, E.H.W., Pourtois, G. & Derakshan, N.\n(2016). Training working memory to improve atten-\ntional control in anxiety: A proof-of-principle study\nusing behavioural and electrophysiological measures.\nBiological Psychology, 121, 203–212.\nSarri, M., Ruff, C.C., Rees, G. & Driver, J. (2010). Neural\ncorrelates of visual extinction or awareness in a series of\nCreated from usyd on 2022-02-18 03:51:57.",
    "896\nReferences\nSchumacher, E.H., Seymour, T.L., Glass, J.M., Fencsik, D.E.,\nLauber, E.J., Kieras, D.E., et al. (2001). Virtually perfect\ntime sharing in dual-task performance: Uncorking the\ncentral cognitive bottleneck. Psychological Science, 12,\n101–108.\nSchwark, J., Sandry, J., MacDonald, J. & Dolgov, I. (2012).\nFalse feedback increases detection of low-preva-\nlence targets in visual search. Attention, Perception &\nPsychophysics, 74, 1583–1589.\nSchwartz, B., Ward, A., Monterosso, J., Lyubormirsky, S.,\nWhite, K. & Lehman, D.R. (2002). Maximising versus\nsatisficing: Happiness is a matter of choice. Journal of\nPersonality and Social Psychology, 83, 1178–1197.\nSchwartz, B.L. & Hashtroudi, S. (1991). Priming is independ-\nent of skill learning. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 17, 1177–1187.\nSchwartz, J., Chapman, G., Brewer, N. & Bergus, G. (2004).\nThe effects of accountability on bias in physician deci-\nsion making: Going from bad to worse. Psychonomic\nBulletin & Review, 11, 173–178.\nSchwarz, N. & Clore, G.L. (1983). Mood, misattribution, and\njudgements of well-being – Informative and directive\nfunctions of affective states. Journal of Personality and\nSocial Psychology, 45, 513–523.\nSchwartz, S., Vuilleumier, P., Hutton, C., Marouta, A.,\nDolan, R.J. & Driver, J. (2005). Modulation of fMRI\nresponses by load at fixation during task-irrelevant stim-\nulation in the peripheral visual field. Cerebral Cortex, 15,\n770–786.\nSchwartz, Z.P. & David, S.V. (2018). Focal suppression of\ndistractor sounds by selective attention in auditory\ncortex. Cerebral Cortex, 28, 323–339.\nSchweinberger, S.R. & Soukup, G.R. (1998). Asymmetric\nrelationships among perceptions of facial identity,\nemotion and facial speech. Journal of Experimental\nPsychology: Human Perception and Performance, 24,\n1748–1765.\nSchweizer, T.A., Kan, K., Hung, Y., Tam, F., Naglie, G. &\nGraham, S.J. (2013). Brain activity during driving with\ndistraction: An immersive fMRI study. Frontiers in\nHuman Neuroscience, 7 (Article no. 53).\nSchweppe, J., Grice, M. & Rummer, R. (2011). What models\nof verbal working memory can learn from phonological\ntheory: Decomposing the phonological similarity effect.\nJournal of Memory and Language, 64, 256–269.\nSchwieren, J., Barenberg, J. & Dutke, S. (2017). The testing\neffect in the psychology classroom: A meta-analytic pers-\npective. Psychology Learning and Teaching, 16, 179–196.\nScott-Phillips, T.C. (2015). Nonhuman primate communica-\ntion, pragmatics, and the origins of language. Current\nAnthropology, 56, 56–66.\nScoville, W.B. & Milner, B. (1957). Loss of recent memory\nafter bilateral hippocampal lesions. Journal of Neurology,\nNeurosurgery & Psychiatry, 20, 11–21.\nScullin, M.K., McDaniel, M.A., Dasse, M.N., Lee, J.H.,\nKurinac, C.A., Tami, C., et al. (2018). Thought probes\nduring prospective memory encoding: Evidence for\nperfunctory processes. PLoS ONE, 13 (Article no.\ne0198646).\nScullin, M.K., McDaniel, M.A., Shelton, J.T. & Lee, J.H.\n(2010). Focal/nonfocal cue effects in prospective\nmemory: monitoring diﬃculty or different retrieval pro-\ncesses? Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 36, 736–749.\nScullin, M.K., Kurinec, C.A. & Nguyen, K. (2017). The effects\nof implementation intention strategies on prospective\nmemory cue encoding. Journal of Cognitive Psychology,\n29, 929–938.\nScully, I.D., Napper, L.E. & Hupbach, A. (2017). Does reacti-\nvation trigger episodic memory change? A meta- analysis.\nNeurobiology of Learning and Memory, 142, 99–107.\nSearston, R.A., Tangen, J.M. & Eva, K.W. (2016). Putting\nbias into context: The role of familiarity in identification.\nLaw and Human Behavior, 40, 50–64.\nSebastianelli, L., Saltuari, L. & Nardone, R. (2017). How the\nbrain can rewire itself after an injury: The lesson from\nhemispherectomy. Neural Regeneration Research, 12,\n1426–1427.\nSedgwick, H.A. & Gillam, B. (2017). A non-modular approach\nto visual space perception. Ecological Psychology, 29,\n72–94.\nSegaert, K., Weber, K., de Lange, F.P., Petersson, K.M.\n& Hagoort, P. (2013). The suppression of repe-\ntition enhancement: A review of fMRI studies.\nNeuropsychologia, 51, 59–66.\nSekeres, M.J., Bonasia, K., St-Laurent, M., Pishdadian, S.,\nWinocur, G., Grady, C., et al. (2016). Recovering and\npreventing loss of detailed memory: Differential rates of\nforgetting for detail types in episodic memory. Learning\nand Memory, 23, 72–82.\nSenghas, A., Kita, S. & Őzyűrek, A. (2004). Children creat-\ning core properties of language: Evidence from emerging\nsign language in Nicaruagua. Science, 305, 1779–1782.\nSeo, M.-G. & Barrett, L.F. (2007). Being emotional during\ndecision making – Good or bad? An empirical investiga-\ntion. Academy of Management Journal, 50, 923–940.\nSeymour, K., Clifford, C.W.G., Logothetis, N.K. & Bartels,\nA. (2009). The coding of color, motion and their con-\njunction in the human visual cortex. Current Biology, 19,\n177–183.\nSeymour, K.J., Williams, M.A. & Rich, A.N. (2016). The\nrepresentation of colour across the human visual\ncortex: Distinguishing chromatic signals contributing to\nobject form versus surface colour. Cerebral Cortex, 26,\n1997–2008.\nShallice, T. (2015). Cognitive neuropsychology and its vicis-\nsitudes: The fate of Caramazza’s axioms. Cognitive\nNeuropsychology, 32, 385–411.\nCreated from usyd on 2022-02-18 03:51:57.",
    "898\nReferences\nhappiness: Building a science of discrete positive emo-\ntions. American Psychologist, 72, 617–643.\nShipstead, Z., Harrison, T.L. & Engle, R.W. (2016). Working\nmemory capacity and fluid intelligence: Maintenance and\ndisengagement. Perspectives on Psychological Science, 11,\n771–799.\nShiv, B., Loewenstein, G. & Bechara, A. (2005). The dark side\nof emotion in decision making: When individuals with\ndecreased emotional reactions make more advantageous\ndecisions. Cognitive Brain Research, 23, 85–92.\nShomstein, S., Lee, J. & Behrmann, M. (2010). Top-down and\nbottom-up attentional guidance: Investigating the role\nof the dorsal and ventral parietal cortices. Experimental\nBrain Research, 206, 197–208.\nShrem, T., Murray, M.M. & Deouell, L.Y. (2017). Auditory-\nvisual integration modulates location-specific repetition\nsuppression of auditory responses. Psychophysiology, 54,\n1663–1675.\nShrout, P.E. & Rodgers, J.L. (2018). Psychology, science, and\nknowledge construction: Broadening perspectives from\nthe replication crisis. Annual Review of Psychology, 69,\n487–510.\nSides, A., Osherson, D., Bonni, N. & Viale, R. (2002). On the\nreality of the conjunction fallacy. Memory & Cognition,\n30, 191–198.\nSidi, Y., Ophir, Y. & Ackerman, R. (2016). Generalising\nscreen inferiority – Does the medium, screen versus\npaper, affect performance even with brief tasks?\nMetacognition Learning, 11, 15–33.\nSidi, Y., Shpigelman, M., Zalmanov, H. & Ackerman, R.\n(2017). Understanding metacognitive inferiority on\nscreen by exposing cues for depth of processing. Learning\nand Instruction, 51, 61–73.\nSiebert, M., Markowitsch, H.J. & Bartel, P. (2003). Amygdala,\naffect and cognition: Evidence from 10 patients with\nUrbach-Wiethe disease. Brain, 126, 2627–2637.\nSiegel, E.H., Sands, M.K., Van den Noortgate, W., Condon,\nP., Chang, Y., Dy, J., et al. (2018). Emotion fingerprints\nor emotion populations? A meta-analytic investigation of\nautonomic features of emotion categories. Psychological\nBulletin, 144, 343–393.\nSiegert, R., Weatherall, M., Taylor, K.D. & Abernethy, D.\n(2008). A meta-analysis of performance on simple span\nand more complex working memory tasks in Parkinson’s\ndisease. Neuropsychology, 22, 450–461.\nSigurdardottir, H.M., Fridriksdottir, L.E., Gudjonsdottir, S.\n& Kristjánsson, A. (2018). Cognition, 175, 157–168.\nSilbert, L.J., Honey, C.J., Simony, E., Poeppel, D. & Hasson,\nU. (2014). Coupled neural systems underlie the produc-\ntion and comprehension of naturalistic narrative speech.\nProceedings of the National Academy of Sciences, 111,\nE4687–E4696.\nSimion, F., Regolin, L. & Bulf, H. (2008). A predisposition\nfor biological motion in the newborn baby. Proceedings\nof the National Academy of Sciences of the United States\nof America, 105, 809–813.\nSimmons, J.P., Nelson, L.D. & Simonsohn, U. (2018). False-\npositive citations. Perspectives on Psychological Science,\n13, 255–259.\nSimmons, S.M., Hicks, A. & Caird, J.K. (2016). Safety-critical\nevent risk associated with cell phone tasks as measured\nin naturalistic driving studies: A systematic review and\nmeta-analysis. Accident Analysis and Prevention, 67,\n161–169.\nSimon, D., Krawczyk, D.C. & Holyoak, K.J. (2004).\nConstruction of preferences by constraint satisfaction.\nPsychological Science, 15, 331–336.\nSimon, H.A. (1945). Theory of games and economic behav-\niour. American Sociological Review, 50, 558–560.\nSimon, H.A. (1957). Models of Man: Social and rational. New\nYork: Wiley.\nSimon, H.A. (1966). Scientific discovery and the psychol-\nogy of problem solving. In H.A. Simon (ed.), Mind and\nCosmos: Essays in contemporary science and philosophy\n(pp. 22–40). Pittsburgh, PA: University of Pittsburgh\nPress.\nSimon, H.A. (1974). How big is a chunk? Science, 183,\n482–488.\nSimon, H.A. (1990). Invariants of human behaviour. Annual\nReview of Psychology, 41, 1–19.\nSimons, D.J. & Chabris, C.F. (1999). Gorillas in our midst:\nSustained inattentional blindness for dynamic events.\nPerception, 28, 1059–1074.\nSimons, D.J. & Chabris, C.F. (2011). What people believe\nabout how memory works: A representative survey of\nthe US population. Public Library of Science One, 6\n(Article no. e22757).\nSimonson, I. & Staw, B.M. (1992). De-escalation strategies: A\ncomparison of techniques for reducing commitment to\nlosing courses of action. Journal of Applied Psychology,\n77, 419–426.\nSinai, M.J., Ooi, T.L. & He, Z.J. (1998). Terrain influ-\nences  the  accurate judgment of distance. Nature, 395,\n497–500.\nSinger, W. & Gray, C.M. (1995). Visual feature integration\nand the temporal correlation hypothesis. Annual Review\nof Neuroscience, 18, 555–586.\nSingmann, H., Klauer, K.C. & Beller, S. (2016). Probabilistic\nconditional reasoning: Disentangling form and content\nwith the dual-source model. Cognitive Psychology, 88,\n61–87.\nSio, U.N. & Ormerod, T.C. (2009). Does incubation enhance\nproblem solving? A meta-analytic review. Psychological\nBulletin, 135, 94–120.\nSio, U.N. & Ormerod, T.C. (2015). Incubation and cueing\neffects in problem-solving: Set aside the difficult prob-\nlems but focus on the easy ones. Thinking & Reasoning,\n21, 113–129.\nCreated from usyd on 2022-02-18 03:51:57.",
    "900\nReferences\nadaptive decision making. Journal of Experimental\nPsychology: Learning, Memory, and Cognition, 42,\n215–237.\nSolomon, S.H. & Thompson-Schill, S.L. (2017). Finding fea-\ntures, figuratively. Brain & Language, 174, 61–71.\nSong, J.-H. (2017). Abandoning and modifying one action\nplan for alternatives. Philosophical Transactions of the\nRoyal Society B, 372 (Article no. 20160195).\nSong, J.-H. & Nakayama, K. (2008). Target selection in visual\nsearch as revealed by movement trajectories. Vision\nResearch, 48, 853–861.\nSoni, M., Lambon Ralph, M.A., Noonan, K., Ehsan, S.,\nHodgson, C. & Woollams, A.M. (2009). “L” is for tiger:\nEffects of phonological (mis)cueing on picture naming\nin semantic aphasia. Journal of Neurolinguistics, 22,\n538–547.\nSoni, M., Lambon Ralph, M.A. & Woollams, A.M. (2011).\n“W” is for bath: Can associative errors be cued? Journal\nof Neuolinguistics, 24, 445–465.\nSörqvist, P. (2010). High working memory capacity attenu-\nates the deviation effect but not the duplex-mechanism\naccount of auditory distraction. Memory & Cognition,\n38, 651–658.\nSörqvist, P., Dahlstrom, Ő., Karlsson, T. & Rönnberg, J.\n(2016). Concentration: The neural underpinnings of how\ncognitive load shields against distraction. Frontiers in\nHuman Neuroscience, 10 (Article no. 221).\nSotiropoulos, A. & Hanley, J.R. (2017). Developmental\nsurface and phonological dyslexic in both Greek and\nEnglish. Cognition, 168, 205–216.\nSoto, D. & Silvanto, J. (2014). Reappraising the relationship\nbetween working memory and conscious awareness.\nTrends in Cognitive Sciences, 18, 520–525.\nSoto-Faraco, S. & Alsius, A. (2009). Deconstructing the\nMcGurk-MacDonald illusion. Journal of Experimental\nPsychology: Human Perception and Performance, 35,\n580–587.\nSowden, S. & Catmur, C. (2015). The role of the right tempo-\nro-parietal junction in the control of imitation. Cerebral\nCortex, 25, 1107–1113.\nSpanel, K., Wagner, K., Geiger, M.J., Ofer, I., Schulze-\nBonhage, A. & Metternich, B. (2018). Flashbulb\nmemories: Is the amygdala central: An investigation of\npatients with amygdalar damage. Neuropsychologia, 111,\n163–171.\nSpelke, E.S., Hirst, W.C. & Neisser, U. (1976). Skills of\ndivided attention. Cognition, 4, 215–230.\nSpence, C. (2012). Drive safely with neuroergonomics.\nPsychologist, 25, 664–667.\nSpence, C., Parise, C. & Chen, Y.-C. (2011). The Colavita\nvisual dominance effect. In M.M. Murray and\nM. Wallace (eds), Frontiers in the Neural Bases of\nMultisensory Processes (pp. 523–550). Boca Raton, FL:\nCRC Press.\nSperber, D. & Girotto, V. (2002). Use or misuse of the selec-\ntion task? Rejoinder to Fiddick, Cosmides, and Tooby.\nCognition, 85, 277–290.\nSperling, G. (1960). The information that is available in brief\nvisual presentations. Psychological Monographs, 74,\n1–29.\nSperry, R.W. (1968). Hemisphere deconnection and unity in\nconscious awareness. American Psychologist, 23, 723–733.\nSpiers, H.J., Maguire, E.A. & Burgess, N. (2001).\nHippocampal amnesia. Neurocase, 7, 357–382.\nSpiers, M.V. (2016). The head trauma amnesia cure.\nNeurology, 86, 2291–2294.\nSpille, C. & Meyer, B.T. (2014). Identifying the human-ma-\nchine differences in complex binaural scenes: What\ncan be learned from our auditory system. 15th Annual\nConference of the International Speech Communication\nassociation (Interspeech 2014), Singapore, Vols. 1–4,\n626–630.\nSquire, L.R. & Dede, A.J.O. (2015). Conscious and uncon-\nscious memory systems. Cold Spring Harbor Perspectives\nin Biology, 7 (Article no. a021667).\nSquire, L.R., Genzel, L., Wixted, J.T. & Morris, R.G. (2015).\nMemory consolidation. Cold Spring Harbor Perspectives\nin Biology, 7 (Article no. a021766).\nSquire, L.R., Slater, P.C. & Chace, P. (1975). Retrograde\namnesia temporal gradient in very long-term memory\nfollowing electroconvulsive therapy. Science, 187, 77–79.\nSt. Jacques, P.L., Kragel, P.A. & Rubin, D.C. (2011).\nDynamic neural networks supporting memory retrieval.\nNeuroImage, 57, 608–616.\nSt-Laurent, M., Moscovitch, M. & McAndrews, M.P. (2016).\nThe retrieval of perceptual memory details depends on\nright hippocampal integrity and activation. Cortex, 84,\n15–33.\nStagg, C.J. & Nitsche, M.A. (2011). Physiological basis\nof\ntranscranial\ndirect\ncurrent\nstimulation.\nThe\nNeuroscientist, 17, 37–53.\nStagg, C.J., Antal, A. & Nitsche, M.A. (2018). Physiology of\ntranscranial direct current stimulation. Journal of ECT,\n34, 144–152.\nStanford Encylopedia of Philosophy (2013). Analogy.\nRetrieved from http://plato.stanford.edu/entries/r e a s o n\ning-analogy/.\nStange, J.P., Hamlat, E.J., Hamilton, J.L., Abramson, L.Y.\n& Alloy, L.B. (2013). Overgeneral autobiographical\nmemory, emotional maltreatment, and depressive symp-\ntoms in adolescence: Evidence of a cognitive vulnerabili-\nty-stress interaction. Journal of Adolescence, 36, 201–208.\nStanley, D.J. & Spence, J.R. (2014). Expectations for replica-\ntions: Are yours realistic? Perspectives on Psychological\nScience, 9, 305–318.\nStanley, T.D., Carter, E.C. & Doucouliagos, H. (2018). What\nmeta-analyses reveal about the replicability of psycho-\nlogical research. Psychological Bulletin, 144, 1325–1346.\nCreated from usyd on 2022-02-18 03:51:57.",
    "902\nReferences\nStrobach, T., Antonenko, D., Abarrin, M., Escher, M., Flöel,\nA. & Schubert, T. (2018). Modulation of dual-task\ncontrol with right prefrontal transcranial direct current\nstimulation. Experimental Brain Research, 236, 227–241.\nStrobach, T., Liepelt, R., Pashler, H., Frensch, P.A. &\nSchubert, T. (2013). Effects of extensive dual-task prac-\ntice on processing stages in simultaneous choice tasks.\nAttention, Perception & Psychophysics, 75, 900–920.\nStrong, S.L., Silson, E.H., Gonws, A.D., Morland, A.R. &\nMcKeefry, D.J. (2017). Differential processing of the\ndirection and focus of expansion of optic flow stimuli in\nareas MST and V3A of the human visual cortex. Journal\nof Neurophysiology, 117, 2209–2217.\nStuder, B., Manes, F., Humphreys, G., Robbins, T.W. &\nClark, L. (2015). Risk-sensitive decision-making in\npatients with posterior parietal and ventromedial pre-\nfrontal cortex injury. Cerebral Cortex, 25, 1–9.\nStupple, E.J.N. & Ball, L.J. (2008). Belief-logic conflict reso-\nlution in syllogistic reasoning: Inspection-time evidence\nfor a parallel-process model. Thinking & Reasoning, 14,\n168–181.\nStupple, E.J.N., Ball, L.J. & Ellis, D. (2013). Matching bias\nin syllogistic reasoning: Evidence for a dual-process\naccount from response times and confidence ratings.\nThinking & Reasoning, 19, 54–77.\nStuss, D.T. (2011). Functions of the frontal lobes: Relation\nto executive functions. Journal of the International\nNeuropsychological Society, 17, 759–765.\nStuss, D.T. & Alexander, M.P. (2007). Is there a dysexecu-\ntive syndrome? Philsophical Transactions of the Royal\nSociety of London. Series B: Biological Sciences, 362,\n901–915.\nSulin, R.A. & Dooling, D.J. (1974). Intrusion of a thematic\nidea in retention of prose. Journal of Experimental\nPsychology, 103, 255–262.\nSummerfield, C. & Li, V. (2018). Perceptual sub optimality:\nBug or feature? Behavioral and Brain Sciences, 41, e22, 39.\nSuri, G., Whittaker, K. & Gross, J.J. (2015). Launching reap-\npraisal: It’s less common than you might think. Emotion,\n15, 73–77.\nSuter, R.S., Pachur, T. & Hertwig, R. (2016). How affect\nshapes risky choice: Distorted probability weighting\nversus probability neglect. Journal of Behavioral Decision\nMaking, 29, 437–449.\nSvenson, O., Salo, I. & Lindholm, T. (2009). Post-decision\nconsolidation and distortion of facts. Judgment and\nDecision Making, 4, 397–407.\nSvoboda, E., McKinnon, M.C. & Levine, B. (2006). The func-\ntional neuroanatomy of autobiographical memory: A\nmeta-analysis. Neuropsychologia, 44, 2189–2208.\nSweller, J. & Levine, M. (1982). Effects of goal specific-\nity on means-ends analysis and learning. Journal\nof Experimental Psychology: Learning, Memory &\nCognition, 8, 463–474.\nSwets, B., Desmet, T., Clifton, C. & Ferreira, F. (2008).\nUnderspecification of syntactic ambiguities: Evidence\nfrom self-paced reading. Memory & Cognition, 36,\n201–216.\nSwets, B., Jacovina, M.E. & Gerrig, R.J. (2013). Effects of\nconversational pressures on speech planning. Discourse\nProcesses, 50, 23–51.\nSylvester, C.M., Corbetta, M., Raichle, M.E., Rodebaugh,\nT.L., Schlaggar, B.L., Sheline, Y.I., et al. (2012).\nFunctional network dysfunction in anxiety and anxiety\ndisorders. Trends in Neurosciencces, 35, 528–535.\nSzczepanski, S. & Knight, R.T. (2014). Insights into human\nbehaviour from lesions to the prefrontal cortex. Neuron,\n83, 1002–1018.\nTaatgen, N.A. (2011). Threaded cognition, a model of\nhuman multitasking. Talk at Interdisciplinary Workshop\non Cognitive Neuroscience, Educational Research and\nCognitive Modelling, March. Delmenhorst, Germany.\nTaatgen, N.A. (2013). The nature and transfer of cognitive\nskills. Psychological Review, 120, 439–471.\nTaatgen, N.A., van Vugt, M.K., Borst, J.P. & Melhorn, K.\n(2016). Cognitive modelling at ICCM: State of the art\nand future directions. Topics in Cognitive Science, 8,\n259–263.\nTajadura-Jiménez, A., Banakou, D., Bianchi-Berthouze, N.\n& Slater, M. (2018). Embodiment in a child-like talking\nvirtual body influences object size perception, self-iden-\ntification, and subsequent real speaking. Scientific\nReports, 8 (Article no. 4854).\nTalarico, J.M. & Rubin, D.C. (2003). Confidence, not con-\nsistency, characterises flashbulb memories. Psychological\nScience, 14, 455–461.\nTalarico, J.M., Berntsen, D. & Rubin, D.C. (2009). Positive\nemotions enhance recall of peripheral details. Cognition\n& Emotion, 23, 380–398.\nTambini, A., Rimmele, U., Phelps, E.A. & Davachi, L.\n(2017). Emotional brain states carry over and enhance\nfuture  memory formation. Nature Neuroscience, 20,\n271–278.\nTamietto, M. & Morrone, M.C. (2016). Visual plasticity:\nBlindsight bridges anatomy and function in the visual\nsystem. Current Biology, 26, R70–R73.\nTamietto, M., Castelli, L., Vighetti, S., Perozzo, P.,\nGeminiani, G., Weiskrantz, L., et al. (2009). Unseen\nfacial and bodily expressions trigger fast emotional reac-\ntions. Proceedings of the National Academy of Sciences of\nthe United States of America, 106, 17661–17666.\nTanaka, J.W. & Taylor, M.E. (1991). Object categories and\nexpertise: Is the basic level in the eye of the beholder?\nCognitive Psychology, 15, 121–149.\nTang, D. & Schmeichel, B.J. (2014). Stopping anger and\nanxiety: Evidence that inhibitory control predicts neg-\native emotional responding. Cognition & Emotion, 28,\n132–142.\nCreated from usyd on 2022-02-18 03:51:57.",
    "904\nReferences\nThorpe, S., Fize, D. & Marlot, C. (1996). Speed of processing\nin the human visual system. Nature, 381, 520–522.\nTierney, A., Dick, F., Deutsch, D. & Sereno, M. (2013).\nSpeech versus song: Multiple pitch-sensitive areas\nrevealed by a naturally occurring musical illusion.\nCerebral Cortex, 23, 249–254.\nTierney, A., Patel, A.D. & Breen, M. (2018). Acoustic\nfoundations of the speech-to-song illusion. Journal of\nExperimental Psychology: General, 147, 888–904.\nTijtgat, P., Mazyn, L., De Laey, C. & Lenoir, M. (2008). The\ncontribution of stereo vision to the control of braking.\nAccident Analysis and Prevention, 40, 719–724.\nTindle, R. & Longstaff, M.G. (2015). Writing, reading, and\nlistening differentially overload working memory per-\nformance across the serial position curve. Advances in\nCognitive Psychology, 11, 147–155.\nTindle, R. & Longstaff, M.G. (2016). Investigating the lower\nlevel demands of writing: Handwriting movements\ninterfere with immediate verbal serial recall. Journal of\nCognitive Psychology, 28, 443–461.\nToba, M.N., Migliaccio, R., Batrancourt, B., Bourlon, C.,\nDuret, C., Pradat-Diehl, P., et al. (2018a). Common\nbrain networks for distinct deficits in visual neglect: A\ncombined structural and tractography MRI approach.\nNeuropsychologia, 115, 167–178.\nToba, M.N., Rabuffetti, M., Duret, C., Pradat-Diehl, P.,\nGainotti, G. & Bartolomeo, P. (2018b). Component defi-\ncits of visual neglect: “Magnetic” attraction of attention\nvs. impaired spatial working memory. Neuropsychologia,\n109, 52–62.\nTodorović, D. (2009). The effect of the observer vantage point\non perceived distortions in linear perspective images.\nAttention, Perception, & Psychophysics, 71, 183–193.\nToffolo, M.B.J., van den Hout, M.A., Radomsky, A.S. &\nEngelhard, I.M. (2016). Check, check, double check:\nInvestigating memory deterioration within multiple ses-\nsions of repeated checking. Journal of Behavior Therapy\nand Experimental Psychiatry, 53, 59–67.\nToli, A., Webb, T.L. & Hardy, G.E. (2016). Does forming\nimplementation intentions help people with mental\nhealth problems to achieve goals? A meta-analysis of\nexperimental studies with clinical and analogue samples.\nBritish Journal of Clinical Psychology, 55, 69–90.\nTollestrup, P.A., Turtle, J.W. & Yuille, J.C. (1994). Actual\nvictims and witnesses to robbery and fraud: An archival\nanalysis. In D.F. Ross, J.D. Read & M.P. Toglia (eds),\nAdult Eyewitness Testimony: Current trends and develop-\nments (pp. 144–160). New York: Wiley.\nTolman, E.C. (1948). Cognitive maps in rats and men.\nPsychological Review, 55, 189–208.\nTong, F. & Pratte, M.S. (2012). Decoding patterns of human\nbrain activity. Annual Review of Psychology, 63, 483–509.\nTononi, G., Boly, M., Massimini, M. & Koch, C. (2016).\nIntegrated information theory: From consciousness to\nits physical substrate. Nature Reviews Neuroscience, 17,\n450–461.\nToplak, M.E., West, R.F. & Stanovich, K.E. (2011). The\nCognitive Reflection Test as a predictor of performance\non heuristics-and-biases tasks. Memory & Cognition, 39,\n1275–1289.\nToplak, M.E., West, R.F. & Stanovich, K.E. (2014).\nAssessing miserly information processing: An expansion\nof the Cognitive Reflection Test. Thinking & Reasoning,\n20, 147–168.\nToplak, M.E., West, R.F. & Stanovich, K.E. (2017). Real-\nworld correlates of performance on heuristics and biases\ntasks in a community sample. Journal of Behavioral\nDecision Making, 30, 541–554.\nTrabasso, T. & Sperry, L.L. (1985). Causal relatedness and\nimportance of story events. Journal of Memory and\nLanguage, 24, 595–611.\nTranel, D., Damasio, A.R., Damasio, H. & Brandt, J.P.\n(1994).\nSensori-motor\nskill\nlearning\nin\namnesia:\nAdditional evidence for the neural basis of non-\ndeclarative memory. Learning and Memory, 1, 165–179.\nTrapp, S. & Bar, M. (2015). Prediction, context, and com-\npetition in visual recognition. Annals of the New York\nAcademy of Sciences, 1339, 190–198.\nTravaglia, A., Bisaz, R., Sweet, E.S., Blitzer, R.D. & Alberini,\nC.M. (2016). Infantile amnesia reflects a developmen-\ntal critical period for hippocampal learning. Nature\nNeuroscience, 19, 1225–1233.\nTravers, E., Rolison, J.J. & Feeney, A. (2016). The time course\nof conflict on the Cognitive Reflection Test. Cognition,\n150, 109–118.\nTraxler, M.J. (2014). Trends in syntactic parsing: Anticipation,\nBayesian estimation, and good-enough parsing. Trends\nin Cognitive Sciences, 18, 605–611.\nTreiman, R. (2017). Learning to spell: Phonology and beyond.\nCognitive Neuropsychology, 34, 83–93.\nTreiman, R. & Kessler, B. (2016). Choosing between alter-\nnative spellings of sounds: The role of context. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 42, 1154–1159.\nTreisman, A.M. (1964). Verbal cues, language, and meaning\nin selective attention. American Journal of Psychology,\n77, 206–219.\nTreisman, A.M. (1998). Feature binding, attention and object\nperception. Philosophical Transactions of the Royal\nSociety of London Series B: Biological Sciences, 353,\n1295–1306.\nTreisman, A.M. & Davies, A. (1973). Divided attention\nto ear and eye. In S. Kornblum (ed.), Attention and\nPerformance, Vol. IV (pp. 101–117). London: Academic\nPress.\nTreisman, A.M. & Gelade, G. (1980). A feature integra-\ntion theory of attention. Cognitive Psychology, 12,\n97–136.\nCreated from usyd on 2022-02-18 03:51:57.",
    "906\nReferences\nTversky, A. & Kahneman, D. (1983). Extensional versus intu-\nitive reasoning: The conjunction fallacy in probability\njudgment. Psychological Review, 91, 293–315.\nTversky, A. & Kahneman, D. (1992). Advances in pros-\npect theory: Cumulative representation of uncertainty.\nJournal of Risk and Uncertainty, 5, 297–323.\nTversky, A. & Koehler, D.J. (1994). Support theory: A\nnon-extensional representation of subjective probability.\nPsychological Review, 101, 547–567.\nTversky, A. & Shafir, E. (1992). The disjunction effect in choice\nunder uncertainty. Psychological Science, 3, 305–309.\nTwedt, E. & Parfitt, P.R. (2018). Perception. In S. Dunn (ed.),\nOxford Bibliographies in Psychology (pp. 1–12). Oxford:\nOxford University Press.\nTweney, R.D., Doherty, M.E., Worner, W.J., Pliske, D.B.,\nMynatt, C.R., Gross, K.A., et al. (1980). Strategies for\nrule discovery in an inference task. Quarterly Journal of\nExperimental Psychology, 32, 109–123.\nTyler, C.W. (2015). The vault of perception: Are straight lines\nseen as curved? Art & Perception, 3, 117–137.\nTyler, L.K., Voice, J. & Moss, H.E. (2000). The interaction\nof meaning and sound in spoken word recognition.\nPsychonomic Bulletin & Review, 7, 320–326.\nTyszka, J.M., Kennedy, D.P., Adolphs, R. & Paul, L.K.\n(2011). Intact bilateral resting-state networks in the\nabsence of the corpus callosum. Journal of Neuroscience,\n31, 15154–15162.\nTzourio-Mazoyer, N., Josse, G., Crivello, F. & Mazoyer, B.\n(2004). Interindividual variability in the hemispheric\norganisation for speech. NeuroImage, 21, 422–435.\nUchino, B.N., Thoman, D. & Byerly, S. (2010). Inference\npatterns in social psychology: Looking back as we move\nforward. Social and Personality Psychology Compass, 20,\n417–427.\nUcros, C.G. (1989). Mood-state-dependent memory: A\nmeta-analysis. Cognition & Emotion, 3, 139–167.\nUddén, J., Ingvar, M., Hagoort, P. & Petersson, K.M. (2017).\nBroca’s region: A causal role in implicit processing\nof grammars with crossed non-adjacent dependences.\nCognition, 164, 188–198.\nUddin, L.Q. (2013). Complex relationships between structural\nand functional brain complexity. Trends in Cognitive\nSciences, 17, 600–602.\nUddin, L.Q., Rayman, J. & Zaidel, E. (2005). Split-brain\nreveals separate but equal self-recognition in the two\ncerebral hemispheres. Consciousness and Cognition, 14,\n633–640.\nUddin, S., Heald, S.L.M., Van Hedger, S.C., Klos, S. &\nNusbaum, H.C. (2018). Understanding environmental\nsounds in sentence context. Cognition, 172, 134–143.\nUeno, T., Meteyard, L., Hoffman, P. & Murayama, K.\n(2018). The ventral anterior temporal lobe has a neces-\nsary role in exception word reading. Cerebral Cortex, 28,\n3035–3045.\nUllén, F., Hambrick, D.Z. & Mosing, M.A. (2016).\nRethinking expertise: A multifactorial gene-environment\ninteraction model of expert performance. Psychological\nBulletin, 142, 427–446.\nUncapher, M.R. & Wagner, A.D. (2018). Minds and brains\nof media multitaskers: Current findings and future\ndirections. Proceedings of the National Association of\nSciences, 115, 9889–9896.\nUnsworth, N. & McMillan, B.D. (2013). Mind wandering and\nreading comprehension: Examining working memory\ncapacity, interest, motivation, and topic experience.\nJournal of Experimental Psychology: Learning, Memory,\nand Cognition, 39, 832–842.\nUnsworth, N., Brewer, G.A. & Spillers, G.J. (2013). Focusing\nthe search: Proactive and retroactive interference and\nthe dynamics of free recall. Journal of Experimental\nPsychology: Learning, Memory and Cognition, 39,\n1742–1756.\nUnsworth, N., Redick, T.S., Spillers, G.J. & Brewer, G.A.\n(2012). Variation in working memory capacity and cog-\nnitive control: Goal maintenance and micro-adjustments\nof control. Quarterly Journal of Experimental Psychology,\n65, 326–355.\nUrbanski, M., Bréchemier, M.-L., Garcin, B., Bendetowicz,\nD., de Schotten, M.T., Foulon, C., et al. (2016).\nReasoning by analogy requires the left frontal pole:\nLesion-deficit mapping and clinical implications. Brain,\n139, 1783–1799.\nUttal, W.R. (2012). Reliability in Cognitive Neuroscience: A\nmeta-meta analysis. Cambridge, MA: MIT Press.\nVadillo,\nM.A.,\nKonstantinis,\nE.\n&\nShanks,\nD.R.\n(2016).  Underpowered samples, false negatives, and\nunconscious learning. Psychonomic Bulletin & Review,\n23, 87–102.\nVahdat, S., Fogel, S., Benali, H. & Doyon, J. (2017).\nNetwork-wide reorganization of procedural memory\nduring NREM sleep revealed by fMRI. eLIFE, 6 (Article\nno. e24987).\nVaina, L.M. (1998). Complex motion perception and its defi-\ncits. Current Opinion in Neurobiology, 8, 494–502.\nVaina, L.M., Lemaya, M., Beinfanga, D.C., Choia, A. &\nNakayama, K. (1990). Intact “biological motion” and\n“structure from motion” in a patient with impaired\nmotion mechanisms: A case study. Visual Neuroscience,\n5, 353–359.\nValentine,\nT.,\nPickering,\nA.\n&\nDarling,\nS.\n(2003).\nCharacteristics\nof\neyewitness\nidentification\nthat\npredict the outcome of real line-ups. Applied Cognitive\nPsychology, 17, 969–993.\nValero-Cabré, A., Amengual, J.L., Stengel, C., Pascal-Leone,\nA. & Coubard, O.A. (2017). Transcranial magnetic stim-\nulation in basic and clinical neuroscience: A comprehen-\nsive review of fundamental principles and novel insights.\nNeuroscience and Biobehavioral Reviews, 83, 381–404.\nCreated from usyd on 2022-02-18 03:51:57.",
    "908\nReferences\nvan Orden, G.C. (1987). A rows is a rose: Spelling, sound and\nreading. Memory & Cognition, 14, 371–386.\nvan Petten, C. & Luka, B.J. (2012). Prediction during\nlanguage comprehension: Benefits, costs, and ERP\ncomponents.  International Journal of Psychophysiology,\n83, 176–190.\nvan Petten, C., Coulson, S., Rubin, S., Plante, E. & Parks, M.\n(1999). Time course of word identification and semantic\nintegration in spoken language. Journal of Experimental\nPsychology: Learning, Memory, and Cognition, 25,\n394–417.\nvan Polanen, V. & Davare, M. (2015). Interactions between\ndorsal and ventral streams for controlling skilled grasp.\nNeuropsychologia, 79, 186–191.\nvan Turennout, M., Hagoort, P. & Brown, C.M. (1998). Brain\nactivity during speaking: From syntax to phonology in\n40 milliseconds. Science, 280, 572–574.\nvan Velzen, M.H., Nanetti, L. & de Deyn, P.P. (2014). Data\nmodelling in corpus linguistics: How low can we go?\nCortex, 55, 192–201.\nVaquero, L., Hartmann, K., Ripollés, P., Rojo, N.,\nSierpowska, J., Francois, C., et al. (2016). Structural\nneuroplasticity in expert pianists depends on the age of\nmusical training onset. NeuroImage, 126, 106–119.\nVarakin, D.A., Levin, D.T. & Collins, K.M. (2007).\nComparison and representation failures both cause real-\nworld change. Perception, 36, 737–749.\nVargha-Khadem,\nF.,\nGadian,\nD.G.,\nWatkins,\nK.E.,\nConnelly, A., Van Paesschen, W. & Mishkin, M.\n(1997). Differential effects of early hippocampal patho-\nlogy on episodic and semantic memory. Science, 277,\n376–380.\nVasilev, M.R. & Angele, B. (2017). Parafoveal preview effects\nfrom word N + 1 and word N + 2 during reading: A\ncritical review and Bayesian meta-analysis. Psychonomic\nBulletin & Review, 24, 666–689.\nVendetti, M.S., Starr, A., Johnson, E.L., Modavi, K. &\nBunge, S.A. (2017). Eye movements reveal optimal strat-\negies for analogical reasoning. Frontiers in Psychology, 8\n(Article no. 932).\nVergauwe, E. & Langerock, N. (2017). Attentional refreshing\nof information in working memory: Increased immediate\naccessibility of just-refreshed representations. Journal of\nMemory and Language, 96, 23–35.\nVergauwe, E., Barrouillet, P. & Camos, V. (2009). Visual\nand spatial working memory are not dissociated after\nall: A time-based resource-sharing account. Journal\nof Experimental Psychology: Learning, Memory, and\nCognition, 35, 1012–1028.\nVerleger, R., Binkofski, F., Friedrich, M., Sedlmeier, P. &\nKömpf, D. (2011). Anarchic-hand syndrome: ERP\nreflections of lost control over the right hemisphere.\nBrain and Cognition, 77, 138–150.\nVerschueren, N., Schaeken, W. & d’Ydewalle, G. (2005). A\ndual-process specification of causal conditional reason-\ning. Thinking & Reasoning, 11, 239–278.\nVesia, M. & Crawford, J.D. (2012). Specialisation of\nreach function in human posterior parietal cortex.\nExperimental Brain Research, 221, 1–18.\nVetter, P., Grosbras, M.-H. & Muckli, L. (2015). TMS over\nV5 disrupts motion prediction. Cerebral Cortex, 25,\n1052–1059.\nVidal-Piñeiro, D., Sneve, M.H., Storsve, A.B., Roe, J.M.,\nWalhovd, K.B. & Fhell, A.M. (2018). Neural correlates\nof durable memories across the adult lifespan: Brain\nactivity at encoding and retrieval. Neurobiology of Aging,\n60, 20–33.\nViggiano, M.P., Giovannelli, F., Borgheresi, A., Feurra, M.,\nBerardi, N., Pizzorusso, T., et al. (2008). Disruption\nof the prefrontal cortex function by rTMS produces\na category-specific enhancement of the reaction times\nduring visual object identification. Neuropsychologia, 46,\n2725–2731.\nVigliocco, G., Antonini, T. & Garrett, M.F. (1997).\nGrammatical gender is on the top of Italian tongues.\nPsychological Science, 8, 314–317.\nVirtue, S., Schutzenhofer, M. & Tomkins, B. (2017).\nHemispheric processing of predictive inferences during\nreading: The influence of negatively emotional valenced\nstimuli. Laterality, 22, 455–472.\nVisted, E., Vollestad, J., Nielsen, M.B. & Schanche, E. (2018).\nEmotion regulation in current and remitted depression:\nA systematic review and meta-analysis. Frontiers in\nPsychology, 8 (Article no. 756).\nViviani, R. (2013). Emotion regulation, attention to emotion,\nand the ventral attentional network. Frontiers in Human\nNeuroscience, 7 (Article no. 746).\nVõ, M.L.-H. & Wolfe, J.M. (2012). When does repeated search\nin scenes involve memory? Looking at versus looking for\nobjects in scenes. Journal of Experimental Psychology:\nHuman Perception and Performance, 38, 23–41.\nVolden, J. (2017). Autism spectrum disorder. In L. Cummings\n(ed.), Research in Clinical Pragmatics: Perspectives in\nPragmatics, Philosophy & Psychology, 11, 59–83.\nVolz, L.J. & Gazzaniga, M.S. (2017). Interaction in isolation:\n50 years of insights from split-brain research. Brain, 140,\n2051–2060.\nVolz, L.J., Hillyard, S.A., Miller, M.B. & Gazzaniga, M.S.\n(2018). Unifying control over the body: Consciousness\nand cross-cueing in split-brain patients. Brain, 141\n(Article no. e15).\nVon Neumann, J. & Morgenstern, O. (1944). Theory of Games\nand Economic Behaviour. Princeton, NJ: Princeton\nUniversity Press.\nVossel, S., Geng, J.J. & Fink, G.R. (2014). Dorsal and ventral\nattention system: Distinct neural circuits but collabora-\ntive roles. The Neuroscientist, 20, 150–159.\nCreated from usyd on 2022-02-18 03:51:57.",
    "910\nReferences\nusing animal models. Neuroscience and Biobehavioral\nReviews, 84, 12–28.\nWaters, E.A. (2008). Feeling good, feeling bad, and feeling at\nrisk: A review of incidental affect’s influence on likeli-\nhood estimates of health hazards and life events. Journal\nof Risk Research, 11, 569–595.\nWaters, F., Collerton, D., Ffytche, D.H., Jardri, R., Pins, D.,\nDudley, R., et al. (2014). Visual hallucinations in the psy-\nchosis spectrum and comparative information from neu-\nrodegenerative disorders and eye disease. Schizophrenia\nBulletin, 40, S233–S245.\nWatkins, E., Moulds, M. & Mackintosh, B. (2005).\nComparisons between rumination and worry in a\nnon-clinical\npopulation.\nBehaviour\nResearch\nand\nTherapy, 43, 1577–1585.\nWatson, D. (2009). Differentiating the mood and anxiety dis-\norders: A quadripartite model. Annual Review of Clinical\nPsychology, 5, 221–247.\nWatson, D. & Tellegen, A. (1985). Toward a consensual struc-\nture of mood. Psychological Bulletin, 98, 219–235.\nWatson, J.B. (1913). Psychology as the behaviourist sees it.\nPsychological Review, 20, 158–177.\nWatson, J.B. (1920). Is thinking merely the action of language\nmechanisms? British Journal of Psychology, 11, 87–104.\nWatson, T.L. & Robbins, R.A. (2014). The nature of holistic\nprocessing in face and object recognition: Current opin-\nions. Frontiers in Psychology, 5 (Article no. 3).\nWatt, C.A. & Kennedy, J.E. (2017). Options for prospective\nmeta-analysis and introduction of registration-based\nprospective meta-analysis. Frontiers in Psychology, 7\n(Article no. 2030).\nWebb, M.E., Little, D.R. & Cropper, S.J. (2016a). Insight\nis not in the problem: Investigating insight in problem\nsolving across task types. Frontiers in Psychology, 7\n(Article no. 1424).\nWebb, T.L., Miles, E. & Sheeran, P. (2012). Dealing with\nfeeling: A meta-analysis of the effectiveness of strategies\nderived from the process model of emotion regulation.\nPsychological Bulletin, 138, 775–808.\nWebb, T.W. & Graziano, M.S.A. (2015). The attention\nschema theory: A mechanistic account of subjective\nawareness. Frontiers in Psychology, 6 (Article no. 500).\nWebb, T.W., Kean, H.H. & Graziano, M.S.A. (2016b).\nEffects of awareness on the control of attention. Journal\nof Cognitive Neuroscience, 28, 842–851.\nWeber, A. & Crocker, M.W. (2012). On the nature of semantic\nconstraints on lexical access. Journal of Psycholinguistic\nResearch, 41, 195–214.\nWebster, M.A. (2016). Individual differences in colour\nvision. In A.J. Eliot, M.D. Fairchild & A. Franklin\n(eds), Handbook of Colour Psychology (pp. 187–215).\nCambridge: Cambridge University Press.\nWebster, R.J. (2015). Does disruptive camouflage conceal\nedges and features? Current Zoology, 61, 708–717.\nWegner, D.M. (2003). The mind’s best trick: How we experi-\nence free will. Trends in Cognitive Sciences, 7, 65–69.\nWegner, D.M. & Wheatley, T. (1999). Apparent mental causa-\ntion: Sources of the experience of free will. American\nPsychologist, 54, 480–492.\nWeibert, K., Harris, R.J., Mitchell, A., Byrne, H., Young,\nA.W. & Andrewsm T.J. (2016). An image-invariant\nneural response to familiar faces in the human medial\ntemporal lobe. Cortex, 84, 34–42.\nWeidema, J.L., Roncaglia-Denissen, M.P. & Honing, H.\n(2016). Top-down perception and categorisation of iden-\ntical pitch contours in speech and music. Frontiers in\nPsychology, 7 (Article no. 817).\nWeingarten, E., Chen, Q., McAdams, M., Hepler, J., Yi, J. &\nAlbarracín, D. (2016). From primed concepts to action:\nA meta-analysis of the behavioural effects of incidentally\npresented words. Psychological Bulletin, 142, 472–497.\nWeisberg, R.W. (2018). Problem solving. In L.J. Ball & V.A.\nThompson (eds), Routledge International Handbook of\nThinking and Reasoning (pp. 607–623). Abingdon, Oxon:\nRoutledge.\nWeiskrantz, L. (1980). Varieties of residual experience.\nQuarterly Journal of Experimental Psychology, 32,\n365–386.\nWeiskrantz, L. (1997). Consciousness: Lost and found: A neu-\nropsychological exploration. Oxford: Oxford University\nPress.\nWeiskrantz, L. (2010). Looking Back: blindsight in hindsight.\nThe Psychologist, 23, 356–358.\nWeiskrantz, L., Warrington, E.K., Sanders, M.D. & Marshall,\nJ. (1974). Visual capacity in the hemianopic field follow-\ning a restricted occipital ablation. Brain, 97, 709–728.\nWeiss, N., Mardo, E. & Avidan, G. (2016). Visual exper-\ntise for horses in a case of congenital prosopagnosia.\nNeuropsychologia, 83, 63–75.\nWelch, R.B. & Warren, D.H. (1980). Immediate perceptual\nresponse to intersensory discrepancy. Psychological\nBulletin, 88, 638–667.\nWeller, J.A., Levin, I.P., Shiv, B. & Bechara, A. (2007).\nNeural correlates of adaptive decision making for risky\ngains and losses. Psychological Science, 18, 958–964.\nWells, G.L., Steblay, N.K. & Dysart, J.E. (2015). Double-\nblind photo lineups using actual eyewitnesses: An exper-\nimental test of a sequential versus simultaneous lineup\nprocedure. Law and Human Behavior, 39, 1–14.\nWen, T., De-Cyuan, L. & Hsieh, S. (2018). Connectivity pat-\nterns in cognitive control networks predict naturalistic\nmultitasking ability. Neuropsychologia, 114, 198–202.\nWen, X., Liu, Y. & Ding, M. (2012). Causal interactions in\nattention networks predict behavioural performance.\nJournal of Neuroscience, 32, 1284–1292.\nWerner-Seidler, A., Hitchcock, C., Bevan, A., McKinnon, A.,\nGillard, J., Dahm, T., et al. (2018). A cluster randomised\ncontrolled platform trial comparing group MEmory\nCreated from usyd on 2022-02-18 03:51:57.",
    "912\nReferences\ninformation in depressed persons. Psychological Bulletin,\n142, 18–78.\nWing, E.A., Ritchey, M. & Cabeza, R. (2015). Reinstatement\nof individual past events revealed by the similarity of\ndistributed activation patterns during encoding and\nretrieval. Journal of Cognitive Neuroscience, 27, 679–691.\nWinkielman, P., Berridge, K.C. & Wilbarger, J.L. (2005).\nUnconscious affective reactions to masked happy versus\nangry faces influence consumption behaviour and\njudgements of value. Personality and Social Psychology\nBulletin, 31, 121–135.\nWinlove, C.I.P., Milton, F., Ranson, J., Fulford, J.,\nMacKisack, M., Macpherson, F., et al. (2018). The\nneural correlates of visual imagery: A co-ordinate-based\nmeta-analysis. Cortex, 105, 4–25.\nWischgoll, A. (2016). Combined training of one cognitive and\none metacognitive strategy improves academic writing\nskills. Frontiers in Psychology, 7 (Article no. 187).\nWithagen, R., de Poel, H.J., Araujo, D. & Pepping, G.-J.\n(2012). Affordances can invite behaviour: Reconsidering\nthe relationship between affordances and agency. New\nIdeas in Psychology, 30, 250–258.\nWixted, J.T. (2004). The psychology and neuroscience of for-\ngetting. Annual Review of Psychology, 55, 235–269.\nWixted, J.T. & Wells, G.L. (2017). The relationship between\neyewitness confidence and identification accuracy: A new\nsynthesis. Psychological Science in the Public Interest, 18,\n10–65.\nWixted, J.T., Mickes, L., Dunn, J.C., Clark, S.E. & Wells, S.\n(2016). Estimating the reliability of eyewitness identifi-\ncations from police lineups. Proceedings of the National\nAssociation of Sciences, 113, 304–309.\nWoike, B., Gershkovich, I., Piorkowski, R. & Polo, M.\n(1999). The role of motives in the content and structure\nof autobiographical memory. Journal of Personality and\nSocial Psychology, 76, 600–612.\nWolfe, J.M., Võ, M.L.-H., Evans, K.K. & Greene, M.R.\n(2011). Visual search in scenes involves selective and\nnonselective pathways. Trends in Cognitive Sciences, 15,\n77–84.\nWolff, P. & Gentner, D. (2011). Structure-mapping in meta-\nphor comprehension. Cognitive Science, 35, 1456–1488.\nWolff, P. & Holmes, K.J. (2011). Linguistic relativity. Wiley\nInterdisciplinary Reviews: Cognitive Science, 2, 253–265.\nWon, E.J.S. (2012). A theoretical investigation on the attrac-\ntion effect using the elimination-by- aspects model\nincorporating higher preference for shared features.\nJournal of Mathematical Psychology, 56, 386–391.\nWong, C.K. & Read, J.D. (2011). Positive and negative effects\nof physical context reinstatement on eyewitness recall\nand recognition. Applied Cognitive Psychology, 25, 2–11.\nWoods, K.J.P. & McDermott, J.H. (2018). Schema learn-\ning for the cocktail party problem. Proceedings of the\nNational Academy of Sciences, 115, E3313–E3322.\nWoollams, A.M. & Patterson, K. (2012). The consequences of\nprogressive phonological impairment for reading aloud.\nNeuropsychologia, 50, 3469–3477.\nWoollams, A.M., Halai, A. & Lambon Ralph, M.A. (2018).\nMapping the intersection of language and reading: The\nneural bases of the primary systems hypothesis. Brain\nStructure and Function, 223, 3769–3786.\nWoollams, A.M., Lambon Ralph, M.A., Plaut, D.C. &\nPatterson, K. (2007). SD-squared: On the associa-\ntion between semantic dementia and surface dyslexia.\nPsychological Review, 114, 316–339.\nWoollett, K. & Maguire, E.A. (2009). Navigational exper-\ntise may compromise anterograde associative memory.\nNeuropsychologia, 44, 1088–1095.\nWoollett, K. & Maguire, E.A. (2011). Acquiring “the\nKnowledge” of London’s layout drives structural brain\nchanges. Current Biology, 21, 2109–2114.\nWoollett, K., Spiers, H.J. & Maguire, E.A. (2009). Talent\nin the taxi: A model system for exploring expertise.\nPhilosophical Transactions of the Royal Society B:\nBiological Sciences, 364, 1407–1416.\nWright, D.B. & Loftus, E.F. (2008). Eyewitness memory. In\nG. Cohen & M.A. Conway (eds), Memory in the Real\nWorld (3rd edn) (pp. 91–106). Hove, UK: Psychology\nPress.\nWright, D.B. & Stroud, J.N. (2002). Age differences in line-up\nidentification accuracy: People are better with their own\nage. Law and Human Behavior, 26, 641–654.\nWright, O., Davies, I.R.L. & Franklin, A. (2015).\nWhorfian effects on colour memory are not reliable.\nQuarterly  Journal of Experimental Psychology, 68,\n745–758.\nWroe, A.L., Bhan, A., Salkovskis, P. & Bedford, H. (2005).\nFeeling bad about immunising our children. Vaccine, 23,\n1428–1433.\nWu, L.L. & Barsalou, L.W. (2009). Perceptual simulation in\nconceptual combination: Evidence from property gener-\nation. Acta Psychologica, 132, 173–189.\nWulff, D.U., Mergenthaler-Canseco, M. & Hertwig, R.\n(2018). A meta-analytic review of two modes of learn-\ning and the description-experience gap. Psychological\nBulletin, 144, 140–176.\nWurm, M.F., Ariani, G., Greenlee, M.W. & Lingnau, A.\n(2016). Decoding concrete and abstract action rep-\nresentations during explicit and implicit conceptual pro-\ncessing. Cerebral Cortex, 26, 3390–3401.\nWutzler, A., Becker, R., Lämmler, G., Haverkamp, W. &\nSteinhagen-Thiessen, E. (2013). The anticipatory pro-\nportion as an indicator of language impairment in ear-\nly-stage cognitive disorder in the elderly. Dementia and\nGeriatric Cognitive Disorders, 36, 300–309.\nWynn, V.E. & Logie, R.H. (1998). The veracity of long-term\nmemories – Did Bartlett get it right? Applied Cognitive\nPsychology, 12, 1–20.\nCreated from usyd on 2022-02-18 03:51:57.",
    "914\nReferences\nZatorre, R.J. (2013). Predispositions and plasticity in music\nand speech learning: Neural correlates and  implications.\nScience, 342, 585–589.\nZeidman, P. & Maguire, E.A. (2016). Anterior hippocampus:\nThe anatomy of perception, imagination and episodic\nmemory. Nature Reviews Neuroscience, 17, 173–182.\nZeki, S. (1993). A Vision of the Brain. Oxford: Blackwell.\nZeki, S. (2001). Localisation and globalization in conscious\nvision. Annual Review of Neuroscience, 24, 57–86.\nZeki, S. (2005). The Ferrier Lecture 1995. Behind the seen:\nThe functional specialisation of the brain in space and\ntime. Philosophical Transactions of the Royal Society B,\n360, 1145–1183.\nZeki, S. (2015). Area V5 – A microcosm of the visual brain.\nFrontiers in Integrative Neuroscience, 9 (Article no. 21).\nZeki, S. (2016). Multiple asynchronous stimulus- and task-\ndependent hierarchies within the visual brain’s parallel\nprocessing systems. European Journal of Neuroscience,\n44, 2515–2527.\nZeman, A., Dewar, M. & Della Sala, S. (2015). Lives without\nimagery – Congenital aphantasia. Cortex, 73, 378–380.\nZetsche, U. & Joormann, J. (2011). Components of inter-\nference control predict depressive symptoms and\nrumination cross-sectionally and at six months fol-\nlow-up. Journal of Behavior Therapy and Experimental\nPsychiatry, 42, 65–73.\nZevin, J.D. & Seidenberg, M.S. (2006). Simulating consistency\neffects and individual differences in non-word naming: A\ncomparison of current models. Journal of Memory and\nLanguage, 4, 145–160.\nZhang, H., Eppes, A., Beatty-Martinez, A., Navarro-Torres,\nC. & Diaz, M.T. (2018). Task difficulty modulates\nbrain-behaviour correlations in language production\nand cognitive control: Behavioural and fMRI evidence\nfrom a phonological go/no-go picture-naming para-\ndigm. Cognitive, Affective & Behavioral Neuroscience, 18,\n964–981.\nZhang, T.R. & Chan, A.H.S. (2016). The association between\ndriving anger and driving outcomes: A meta- analysis of\nevidence from the past twenty years. Accident Analysis\nand Prevention, 90, 50–62.\nZhang, X. & Samuel, A.G. (2018). Is speech recognition auto-\nmatic? Lexical competition, but not initial lexical access,\nrequires cognitive resources. Journal of Memory and\nLanguage, 100, 32–50.\nZhuang, J., Randall, B., Stamatakis, E.A., Marslen-Wilson,\nW.D. & Tyler, L.K. (2011). The interaction of lexical\nsemantics and cohort competition in spoken word\nrecognition: An fMRI study. Journal of Cognitive\nNeuroscience, 23, 3778–3790.\nZiegler, J.C., Grainger, J. & Brysbaert, M. (2010). Modelling\nword recognition and reading aloud. European Journal\nof Cognitive Psychology, 22, 641–649.\nZihl, J. & Heywood, C.A. (2015). The contribution of LM\nto the neuroscience of movement vision. Frontiers in\nIntegrative Neuroscience, 9 (Article no. 6).\nZihl, J. & Heywood, C.A. (2016). The contribution of single\ncase studies to the neuroscience of vision. Psych Journal,\n5, 5–17.\nZihl, J., von Cramon, D. & Mai, N. (1983). Selective distur-\nbance of movement vision after bilateral brain damage.\nBrain, 106, 313–340.\nZimmer, H.D. (2008). Visual and spatial working memory:\nFrom boxes to networks. Neuroscience and Biobehavioral\nReviews, 32, 1373–1395.\nZimmermann, F.G.S. & Eimer, M. (2013). Face learning and\nthe emergence of view-independent face recognition: An\nevent-related brain potential study. Neuropsychologiat\n51, 1320–1329.\nZogg, J.B., Woods, S.P., Sauceda, J.A., Wiebe, J.S. & Simoni,\nJ.M. (2012). The role of prospective memory in medi-\ncation adherence: A review of an emerging literature.\nJournal of Behavioral Medicine, 35, 47–62.\nZuk, J. & Gaab, N. (2018). Evaluating predisposition and\ntraining in shaping the musician’s brain: The need for\na developmental perspective. Annals of the New York\nAcademy of Sciences, 1423, 4–60.\nZwaan, R.A. (2014). Embodiment and language compre-\nhension: Reframing the discussion. Trends in Cognitive\nSciences, 18, 229–234.\nZwaan, R.A. (2016). Situation models, mental simulations,\nand abstract concepts in discourse comprehension.\nPsychonomic Bulletin and Review, 23, 1028–1034.\nZwaan, R.A. & Madden, C.J. (2004). Updating situation\nmodels. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 30, 283–288.\nZwaan, R.A. & Pecher, D. (2012). Revisiting mental sim-\nulation in language comprehension: Six replication\nattempts. PLoS ONE, 7 (Article no. e51382).\nZwaan, R.A. & van Oostendorp, U. (1993). Do readers con-\nstruct spatial representations in naturalistic story com-\nprehension? Discourse Processes, 1, 125–143.\nZwaan, R.A., Langston, M.C. & Graesser, A.C. (1995).\nDimensions of situation-model construction in narrative\ncomprehension. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 21, 386–397.\nZwaan, R.A., Stanfield, R.A. & Yaxley, R.H. (2002). Langue\ncomprehenders mentally represent the shapes of objects.\nPsychological Science, 13, 168–171.\nZwitserlood, P. (1989). The locus of the effects of sentential-\nsemantic context in spoken-word processing. Cognition,\n32, 25–64.\nCreated from usyd on 2022-02-18 03:51:57.",
    "Author index\nAuthor index\nAarts, H. 772\nAbbott, R.D. 554\nAbdellaoui, M. 645f, 646\nAberegg, S.K. 651\nAblinger, I. 432, 451\nAbramov, I. 66\nAchim, A.M. 545\nAckerman, P.L. 597, 619\nAckerman, R. 589, 590, 688, 689, 689f,\n708\nAczel, B. 663\nAdank, P. 516\nAddis, D.R. 311, 358\nAddyman, C. 33\nAdelman, J.S. 446\nAdlam, A.-L.R. 303\nAdolphs, R. 734\nAdriaanse, M.A. 769\nAggleton, J.P. 297, 336\nAhtamad, M. 211\nAikin, S.F. 694\nAjina, S. 85\nAkhtar, S. 351\nAlain, C. 408\nAlais, D. 210\nAl-Azary, H. 482\nAlbarracin, D. 651\nAlbo, Z. 290\nAlbouy, G. 330, 332\nAlbright, T.D. 372\nAldao, A. 729\nAlea, N. 347\nAlexander, M.P. 251, 260\nAlexeeva, S. 410\nAli, S.S. 25, 26f\nAllen, R.J. 252\nAllison, M. 548\nAllopenna, P.D. 422, 422f, 426\nAl-Moteri, M.O. 605, 605f, 607\nAlonso, J.M. 96\nAlsius, A. 411\nAltarriba, J. 237\nAltenberg, B. 518\nAltmann, E.M. 379, 464, 591\nÁlvaro, L. 65\nAlves, R.A. 552, 553f, 556\nAly, M. 297\nAmado, S. 751\nAmer, T. 195, 586, 588\nAmes, A. 79\nAmir, N. 760\nAmitani, Y. 632, 633\nAnderson, C.J. 651\nAnderson, F.T. 376, 388\nAnderson, J.R. 7, 27, 30, 31f, 32,\n271\nAnderson, M.C. 271, 285, 286, 286f,\n287\nAnderson, R.B. 635\nAnderson, R.C. 374, 500\nAnderson, S.W. 329\nAndrade, J. 132\nAndrews, P.W. 751\nAndrews, S. 439\nAndrews-Hanna, J.R. 346, 347f\nAngele, B. 454, 456\nAngelone, B.L. 171\nAngie, A.D. 743\nAnsorge, U. 230\nArdila, A. 51, 557\nArmstrong, T. 757\nAsk, K. 747\nAtkins, J.E. 76\nAtkinson, A.P. 160\nAtkinson, R.C. 240, 240f, 241, 242, 243,\n244, 296\nAtkinson, R.L. 394\nAuckland, M.E. 113\nAugustine, A.A. 726\nAvenanti, A. 162\nAverell, L. 278\nAwasthi, B. 104, 104f\nAwh, E. 184, 185, 185f\nAxelrod, R. 653\nAxelrod, V. 121\nAydelott, J. 181\nAzevedo, R.T. 113\nAzuma, T. 406–407\nBaars, B.J. 783\nBaddeley, A.D. 132, 179, 238, 246, 246f,\n247, 248, 248f, 249, 251, 252, 255,\n262, 263f, 265, 288, 290, 293, 301,\n310, 376, 557, 597, 617\nBader, M. 475\nBadets, A. 143, 144\nBae, G.-Y. 400\nBagneux, V. 751\nBaker, C.M. 55\nBakker, M. 672\nBakroon, A. 160\nBaldassarre, A. 197\nBaldassi, C. 50\nBall, F. 164, 167\nBall, L.J. 668, 679, 684\nBalota, D.A. 434\nBanks, M.S. 76\nBannard, C. 397\nBannert, M.M. 51, 68\nBaptista, M. 395\nBar, M. 108, 114, 115, 115f\nBarense, M.D. 102, 102f\nBargh, J.A. 229, 639, 640, 690\nBar-Haim, Y. 756\nBarliya, A. 160\nBaronchelli, A. 395\nBarrett, L.F. 652, 716, 716f\nBarreyro, J.P. 494\nBarriuso, T.A. 488\nBarry, C. 165, 561\nBarry, C. (with Martin) 561\nBarry, S. 74\nBarsalou, L.W. 316–318, 321, 341, 481\nBartels, A. 51, 68\nBarth, M. 272\nBartlett, F.C. 364, 498–500, 501, 502\nBartley, J.E. 576, 577f\nBartolo, A. 11, 12, 58\nBartolomeo, P. 11, 12, 136\nBarton, J.J.S. 120\nBartsch, M.V. 188–189\nBaruch, O. 115, 115f, 116, 116f, 138\nBarzykowski, K. 358, 359\nCreated from usyd on 2022-02-18 03:52:37.",
    "916\nAuthor index\nBasehore, Z. 635\nBastin, C. 337\nBauer, A.J. 314\nBaum, S.R. 493\nBaumeister, R.F. 768, 771, 772, 773, 781\nBaumgartner, S.E. 213\nBäuml, K.-H. 265, 281, 282, 282f\nBäuml, K-H.T. 268, 268f\nBaurès, R. 150\nBavelas, J. 548\nBaxendale, S. 296\nBayley, P.J. 302\nBayne, T. 767, 778, 793\nBaynes, K. 794\nBays, P.M. 199\nBeauvais, C. 552, 555\nBeck, A.T. 753, 757\nBeck, C. 413\nBeck, S.M. 385\nBecker, E.S. 736\nBecker, M.W. 201, 201f\nBeckers, G. 83\nBeckmann, C.F. 63, 64\nBeeke, S. 540\nBeeman, M. 577, 578\nBeer, J.S. 740\nBehrmann, M. 119, 189\nBeisswingert, B.M. 752\nBennett, C.M. 25, 25f\nBennett, P. 721\nBenoit, R.G. 311–312, 312f\nBenton, C.P. 128\nBereiter, C. 554, 555\nBeres, A.M. 475\nBergeron, V. 10\nBerggren, N. 204\nBergman, E. 500\nBergmann, H.C. 245\nBergström, Z.M. 286, 287\nBerisha, V. 518\nBerman, M.G. 242\nBermúdez-Rattoni, F. 293\nBernier, J. 561\nBerninger, V.W. 554\nBerntsen, D. 351, 353, 354, 354f, 355,\n358\nBerwick, R.C. 536f\nBesson, G. 314\nBeukema, P. 276, 276f, 333, 338\nBezdicek, O. 330\nBezuidenhout, A. 484\nBhatt, R.S. 101\nBi, Y.C. 436\nBialek, M. 626, 743\nBickerton, D. 396\nBidelman, G.M. 405\nBiederman, I. 106–107, 107f, 108, 111,\n137–138, 532\nBier, N. 323\nBiggs, A.T. 190, 190f, 201, 201f, 368\nBilalić, M. 123, 585, 604\nBinder, E. 161\nBinder, J.R. 300, 320, 337\nBindschaedler, C. 301–302\nBinkofski, F. 155\nBird, C.M. 308, 310, 336\nBischof, W.F. 146\nBisenius, S. 789\nBixler, R. 457\nBlackmer, E.R. 525\nBlackmon, J. 12, 794\nBlanchette, I. 595, 730, 749\nBlaney, P.H. 759\nBlank, H. 367, 368f\nBlank, I.A. 537\nBlanke, O. 769, 771\nBliss, D.P. 172\nBlock, N. 767, 776\nBluck, S. 347\nBlumenthal, A. 302, 335\nBode, S. 774–775, 774f\nBodien, Y.G. 791\nBoettger, R. 653\nBoiteau, T.W. 517\nBolden, G.B. 549\nBoly, M. 782, 792\nBonato, M. 199, 200\nBonin, P. 533\nBonnefon, J.-F. 741, 742f\nBonnefond, M. 691–693\nBooth, R.W. 760, 763\nBor, D. 767\nBorges, J.L. 279\nBorghesani, V. 318, 321\nBorghi 317\nBorhn 478–479\nBormann, T. 9, 431\nBorst, G. 691, 693\nBorst, J.P. 218–219\nBos, E.M. 771\nBose, A. 542\nBostyn, D.H. 743\nBourke, L. 557\nBourne, L.E. 600\nBouvier, S.E. 50\nBowden, E.M. 578\nBowen, H.J. 734\nBower, G.H. 322\nBowers, J.S. 28, 29, 336, 701\nBowles, B. 307\nBown, H.E. 532\nBoyles, T. 647\nBrainard, D.H. 67f, 68\nBrainerd, C.J. 309, 311\nBramăo, I. 289\nBramão, I. 288\nBraňas-Garza, P. 2\nBrandt, A. 404\nBrandt, K.R. 306, 307\nBranigan, C. 731, 732, 733\nBransford, J.D. 491, 499, 500\nBrase, G.L. 34\nBraunstein, M. 725, 727, 728\nBreitmeyer, B.G. 90\nBremmer, F. 146\nBrendel, E. 152\nBrenner, E. 77, 146\nBrewer, N. 364, 370\nBrewer, N.T. 651, 703\nBrewin, C.R. 350\nBridge, H. 74, 86, 87, 136\nBriggs, G.F 731\nBroadbent, D.E. 180, 181f, 182\nBrock, J. 4, 414f\nBröder, A. 636\nBrooks, D.N. 310\nBrooks, R. 647\nBrosch, T. 719\nBrothers, T. 456\nBrown, A.S. 345\nBrown, K.F. 651\nBrown, R. 349\nBrown, T.J. 371\nBrown-Schmidt, S. 484, 487, 521, 545,\n546\nBruce, V. 125, 125f, 127, 128, 129, 130,\n138, 144\nBruner, J.S. 4, 59, 72f\nBrüning, J. 214\nBruno, N. 59, 75, 76\nBrunyé, T.T. 607, 682\nBrusovansky, M. 656\nBruyer, R. 117\nBrysbaert, M. 435, 436, 443, 446,\n470\nBuchanan, L. 482\nBuchanan, T.W. 359\nBuckley, M.J. 298\nBuckthought, A. 73\nBuetler, K.A. 452\nBullmore, E. 8, 14, 14f\nBülthoff, I. 74\nBurdett, B.R.D. 215\nBurgess, P.W. 261\nBurgoyne, A.P. 604, 618\nBurke, K.A. 494\nBürki, A. 531\nBurman, J.T. 3\nBurnham, B.R. 190–191\nBurns, B.D. 576, 602, 603\nBurr, D. 210\nBurton, A.M. 123, 127, 128, 129, 370\nBusch, N.A. 167\nBusigny, T. 119–120, 120f\nButterfield, S. 411\nButterworth, B. 542\nBuxbaum, L.J. 155\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n917\nByrne, M.D. 27\nByrne, R.M.J. 668–669, 670\nCabeza, R. 338, 339f\nCaccappolo-van Vliet, E. 445, 450\nCaharel, S. 117\nCahill, L. 735\nCahir, C. 749\nCai, Z.G. 411, 412f, 469\nCaird, J.K. 214, 215\nCalder, A.J. 128\nCalderwood, L. 128\nCalet, N. 463–464\nCaliglore, D. 276\nCaltagirone, C. 200\nCalvillo, D.P. 584\nCalvo, M.G. 494, 495\nCamerer, C. 708\nCampbell, K.L. 398\nCampbell, T.H. 695\nCampitelli, G. 614, 615\nCampos, B. 748\nCampoy, G. 242, 748\nCane, J.E. 486\nCann, H.W. 695\nCaparos, S. 191\nCappa, S.F. 539\nCaramazza, A. 32\nCaravolas, M. 434, 434f\nCarbonell, K.M. 404\nCarpenter, P.A. 255, 487–488, 489\nCarpenter, S.K. 265\nCarrasco-Ortiz, H. 436\nCarrera, E. 11\nCarriedo, N. 482\nCarter, O.L. 114\nCartmill, E.A. 548\nCasasanto, D. 400\nCasey, J.P. 694\nCastillo, M.D. 758\nCatmur, C. 771\nCattinelli, I. 446\nCavaco, S. 329\nCave, K.R. 184\nČavojová, V. 697\nCeci, S.J. 618\nCeleghin, A. 86, 87\nCeraso, J. 679\nCermak, L.S. 326\nChabanat, E. 83\nChabris, C.F. 172, 172f, 173, 310, 363\nChallis, B.H. 263\nChalloner, J. 586\nChalmers, D. 768\nChamberlain, F. 251\nChampod, C. 98\nChan, A.H.S. 730, 748\nChan, A.H.S. Tsang, S.N.H. 216\nChan, A.H.S. Zhang, T.R. 730, 748\nChan, J. 593\nChan, J.C.K. 291–292, 310\nChang, E.F. 182\nChang, H. 207, 208, 208f\nChang, J.Y. 602–603, 604\nChangeux, J.P. 783, 784\nChaplin, T.A. 52\nCharness, N. 602\nCharpentier, C.J. 649–650, 745\nChase, W.G. 614\nChater, N. 394, 395, 398, 401, 409, 516,\n517, 521, 535, 564, 701\nChee, Q.W. 263, 264, 264f\nCheek, N.N. 656\nChen, C.C. 77\nChen, J. 60, 61f, 320\nChen, Q. 438\nChen, S. 778\nChen, X.-J. 387\nChen, Y. 189\nChen, Y.-C. 209, 210\nChen, Z. 184, 187f, 188, 242, 594\nChenoweth, N.A. 551, 556, 557\nCherry, E.C. 179–180\nCherubini, P. 669\nChiarello, C. 417\nChica, A.B. 193, 194\nChick, C.F. 643\nChoe, H. 515\nCholewa, J. 560–561\nChomsky, N. 4, 393, 394, 395–398, 462,\n465\nChouinard, B. 480, 480f\nChristiansen, M.H. 394, 395, 398, 409,\n517, 521, 535, 540, 564\nChristianson, K. 441–442, 474\nChristianson, S.A. 364\nChristopher, E.A. 386, 386f\nChristopher, M.E. 494\nChristou, A.I. 270\nChrysikou, E.G. 587–588\nChukoskie, L. 205–206\nChun, M.M. 179\nChun, W.Y. 639, 640\nChung, S. 396\nChurch, B.A. 326, 327\nChurchland, P.S. 17f\nChuy, M. 555\nCiaraffa, F. 196\nCichy, R.M. 205\nCipiolotti, L. 258\nCisler, J.M. 756\nClancy, S.A. 285\nClark, C.M. 277, 598\nClark, I.A. 329\nClark, L.A. 745, 746, 755\nClarke, J. 171, 240–241\nClarke, P. 763\nClarkson, G. 602\nClay, Z. 394\nClifton, C. 403, 466, 471\nClore, G.L. 734, 744\nClose, J. 314\nCoch, D. 181\nCoco, M.I. 467\nCoetzee, J.P. 690\nCoget, J.-F. 748\nCohen, L.R. 159\nCohen, M.A. 170, 777, 790\nColavita, F.B. 209\nCole, J. 464\nCollegio, A.J. 184\nCollette, F. 259–260\nCollin, G. 15\nCollins, A.M. 315, 497\nCollins, W.M. 497\nColman, A.M. 716, 767\nColomb, C. 374\nColombo, L. 557\nColtheart, M. 7–8, 8f, 11, 27, 29, 406,\n435, 442, 443, 444f, 445, 450, 452\nColvin, M.K. 590, 795\nCona, G. 377, 384–385\nConnor, C.E. 50\nConway, A.R.A. 181, 255, 257\nConway, M.A. 353, 355–356, 356–357,\n357f, 358f, 359, 362\nCook, A.E. 492, 504, 505–506, 506f\nCook, G.I. 387\nCook, S.W. 548\nCopeland, D.E. 682\nCorbetta, M. 178, 191–193, 193f,\n194–195, 196, 197, 198–199\nCorkin, S. 297\nCorley, M. 528\nCormack, L.K. 146\nCormier, D.C. 549\nCorner, A. 700, 701f\nCorrow, S.L. 120\nCosentino, S. 323\nCoste, C.P. 195\nCostello, F.J. 27\nCôté, S. 744\nCourage, M.L. 351, 352\nCowan, N. 242\nCowen, A.S. 716\nCowey, A. 52, 55\nCowley, M.B. 668–669, 669–670, 670\nCowley, S.J. 484\nCox, W.T.L. 113\nCraik, F.I.M. 262, 264, 294\nCrassini, B. 150, 150f\nCrawford, J.D. 57, 57f\nCrawford, J.R. 376\nCraycraft, N.N. 546\nCreem, S.H. 61\nCrescentini, C. 591\nCrible, L. 549\nCreated from usyd on 2022-02-18 03:52:37.",
    "918\nAuthor index\nCrisp, J. 450–451\nCristea, I.A. 762\nCrocker, M.W. 427, 428f\nCroskerry, P. 625–626, 625f, 629, 708\nCrupi, V. 626\nCruse, D. 778, 779f\nCryder, C.E. 746, 746f\nCrystal, D. 393, 515, 516\nCuriel, J.M. 508\nCurot, J. 302\nCurran, T. 117\nCurtis-Holmes, J. 685\nCusack, R. 131\nCutini, S. 199\nCutler, A. 411\nCutting, J.E. 75, 76\nCuttler, C. 380\nCvejic, E. 548\nDąbrowska, E. 465, 472\nDagher, A. 590–591, 590f\nDalgleish, T. 361, 361f, 362–363, 362f,\n713\nDalrymple, K.A. 95\nDamian, M.F. 533\nDanckert, J. 197f\nDando, C.J. 374\nDandolo, L.C. 293\nDanek, A.H. 578, 582\nDaneman, M. 255\nDaniel, F. 497\nDarbor, K.E. 630, 745\nDarling, S. 246f, 253, 253f\nDas, T. 330\nD’Avanzato, C. 729\nDavare, M. 61\nDavid, S.V. 182\nDavies, A. 212, 216\nDavies, B.L. 543\nDavies, M. 10\nDavies-Thompson, J. 126, 127f,\n128–129\nDavis, C.J. 701\nDavis, D. 284\nDavis, J.I. 722\nDavis, M. 499\nDawes, R.M. 644, 704\nDawson, E. 677, 697\nDay, M.V. 350\nde Bode, S. 794\nde Gardelle, V. 327, 777\nde Graaf, T.A. 780, 788, 792\nDe Groot, A.D. 601\nde Haan, E.H.F. 56f, 62, 64, 197, 199,\n200\nDe Houwer, J. 228\nde la Rosa, S. 161\nde Manzano, O. 610, 611, 618\nDe Martino 652\nDe Neys, W. 576, 637, 638, 640, 675,\n685–686, 685f, 743\nDe Salvo, S. 778\nde Schotten, M.T. 8–9\nDe Vries, J.V. 72, 72f\nDe Vries, M. 749\nDeady, D.K. 722\nDean, M. 651\nDebelak, R. 591\nDębska 484\nDeCaro, M.S 255, 257, 587, 587f\nDede, A.J.O. 299, 331\nDeffenbacher, K.A. 369\nDegno, F. 456\nDehaene, S. 783, 784\nDeHart, T. 736\nDel Cul, A. 789\nDel Guidice, M. 754\ndel Prete, F. 287\nDelaney, P.F. 591\nDell, G.S. 29, 32, 514, 519, 521, 522,\n525–526, 526–527, 528, 529–530, 533,\n538, 539, 541, 564\nDeLong, K.A. 440–441\nDeLucia, P.R. 151\nDemertzi, A. 792\nDeMiguel, V. 655\nDemiray, B. 347\nden Ouden, D.-B. 467\nDenison, R. 77\nDennis, N.A. 285\nDerakshan, N. 761\nDerryberry, D. 761\nDesai, R.H. 300\nDestrebecqz, A. 275\nDeutsch, D. 180, 181f, 182\nDeutsch, J.A. 180, 181f, 182\nDevine, P.G. 113\nDew, I.T.Z. 338, 339f\nDewar, M.T. 283\nDi Lollo, V. 186\nDi Russo, F. 198\nDi Stasi, L.L. 142\nDiana, R.A. 306, 307f, 308, 309–310\nDiano, M. 198\nDiao, L. 722–723\nDick, A.S. 537\nDick, F. 537\nDidierjean, A. 584\nDijksterhuis, A. 662, 664\nDijkstra, K. 510\nDijkstra, N. 23, 134–136, 135f, 137\nDing, S. 95\nDismukes, K.R. 387\nDismukes, R.K. 378, 379, 387\nDitto, P.H. 628\nD’Mello, S. 457\nDodhia, R.M. 387\nDöhring, J. 330\nDolcos, F. 734, 735, 735f\nDomeier, M. 644, 644f\nDomini, F. 74\nDomurat, A. 632–633\nDonovan, I. 187, 189\nDooling, D.J. 500\nDoré, B.P. 727, 730\nDosenbach, N.U.F. 195–196\nDouglass, A.B. 364\nDowning, P.E. 24, 121\nDoyon, J. 331\nDozois, D.J.A. 753, 757\nDrews, F.A. 214, 215\nDreyer, F.R. 318\nDronkers, N.F. 536–537\nDror, I.E. 98–99, 98f\nDrummond, L. 187\nDrury, J.E. 463, 466–467\nDubarry, A.-S. 534\nDuchaine, B. 121f\nDudai, Y. 311\nDuff, M.C. 302, 545\nDuffau, H. 9\nDuffy, S.A. 463\nDufour, S. 423\nDuggan, G.B. 590\nDugué, L. 197–198\nDuin, R.P.W. 95\nDummel, S. 636\nDunbar, K. 595, 670\nDuncan, J. 199, 203\nDuncker, K. 585, 585f, 586, 594, 595\nDunlosky, J. 265\nDunn, J.C. 306\nDunning, D. 705\nDuss, S.B. 335\nDux, P.E. 222\nDyer, J.S. 656\nDysart, J.E. 370\nEagle, M.N. 162\nEasterbrook, J.A. 369, 731, 732,\n734–735\nEaton, E. 542\nEbbinghaus, H. 58, 59, 59f, 278, 279f\nEcker, U.K.H. 283\nEdelson, M.G. 311, 367, 368\nEdelstein, R.S. 733\nEgly, R. 186–187, 187f, 188\nEherenfreund-Hager, A. 746, 749\nEhinger, K.A. 204, 204f, 206\nEhrenfreund-Hager, A. 746\nEich, E. 737\nEichenbaum, H. 297\nEil, D. 646\nEimer, M. 110, 119, 204, 209\nEinstein, G.O. 375, 382\nEkroll, V. 582, 582f\nEldar, E. 716\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n919\nElder, J.H. 100\nElliott, D. 154\nEllis, A.W. 430, 430f, 431, 515\nEllis, B.J. 754\nEllis, J. 345–346\nEllis, J.J. 437f, 579\nEllsworth, P.C. 719\nElman, J.L. 417, 420\nElqayam, S. 694, 703\nElsey, J.W.B. 291, 292\nElward, R.L. 301\nEndres, T. 266\nEndress, A.D. 242, 243f\nEngbert, R. 455\nEngel, P.J.H. 605\nEngel, S. 539\nEngel, S.A. 50\nEngle, R.W. 254, 255, 488\nEngstrom, J. 215\nEnz, K.F. 355\nErdfelder, E. 636, 637\nEreku, M.H. 614\nErez, J. 110\nEricsson, K.A. 613–614, 616–617, 620\nEriksen, C.W. 184, 731\nEriksson, J. 791\nEsteves-Sorenson, C. 651–652\nEtchells, D.B. 110\nEtkin, A. 725, 727, 729\nEttlinger, M. 423–424\nEustache, F. 347\nEvans, J.St.B.T. 571, 592, 637, 667, 668,\n683, 684, 685, 686, 689, 690, 694, 703,\n704, 705\nEvans, N. 396, 683–684\nEvans, S. 183\nEveraert, J. 758, 760, 761f, 763\nEysenck, M.C. 263\nEysenck, M.W. 4, 179, 264, 287, 289,\n300, 443, 732, 754, 757, 758, 759, 761\nFabbro, F. 535\nFajkowska, M. 754, 757\nFama, R. 299\nFarag, C. 323\nFarah, M.J. 117, 118\nFarmer, C.M. 214\nFarmer, G.D. 219\nFarmer, M.E 403\nFaroqi-Shah, Y. 540\nFaroqui-Shah, Y. 541, 542\nFatania, J. 283\nFath, A.J. 150–151\nFattori, P. 46\nFawcett, J.M. 369, 733\nFazekas, P. 768\nFazio, L.K. 629\nFecher, B. 33\nFedor, A. 581\nFedorenko, E. 461, 537\nFedzechkina, M. 396\nFeeser, M. 728\nFeinstein, J.S. 735\nFeist, G.J. 671\nFeldman, A.G. 145\nFeldman, G. 651\nFeldman, J. 55, 241\nFelleman, D.J. 44, 95\nFemandes, M.A. 307, 336\nFerber, R. 521\nFerber, S. 197f\nFerbinteanu, J. 338–339, 340\nFernandez, K.C. 729\nFerrari, P.F. 163\nFerrari, V. 327\nFerreira, F. 472–473, 473–474, 473f,\n475, 520\nFerreira, V.S. 527, 544, 545, 546, 546f\nFerrer, R.A. 747–748\nFerrucci, S. 131\nFetkewicz, J. 284\nffytche, D.H. 131\nFiedler, K. 630, 632, 633, 636, 637\nFilmer, H.L. 221\nFindlay, J.M. 165, 166f\nFine, A.B. 469–470\nFinn, E.S. 9\nFirestone, C. 112, 113, 114\nFischer, J. 172\nFischer, P. 658–659, 659f\nFischer, R. 214, 226\nFischer-Baum, S. 445\nFisher, D.L. 214, 215\nFisher, R.P. 373–374\nFisher, S.E. 397\nFisk, J. 361\nFitousi, D. 128\nFivush, R. 351, 352\nFleck, J.I. 581\nFlegal, K.E. 271\nFlevaris, A.V. 105\nFlinker A. 537\nFodor, J.D. 463–464\nFoerde, K. 325, 328\nFoland-Ross, L.C. 759\nFollmer, D.J. 504, 505\nFontaine, J.R.J. 720\nForbus, K. 593, 594f, 598–599\nFord, J.H. 359\nForster, S. 190\nFossett, T.R.D. 530\nFoster, D.H. 68–69, 70, 71\nFoster, J.D. 647\nFoulsham, T. 144\nFowlkes, C.C. 100\nFox, C.J. 128\nFrancesconi, M. 658\nFrank, M.C. 400\nFrankland, P.W. 279, 352, 352f\nFranklin, S. 431\nFranz, V.H. 60\nFraser H. 21f, 413\nFrässle, S. 780, 781f\nFrauenfelder, U.H. 423, 424, 426\nFrazier, L. 464, 465, 466\nFrederick, S. 1, 592, 701, 708\nFredrickson, B.L. 731, 732\nFreed, E.M. 489, 490\nFreeman, J. 777, 777f\nFrench, R.M. 33\nFreud, E. 62, 104\nFreud, S. 284, 285, 351, 769\nFreuenberger, D. 441\nFrick-Horbury, D. 548\nFried, I. 775\nFriederici, A.D. 463\nFriedman, L. 540\nFriedman, N.P. 257, 258–259, 259f,\n260, 261, 262\nFriedman-Hill, S.R. 202–203\nFriedmann, N. 538\nFriedrich, C.K. 427\nFriedrich, T.E. 196\nFriesen, L.K. 793\nFrijda, N.H. 723\nFrisson, S. 441\nFroyen, V. 102\nFugelsang, J.A. 671–672\nFukumura, K. 546\nFunahashi, S. 222\nFunnell, M. 538\nFutrell, R. 396\nGable, P.A. 731–732, 733–734\nGabrieli, J.D.E. 326\nGaeth, G.J. 704\nGilaie-Dotan, S. 53, 53f\nGaillard, R. 54, 89, 272, 329, 789\nGainotti, G. 196\nGaissmaier, W. 624, 634\nGale, M. 668\nGallagher, S. 773\nGallese, V. 161, 163\nGalletti, C. 46\nGallivan, J.P. 154\nGallo, D.A. 264–265\nGalotti, K.M. 659–660, 660f\nGalton, F. 130\nGambetti, E. 745, 747\nGambi, C. 517\nGandhi, T. 131\nGangemi, A. 2, 593\nGanong, W.F. 415–416\nGao, X. 97, 509\nGarcea, F.E. 144\nGarcia-Retamero, R. 647\nGardiner, J.M. 301\nCreated from usyd on 2022-02-18 03:52:37.",
    "920\nAuthor index\nGarg, N. 746\nGarner, K.G. 222\nGarnsey, S.M. 469\nGarrard, P. 466, 550\nGarrett, B. 363–364\nGarrett, M. 519–520\nGarrod, S. 401, 494, 543\nGarson, J. 29–30\nGaskell, M.G. 426, 427, 428, 429\nGathercole, S.E. 557\nGauld, A. 500\nGauthier, I. 110, 111\nGauvin, H.S. 525\nGavilán, J.M. 106\nGawronski, B. 740, 740f, 743\nGazzaniga, M.S. 691, 793, 794, 795\nGegenfurtner, A. 604, 607\nGegenfurtner, K.R. 60\nGeiselman, R.E. 373–374\nGeisler, W.S. 100\nGelade, G. 202, 203, 203f, 206\nGelbard-Sagiv, H. 88\nGeng, J.J. 202\nGenon, S. 11\nGentner, D. 481, 482, 483f\nGenty, E. 394\nGeorge, T. 480, 483\nGeraerts, E. 284–285\nGerhardstein, P.C. 108\nGermine, L. 119\nGerrig, R.J. 491, 545, 547\nGerwing, J. 548\nGeskin, J. 119\nGeurten, M. 309, 309f\nGhafur, R.D. 724, 730\nGheysen, F. 276\nGhose, G.M. 54\nGhosh, V.E. 322–323, 499, 501\nGibbs, R.W. 483\nGibson, B.S. 190, 191f\nGibson, E. 488\nGibson, J.J. 72, 141–146, 142f, 148–149,\n175\nGick, M.L. 594–595\nGigerenzer, G. 631, 634, 635, 636, 637,\n647, 655\nGilaie-Dotan, S. 50, 53–54, 53f, 159\nGilbert, C.D. 111\nGilboa, A. 304, 322, 499, 501\nGilden, D.L. 203, 207\nGilhooly, K.J. 584\nGillam, B. 77\nGinet, M. 374\nGiorgetta, C. 649\nGirotto, V. 677\nGirshick, A.R. 76\nGiusberti, F. 745, 747\nGlennerster, A. 80\nGlöckner, A. 636, 646\nGlover, S. 152, 153, 154\nGobet, F. 4, 585, 588, 601, 602, 602f,\n603, 614, 615\nGodden, D.R. 288, 290\nGodefroy, O. 251\nGodwin, D. 89\nGoel, V. 573, 574, 590, 691, 693\nGoh, W.D. 263, 264, 264f, 289, 289f\nGoldberg, A. 558\nGoldberg, I.I. 789\nGoldberg, R.M. 100\nGoldenberg, G. 131\nGoldinger, S.D. 125, 406–407\nGoldrick, M. 398, 522, 526, 529, 536,\n537, 543\nGoldstein, D.G. 635\nGollwitzer, P. 387\nGolob, E.J. 256\nGolumbic, E.Z. 183\nGómez, A.T. 74\nGomulicki, B.R. 498\nGong, L. 326, 331\nGontar, P. 378–379\nGoodale, M.A. 53, 55, 56–57, 56f, 58,\n59, 61, 63–64, 63f, 91, 103–104, 141,\n144, 152, 153, 155\nGoodhew, S.C. 184\nGoolkasian, P. 96, 111, 112f\nGordon, J. 66\nGotlib, I.H. 757, 759\nGottfredson, L.S. 617, 618\nGrabner, R.H. 604\nGraesser, A.C. 492, 497\nGraf, P. 375, 376, 380\nGräff, J. 290\nGrafman, J. 574, 590\nGrafton, B. 762\nGraham, M.E. 73\nGraham, S.A. 397\nGrainger, J. 438\nGranhag, P.A. 747\nGranzier, J.J.M. 68\nGras, D. 495–496, 496f\nGrassini, S. 88–89, 89f, 90, 786\nGray, C.M. 54\nGray, R. 211\nGraziano, M.S.A. 770, 771, 771f, 784,\n785f\nGreen, A.E. 600\nGreen, C. 285\nGreenberg, D.L. 304\nGreenberg, J.H. 396\nGreene, A.J. 336\nGreene, C.M. 191\nGreene, J.D. 738–740\nGreitemeyer, T. 658–659, 659f\nGrice, H.P. 480, 484, 543–544\nGriffin, Z.M. 527\nGriffiths, J.D. 540–541, 540f\nGrill-Spector, K. 23, 121, 123\nGriskevicius, V. 750\nGrisoni, L. 415, 416, 429\nGroome, D. 4, 300\nGroopman, J. 625, 629\nGross, J.J. 724, 725f, 729\nGross, S. 776\nGrossman, E.D. 159\nGrossnickle, E.M. 596, 597f\nGrot, S. 253\nGuan, C.Q. 557\nGuardini, P. 142\nGueliai, B. 549\nGuida, A. 613, 614\nGüllich, A. 615\nGustavson, D.E. 259\nGutchess, A.H. 35\nGutierrez-Sigut, E. 436\nGuttentag, R.E. 548\nGvion, A. 538\nGwilliams, L. 425\nHaak, K.V. 63, 64\nHaber, R.N. 78–79, 78f\nHafenbrädl, S. 655\nHagoort, P. 469, 476, 476f, 477\nHahn, B. 193\nHahn, S. 146\nHahn, U. 694, 698–699, 701\nHaider, H. 272, 273, 273f, 278\nHaigh, M. 700\nHall, S. 705\nHalle, M. 418\nHambrick, D.Z. 616, 618\nHamlin, J.K. 36, 672\nHamm, J.P. 109\nHan, S. 751\nHan, S.W. 225\nHan, Z.Z. 436\nHanley, J.R. 128, 436, 444, 445, 560,\n562\nHannula, D.E. 245, 336\nHansen, T. 70\nHaque, S. 64\nHarada, Y. 369\nHardt, O. 280\nHardwicke, T.E. 292, 293\nHareli, S. 747\nHarley, T.A. 24, 393, 409, 413, 423,\n424, 447, 449, 451, 468, 493, 501, 530,\n531, 532, 534, 539, 541, 542\nHarm, M.W. 442, 449\nHarmon-Jones, E. 732, 733–734\nHarris, A.J.L. 699, 700f, 701, 744\nHarrison, H.S. 150, 151\nHarrison, T.L. 598\nHart, W. 659\nHartwigsen, G. 12, 22\nHarvey, L.O. 130\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n921\nHarvey, M.I. 484\nHashtroudi, S. 331\nHaskell, T.R. 522\nHassabis, D. 312\nHassin, R.R. 569, 769\nHasson, U. 478\nHata, K. 549\nHauk, O. 317\nHäuser, K.I. 478\nHavelka, J. 253, 253f\nHayes, J.R. 514, 551, 552f, 553, 556,\n557\nHayne, H. 351, 352, 353\nHayward, W.G. 109, 110\nHealing, S. 548\nHeathcote, A. 278\nHeck, D.W. 636, 637\nHegdé, J. 43, 43f, 46, 48, 104\nHeimler, B. 609–610\nHeld, R.T. 73\nHelder, A. 492, 492f, 494, 495, 497–498\nHeller, D. 484\nHellmann, J.H. 345\nHemenover, S.H. 726\nHenderson, E.N. 499\nHenderson, J.M. 168–169, 169f, 186\nHenke, K. 276, 300f, 333–335, 334f,\n336–337, 338, 342\nHenry, M.L. 450\nHepner, C. 559, 560f, 562\nHerholz, S.C. 609, 610, 611\nHering, E. 65–66\nHerlihey, T.A. 146\nHerrera, S. 759\nHertwig, R. 630\nHesse, C. 60, 153\nHesselmann, G. 62, 87, 90, 225, 570,\n769, 795, 796f\nHeutink, J. 51–52\nHeyman, T. 316\nHeywood, C.A. 50, 51, 52, 55\nHibberd, D.L. 223\nHicks, J.L. 377\nHigham, P.A. 367\nHilbert, M. 634\nHilger, K. 15\nHilliard, C. 548\nHimmelbach, M. 58\nHirsch, C.R. 759\nHirst, W. 350\nHitch, G.J. 246, 246f, 262, 263f, 265\nHitchcock, C. 363\nHo, C. 211\nHobbs, S. 3\nHobeika, L. 600\nHochman, G. 645\nHodgkinson, G.P. 707\nHodgson, C. 537\nHofer, F. 202\nHoffman, P. 442, 447, 448f, 449\nHoffrage, U. 631, 632f, 703\nHogarth, R.B. 708\nHolan, A.D. 544\nHolland, A.C. 736, 759\nHolland, R.W. 750, 750f\nHoller, J. 548\nHollingworth, A. 168–169, 169f, 186,\n187, 188f\nHolmes, A. 754\nHolmes, K.J. 400\nHolmes, V.M. 519\nHolyoak, K.J. 480, 594–595\nHolzgrefe, J. 463\nHommel, B. 225\nHornikx, J. 699, 701\nHortensius, R. 734\nHorton, C. 181–182\nHorton, W.S. 545, 547\nHosking, S.G. 150, 150f\nHoudé, O. 691, 693\nHouston, A.I. 648\nHoward, R.W. 615, 616f\nHowe, M.L. 351, 352, 353\nHowe, P.D. 695\nHowe, P.D.L. 114, 171\nHowes, A. 603, 604, 658\nHuang, J. 468\nHuang, Y. 64\nHubel, D.H. 96\nHuberdeau, D.M. 274\nHuber-Huber, C. 230\nHübner, R. 213–214\nHuddleston, E. 286, 286f\nHudetz, A.G. 788\nHuestegge, L. 217\nHuettel, S.A. 16t\nHuettig, F. 403, 416, 426\nHuff, M. 509\nHugenberg, K. 371\nHuijser, S. 219\nHulleman, J. 203, 207–208\nHumphreys, G.W. 203\nHung, C.P. 19\nHunt, R.R. 263\nHuntsinger, J.R. 730–731, 732, 733f,\n734\nHuppert, J.D. 753\nHurme, M. 48, 85\nHurvich, L.M. 66\nHuth, A.G. 19\nHyde, K.L. 610, 611f, 612f\nHyman, I. 164, 164f\nHyönä, J. 503, 504, 505\nIhlebaek, C. 372\nIndefrey, P. 531, 532f, 533, 534\nInman, C.S. 360\nInsausti, R. 326, 326f\nInzlicht, M. 249\nIoannides, A.A. 241\nIpser, A. 411\nIrish, M. 303\nIshibashi, R. 320, 321f\nItkonen, T. 147\nIttelson, W.H. 73\nIttelson, W.H. 78\nItzhak, I. 493\nIyilikci, E.A. 751\nIzard, C.E. 716\nJ. McGurk, H. 411\nJ. Tsotsos, J. 27\nJaarsma, T. 607\nJack, F. 351, 352\nJacobs, A. 160\nJacobs, P. 631, 632\nJacobs, R.A. 75–76\nJacoby, L.L. 281, 282, 283, 369\nJacquemot, C. 248\nJaeger, T.F. 415, 467, 547\nJain, A.K. 95\nJäkel, F. 103\nJalbert, A. 248\nJames, D. 576\nJames, E.L. 351\nJames, G. 704\nJames, K.H. 562, 563f\nJames, T.W. 58\nJames, W. 178, 722\nJameson, D. 66\nJanczyk, M. 225\nJanelle, C.M. 731\nJans, B. 184\nJansma, J.M. 227\nJanssen, P. 64\nJanssen, S.M.J. 347\nJantzen, M.G. 405\nJared, D. 435–436, 438, 451, 451f\nJarosz, A.F. 587\nJeneson, A. 245\nJenkins, R. 127\nJensen, M.S. 165, 174\nJiahui, G. 122\nJiang, T. 509\nJiang, Y. 790\nJiménez, L. 274\nJoanisse, M.F. 421–422, 424\nJobard, G. 445\nJohannessen, K.B. 358\nJohansson, G. 157–158\nJohansson, M. 288, 289\nJohn, L.K. 672\nJohnson, M.K. 499, 500\nJohnson-Laird, P.N. 501–502, 678,\n680–682, 683, 705, 709, 751, 754\nJolicoeur, P. 314\nJones, E.B. 762\nCreated from usyd on 2022-02-18 03:52:37.",
    "922\nAuthor index\nJones, P.R. 75\nJones, S.P. 371, 371f\nJongman, S.R. 535–536\nJonides, J. 244, 249\nJoormann, J. 760, 761f\nJosselyn, S.A. 352, 352f\nJun, S.A. 464\nJuphard, A. 446\nJuskenaite, A. 347\nJust, M.A. 314, 487–488, 489\nKaakinen, J.K. 503, 504, 505\nKahan, D.M. 695, 696, 696f, 698, 707\nKahane, G. 740\nKahneman, D. 623, 624, 627, 630, 637,\n637–640, 638, 640, 641, 642, 642f,\n649, 683, 704\nKaiser, D. 205\nKaiser, E. 493\nKaland, N. 479\nKandasamy, N. 652\nKandil, F.I. 147\nKane, J. 671\nKane, M.J. 254, 255, 256, 488\nKanizsa, G. 73, 73f\nKanwisher, N. 121\nKaplan, S. 657\nKarimi, H. 472–473, 473f, 475\nKarlen, Y. 555\nKarlsson, J. 503\nKasselimis, D.S. 430–431\nKassin, S.M. 98\nKastner, S. 770, 771f\nKatidioti, I 219, 220\nKatti, H. 206\nKauffmann, L. 105\nKay, A.C. 695\nKay, K. 19\nKazanas, S.A. 237\nKeane, M. 595\nKeane, M.T. 27\nKeating, J. 370\nKelber, A. 65\nKeller, F. 467\nKellogg, R.T. 549, 554–555, 554f, 556,\n556f, 557, 558\nKeltner, D. 716, 747, 751\nKemeny, F. 329, 330, 330f\nKendeou, P. 509\nKenealy, P.M. 737, 737f\nKenett, Y.N. 315\nKennedy, A. 456\nKennedy, J.E. 36, 672\nKensinger, E.A. 736, 759\nKent, S.C. 554\nKersten, A.W. 339\nKessler, B. 561\nKessler, J. 789\nKeys, D.J. 704\nKeysar, B. 484, 486, 545, 547\nKeysers, C. 161, 161f\nKhemlani, S. 681, 682, 683\nKidd, E. 489\nKilpatrick, F.P. 78\nKim, D. 410\nKim, E.J. 432\nKim, H. 327, 328, 328f, 337\nKim, J.H. 352\nKim, N.-G. 80, 81\nKim, P.Y. 377\nKim, S. 80, 337, 337f, 340\nKimchi, R. 170, 187\nKindt, M. 380\nKing, B.R. 270\nKing, J.-R. 787, 788, 788f, 791\nKingston, J. 415\nKingstone, A. 144\nKinoshita, S. 438\nKintsch, W. 481, 482, 501, 502f, 503,\n503f, 510, 613\nKircanski, K. 757\nKizilirmak, J.M. 578\nKlargaard, S.K. 117\nKlauer, K.C. 250, 250f, 674, 678–679,\n679f\nKlaus, J. 520\nKlein, C. 24\nKlein, G. 660–661, 661f\nKlein, R.M. 403\nKleinschmidt, A. 195\nKliegl, O. 265, 281, 282, 282f\nKloeters, S. 160\nKlooster, N.B. 302\nKlumpp, H. 727–728\nKnauff, M. 682–683\nKnight, R.T. 537, 590, 591\nKnoblich, G. 580, 581f, 587\nKnol, H. 59\nKnowlton, B.J. 325\nKocab, A. 396–397\nKocagoncu, E. 426\nKoch, C. 790\nKoch, I. 213, 217, 223\nKoehler, D.J. 633\nKoehler, D.J. 704\nKoellinger, P. 749\nKohn, N. 728, 728f\nKoivisto, M. 21, 88–89, 89f, 90, 782,\n783, 783f, 786\nKok, P. 116\nKondziella, D. 778–779\nKonishi, M. 768\nKonopka, A.E. 521\nKoole, S.L. 725–726\nKoornneef, A. 475\nKopiske, K.K. 60\nKoppel, J. 353, 354f, 355\nKoppenol-Gonzalez, G.V. 591\nKornell, N. 266\nKosslyn, S.M. 23, 131–132, 132f, 133,\n137\nKoster, E.H.W. 756, 763\nKotseruba, I. 27\nKotz, S.A. 427\nKouider, S. 88, 89\nKounios, J. 577, 578\nKourtzi, Z. 50\nKovacs, G. 328\nKovacs, K. 255, 257\nKovera, M.B. 373\nKraft, J.M. 68\nKragel, J.E. 310\nKraus, N. 404\nKrauss, S. 575, 575f\nKravitz, D.J. 48, 48f, 189\nKrawczyk, D.C. 595, 599, 599f, 600\nKretz, D. 595\nKriengwatana, B. 409\nKróliczak, G. 59, 60f, 61\nKroll, J.F. 535\nKruger, J.M. 705\nKruglanski, A.W. 635, 639, 640\nKrupinski, E.A. 606, 606f, 609\nKrynski, T.R. 626–627, 627f, 631\nKubricht, J.R. 595\nKugler, T. 747\nKühberger, A. 643\nKuhn, G. 165, 166f, 167, 170\nKulatunga-Moruzi, C. 608, 609\nKulik, J. 349\nKundel, H.L. 122, 606\nKuperberg, G.R. 415, 467, 491, 496\nKuppens, P. 720, 723\nKurby, C.A. 508, 509\nKurt, S. 183\nKvavilashvili, L. 345–346\nKwon, M. 432\nKwon, Y. 417\nLacey, S. 481\nLacroix, A.N. 406, 406f\nLaeng, B. 133, 133f\nLafer-Sousa, R. 51\nLaganaro, M. 538\nLahmer, M. 211\nLai, C.S.L. 397\nLaird, J.E. 31–32\nLakatos, I. 671\nLakshminarayanan, V. 160\nLambe, K.A. 629\nLambon Ralph, M.A. 11, 303, 313, 319,\n319f, 322, 442, 537\nLamme, V.A.F. 21, 48, 90, 111, 776,\n781, 782f, 784, 790, 791\nLamy, D. 786, 786f\nLand, E.H. 68\nLand, M. 152\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n923\nLand, M.F. 147\nLandin-Romero, R. 303\nLandy, M.S. 75, 76, 77\nLane, D.M. 602–603, 604\nLane, P. 4, 588\nLane, R.D. 719, 720f\nLang, A. 369\nLangenburg, G. 99\nLanger, M.S. 73\nLangerock, N. 242, 244\nLangille, D. 746\nLaPaglia, J.A. 291–292\nLappi, O. 147, 148, 148f\nLasaponara, S. 198\nLatorella, K.A. 378\nLau, H. 83\nLau, H. Ko, Y. 84–85\nLau, J.Y.F. 761\nLaukkonen, R.E. 579\nLaunay, C. 367, 368f\nLaunder, D. 661\nLavie, N. 189–190, 231\nLawrence, A. 637\nLawson, R.R. 274, 333\nLazarus, R.S. 720\nLe, X. 550\nLeach, F.R. 651\nLeding, J.K. 237\nLedoux, J.E. 795\nLee, C.Y. 451\nLee, D.N. 147, 149–150, 151\nLee, E.K. 519\nLee, H. 134, 135f, 137, 727\nLee, J.-S. 762\nLee, P. 399\nLee, R.J. 71\nLee, S.-H. 45\nLee, W.E. 745\nLégal, J.-B. 173\nLehar, S. 46f\nLehle, C. 213–214\nLeinenger, M. 435, 436\nLeiserowitz, A. 695\nLench, H.C. 630, 731, 744, 745, 749\nLenton, A.P. 657, 658\nLenton-Brym, A. 358\nLeonard, C.J. 186\nLeonard, M.K. 414\nLeopold, D.A. 45\nLePort, A.K.R. 348–349, 348f\nLerner, J.S. 738, 743–744, 746, 747, 748,\n751, 752–753, 752f\nLev-Ari, S. 409, 488\nLevelt, W.J.M. 29, 523, 525–526, 527,\n530–533, 534, 535, 537, 538, 539\nLevin, C.A. 78–79, 78f\nLevin, D.T. 164, 777\nLevin, I.P. 704\nLevine, D.N. 515, 589\nLevine, L.J. 733, 744, 749\nLevine, M. 589\nLevinson, S. 396, 683–684\nLevis, J. 488\nLeviston, Z. 695\nLevy, C.M. 552, 555\nLevy, D.A. 326\nLewis, P.A. 736\nLi, H. 656\nLi, O. 181\nLi, P. 399\nLi, V. 77\nLi, W. 111\nLiberman, A.M. 417–418\nLibet, B. 774\nLichtenstein, S. 628\nLiden, C. 413\nLiebenthal, E. 418–419\nLieberman, P. 403–404\nLief, H. 284\nLien, J.W. 646\nLieto, A. 31\nLiker, J.K. 618\nLimpo, T. 552, 553f, 556\nLin, S. 486\nLindholm, T. 364\nLindquist, K.A. 717–718, 717f\nLindsay, D.S. 366, 367–368\nLingnau, A. 162, 163\nLinhares, A. 603, 604\nLinkovski, O. 380, 381f\nLinnell, K.J. 191\nLipka, K. 562\nLisanby, S.H. 21–22\nList, A. 188\nLitvak, P.M. 747, 748\nLiu, H.N. 721, 762\nLiu, S. 518\nLivingstone, M.S. 105f\nLleras, A. 583\nLockhart, R.S. 262, 264, 294\nLoft, S. 379, 380\nLoftus, E.F. 284, 315, 365, 366, 367,\n368, 497\nLogačev, P. 472\nLogan, G.D. 228, 271\nLogie, R.H. 501\nLong, G.M. 113\nLong, M.R. 546\nLongstaff, M.G. 551, 555–556\nLotto, A.J. 404\nLoukusa, S. 479\nLourenço, J.S. 385–386\nLove, J. 493\nLovell, P.G. 76–77\nLovett, A. 593, 594f, 598–599\nLowder, M.W. 472, 474\nLowe, R. 721\nLu, H. 158, 158f\nLu, S.A. 216\nLu, S.H.X. 289, 289f\nLuan, M. 656\nLuber, B. 21–22\nLuchins, A.S. 584\nLudwig, K. 62\nLuk, K.K.S. 486\nLuka, B.J. 440\nLuke, S.G. 441–442, 455\nLupyan, G. 113, 114\nLuria, A.R. 280\nLustig, C. 283\nLyn, H. 394\nMacDonald, M.C. 365, 411, 468, 475,\n477, 522, 535\nMace, J.H. 333\nMacerollo, A. 163\nMacGregor, J.N. 590\nMack, A. 142, 171, 240–241, 791\nMacLeod, A.K. 313\nMacLeod, C. 763\nMacnamara, B.N. 614–615, 616, 617\nMacoir, J. 561\nMacPherson, S.E. 212\nMadden, C.J. 508\nMädebach, A. 529, 533\nMadore, K.P. 311, 312\nMadsen, H.B. 352\nMaffei, C. 431\nMagalhaes, P. 644\nMagliano, J. 498, 504, 507, 510\nMagnuson, J.S. 409\nMaguire, E.A. 329, 610\nMahon, B.Z. 144\nMahowald, K. 518\nMaier, N.R.F. 583\nMaiworm, M. 210\nMakovski, T. 80, 81f\nMallow, J. 288, 290\nMallpress, D.E.W. 648\nMaloney, L.T. 67f, 68\nMamede, S. 608, 629\nManassi, M. 172\nMandel, D.R. 643, 667\nManfredi, D.A. 481\nMani, N. 416\nManning, D. 607\nManns, J.R. 290, 302\nManstead, A.S.R. 723\nManzy, D. 214\nMargolin, S.J. 498\nMarien, H. 769, 770f\nMarinelli, L. 277\nMarinsek, N.L. 793\nMark, V. 794\nMarkovits, H. 675–676, 676f, 685\nMarkowitsch, H.J. 789\nMarlatte, H. 304, 322, 501\nCreated from usyd on 2022-02-18 03:52:37.",
    "924\nAuthor index\nMarois, R. 225\nMarques, J.F. 321, 473\nMarques, L.M. 411\nMarr, D. 105–106, 111\nMarrero, H. 677–678\nMarsh, E.J. 346\nMarslen-Wilson, W.D. 417, 425–426,\n427, 428, 429\nMartin, C.D. 156\nMartin, D.H. 165, 561\nMartin, P.R. 66, 67\nMartin, R.C. 519\nMartinez, A. 189\nMartinez, L.M. 96, 165\nMashour, G.A. 788\nMasicampo, E.J. 768, 781\nMather, G. 47f, 66, 106\nMather, M. 22\nMathews, A. 758\nMathy, F. 241\nMatsushima, K. 555\nMattys, S.L. 408, 410–411, 410f\nMaule, A.J. 707\nMauss, I.B. 726\nMayberry, E.J. 319–320, 324f\nMayer, K.M. 159\nMayhorn, C.B. 377\nMaylor, E.A. 530\nMayor, J. 30\nMazzi, C. 82, 85, 87\nMcAlpine, D. 183\nMcAndrew, S. 393\nMcBride, P.M. 376\nMcCabe, D.P. 255\nMcCaffrey, T. 586\nMcCarthy, R. 444\nMcClain, R. 398, 536, 537, 543\nMcClelland, J.L. 5, 29, 417, 420,\n421–422, 424, 437, 437f, 438, 443,\n457, 528\nMcCormick, C. 339, 340, 358, 610\nMcCright, A.M. 695\nMcCrudden, M.T. 697\nMcDaniel, M.A. 375, 376, 382, 383f,\n384, 385f, 503\nMcDermott, J.H. 179, 183, 648\nMcDermott, K.B. 346\nMcDermott, R. 648\nMcDonald, J.L. 522\nMcDonnell, V. 436\nMcDowell, M. 631, 632\nMcEachrane, M. 723\nMcFall, T.A. 646\nMcGaugh, J.L. 293\nMcGlone, M.S. 481\nMcGregor, S.J. 603, 604\nMcGugin, R.W. 123\nMcIntosh, R.D. 56\nMcKeeff, T.J. 123\nMcKeefry, D.J. 51\nMcKone, E. 117, 122–123\nMcKoon, G. 491, 493, 494\nMcLaughlin, K. 606\nMcLeod, P. 87–88, 90, 212, 216\nMcMillan, B.D. 488\nMcMullen, P.A. 109\nMcNally, R.J. 285\nMcNamara, D.S. 498, 504, 507, 510\nMcNeil, M.R. 537\nMcNerney, M.W. 508, 510\nMcQueen, J.M. 423, 424, 426\nMcRae, K. 730\nMcVay, J.C. 256\nMeador, K.J. 794\nMedimorec, S. 552\nMeehan, T.P. 194\nMegreya, A.M. 365f, 371\nMeiser, T. 7\nMelara, R.D. 173–174, 174f\nMelby-Lervag, A. 435\nMelinger, A. 533\nMelloni, L. 54, 89, 90, 786, 787, 787f\nMello-Thoms, C. 607\nMelnikoff, D.E. 229, 639, 640, 690\nMelo, M. 607–608, 608f\nMély, D.A. 100\nMemon, A. 374\nMeng, M. 475\nMenneer, T. 202\nMennin, D.S. 729\nMercer, T. 283\nMercier, H. 694–695, 697, 707\nMesgarani, N. 182\nMessina, I. 729\nMesulam, M.M. 322\nMetcalfe, J. 578, 737\nMetzner, P. 478\nMeyer, A.S. 533\nMeyer, B.T. 182, 543\nMeyer, D.E. 439\nMeyer, K.N. 194\nMickes, L. 310\nMigo, E.M. 306\nMilivojevic, B. 109–110\nMilkowski, M. 33\nMiller, G.A. 4\nMiller, J. 223, 225, 317, 318\nMills, W.P.C. 108\nMilner, A.D. 53, 55, 56–57, 56f, 59, 61,\n63–64, 63f, 91, 103–104, 141, 144,\n152, 153, 155, 297\nMinervino, R.A. 595\nMiozzo, M. 514–515\nMirković, J. 522\nMirman, D. 438\nMischel, W. 7\nMisra, M. 282\nMitchell, A.S. 298\nMitchell, D.B. 280\nMitchell, D.C. 470\nMitchell, D.J. 131\nMitroff, S.R. 201, 201f\nMittelstädt, V. 223\nMitterer, H. 407, 408\nMitton, J.L. 525\nMiyake, A. 5–6, 257, 258–259, 259–260,\n259f, 260, 261, 262\nMogensen, J. 85\nMohamed, T. 471\nMoisala, M. 213\nMojardin, A.H. 309\nMole, C.D. 147, 148, 149\nMolenberghs, P. 197\nMomma, S. 468–469\nMonahan, P.J. 405, 418\nMonin, B. 629\nMonti, M.M. 690, 778\nMoore, A.T. 435, 509\nMoore, J.W. 773\nMoore, R. 394\nMoore-Berg, S. 113\nMoors, A. 228, 229–231, 229f, 233,\n570, 769\nMoors, P. 570, 769\nMorawetz, C. 185\nMoray, N. 180\nMorcom, A.M. 370\nMorewedge, C.K. 638, 640\nMorey, C.C. 250, 254\nMorgan, C.A. 369\nMorgan, P.H. 592\nMorgenstern, O. 641, 753\nMoro, V. 136\nMorris, C.D. 263, 264, 287, 410\nMorrison, R.G. 597\nMorrone, M.C. 86f\nMoscovitch, M. 118–119, 304, 305f,\n339, 340, 376\nMoser, J.S. 495, 758–759\nMosing, M.A. 616\nMoss, J. 581\nMost, S.B. 173\nMotley, M.T. 521\nMotta, M. 251, 705\nMottaghy, F.M. 251\nMöttönen, R. 418–419\nMoulton, P.L. 291\nMoulton, S.T. 131\nMousikou, P. 446–447\nMoxley, J.H. 603–604, 603f\nMoyes, J. 384\nMozuraitis, M. 487\nMueller, K.D. 518\nMueller, K.L. 397\nMueller, S. 558\nMüller, N.G. 184\nMunding, D. 534, 534f\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n925\nMurphy, C. 320\nMurphy, G. 191\nMurphy, G.L. 27\nMurray, J.D. 494\nMurty, V.P. 735\nMusel, B. 104\nMustanski, B. 749\nMuter, P. 288\nMyers, J.L. 504, 505–506, 506f\nNaccache, L. 87, 90, 768\nNachar, R.A. 97\nNairne, J.S. 237, 290, 300\nNakayama, K. 155\nNamdar, G. 153\nNardo, D. 538\nNascimento, S.M.C. 68–69, 70\nNaselaris, T. 133\nNation, K. 413–414, 414f\nNavarrete, G. 667\nNavarro, D.J. 669\nNavarro-Torres, C. 535\nNavon, D. 95, 95f, 223\nNee, D.E. 261\nNeely, J.H. 439, 440f\nNeghavi, H.R. 778–779\nNeisser, U. 344, 345\nNelson, K.E. 479\nNelson, L.D. 36, 414f, 479\nNeumann, M.F. 370\nNewell, A. 588, 588–589, 591, 593\nNewell, B. 647, 648–649\nNewell, B.R. 636, 637\nNewman, I.R. 639–640, 686–687, 688,\n704–705\nNewman-Toker, D.E. 655\nNewsome, M.R. 682\nNewstead, S.E. 682\nNguyen, K. 503\nNicolle, A. 651\nNiebergall, R. 185\nNiendam, T.A. 260, 260f\nNieuwenstein, M.R. 662, 663\nNieuwland, M.S. 427, 440, 441, 477,\n493\nNijboer, M. 217, 218, 219, 220f\nNisbett, R.E. 769\nNitsche, M.A. 22\nNitschke, K. 591\nNodine, C. 607\nNodine, C.F. 606\nNooteboom, S.G. 523, 525, 528\nNørby, S. 278–279\nNordgren, L.F. 662–663\nNorman, D.A. 33\nNorman, E. 269\nNorris, D. 245, 423, 438, 442\nNovick, J. 523\nNowinski, J.L. 378\nNozari, N. 523–524, 524f, 525, 529\nNurullah, A.S. 214\nNusbaum, H.C. 409\nNuttall, H.E. 419\nNuzzo, R. 671\nNyberg, L. 778–779\nNyholm, S. 741–742\nOaksford, M. 677, 693, 694, 698–699,\n705\nOatley, K. 751, 754\nOberauer, K. 246\nO’Brien, E.J. 491, 492, 505–506, 506f,\n508\nO’Brien, G.E. 403\nOchsner, K.N. 718, 718f\nO’Craven, K. 186\nOdinot, G. 370\nO’Donnell, K. 435–436, 438\nOeberst, A. 367\nOh, H. 655, 656\nOhlsson, S. 579\nOkala, B.M. 405\nOlatunji, B.O. 757\nOlguin, A. 182\nOlive, T. 557–558\nOliveri, M. 200\nOlivers, C.N.L. 203, 207–208\nOlkoniemi, H. 480\nÖllinger, M. 579, 582\nOlson, J.A. 773\nOpen Science Collaboration 34, 670\nOphir, E. 213\nOppenheimer, D.M. 629\nOrchard-Mills, E. 210–211\nO’Reilly, R.C. 781\nOrmerod, T.C. 583–584\nOrtega, J. 166\nOrtony, A. 490\nOsiurak, F. 143, 144, 155, 157\nOsman, M. 331\nO’Toole, A.J. 160\nOtworowska, M. 655\nOudman, E. 277, 325, 329\nOver, D.E. 637\nOvergaard, M. 84, 85, 87, 768\nPachur, T. 628, 628f, 636, 645, 648,\n650, 661\nPainter, D.R. 131\nPakhomov, S. 550\nPaller, K.A. 291\nPalmer, J.C. 365, 366\nPalmer, S.E. 101, 115\nPalmeri, T.J. 220\nPalombo, D.J. 349\nPan, S.C. 265, 266, 266f, 268\nPanouilleres, M.T.N. 419\nPapageorgiou, C. 754\nPapagno, C. 248–249\nPapesh, M.H. 125\nPapo, D. 693\nPappas, Z. 142\nParasuraman, R. 52, 159\nParfitt, P.R. 41\nPark, D.C. 35\nParker, E.S. 348\nParker, S.M. 107–108\nParketny, J. 129\nParkinson, B. 720, 723, 724\nParks, C.M. 263\nPashler, H. 184, 185, 185f, 223\nPasserault, J.-M. 557\nPastötter, B. 268, 268f\nPatal, E.Z. 310\nPatihis, L. 346\nPatrick, J. 592\nPatsenko, E.G. 591\nPattamadilok, C. 417\nPatterson, K. 12, 136, 314, 319, 442,\n450\nPatterson, R. 661\nPauker, E. 463, 466\nPaulo, R.M. 375\nPavan, A. 50\nPavlova, M.A. 52\nPayne, B.K. 113\nPayne, J. 657\nPayne, S.J. 590\nPaynter, C.A. 592\nPearson, J. 131–132\nPecher, D. 509\nPeckham, A.D. 757\nPedrazzini, E. 196–197\nPellicano, A. 156\nPeltier, C. 201, 201f\nPenaloza, A.A. 584\nPeng, P. 489\nPenhune, V.B. 275, 275f, 278, 331\nPennycook, G. 638, 640, 688\nPerenin, M.-T. 57\nPeretz, I. 406\nPerfetti, C. 433f\nPerfors, A.F. 669\nPerkins, A.M. 739–740\nPerretti, F. 651–652\nPerry, A. 161\nPerry, C. 27, 32, 446, 661\nPersaud, N. 83–84, 84f, 87–88, 90\nPersuh, M. 173–174, 174f\nPessoa, L. 717\nPeters, M.A.K. 90\nPetris, S. 162, 163\nPetrone, C. 463\nPezdek, K. 250\nPham, M.T. 745–746, 745f\nPhelps, E.A. 350\nPhillips, C. 468–469\nCreated from usyd on 2022-02-18 03:52:37.",
    "926\nAuthor index\nPhillips, J.D. 373\nPhillips, W.J. 759\nPiai, V. 535\nPiantadosi, S.T. 462\nPiazza, M. 318\nPichert, J.W. 374, 500\nPickel, K.L. 369\nPickering, M.J. 401, 517, 543\nPilkington, E. 542\nPilz, K.S. 187, 189\nPinker, S. 768\nPinna, D. 101, 101f\nPinto, J. 158\nPinto, Y. 797, 797f\nPirkner 170\nPirogovsky-Turk, E. 329\nPisella, A. 58\nPisella, L. 57\nPisoni, D.B. 463\nPitcher, D. 128\nPitts, M.A. 173, 174, 790, 791\nPlait, P. 114f\nPlaks, J.E. 651\nPlanton, S. 558–559, 559f\nPlaut, D.C. 12, 27, 29, 442, 447, 448,\n449\nPleskac, T.J. 634\nPlessow, F. 214\nPleydell-Pearce, C.W. 355–356, 359,\n362\nPobric, G. 320\nPoeppel, D. 418\nPohl, R.F. 636\nPoldrack, R.A. 22–23, 24–25, 328, 405\nPolyn, S.M. 310\nPope, D.G. 646\nPope, S.M. 586–587, 703–704\nPopov, V. 19\nPopper, K.R. 667, 670, 671\nPosner, M.I. 184, 191–192\nPost, L. 510\nPostle, B.R. 254\nPothos, E.M. 314\nPotter, M.C. 242, 243f\nPourtois, G. 732\nPower, M. 713\nPozzulo, J.D. 372\nPrado, J. 690–691, 690f, 693\nPrass, M. 314, 314f\nPratte, M.S. 19\nPrebble, S.C. 347\nPrecht, L. 215\nPrincipe, A. 529\nProffitt, D.R. 61\nProvitera, A. 679\nPrull, M.W. 368\nPurcell, J.J. 563\nPurdon, C. 381\nPutnam, A.L. 366, 366f\nPuvvada, K.C. 182\nPyc, M.A. 267, 267f\nPylyshyn, Z.W. 130, 132, 134f, 138\nQian, Z. 467, 475\nQu, W. 730\nQuamme, J.R. 335\nQuené, H. 523, 525, 528\nQuinlan, T. 553, 558\nQuinn, P.C. 101\nQuiroga, R.Q. 17, 29\nRabin, J. 69f\nRabovsky, M. 435, 476\nRace, E. 327\nRączaszek-Leonardi, J. 484\nRadach, R. 451, 456\nRadomsky, A.S. 381\nRadonjić, A. 68\nRadvansky, G.A. 507, 508, 682\nRaghunathan, R. 745–746, 745f\nRagni, M. 677–678, 682–683\nRahnev, D. 77\nRaichle, M.E. 25\nRaizada, R.D.S. 405\nRajaram, S. 306\nRakow, T. 629\nRamsey, L.E. 197\nRamsey, R. 163\nRanganath, C. 297\nRansdell, S. 552, 555\nRao, K.V. 597\nRao, R.P.N. 64\nRaposo, A. 473\nRapp, B. 515, 561, 562\nRashal, E. 102, 103\nRastle, K. 435, 436, 446\nRatcliff, R. 491, 494\nRaven, J. 593, 594f, 595, 597–598, 600\nRawson, K.A. 228, 267, 267f\nRay, C. 731, 732, 733f, 734\nRaymond, L. 695\nRayner, K. 403, 438, 453, 456, 464, 465,\n466, 470\nRead, J.D. 375\nReber, A.S. 269, 270\nReber, P.J. 276, 329\nRecanzone, G.H. 209\nRedelmeier, C. 633\nRedfern, A.S. 128\nReed, M.A. 761\nRees, G. 89, 90\nReeves, A.J. 68\nRegier, T. 400\nRego, S. 644\nReichle, E.D. 454, 455f, 505\nReingold, E.M. 454, 455, 457, 602, 606\nReiss, J.P. 274\nRemez, R.E. 409\nRemington, R.W. 379\nRenkl, A. 266\nRenna, M.E. 729\nRenoult, L. 303, 338, 347\nRens, N. 775\nRensink, R.A. 167, 168, 168f\nResnik, K. 532–533\nReuland, E. 475\nReverberi, C. 691\nReverberi, D.J. 581\nRhys, C.S. 540\nRice, G.E. 319\nRichards, A. 730, 749\nRichards, B.A. 279\nRichler, J.J. 117\nRichter, T. 636\nRickard, T.C. 265, 266, 266f, 268\nRiddoch, M.J. 200\nRiege, A.H. 633, 634\nRientamo, E. 783\nRies, S.K. 535\nRigoli, F. 314\nRiley, J.G.A. 181\nRimmele, U. 350\nRinck, M. 736\nRisko, E.F. 552\nRitchey, M. 734\nRitchie, S.J. 707\nRizio, A.A. 285\nRizzolatti, G. 162\nRobbins, R.A. 116\nRobbins, T. 216–217, 247\nRoberts, J. 154\nRobertson, D.J. 125\nRobertson, I.H. 199\nRobertson, L.C. 105, 188\nRobin, J. 304, 305f, 312\nRobinson, B.L. 183\nRobinson, G.A. 542\nRobison, M.W. 256\nRock, I. 101\nRock, P.B. 152\nRodgers, J.L. 34\nRoediger, H.L. 238, 264–265, 346, 499,\n500\nRoeham, D. 441\nRogers, B. 73\nRogers, T.T. 314\nRohde, H. 423–424\nRohde, M. 75\nRolls, E.T. 108\nRorden, C. 196\nRosch, E. 313–314\nRose, N.S. 262\nRose, S.B. 315\nRosenbaum, R.S. 357\nRosenbloom, P.S. 27, 31\nRosenholtz, R. 65, 167, 170, 172, 206,\n207, 208, 208f, 777\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n927\nRosenthal, G. 117\nRoss, C.T. 113\nRoss, D.A. 117\nRoss, D.F. 370\nRoss, M. 350\nRossetti, Y. 46, 58, 62, 63f, 64\nRossion, B. 117\nRossit, S. 58\nRothkirch, M. 90\nRounis, E. 789\nRoussel, M. 277, 330\nRoux, S. 533\nRowe, M.L. 397\nRowland, C.A. 265, 266–267\nRoy, D.F. 374\nRubin, D.C. 278, 350, 351, 352f, 354,\n607\nRuffieux, N. 158\nRumelhart, D.E. 29, 437, 437f, 443,\n457, 490, 528\nRummel, J. 384, 387, 388\nRusconi, E. 202\nRushton, S.K. 146\nRussell, J.A. 716, 716f\nRustemeier, M. 329\nRusting, C.L. 736\nRuthruff, E. 223\nRyskin, R. 488\nRyu, J. 45\nSabri, M. 190\nSadeh, T. 280–281, 333\nSaenen, L. 576\nSævland, W. 269\nSakreida, K. 62–63, 64, 155, 156, 156f,\n157\nSala, G. 601, 603\nSalem, T. 757\nSalvucci, D.D. 217, 220\nSampson, M. 541, 542\nSamuel, A.G. 424\nSamuelson, W. 651\nSanbonmatsu, D.M. 214, 671\nSanborn, A.N. 701\nSand, K. 437\nSandberg, K. 88\nSandler, W. 396\nSanocki, T. 108\nSantangelo, V. 348–349\nSaposnik, G. 626\nSari, D.A. 763\nSarri, M. 198\nSato, K. 555\nSavage, L.J. 641\nSavelsbergh, G.J.P. 150\nSavitsky, K. 487\nSaygin, A.P. 160\nScalici, F. 308, 309f\nScardamalia, M. 554\nSchacter, D.L. 296, 311–312, 312, 312f,\n326, 327\nSchad, D.J. 455\nSchartau, P.E.S. 721, 721f\nSchatzberg, A.F. 729\nSchechter, E. 793\nSchenk, T. 56\nScherer, K.R. 719\nScherer, L.D. 629\nScherman, A.Z. 354–355\nSchiffer, F. 794\nSchmeichel, B.J. 719\nSchmidt, J.R. 679\nSchmidt, S. 249\nSchmidtmann, G. 108\nSchneider, W. 226–228, 227f, 230, 233\nSchnuerch, R. 173\nScholl, B.J. 112, 113, 114, 164, 174\nScholte, H.S. 783\nSchotter, E.R. 456\nSchouten, D.I. 291\nSchraagen, J.M. 662, 702\nSchröder, E. 209\nSchulkind, M.D. 352f\nSchulz, D.P.A. 96\nSchumacher, E.H. 224–225\nSchvaneveldt, R.W. 439\nSchwabe, L. 293\nSchwaninger, A. 202\nSchwark, J. 202\nSchwartz, B. 656, 704\nSchwartz, B.L. 331\nSchwartz, J. 653\nSchwartz, S. 190\nSchwartz, Z.P. 182\nSchwarz, N. 744\nSchweinberger, S.R. 128, 328\nSchweitzer, M.E. 646\nSchweizer, T.A. 221, 221f\nSchweppe, J. 248\nSchwieren, J. 265\nSchwitzgebel, E. 435, 509\nScott-Phillips, T.C. 394\nScoville, W.B. 297\nScullin, M.K. 379, 382, 383f, 384, 385,\n387, 388, 388f\nScully, I.D. 292\nSearston, R.A. 99\nSebastianelli, L. 794\nSedgwick, H.A. 77\nSegaert, K. 331\nSeidenberg, M.S. 442, 449, 452\nSejnowski, T.J. 17f\nSekeres, M.J. 304\nSenghas, A. 396\nSeo, M.-G. 652\nSeoane, L.F. 462\nSerre, T. 107–108\nSeth, A.K. 767\nSeymour, K. 54\nSeymour, K.J. 54\nShafir, E. 641\nShallice, T. 7, 9, 11, 172, 243, 258\nShamma, S.A. 183\nShanks, D.R. 87, 90, 271, 272, 272f, 278\nSharan, L. 167, 170, 170f, 171\nShare, D.L. 433, 435\nSharma, T. 44\nSharot, T. 349, 350, 734, 735\nSharpe, D. 762\nSharpe, L. 36\nSheffer, L. 653–654, 654f\nShelton, J.R. 560\nShelton, J.T. 379, 382, 383f, 384, 386,\n386f, 387, 388\nShen, W. 179, 579\nSheppes, G. 725\nSheridan, H. 454, 455f, 505, 602, 606\nShevell, S.K. 66, 67\nShifferman, E. 20\nShiffrar, M. 157f, 159, 160\nShiffrin, R.M. 226–228, 227f, 230, 233,\n240, 240f, 241, 242, 243, 244, 296\nShimizu, R.E. 275\nShiota, M.N. 748–749, 748f\nShipstead, Z. 593, 597–598, 598f\nShiv, B. 652\nShomstein, S. 187, 194\nShrem, T. 210\nShrout, P.E. 34\nShulman, G.L. 178, 191–193, 193f,\n194–195, 196, 197, 198–199\nShwartz, B. 656\nSiciliano, R.A. 73\nSides, A. 625\nSidi, Y. 498\nSiebert, M. 735\nSiegel, E.H. 722\nSiegert, R. 277\nSigurdardottir, H.M. 452\nSilbert, L.J. 418, 516, 517f\nSilvanto, J. 254\nSimion, F. 158\nSimmons, J.P. 34\nSimmons, S.M. 215\nSimon, D. 658\nSimon, H.A. 241, 584, 588–589, 591,\n593, 602, 660, 702, 707\nSimon, J.Z. 182\nSimoncelli, E.P. 777, 777f\nSimons, D.J. 172, 172f, 173, 310, 363\nSimonson, I. 644, 653\nSinai, M.J. 73\nSinger, W. 54\nSingmann, H. 674, 675\nSinigaglia, C. 162, 163\nSio, U.N. 583–584\nSitek, E.J. 557\nCreated from usyd on 2022-02-18 03:52:37.",
    "928\nAuthor index\nSkinner, B.F. 393\nSkinner, E.I. 307, 336\nSkipper, J.I. 418, 419–420\nSlater, J. 404\nSlevc, L.R. 405, 431\nSlezak, P. 134, 134f\nSliwinska, M.W. 128, 436\nSloman, S. 634\nSmall, D.A. 748\nSmallwood, J. 768\nSmeets, J.B.J. 77\nSmith, C.A. 720\nSmith, C.N. 263, 298, 308\nSmith, E.E. 249\nSmith, E.R. 508\nSmith, R. 286, 719, 720f\nSmith, R.E. 263\nSmith, T.J. 166, 170\nSnell, J. 438, 453, 457\nSnider, N.E. 547\nSnyder, J.J. 146\nSnyder, K.M. 270–271, 270f, 277f\nSohoglu, E. 416\nSokol-Hessner, P. 652\nSokolov, A.A. 159f\nSolé, R.V. 462\nSöllner, A. 636\nSolomon, S.H. 482, 482f\nSong, J.-H. 155\nSoni, M. 538–539\nSörqvist, P. 191, 256\nSotiropoulos, A. 444, 445, 560, 562\nSoto, D. 254\nSoto-Faraco, S. 411\nSoukup, G.R. 128\nSowden, S. 771\nSpaar, M. 661\nSpanel, K. 350\nSpäth, P. 636\nSpelke, E.S. 212\nSpence, C. 209, 210, 211\nSpence, J.R. 34\nSperber, D. 677\nSperling, G. 776, 777, 790\nSperry, L.L. 498\nSperry, R.W. 793, 794\nSpiers, H.J. 243, 246, 301, 329, 333\nSpiers, M.V. 296\nSpille, C. 182\nSporns, O. 8, 14, 14f\nSquire, L.R. 245, 290, 291, 299, 331\nSt. Jacques, P.L. 360, 360f\nSt. James, J.D. 184, 731\nSt. John, M.F. 271\nStafura, J. 433f\nStagg, C.J. 22\nStamenković, D. 480\nStanford Encylopedia of Philosophy 593\nStange, J.P. 361\nStanley, D.J. 34\nStanley, T.D. 34\nStanovich, K.E. 592, 683–684, 685,\n686, 696–697, 698, 703, 704, 705–706,\n706f, 707, 708\nStaub, A. 440\nStaudigl, T. 288\nStaugaard, S.R. 358, 359\nStaw, B.M. 644, 653\nSteblay, N.K. 364, 370, 373\nSteblay, N.M. 373\nSteele, C.J. 275, 275f, 278, 331\nSteiger, A. 643\nSteinborn, M.B. 217\nSteinhauer, K. 463\nSteinmetz, K.R.M. 733\nStephens, R.G. 666–667\nStephenson, G.M. 500\nSternberg, R.J. 703\nStevens, K. 418\nStewart, A. 657\nStivers, T. 517\nSt-Laurent, M. 304\nStorm, J.F. 780\nStrayer, D.L. 214, 215\nStrick, M. 662\nStrobach, T. 221, 222, 224–225, 224f\nStrong, S.L. 145, 198\nStroud, J.N. 370\nStuder, B. 652\nStupple, E.J.N. 679\nStuss, D.T. 251, 260–261\nSulin, R.A. 500\nSummerfield, C. 77\nSuri, G. 724, 730\nSurloff, C. 557\nSuter, R.S. 649, 650, 650f\nSutter, M.L. 209\nSvoboda, E. 359\nSweller, J. 589\nSwets, B. 508, 520\nSylark, W.J. 629\nSylvester, C.M. 195, 195f\nSzabó, S. 242\nSzczepanski, S. 590, 591\nTaatgen, N.A. 26, 32, 33, 217, 218f,\n219, 220\nTadmor, Y. 144\nTajadura-Jiménez, A. 81\nTalarico, J.M. 350, 733\nTambini, A. 734\nTamietto, M. 86f, 722\nTanaka, J.W. 314\nTang, D. 719\nTangen, J.M. 98, 579\nTanguay, A.N. 303\nTanovic, E. 760\nTarenskeen, S. 544, 544f\nTarr, M.J. 109, 110, 111\nTassy, S. 739\nTaubman-Ben-Ari, O. 749\nTaylor, C.T. 761\nTaylor, J.A. 274\nTaylor, M.E. 314\nTaylor, T. 215\nTecher, F. 748\nTellegen, A. 716, 716f\nTenenbaum, J.B. 626–627, 627f, 631\nTentori, K. 625, 626\nTerras, M. 494\nTerzi, A. 648\nTetlock, P.E. 653, 664, 703, 707\nThagard, P. 695\nThakral, P.P. 336\nTheeuwes, J. 188\nThibaut, M. 207\nThomas, B.C. 739\nThomas, C. 584\nThomas, J.P. 157f, 159, 160\nThomas, K. 749\nThomas, L.E. 583\nThompson, J. 52, 159\nThompson, M.B. 98\nThompson, R.A. 724, 725f\nThompson, V.A. 589, 590, 638, 640,\n677, 679, 684, 687, 687f, 688, 689,\n689f, 708\nThompson, W.L. 23, 132f, 133\nThompson-Schill, S.L. 482, 482f\nThomsen, D.K. 356, 359\nThomson, J.A. 751\nThornton, T.L. 203, 207\nThorpe, S. 44\nTiedens, L.Z. 747, 751\nTiegen, K.H. 633, 634\nTierney, A. 405\nTijtgat, P. 151\nTindle, R. 551, 555–556\nTinkelenberg, C.E. 660\nToba, M.N. 198, 199–200\nTodorović, D. 72f\nToffolo, M.B.J. 380–381\nToglia, M.P. 237\nToli, A. 773\nTollestrup, P.A. 372\nTolman, E.C. 3\nTong, F. 19\nTononi, G. 11\nToplak, M.E. 593, 705, 707\nToppino, T.C. 113\nTrabasso, T. 498\nTranel, D. 329\nTrapp, S. 108, 115\nTravaglia, A. 352\nTravers, E. 593\nTraxler, M.J. 462, 464\nTreffers, T. 749\nCreated from usyd on 2022-02-18 03:52:37.",
    "Author index\n929\nTreiman, R. 561, 562\nTreisman, A.M. 180–181, 181f, 202,\n203, 203f, 206, 212, 216\nTremblay, P. 537\nTrench, M. 596\nTresilian, J.R. 149\nTressoldi, P.E. 24\nTriesch, J. 76\nTrigg, D. 773\nTrippas, D. 684, 686, 687, 691, 704–705\nTroiani, V. 790\nTrouche, E. 698\nTrout, J.D. 404\nTroy, A.S. 726, 727f\nTsano, S.H. 44\nTsarfaty, R. 462\nTs’o, D.Y. 54\nTsuchiya, N. 790\nTsujii, T. 691, 692f\nTubau, E. 576\nTucker-Drob, E.M. 618\nTuckey, M.R. 364\nTullett, A.M. 249\nTulving, E. 262, 287, 287f, 289–290,\n296, 300–301, 302, 374, 736\nTurano, M.T. 125\nTurner, R. 20\nTustin, K. 353\nTversky, A. 623, 624, 627, 630, 633,\n637, 638, 641, 642, 642f, 657\nTwedt, E. 41\nTweney, R.D. 668\nTyler, C.W. 72, 77\nTyler, L.K. 398, 417, 425, 429\nTyszka, J.M. 792\nTzourio-Mazoyer, N. 9\nUchino, B.N. 671\nUcros, C.G. 736–737\nUddén, J. 540\nUddin, L.Q. 792, 794\nUddin, S. 419–420, 420f, 423, 424\nUeno, T. 449\nUlicheva, A. 452\nUllén, F. 610, 611, 617, 617f, 618\nUncapher, M.R. 213\nUnsworth, N. 256, 256f, 257, 283, 488\nUrbanski, M. 600, 691\nUttal, W.R. 24\nVadillo, M.A. 271–272\nVahdat, S. 292\nVaina, L.M. 52, 159\nValentine, T. 370\nValero-Cabré, A. 22\nVallée-Tourangeau, F. 584\nvan Atteveldt, N. 212\nVan Belle, G. 120\nvan Berkum, J.J.A. 415, 477, 493\nVan Bockstaele, B. 758\nvan den Berg, A.V. 146\nvan den Bos, K 772\nVan den Brink, D. 477, 497\nvan den Broek 492, 492f, 494, 495,\n497–498\nVan den Hout, M. 380\nvan der Hoort, B. 80, 81, 81f\nvan der Schuur, W.A. 213\nVan der Steen, S. 557, 558\nvan der Weiden, A. 772\nVan Dyke, J.A. 490\nVan Essen, D.C. 44, 46, 95\nvan Gaal, S. 111, 789\nvan Gompel, R.P.G. 470, 471, 471f,\n546\nvan Harreveld, F. 602, 604\nvan Kesteren, M.T.R. 501\nvan Oostendorp, U. 510\nvan Orden, G.C. 435\nvan Petten, C. 427, 440\nvan Polanen, V. 61\nvan Turennout, M. 531\nvan Velzen, M.H. 550\nVandenbroucke, A.R.E. 70\nVanlancker-Sidtis, D. 794\nVanlessen, N. 732\nVannuscorps, G. 160, 318\nVaquero, L. 612\nVarakin, D.A. 171\nVargha-Khadem, F. 301\nVasilev, M.R. 454, 456\nVasishth, S. 472\nVázquez, G.A. 274\nVendetti, M.S. 596, 597\nVergauwe, E. 242, 244, 250\nVerleger, R. 795\nVerschueren, N. 576, 674, 675, 689\nVerstynen, T. 276, 276f, 333, 338\nVesia, M. 57, 57f\nVetter, P. 51\nVidal-Pineiro, D. 297\nViggiano, M.P. 112\nVighetto, A. 57\nVigliocco, G. 532\nVirtue, S. 492\nVisted, E. 729\nViviani, R. 719\nVõ, M.L.-H. 205\nVolden, J. 479\nVolz, L.J. 793, 798\nvon der Heydt, R. 101\nVon Neumann, J. 641, 753\nvon Sydow, M. 630, 636, 637\nVoss, J.L. 337, 337f, 340\nVossel, S. 194\nVousden, J.I. 530\nVranić, A. 347\nVuilleumier, P 198\nWachtel, P.L. 6\nWaechter, R. 691, 693\nWagemans, J. 97–98, 99, 100, 103\nWagman, J.B. 586\nWagner, A.D. 20, 213\nWagner, V. 520\nWagoner, B. 501\nWaldum, E.R. 376\nWalker, B.S. 405\nWallas, G. 583\nWallis, G. 122\nWallisch, P. 69, 69f\nWalsh, J.J. 1, 495, 758\nWalter, S. 186\nWalton, D. 694, 700\nWang, M. 654\nWang, P. 119, 122\nWang, S. 141\nWang, X.T. 575, 575f, 643\nWang, Y. 727\nWann, J.P. 146–147, 147f\nWanzek, J. 554\nWard, E.J. 164, 174\nWard, J. 14, 96\nWaris, O. 261\nWarren, D.E. 323\nWarren, D.H. 210\nWarren, R.M. 414\nWarren, R.P. 414\nWarren, W.H. 151\nWarrington, E.K. 7, 243, 444\nWatanabe, K. 222\nWatanabe, S. 691, 692f\nWaters, A.J. 601\nWaters, E.A. 745, 747\nWaters, F. 130\nWatkins, E. 754\nWatson, D. 716, 716f, 745, 746, 755\nWatson, J.B. 3, 714\nWatson, T.L. 116\nWatt, C.A. 36, 672\nWebb, M.E. 171, 578\nWebb, T.L. 726\nWebb, T.W. 784, 785f, 791\nWeber, A. 427, 428f\nWebster, G.A. 671\nWebster, M.A. 71\nWebster, R.J. 97, 108\nWegner, D.M. 772, 773\nWeibert, K. 110\nWeidema, J.L. 405\nWeiller, C. 431\nWeiner, B. 747\nWeingarten, E. 769\nWeinrich, M. 560\nWeisberg, R.W. 581\nWeiskrantz, L. 82, 83\nWeiss, N. 117, 120\nWelch, R.B. 210\nCreated from usyd on 2022-02-18 03:52:37.",
    "930\nAuthor index\nWeller, J.A. 652\nWells, G.L. 364f, 370, 373\nWen, T. 222\nWen, X. 194\nWenger, M.J. 128\nWenzel, A.E. 278\nWerner-Seidler, A. 362–363, 362f\nWessel, J.R. 274, 278\nWest, R.F. 696–697, 698\nWestfall, J. 33\nWheatley, T. 772\nWhite, D. 124–125\nWhite, K.G. 644\nWhiteford, A.P. 549, 554–555\nWhitney, D. 172\nWhitwell, R.L. 59\nWhorf, B.L. 398–399\nWhyte, E.M. 479\nWicherts, J.M. 672\nWickens, C.D. 215, 216, 216f, 218\nWiebe, D. 578\nWieber, F. 773\nWiese, H. 370\nWiesel, T.N. 96\nWieth, M. 576\nWig, G.S. 327\nWild, C. 23, 416, 429\nWiley, J. 480, 483, 578\nWilf, M. 142, 143f\nWilkie, R.M. 146–147, 147f\nWilkin, K. 548\nWilkins, N.J. 228\nWilkinson, L. 272, 272f, 277\nWillems, S. 309, 309f\nWilliams, C.R. 505, 506\nWilliams, J.H.G. 161\nWilliams, J.M.G. 755, 759\nWilliford, J.R. 101\nWilmer, J.B. 125, 130\nWilson, M.D. 379–380, 379f\nWilson, M.P. 469\nWilson, T.D. 769\nWinawer, J. 51, 399, 400\nWindmann, S. 412\nWiner, E.S. 757\nWing, E.A. 288\nWinkielman, P. 722\nWinlove, C.I.P. 133\nWischgoll, A. 555\nWithagen, R. 142\nWitthoft, N. 51\nWixted, J.T. 290, 291, 364, 364f, 370,\n373\nWoike, B. 358\nWolfe, J.M. 204, 205, 205f\nWolff, P. 400, 481, 482, 483f\nWon, E.J.S. 658\nWong, C.K. 375\nWoodberry, C. 96, 111, 112f\nWoods, K.J.P. 183\nWoollams, A.M. 450, 452\nWoollett, K. 610\nWorkman, R.A. 376\nWright, D.B. 368, 370\nWright, O. 399\nWroe, A.L. 651\nWu, L.L. 317\nWulff, D.U. 646, 648\nWurm, M.F. 162–163\nWutzler, A. 530\nWynn, V.E. 501\nXie, Y. 654\nXu, Y. 400\nXuebing, L. 727\nYacoub, R. 131\nYang, T.-x. 380\nYardley, H. 111, 114, 115f\nYarkoni, T. 8, 22–23, 24, 33\nYe, L. 585\nYechiam, E. 644, 645, 648\nYegiyan, N.S. 369\nYeung, K.L. 265\nYiend, J. 755–756\nYilmaz, E.H. 151\nYip, J.A. 744\nYockelson, M.B. 368\nYonelinas, A.P. 734, 735\nYoon, J.-S. 614\nYoon, S.O. 547\nYoung, A. 125, 125f, 127, 128, 129,\n130, 138\nYoung, A.H. 207\nYoung, A.W. 123, 127, 128, 129, 370,\n430, 430f, 431, 515\nYovel, G. 121, 121f, 160\nYurgil, K.A. 256\nZachariou, V. 62\nZacks, J.M. 507, 508, 509\nZahn, R. 324\nZalla, T. 479\nZander, T. 578\nZatorre, R.J. 609, 611\nZeckhauser, R.J. 651\nZeidman, P. 610\nZeki, S. 48–50, 49f, 51, 54, 55, 83,\n91\nZelinsky, G.J. 189\nZeman, A. 130\nZetsche, U. 760\nZevin, J.D. 452\nZhang, H. 543\nZhang, T.R. 730, 748\nZhang, X. 424\nZhao, Z. 250, 250f\nZhuang, J. 429\nZiegler, J.C. 33\nZihl, J. 50, 51\nZimmer, H.D. 250\nZimmermann, F.G.S. 110\nZogg, J.B. 377, 378f\nZwaan, R.A. 507–508, 508, 508–509,\n509, 510\nZwitserlood, P. 427\nCreated from usyd on 2022-02-18 03:52:37.",
    "Subject index\nSubject index\nNote: Page numbers pointing to figures are set in italics and or tables in bold.\n2½-D sketch, object recognition 106\n3-D model representation, object\nrecognition 106\n9/11 World Trade Centre attack,\nflashbulb memory 349–350, 349\naccess consciousness 768, 776, 781, 784;\nsee also phenomenal consciousness\naccommodation, depth cues 74–75\nachromatopsia 50–51\nacoustic cues 410\naction: automaticity 227, 228–229, 231;\ncontrol 771–775, 774; perception 161\nad hominem fallacy 695, 701\nAdaptive Control of Thought-Rational\n(ACT-R) 30–32, 31\nadditivity, cue combination 75, 76\naffect 716, 716; and cognition 730–734;\njudgement, decision making 650, 650,\n738–750; mood congruity, memory\n736; see also emotion and cognition\naffect heuristic, reasoning 628, 628\naffective blindsight 722\naffordances 141, 142–144, 143, 151,\n154\nafterimages, colour vision 65–66\nageing, and memory 369–370\nagentic personality type 358\nagrammatism, speech production\n539–541, 540\nagraphia, dysexecutive 557\nairport security checks, visual search\n201–202, 202\nakinetopsia 51\nalcohol, influence on memory 291, 297\nalgorithm, in computational cognitive\nscience 3, 589\nalgorithm language processing 473–474,\n473, 475\nalgorithmic mind 706, 706\nallocentric coding, visual perception 56;\nsee also egocentric coding\nallocentric neglect, visual perception\n196–197\nallophones 407–408, 410–411; see also\nphonemes\nAlzheimer’s disease 518, 550, 561\nambiguity: ambiguous sentences\n462–463, 465–467, 469, 471, 471,\n474, 758; ambiguous phoneme,\nGanong effect 415, 422–423, 424;\ndepth perception cues 71, 75;\ninterpretive bias 721; object/pattern\nrecognition 100, 111, 112, 141;\nreal-world example: anxiety and\ninference drawing 495; real-world\nexample: “The dress” colour illusion\n69; schema interference 364; see also\ninferences; parsing\namblyopia (lazy eye) 74\nAmes room 79–80, 79\namnesia 296–299, 298; causes 127,\n296–297; developmental 301; episodic\nmemory 301; infantile/childhood\n351–353; Korsakoff’s syndrome\n296–298, 325; prosopagnosia, person-\nspecific 118–121, 120, 127, 128–129;\nreal-world example: patient HM\n(Henry Gustav Molaison) 297, 297;\nretrograde 290, 292, 298, 302, 357;\nsemantic dementia 303, 304, 319–320,\n323–324, 324\namygdala: appraisal theories 720,\n722–723, 727–728, 728, 729;\nattention and memory 734–736,\n735; autobiographical memory\n349–350, 351, 359, 367; cognition and\nemotions 717, 718–719; conscious\nawareness 198; decision making 652;\nglobal workspace theories 790\nanalogical problem solving/reasoning\n593–600, 593–601; brain areas\n599–600, 599; fluid intelligence\nadvantage 593, 595, 597, 597–598;\nfour-term analogy problems 596;\nproblem similarities: superficial,\nstructural, procedural 594–595;\nsequential processing stages\n(encoding, inferring, mapping,\napplying) 596–597, 597, 600\nanaphor/anaphor resolution 493\nanarchic-hand syndrome 795\nanatomical modularity 8, 12; see also\ncognitive neuropsychology\nanchoring-and-adjustment heuristic 630\nanger 720–721, 747–748, 751, 752; see\nalso emotion and cognition\nanomia, speech production 319,\n537–539\nanterograde amnesia 298\nanti-cascade task, task-impurity\nproblem 5\nanticipatory errors, spreading-\nactivation theory 528, 529\nAnton’s syndrome 131\nanxiety: attention 731, 732; and\ncognition 744–745, 745, 750, 752;\nand cognitive bias 753–755, 757,\n758, 759, 761; eyewitness testimony\n(weapon/violence focus) 368–369,\n374; generalised anxiety disorder 758;\nobsessive-compulsive disorder (OCD)\n380–381, 381; real world example:\nreducing anxiety and depression 762;\nreal-world example: anxiety and\ninference drawing 495; real-world\nexample: emotion regulation and\nmental disorders 729; trait anxiety\n753, 758, 760; see also emotion and\ncognition\naphasia 536–537; agrammatic aphasia\n539; Broca’s aphasia 536–537, 536;\njargon aphasia 541–543; transcortical\nsensory aphasia 432; Wernicke’s\naphasia 536–537; see also\nanomia\nCreated from usyd on 2022-02-18 03:53:17.",
    "932\nSubject index\nappraisal: affective blindsight 722;\nappraisal-tendency framework\n751–752; automatic/deliberate,\ncontrolled 719; conscious appraisal\nand emotions 720–722, 721; emotion\ngeneration 719, 720; non-conscious\nemotional processing 722–723;\ntheories 719–723\napraxia 161–162; limb apraxia 156–157\nargumentative theory 697–698; see also\ninformal reasoning\narticulatory similarity, phonological\nloop 248\narticulatory suppression 242, 247, 248,\n249, 557; see also phonological loop\nartificial intelligence 41; vs\ncomputational modelling 26–27, 27;\nGeneral Problem Solver (Newell and\nSimon) 588\nAsperger’s syndrome 479; see also\nautism spectrum disorder\nattention: active/passive (top-down/\nbottom-up) 178; affect and cognition\n730–734, 733; automatic processing\n226–231; cognitive bottleneck\n180, 181, 222–226, 224, 535; and\nconsciousness (selective attention)\n790–791; covert 165, 167, 170, 192,\n455; cross-modal 208–209; defined\n178; divided/focuses (see divided\nattention; focused auditory attention;\nfocused visual attention); external/\ninternal 178; feature-based 186,\n188–189; space-/object-based\nattention 186–187, 187, 188, 189\nattentional bias 753, 755–758, 757,\n760, 761, 762–763, 763; cognitive,\nattention control 760–761, 761;\nreal world example: cognitive bias\nmodification 762\naudience design 544–547, 546\nauditory analysis system, speech\nperception 430–431, 430\nauditory input lexicon 430, 430, 431\nautism spectrum disorder 160, 479, 705\nautobiographical memory 346–351;\ndirect (cue-triggered) retrieval 356,\n358–359, 360; emotional, involved\nbrain networks 360, 360; emotional,\ninvolved brain networks 360, 360;\nand episodic memory 346–347, 347;\nepisodic/semantic autobiographical\nmemory 347; flashbulb memories\n349–351, 734; functions of 347;\ngenerative (goal-based) retrieval 356,\n358–359, 360, 360; knowledge base\nand working self 355–357, 357, 358;\nmemory bias 759; and mood 734–736;\nreal-world example: depression and\nautobiographical memory  361–363,\n361, 363; real-world example: highly\nsuperior autobiographical memory\n348–349, 348; theoretical approaches\n(see autobiographical memory,\ntheoretical approaches)\nautobiographical memory knowledge\nbase, self-memory system model\n355–357, 357, 358\nautobiographical memory, theoretical\napproaches 355–363; cognitive\nneuroscience 359–363, 360; self-\nmemory system model 355–359, 357,\n358\nautomatic processing: automaticity\nof action 228–229; controlled\nvs automatic process 226–228;\ndecompositional approach 229–231,\n229; traditional approach: controlled\nvs automatic process 227\nautomaticity of action 227, 228–229, 231\nautostereogram 74\navailability heuristic, judgement\n628–629, 628, 629–630, 630, 633\nback-propagation 28, 29–30\nbackward crosstalk effect 225–226\nbackward masking 781–782, 783\nbase rate: benign cyst scenario, task\n625–627, 627; dual-process theory\n639, 640; heeding 626–628; natural\nfrequency hypothesis 631, 632;\nneglect, science research/medical\npractice 624–628, 627, 638; syllogistic\nreasoning 679, 679\nBayes, Thomas 623\nBayesian inference theorem, judgement\n102, 623–624\nbehaviourism 3, 37, 714; see also\ncognitive psychology\nbelief bias 678–679, 679, 684–685, 686,\n687, 691, 695\nbiased stimuli competition hypothesis\n199, 200\nBiederman, Irving, recognition-by-\ncomponents theory 106–109, 107, 108\nbinding problem 54–55\nbinding-by synchrony hypothesis,\nbinding problem 54\nbinocular cues, depth perception 71,\n74–75\nbinocular disparity 52, 74, 76–77, 146,\n150–151; see also stereopsis\nbinocular rivalry 132, 780, 781\nblindness: blindness denial (Anton’s\nsyndrome) 131; change blindness\n164–167, 169, 170, 171–172, 777;\ncolour blindness 44; face blindness\n(prosopagnosia) 118–121, 120, 127,\n128–129; inattentional blindness 164,\n165–166, 172–174, 172, 174\nblindsight 82–87, 86; affective blindsight\n722; brain damage, reorganisation\n85–86; vs degraded conscious vision\n84–85; evidence 83–84; experience\n83; forced-choice test 82; real-world\nexample: patient DB 82, 83–84, 84\n“blobology” approach, neuroscience 24\nblue-yellow deficiency, visual perception\n66\nblur, depth perception cue 73\nbodily self-consciousness 769\nbody size effect 80–81, 81\nBOLD (blood oxygen- level-dependent\ncontrast) 19, 20; see also functional\nmagnetic resonance imaging (fMRI)\nBonini’s paradox 33\nbonobo ape, language acquisition\n393–394\nBorges, Jorge Luis 279\nbottom-up processing: (visual) word\nrecognition 437, 437, 438; attention\n193, 197, 198; defined 4; emotional\nexperience 718–719, 718, 735–736,\n735; human-motion perception\n158–159; information processing\napproach 4; memory/retrieval 382,\n383, 384, 385, 386; object recognition\n111, 114, 115, 115, 116; pattern\nrecognition 96; speech perception\n408, 409, 417, 420–421, 421, 425–426;\nvisual perception 132, 135–136, 135\nbounded rationality 660, 702, 707\nbrain: activity studies: cognitive\nneuroscience, research techniques\n15–26, 16; integrated brain\nfunctioning 787–788\nbrain, organisation/anatomy (for\ntopic-specific involved brain areas/\nparts: see chapter subheadings\n“Brain mechanisms”, Findings”,\n“Evaluation”): brain areas 13–14;\nbrain locations, terms (dorsal/\nsuperior, ventral/inferior, anterior/\nrostral, posterior, lateral, medial) 13;\nconnectome 14; default mode network\n25, 195; grooves/sulci (sulcus) 13;\nhemispheres 13; lobes 13–14, 13;\nridges/gyri (gyrus) 13, 13, 563\nbrain, visual cortex; see visual cortex\nbrain areas/mechanism, involvement\nin cognitive functions: action,\nvisually guided 156, 156; analogical\nproblem solving 599–600, 599;\nbrain, organisation/anatomy 13–14;\nBrodmann brain areas 13–14, 13,\n24, 322, 739; consciousness 788–790;\ndecision making, social/emotional\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n933\nfactors 352; deductive reasoning\n690–693, 690, 692; emotions,\nemotional regulation 717–718, 717,\n727–728, 728; episodic memory\n306–308, 307, 337–338, 337; explicit\nlearning 274–276, 278; implicit\nlearning 274–276, 274, 275, 276, 278;\nlong-term memory and emotions\n734–735, 735; major attention\nnetworks 192–193, 193, 195, 195;\nmemory systems/processes 337–338,\n337; motion perception 159, 159;\nperception without awareness,\nsubliminal perception 87–89, 89;\nplanning-control model, visually\nguided action 153; pragmatics,\nlanguage comprehension (figurative/\nliteral processing) 478; priming\n337–338; reasoning, analogical\n690–693, 692; recognition memory\n306–310, 309; risk (financial decision\nmaking) 652; speech perception\n405–406; spelling, writing and\nreading 562–563, 563; visual\npathways/processing 46–48, 48\nbrain damage/brain-damaged patients:\namnesia 296–299, 312; attention\nand performance 194, 196, 197;\ncentral-executive 251; cognitive\nneuropsychology 7–9, 12, 22, 32, 35;\nconsciousness 778–779, 782–783,\n787, 788, 789, 792; decision making/\nproblem solving 574, 581, 599, 652,\n742; declarative (explicit) memory\n301–302; episodic memory 307, 308;\nface/object-recognition 118–119, 136;\nmotion-perception 156–157, 161–162;\nsemantic memory 318, 320–321, 322,\n323, 324; non-declarative (implicit)\nmemory 325, 329, 331, 332; reading\n443–444, 445, 450; short-term vs\nlong-term memory 243; reasoning\n691; speech perception 406, 419,\n429–430; speech production 515, 521,\n525, 536, 537; visual imagery 131;\nvisual perception 50, 57–58, 57, 64,\n85; visuo-spatial sketchpad 250, 251;\nworking memory 257, 258, 260, 261;\nwriting 557, 560, 561, 562\nbrain mechanism: top-down processing\n599, emotion 717\nbrain networks: autobiographical\nmemory, emotional 360, 360; schema\n322–323\nbrain plasticity 12, 35, 299, 609–612,\n794; causality 610–611, 611, 612;\ndefined 609; “The Knowledge,”\nLondon taxi driver test 610; research\nevaluation 611–612\nbreast cancer diagnosis, base rate/\nfrequency sampling 625–627, 627, 632\nbridging (backwards) inferences\n490, 493–494; see also discourse\nprocessing, inferences\nbroad vs instrumental rationality 703,\n704\nBroca’s aphasia 536–537, 536\nBroca’s area 248, 249, 406, 537, 539, 540\nBrodmann, Korbinian 13–14, 13\nBrodmann brain areas 13–14, 13, 24,\n322, 739\nCAPTCHA 97, 97\nCarlsen, Magnus 613–614, 613\ncascade processing 4–5, 443, 444\ncategorical perception, speech\nperception 399, 405, 415\ncategorisation 109, 111, 314, 315\ncategory-specific deficits 320–321\ncentral coherence 479\ncentral executive 246–247, 246, 251,\n254, 255, 556–557, 556; dysexecutive\nsyndrome 251, 260, 277, 557; episodic\nbuffer and 252–253; language\nproduction 553; see also working\nmemory component\nchange blindness 163–174; attentional\napproach (target fixation) 168, 168,\n169, 169; causes 167–171, 168, 169,\n170; defined 164; vs inattentional\nblindness 164–167; peripheral\nvision approach 170–171, 170;\nreal-world example: inattentional\nblindness and magicians 166–167,\n166; serial dependence 172; token\nand type changes 168, 168, 169;\nvisual processing and 167; see also\ninattentional blindness\nchange blindness 164, 164\nChaplin, Charlie 160\nCharles Bonnet syndrome 131\nchecking behaviour 380–381\nchess expertise, deliberate practice\n615–616, 616\nchess expertise 601–604; vs medical\nexpertise 609; real-world example:\nMagnus Carlson 613–614, 613\nchild-directed speech 397, 545\nchildhood amnesia; see infantile/\nchildhood amnesia\nChomsky, Noam 4, 393, 394, 395,\n397–398\nChristie, Agatha 550\nchromatic adaptation, colour vision\n70–71\nchunking/chunks, integrated\ninformation units 241–242, 252,\n535\nclimate change, reasoning 680, 695–696,\n696, 698\ncoarse-to-fine processing, spatial\nfrequency 104–105\ncoarticulation, listening 409–410,\n410–411\ncocktail party problem, focused\nauditory attention 179–180, 182–183\ncognition, main approaches to 2,\n3; cognitive neuropsychology\n7–12; cognitive neuroscience\n12–26; cognitive psychology 3–7;\ncomparison of 33–34; computational\ncognitive science 26–33; replication\ncrisis 34–36\ncognition and emotion; see emotion\nand cognition\ncognitive appraisal; see appraisal\ncognitive architecture 27–28, 31, 31, 32,\n35, 560\ncognitive bias: attentional bias 753,\n755–758, 760, 761, 762–763, 763;\ncognitive bias modification 761–764;\nexplicit memory bias 754; impact\nbias 650; implicit memory bias 754;\ninterpretive bias 754\ncognitive bottleneck 180, 181, 222–226,\n224, 535; see also divided attention\ncognitive control 760–761, 761, 762–763\ncognitive impairment 10, 518, 550, 557\ncognitive interviews (eyewitness\ntestimony) 373–375\ncognitive load 190, 191, 408, 424, 639\ncognitive miserliness/miser 592–593\ncognitive neuropsychology 3, 7–12, 35;\ndefined, history 7; limitations 12;\nresearch, problems/methods 9–10;\nsingle case studies vs case series\n10–11; strengths 11; theoretical\nassumptions 8–9\ncognitive neuroscience 1–2, 3, 12–26, 35;\nbrain areas 13–14; brain organisation\n14; defined 12; limitations 23–25,\n25, 26; research areas 2; research\ntechniques, brain activity studies\n15–26, 16; strengths 22–23\ncognitive psychology 1, 3–7, 3, 35;\nbehaviourism (Watson, Tolman) 3;\ndefined 1; history of 3–4; information\nprocessing approach 4, 4; limitations\n6–7; strengths 6; task processing\n4, 4\nCognitive Reflection Test 1–2, 592–593\ncognitive self 356, 358–359, 360\ncoherence: central coherence 479;\ncoherence threshold 505–506, 506;\nstandards of 492, 492\ncohort model, speech perception\n425–429, 428, 429\nCreated from usyd on 2022-02-18 03:53:17.",
    "934\nSubject index\ncolour constancy 67–71, 67; chromatic\nadaptation, colour vision 70–71;\nfamiliarity effect 70; local colour\ncontrast 68–70; real-world example:\n“The dress” colour illusion 69; scene\nillumination, estimate 68\ncolour vision/processing 50–51, 64–71;\ncolour constancy 67–71, 67; dual-\nprocess theory 66–67, 66; negative\nafterimages 65–66; opponent-process\ntheory, vision 65–66; trichromacy\ntheory 65, 66\nColtheart, Max, cognitive\nneuropsychology 7–8\ncommon ground, language\ncomprehension/production: audience\ndesign 544–547; defined 484; gestures\n548; pragmatics 484–487, 485, 486\ncommunal personality type 358\ncommunication: social 770–771, 771;\nspeech as 543–549\ncomorbidity 753\ncompartmentalisation 362, 362\ncompensatory strategies 12, 35\ncomprehension; see discourse\ncomprehension, theoretical\napproaches; language comprehension\ncomputational cognitive science 3,\n26–33, 35; Adaptive Control of\nThought-Rational (ACT-R) 30–32,\n31; cognitive architecture 27–28,\n31, 31, 32, 35, 560; computational\nmodelling (see computational\nmodelling); connectionism/\nconnectionist models 28–30, 28, 442,\n447–449, 728, 728; limitations 33;\nproduction systems 30–32, 318, 502;\nstrengths 32\ncomputational modelling 3, 26–33, 35,\n442; Adaptive Control of Thought-\nRational (ACT-R) 30–32, 31; vs\nartificial intelligence 26–27, 27;\nconnectionist models/neural network\nmodels 28–30, 28; interactive\nactivation model 437–439, 437;\nWeaver++ 530–535, 532, 534\nconceptual priming 325–326, 327; see\nalso priming\nconditional reasoning 673–676, 676,\n686–687\ncones, colour vision 44, 45, 65, 66–67\nconfirmation, hypothesis testing 667, 671\nconfirmation bias: eyewitness accuracy\n364–365, 365; forensic 98–99;\nhypothesis testing 668, 670, 671–672\nconflict-based monitoring theory,\nspeech errors 523–525, 524\nconjunction/double conjunction fallacy,\njudgement 624–626\nconnectionism, connectionist models\n447–449, 728, 728; dual-process\ntheory (see dual-process theory);\nneural network models 28–30, 28,\n360; triangle model 442, 447–453, 448\nconnectome 14\nconscious awareness 61–62, 88, 89, 89,\n198\nconsciousness: assessing 775–783;\nand attention (selective attention)\n790–791; bodily self-consciousness\n769; conscious content vs conscious\nlevel 767; forms (access/phenomenal)\n768, 776, 781, 784; forms\n(phenomenal/conscious thought)\n768, 771; functions 768–775; key\nbrain areas 788–790; theories (global/\nglobal neural workspace) 783–792;\nunconsciousness, “Yes It Can”\nprinciple 769, 770; unitary/separate\nconsciousnesses 792–798 (see also\nsplit-brain patients)\nconsciousness, assessing 775–783; brain-\ndamaged patients 778; feedforward/\nrecurrent processing 781–783, 782;\nneural correlates of consciousness\n779–783; over-reporting of conscious\nexperiences 777–778, 777; real-world\nexample: vegetative state patients\nand consciousness 778–779; under-\nreporting of conscious experiences\n776–777\nconsciousness, functions 768–775;\ncognitive neuroscience findings\n774–775; controlling actions:\nconsciousness in decision making\n774, 774; controlling actions: free will\n771–775, 774; sense of agency 773;\nsocial communication 770–771, 771;\n“Yes It Can” principle 769, 770\nconsistent mapping 226, 227\nconsolidation theory, memory 290, 291,\n293\nconstraint-based model, language\ncomprehension 468–470\nconstruction-integration model\n501–505, 502, 503\ncontext effects: memory/forgetting\n287–288, 306, 307, 308, 312; reading\n440–442; speech reception 412–416\nconverging operations 34\ncortex: cerebral 13, 13; inferotemporal\ncortex, form/colour processing 46;\nparietal cortex, motion processing 46,\n46; visual (see visual cortex)\ncounterexample/counterexample\nstrategy 674–676, 676, 678, 681, 682\ncovert attention 165, 167, 170, 192, 455\nCroskerry, Pat, 625, 625\ncross-cueing between brain hemispheres\n793, 797–798\ncross-modal attention 208–209\ncross-modal effects, perception/\nattention 208–212; real-world\nexample: warning signals promote\nsafe driving 211; temporal\nventriloquism 210–211, 210;\nventriloquism effect 209–210, 210\ncrosstalk/backward crosstalk effect 224,\n225–226\ncrystallised intelligence 225\ncues, listening/speech comprehension:\nacoustic, lexical, segmental, metrical\nprosody 410–411, 410; prosodic cues\n404, 463–464, 466–467, 540, 548–549\ncues, memory: cued recalls 305, 305;\ncue-dependent forgetting 287–288;\ndetection 377, 378, 385; mood-\nstate-dependent memory 737, 737;\nprospective memory 377, 378,\n379–380, 382, 385, 386; retrieval cues\n265, 267, 267, 285–286, 289, 289\ncues, reasoning/judgement 631–632,\n632, 635, 636, 637\ncues, visual: binocular cues, depth\nperception 71, 74–75; blur, depth\nperception 73; covert attention\n192; figure-ground segmentation\n100–101; monocular (pictorial) cues,\ndepth perception 71, 72–74, 72, 73;\noculomotor cues, depth perception\n75; visual attention 186–187\ncues combination/integration 75–77\ncylinder depth cues, visual perception 76\ndecay, memory 242, 280–281\ndecision making 640–663;\ncomplications (preference changes,\nselective exposure) 658–659, 659;\ndescription-experience gap 646–647;\nemotional factors (biases: loss/risk\naversion, impact, omission, status\nquo) 649–652; emotional factors\n(loss aversion, omission bias, status\nquo bias) 650; fast-and-frugal\nheuristics (applied decision-making)\n655; multi-attribute utility theory\n(complex decision making) 655–658;\nnaturalistic decision-making theory\n659–662, 660, 661; prospect theory\n642–645, 642, 644; real-world\nexample: expert loss/risk (golfing,\nfinance) 645–646, 645; real-world\nexample: politicians 653–654, 654;\nreal-world example: tightrope\nwalking decisions, Nik Wallenda 647,\n647; social functionalist approach\n(social factors) 653–654; sunk-cost\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n935\neffect 644–645; unconscious thought\ntheory 662–663; utility theories 641,\n655–658\ndeclarative (explicit) memory 263,\n280, 300–301, 300; explicit and\nimplicit learning 269–278; explicit\nmemory bias 754, 755, 759; levels-\nof-processing effect on 263; vs\nnon-declarative (implicit) memory\n299–300, 328, 332–333; types (see\nepisodic memory; semantic memory)\ndecoding/neural decoding 19, 95, 406,\n774\ndeductive reasoning 570, 571, 666–667,\n672, 690; brain regions in 690–693,\n690, 692; conditional reasoning\n673–676, 676, 686–687; and informal\nreasoning 694–695; normativism 703;\nsyllogistic reasoning 678–679, 679;\nWason selection task 676–678, 676\ndeductive reasoning, theories 680–690;\ndual-process approach 680–681,\n683–690, 685, 687; mental model\ntheory 680–683 (see also working\nmemory)\nDeep Blue vs Garry Kasparov chess\nmatch 26\ndeep dyslexia 445, 448, 450–451\ndeep dysphasia 432\ndefault mode network 25, 195\ndeliberate practice, expertise 613,\n613–617, 616; chess 615–616, 616;\ninnate talent and 613, 615; long-term\nworking memory 613; music 616\ndementia; see Alzheimer’s disease;\nfronto-temporal dementia; semantic\ndementia\ndeontic rules 677\ndeontological judgements 739–740, 743;\nsee also moral dilemma; utilitarian\njudgements\ndepictive representation, visual imagery\n131–132\ndepression: appraisal 727; cognitive\nbias 753–757, 757, 758, 759, 761,\n761, 763; real world example:\nreducing anxiety and depression 762;\nreal-world example: depression and\nautobiographical memory 361–363,\n362; real-world example: emotion\nregulation and mental disorders 729\ndepth perception 71–81; binocular cues\n71, 74–75; combination/integration\n75–76; cues combination/integration\n75–77; cues conflict 76; cues\nreliability 75; haptic 76; monocular\ncues 71, 72–74, 72, 73; oculomotor\ncues 71, 75; size constancy/size\njudgements 78–81, 78, 79, 81\ndevelopmental amnesia 301\ndiagnosis/diagnostic errors, judgement\n607–609, 608, 633–634; breast cancer\ndiagnosis, inference 632, 632; real-\nworld example: availability heuristic\nin medical diagnosis 629; real-\nworld example: heuristic in medical\ndiagnosis 625–626\ndiaschisis 11\ndichotic listening/shadowing task\n179–180\ndichromacy 65\ndigit span, short term memory 241, 249,\n249, 298, 614\ndirect (visual) perception: affordances\n141, 142–144, 143, 151, 154; defined\n141; evaluation of 144–145; focus of\nexpansion 141–142, 142, 145–146;\ninvariants, optic array 142, 144; optic\nflow 141–142, 142, 145–146, 147,\n148–149; see also motion perception;\nvisual perception\ndirect retrieval 356, 358–359, 360; see\nalso generative retrieval\ndirected forgetting 250–251\ndirected retrospection 552\ndiscourse comprehension, theoretical\napproaches 498–510; construction-\nintegration model 501–505, 502,\n503; event-indexing model, and\nevent-segmentation theory 507–510;\nKintsch’s construction-integration\nmodel 501–504, 502, 503; RI-Val\nmodel 505–507, 506; Schema\ntheory 498–501; see also language\ncomprehension\ndiscourse markers 549\ndiscourse processing, inferences\n490–498; anaphor resolutions 493;\nbridging (backwards) inferences 490,\n493–494; discourse vs single sentence\ncomprehension 490; inference\ndrawing (passive, “automatic” vs\nreader-initiated) 491–492; logical\ninterferences 490; predictive\ninterferences 495–496, 495; real-\nworld example: anxiety and inference\ndrawing 495; theories, research\nfindings 491–492, 492, 495–498; see\nalso language comprehension\ndissociation; see double dissociation;\nprocess-dissociation procedure\ndistinctiveness, memory traces 263–264,\n263\ndistraction; see also emotion regulation\ndistraction/distractors: dual/multi-\ntasking, divided attention 213, 221,\n221; emotion regulation 724–726; in\nfocused attention 185, 189–191\ndivided attention, dual-task\nperformance/multi-tasking 178,\n212–226; cognitive neuroscience\nfindings 220–222, 220, 221; multiple\nresource theory 215–217, 216;\npsychological refractory period,\ncognitive bottleneck 222–226, 224;\nserial vs parallel processing 213–215;\nthreaded cognition 217–220, 218;\nsee also cross-modal effects; focused\nauditory attention; focused visual\nattention\ndorsal stream, visual perception 53,\n56–57, 56, 57, 62–63, 63; action\nguidance 155–157, 156; egocentric\ncoding 56; see also two-pathway\naction-perception model; ventral\nstream\ndouble conjunction/conjunction fallacy,\njudgement 624–626\ndouble dissociation 10, 64, 119, 243,\n303, 304–305, 308, 331–332\ndual-pathways model 204–206, 204,\n205, 382, 383, 384, 385\ndual-process theory: emotion and\ncognition 738–739, 742–743;\njudgement 637–640; memory 308;\nreasoning 675, 704–705; visual\nperception 66–67, 66\ndual-route cascaded model, reading\n443–477, 444\ndual-system theory; see dual-process\ntheory\ndual-task performance/multi-tasking;\nsee divided attention\nDunning-Kruger effect 705, 708\ndynamic multiprocess framework\n382–383, 383, 386, 386, 387\ndysexecutive agraphia 557\ndysexecutive syndrome 251, 260, 277,\n557\ndysgraphia (surface, phonological)\n560–561, 562\ndyslexia (surface, phonological,\ndeep) 444–445, 448, 449–451, 452,\n562\ndysphasia (surface, phonological) 432,\n560–562\nEbbinghaus, Hermann 278\nEbbinghaus illusion 58–59, 59\nechoic memory 241\necological validity 6, 25, 148, 345, 408,\n487\nEEG; see electroencephalography\nefference copy 145, 153\nefMRI; see event-related functional\nmagnetic resonance imaging\negocentric coding 56\nCreated from usyd on 2022-02-18 03:53:17.",
    "936\nSubject index\negocentric heuristic 484–487, 485, 486\negocentric neglect, vision/attention\n196–197, 197\nelaborative inferences 491\nelectroencephalography (EEG) 17–18,\n779, 787–788, 788\nelimination-by-aspects theory,\njudgement 657–658\nemotion: affect and attention 731–734,\n733; affect and memory 734–738, 735,\n737; bottom-up/top-down processes\n718, 719; brain mechanisms 717;\ndefined 716; regulation 723–730;\nstructure 716, 716\nemotion, regulation 723–730; distraction\n725; neural network for 728; process\nmodel 724–726; real-world example:\nemotion regulation and mental\ndisorders 729; reappraisal 724, 725,\n726, 727–728, 727, 730; strategies\n724–727, 725, 729, 730\nemotion and cognition: anger 720–721,\n747–748, 751, 752; anxiety 744–745,\n745, 750; appraisal theories 719–723;\nemotion regulation 723–730; emotion\nvs judgement in decision making\n743–744; emotion-imbued choice\nmodel 752, 752–753; mood states\nand decision making 743–750, 745,\n746, 750; moral dilemma: emotion\nvs cognition (reason) 738–740, 743;\noptimism bias 744; positive mood\n748–750, 750; real-world example:\ndriverless cars, moral dilemmas\n741–742, 742; sadness 745–746, 746\nemotion-imbued choice model 752,\n752–753; see also emotion and\ncognition\nencoding 127; vs decoding 95; defined\n95; focal/non-focal tasks, dual\npathway model 382, 383; inference\nand impaired encoding 282, 283–284;\nlanguage, speech 546; learning,\nmemory 239–240, 245, 333–335, 334,\n734, 735; problem solving/reasoning\n597\nencoding specificity principle 287–288,\n289–290, 289, 736, 737; encoding\nspecificity principle 287–288,\n289–290, 289, 736, 737; encoding-\nretrieval overlap 289, 289, 295\nencoding-retrieval overlap 289, 289, 295\nendogenous spatial attention 211\nenergetic masking, listening 408\nepisodic buffer 247, 252–253, 253; see\nalso working memory components\nepisodic memory 300–301, 300,\n305–313, 305, 312, 339; brain\ndamage, amnesia, dementia 297,\n301, 301–304, 307, 308; constructive\ncharacter 310–313, 312, 345, 737,\n737; defined 300; recall memory\n(cued, free serial) 253, 253, 305,\n310, 315, 737, 737, 759; recognition\nmemory 305, 306–310, 307;\nvs semantic memory 301–305;\nsemanticisation 304, 305; see also\ndeclarative (explicit) memory; long-\nterm memory\nERP; see event-related potentials\nevent-based prospective memory\n376–377, 381; see also time-based\nprospective memory\nevent-indexing model, and event-\nsegmentation theory 507–510\nevent-related functional magnetic\nresonance imaging (efMRI) 16, 19–20\nevent-related potentials (ERPs) 16,\n17–18, 35; attention, auditory/\nvisual 181, 189, 198, 209, 214, 225;\nconsciousness 774, 786, 786, 789,\n796, 797; language comprehension/\nproduction 475–478, 496–497, 531,\n534, 538; memory/forgetting 256,\n282, 303, 317; motion perception 167,\n173; N400 component of 18, 417,\n426–427, 435, 440–441, 475–477, 476,\n496–497; object/face recognition 109,\n129, 204; problem solving/reasoning\n592, 693; speech perception/reading\n415, 417, 418–419, 423, 426, 435, 440,\n463; visual perception 44, 88\nevent-segmentation theory, and event-\nindexing model 507–510\neveryday memory: autobiographical\nmemory 346–351, 355–363 (see\nalso autobiographical memory);\necological-validity demand, memory\nresearch 344–346; eyewitness\ntestimony 363–372, 623 (see also\neyewitness testimony, accuracy);\nmemories across lifetime 351–355;\nprospective memory 375–389 (see\nalso prospective memory)\nexecutive functions: dysexecutive\nagraphia 557; language 504;\nParkinson's disease 330; unity/\ndiversity framework 258–259, 259;\nworking memory 251, 254, 255,\n257–262, 259, 260\nexecutive processes 221, 251, 254,\n260–262\nexogenous spatial attention 211\nexpertise 600–619; brain plasticity\n609–612, 611, 612; chess: template\ntheory 601–604, 603; defined 600;\ndeliberate practice 613, 613–617,\n616; medical 604–609, 605, 606, 608;\nmultifactorial gene-environment\ninteraction model 617–619, 617\nexplicit (declarative) memory; see\ndeclarative (explicit) memory\nexplicit and implicit reasoning 605–606,\n607–608\nexplicit learning: brain areas 274–276,\n278; brain-damaged patients 276,\n277; vs implicit learning 269–278\nexplicit memory; see declarative\n(explicit) memory\nextinction, visual attention disorder\n197–198, 199, 200; biased stimuli\ncompetition hypothesis 199, 200\neyewitness testimony, accuracy/\nimpairments 363–375, 623; age\nand memory, own-age bias\n369–370; anxiety, stress 369,\n731; confirmation bias 364, 365;\neyewitness identification 370–372,\n371; laboratory vs real-life findings\n372; misinformation effect 365–368,\n366, 368; other-race effect 370–371;\nschemas 364, 365; unconscious\ntransference 370; weapon focus\n368–369, 733\neyewitness testimony, memory\nenhancing 372–375; cognitive\ninterviews 373–375; line-up\nadministration 372–373\nE-Z Reader model 454, 455–456, 455\nface inversion effect 117\nface recognition: face inversion effect\n17; fusiform face area 24, 121–123,\n121, 127; holistic processing,\nexpertise hypothesis 116–117, 120,\n122; vs object recognition 116–117;\npart-whole effect 117; prosopagnosia\n118–121, 120, 127, 128–129; real-\nworld example: passport checks\nexample 121; super-recognisers 125;\ntheoretical approaches 125–127, 126,\n127; viewpoint, influence on 110,\n335, 335\nfaces–goblet illusion, object recognition\n100, 100\nfalse positive scenario, reasoning\n625–627\nfalsification, hypothesis testing 667,\n670, 671\nfamiliarity: effects, visual perception\n70; E-Z Reader model, language\n454, 455, 455; recollection, memory\n306–310, 309, 336\nfast-and-frugal heuristics 634–637, 655\nfear 651–652, 717, 722, 744, 747, 751;\nsee also anxiety\nfeature detectors, pattern recognition 96\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n937\nfeature integration theory 202–204,\n203, 207\nfeature-based attention 186, 188–189\nfigurative language, metaphors,\nlanguage comprehension 478–479,\n480, 480–483, 482, 483; metaphor\ninterference effect 480; prediction\nmodel 481; research findings,\nevaluation 481–483; standard\npragmatic model 480\nfigure-ground segmentation, object\nrecognition 99, 102\nfingerprint matching, pattern\nrecognition 98–99, 98\nflashbacks 350–351\nflashbulb memories 349–351, 734; 9/11\nWorld Trade Centre attack 349–350,\n349; and flashbacks 350–351\nfluid intelligence 255, 257, 593, 595,\n597–598, 597, 706\nfMRI; see functional magnetic\nresonance imaging\nfocal/non-focal tasks 382, 384–385, 385\nfocus of expansion, direct (visual)\nperception 141–142, 142, 145–146\nfocused auditory attention: cocktail\nparty problem 179–180, 182–183;\nearly vs late input selection 180,\n181; processing bottleneck 180 (see\nalso cognitive bottleneck); sound\nsegregation 179–180; target input\n181, 183; top-down processing 180,\n182–183; unattended input 180–182\nfocused visual attention 183–196;\nattention focus: zoom-lens/spotlight/\nsplit attention 184–185, 185, 186;\nfeature-based 186, 188–189; load\ntheory (perceptual, cognitive)\n189–191, 190; major attention\nnetworks 191–196; object-/space-\nbased 186–187, 187, 188; unattended,\ndistracting stimuli 185, 189–191, 256\nforgetting, from long-term memory\n278–293; consolidation theory\n290–291, 292; interferences (proactive,\nretroactive) 281–284; memory decay\n242, 280–281; motivated 284–290 (see\nalso motivated forgetting); real-world\nexample: perfect memory 279–280;\nreconsolidation 290, 291–293, 367;\nrecovered memories, truthfulness of\n284–285\nform processing, visual 50\nfovea, foveal (central) vision 56, 105;\nsee also lexical parafoveal-on-foveal\neffects\nframing effect, decision making\n642–643, 704\nfree recall 305, 310, 345, 737, 737, 759\nfree will 771–772, 773, 775\nFreud, Sigmund 284, 769\nFreudian slip 521\nFriends (TV series) 128\nfronto-parietal network 192, 195–196,\n195, 337, 360, 371, 789\nfronto-temporal dementia 323–324, 324\nfunctional fixedness, problem solving\n585–586, 585, 587; see also mental\nset, problem solving\nfunctional magnetic resonance imaging\n(fMRI) 16, 19–20, 23, 25, 693\nfunctional specialisation, brain 23, 35,\n48–55, 49; binding problem 54–55;\ncolour processing 50–51; form\nprocessing 50; motion processing\n52, 53\nfusiform face area 24, 121–123, 121\nfuture path/heading, visually guided\nmovement 146–147, 147, 149\ngambling, emotion/decision making\n649, 652, 744, 749; Iowa Gambling\nTask 751\nGanong effect 415, 422–423, 423\ngarden-path model, language\ncomprehension 465–468\ngaze/gaze pattern, motion perception\n147, 148\ngene-environment correlation 618\ngene-environment interaction model\n617–619, 617\nGeneral Problem Solver, software 4,\n588\ngeneralisability, ecological validity\n345–346\ngeneralised anxiety disorder 758\ngenerative retrieval, memory 356,\n358–359, 360, 360; see also direct\nretrieval\ngeneric-parts technique, problem\nsolving 586\nGestalt theories, laws of perceptual\norganisation 96–102, 99, 100, 101;\nevaluation of 100–102, 102, 103;\nfigure-ground segmentation 99–100,\n100–101, 102, 102; law of Prägnanz\n97\nGestalt theories, problem solving\n576–588; functional fixedness\n585–588, 585, 587; hints, incubations\n583–584, 583; insight 577–579, 577;\npast experience 584–585; real-world\nexample: magic tricks 582, 582;\nrepresentational change theory\n579–583, 580, 581; reproductive\nthinking 576–577\ngestures, speech 547–548, 549\nGibson, James 141–146, 148–149\nglobal workspace/global neuronal\nworkspace theories, consciousness\n783–792; early stimulus processing\nand consciousness 785–786, 786;\nintegrated brain functioning 787–788;\nintegrated information theory\n784–785, 785; integrated\nsynchronised brain activity 787, 788;\nselective attention\nGobet, Fernand 601–603, 602\ngood-enough language processing\naccount 472–475\ngood-enough language processing\naccount, language comprehension\n474\ngrammar: agrammatism 539–541, 540;\ninflections 461, 462, 522; syntax\nand 461, 462–463; universal innate\ngrammar 395, 396; see also parsing;\nsyntax\ngrapheme 396, 443\ngrapheme buffer (orthographic working\nmemory) 560, 560\ngrapheme–phoneme conversion\n443–444, 444, 445\ngrasping/graspability 56, 58–59, 60–61,\n61, 142–143, 143, 153\n“gut feeling” 637\ngyrus/guri 12, 13, 13; in cerebral cortex\n13, 13; inferior frontal gyrus 52, 121,\n135, 159, 159, 161, 193, 197, 406;\nsuperior temporal 13, 52, 161, 193,\n197, 406, 418, 517, 536, 537, 578, 728\nHall, Monty 575, 575\nhallucinations 114, 130–131\nhaptic sense 76\nhemifield 186\nhemispherectomy 12, 793–794, 797\nHenke's processing-based theoretical\naccount 333–335, 334, 336\nheuristic: affect 628, 628; availability\n628–629, 628, 629–630, 630, 633;\ndefined 576; egocentric 484–487, 485,\n486; fast-and-frugal 655; heuristic\nroute 473–474, 473, 475; hill-climbing\n589; recognition 635–636, 637;\nrepresentativeness 624–625\nhighly superior autobiographical\nmemory (HSAM) 348–349, 348\nhill-climbing heuristic, problem solving\n589\nhint, problem solving 583\nhippocampal neurogenesis 352, 353\nholistic processing 116–117, 120,\n122–123, 609\nhollow-face illusion 59, 60\nhomophones 435–436, 758\nHoni phenomenon 80\nCreated from usyd on 2022-02-18 03:53:17.",
    "938\nSubject index\nhub-and-spoke model, semantic\nmemory 318–320, 319\nhubs, prefrontal cortex regions 15, 319,\n320\nhuman cognition; see cognition;\nemotion and cognition\nhuman motion perception; see motion\nperception\nhuman rationality 701–708; bounded\nrationality 660, 702, 707; dual-\nsystem theory; instrumental vs\nbroad rationality 702–704; intuitive\nvs rational processes; limitations:\ncognitive miserliness 707–708;\nlimitations: dual-process approach\n704–705; limitations: Dunning-\nKruger effect 705; social rationality\n703 (see also social functionalist\napproach); tripartite model of\nreasoning (individual rationality\ndifferences) 705–706, 706\nhypothesis testing: confirmation bias\n668, 670, 671–672; confirmatory\napproach (non-absolute hypotheses)\n667, 671; falsificatory approach\n(absolute/universal hypotheses)\n667, 671; real-world example:\nhypothesis testing by scientists\n670–672; simulated and real research\nenvironments 670–672; Wason’s 2-4-6\ntask 666–670\niconic memory 240–241, 790–791\nilluminant 67–68, 69–70\nillusion, free will 771–775, 774\nillusions, auditory, Moses illusion 473\nillusions, visual 58–61, 59, 60, 61, 64,\n153; body-size-effect 80–81, 81;\nEbbinghaus illusion 58–59, 59; faces-\ngoblet illusion 100, 100; hollow-face\nillusion 59, 60; Kanizsa’s illusory\nsquare 73, 73; Müller-Lyer illusion 58,\n58, 59, 60, 154; negative afterimages\n65–66; open-object illusion 4–5, 4, 12,\n80, 443; ventriloquist illusion/effect\n209–210, 209–212; vertical-horizontal\nillusion 106\nillusory conjunctions 202–203\nillusory square, interposition 73, 73\nimpact bias 650\nimpasse, problem solving 579, 580, 581\nimplacable experimenter 6\nimplementation intentions 387, 773\nimplicit (non-declarative) memory; see\nnon-declarative (implicit) memory\nimplicit and explicit reasoning 605–606,\n607–608\nimplicit learning 269–278, 274;\nassessing: research findings 272–276,\n273, 274, 275, 277–278; assessing:\ntheory 271–272; brain areas 274–276,\n274, 275, 276, 278; brain-damaged\npatients 277; defined 269; real world\nexample: keyboard typing and\n270–271, 270, 277\nimplicit memory; see non-declarative\n(implicit) memory\ninattentional blindness 73, 164–167,\n164, 165–166, 172–174, 790; causes\n172–174, 172, 173, 174; vs change\nblindness 164–167; defined 164;\nreal-world example: magicians\n165–166; see also change blindness\nincidental emotions 744\nincremental validity 707\nincubation, problem solving 583–584\ninductive reasoning 571, 666, 667; see\nalso deductive reasoning; deductive\nreasoning, theories\ninductive reasoning 666–667\ninfantile/childhood amnesia 351–353,\n352\ninferotemporal cortex, form/colour\nprocessing 46\ninflections, grammar 461, 462, 522\ninformal reasoning 570, 571, 667,\n694–708; bounded rationality\n702; motivation for 695–698, 696;\nprobabilities in 698–701, 700\ninformational overlap, memory 290\ninformativeness, memory traces 314\ninhibition of return, visual perception\n187–188, 188\ninner scribe, visuo-spatial sketchpad 249\ninner voice, inner speech 249, 435, 463,\n515, 523, 528\ninsight, problem solving 577, 577–578,\n577\ninstrumental vs broad rationality\n702–704\nintegral emotions 744\nintegrated brain functioning 787–788\nintelligence: crystallised intelligence\n255; fluid intelligence 255, 257, 593,\n595, 597–598, 706; tripartite model\n705–706, 706, 707\ninteractive activation model 437–439,\n437\ninteractive-iterative framework, object\nrecognition 115–116, 115, 116\ninterferences, retention/forgetting\n208–209, 281–284; proactive 281–282,\n281, 282, 283; retroactive 281, 281,\n282–283, 291, 292, 368 (see also\nproactive interference)\ninteroception 652\ninterpretive bias 721, 754, 758–759,\n760, 763; real world example:\nreducing anxiety and depression\n762\nintuition, “gut feeling” 637; logical\nintuition model 640, 685, 686\ninvariants, optic array 142, 144\nIowa Gambling Task 751\njargon aphasia 541–543; see also\naphasia\nJeopardy (computer vs human) 26\nJoyce, James 569, 570\njudgement: defined 622; judgement\nvs decision making 622; research\n623–633 (see also judgement\nresearch); theories 633–640 (see also\njudgement theories)\njudgement, research: availability\nheuristic 628–629, 628, 629–630, 630,\n633; base-rate neglection 624–626,\n627; Bayesian inference theorem\n623–624; double conjunction fallacy\n626; natural frequency hypothesis\n631–633, 632; real-world example:\navailability heuristic in medical\ndiagnosis 629; real-world example:\nheuristic in medical diagnosis\n625–626, 625; representativeness\nheuristic 624–625; taxi cab problem\n623–624\njudgement, theories 633–640; dual-\nprocess theory 637–640; fast-and-\nfrugal heuristics 634–637; recognition\nheuristic 635–636, 637; subadditivity\neffect 633; support theory 633–634\nKasparov, Garry vs Deep Blue\ncomputer chess match 26\nKay, Peter 413\nKintsch’s construction-integration\nmodel; see construction integration\nmodel\nknow procedure, memory 306, 310\n“Knowledge, The”, London taxi driver\ntest 610; see also brain plasticity\nknowledge effect, writing 555\nKorsakoff's syndrome 296–297, 325\nlanguage: innateness of 395–397;\nlanguage comprehension (see\nlanguage comprehension); language\nproduction (speech, writing) (see\nlanguage production); reading (see\nreading); speech perception (see\nspeech perception); unique-to-humans\nquestion 393–394; universal grammar,\nlinguistic universals 395, 397, 398;\nWhorfian hypothesis 398–400\nlanguage comprehension: discourse\ncomprehension (see discourse\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n939\ncomprehension, theoretical\napproaches); individual differences\n(working memory capacity) 487–490;\nparsing 462–464; pragmatics 478–487;\ntheoretical approaches: parsing,\nprediction 464–478\nlanguage processing: algorithmic route\n473–474, 473, 475; heuristic route\n473, 473\nlanguage production: easing of:\npreformulation 518; easing of:\nsyntactic priming 518, 547; easing of:\nunderspecification 518; real-world\nexample: mild cognitive impairment\n518; speech errors 521–525; speech\nplanning 519–521; speech  production\n(see speech production); speech\nproduction vs speech comprehension\n516–517, 517; stages of speech\nproduction 519; writing (see writing)\nlateral inhibition 46, 46\nlaw of Prägnanz 97\nlearning: implicit learning (see implicit\nlearning); retrieval through (testing\neffect) 265–269, 266, 267, 268\nlemmas 530–532, 533, 534, 535, 538\nlesion, brain 7, 12, 57, 608; diaschisis 11\nlevels-of-processing approach, memory\n262–265, 263, 264\nlexical access 417; E-Z Reader model\n454, 455–456, 455\nlexical bias effect 528\nlexical decision task 434\nlexical parafoveal-on-foveal effects 455,\n456\nlexicalisation 531\nlexicon 430, 431, 433, 433, 445, 527,\n528; auditory input lexicon 430, 430,\n431; orthographic lexicon 562–563;\nphonological output lexicon 538\nlexigrams 393–394\nlife script 354–355\nlifetime memories 351–355\nlifetime period, memory 356, 359\nlimb apraxia 156–157\nlinear perspective 72, 72, 74\nline-ups (eyewitness testimony) 372–373\nlinguistic relativity 399\nlinguistic universals 395, 396\nlistening, speech perception: coping\nwith listening problems 409–412;\ndifficulties, speech masking 408;\nMcGurk effect 411–412, 412; model\nof speech comprehension 412;\nspeaker variability 411; speech\nsegmentation 408–409, 409–411, 410;\nspeech signal problems 408–409\nload theory 189–191; cognitive load\n190, 191, 408, 520, 639; perceptual\nload 190, 190, 191; real-world\nexample: driving and mobile phone\nuse 214–215\nlobes, brain 13–14\nlogical interferences 490\nlogical intuition model 640, 685, 686\nLondon taxi driver test “The\nKnowledge” 610\nlong-term memory 300; declarative\n(explicit) memory (see declarative\n(explicit) memory); level of\nprocessing 262; in multi-store model\n240; non-declarative memory (see\nnon-declarative (implicit) memory)\nloss aversion, decision making 642,\n644–646, 645, 648, 650, 652\nloss neutrality, prospect theory 645\nluminance 52–53, 100\nmagnetic resonance imaging (MRI) 18,\n19–20, 25, 655\nmagneto-encephalography (MEG) 16,\n20, 136, 426, 532–533, 691–692\nmagnocellular (M) visual pathway 45,\n104\nmajor attention networks 191–196;\nbrain areas 192–193, 193, 195, 195;\ncingulo-opercular network 195, 195;\ndefault mode network 25, 195, 195;\nendogenous/goal directed network\n(dorsal) 192, 193, 193, 194, 209, 211;\nexogenous/stimulus-driven network\n(ventral) 192, 193, 193, 211; fronto-\nparietal network 192, 195–196, 195;\ninteractions 193, 194, 196, 200; real-\nworld example: car warning systems\n209\nmajor depressive disorder 361, 361,\n362, 729\nMarr, David, computational approach\nto object recognition 105–106\nMars Rover Mission 593\nmasking, auditory 408, 523\nmatching bias 677\nmatchstick problem, problem solving\n580, 581, 581\nmaximisers vs satisfiers, decision\nmaking 656–657\nMcGurk effect 411–412\nmeans-ends analysis 589\nmeans–ends analysis, problem solving\n589\nmediator effectiveness hypothesis 265,\n267\nmedical diagnosis 625–626; real-world\nexample: availability heuristic in\nmedical diagnosis 629; real-world\nexample: heuristic in medical\ndiagnosis 625–626, 625\nmedical expertise 604–609, 605, 606,\n608; vs chess expertise 609\nMEG; see magneto-encephalography\nmemories across lifetime 351–355;\ninfantile/childhood amnesia 351–353,\n352; reminiscence bump 351, 352,\n353–355, 354\nmemory: affect and memory 734–738,\n735, 737; everyday memory (see\neveryday memory); memory bias\n(implicit, explicit) 754, 759, 760,\n761 (see also cognitive bias); mood\ncongruity 736, 737–738; mood-state-\ndependent memory 288, 736–738,\n737; sensory stores 240–242, 240;\nsynaesthesia and 280; see also\namnesia; memory systems/processes;\nmemory traces\nmemory decay 242, 280–281\nmemory systems/processes 300;\ncomponent-process models 338–340,\n339; declarative/explicit vs non-\ndeclarative/implicit (see declarative\n(explicit) memory; non-declarative\n(implicit) memory); episodic vs\nsemantic (non-declarative) (see\nepisodic memory; semantic memory);\nHenke's processing-based theoretical\naccount 333–335, 334, 336; memory\nsystem–brain area dependency\n337–338, 337; short-term vs long-\nterm (see long-term memory; short\nterm memory)\nmemory traces, retrieval 268, 280,\n287; distinctiveness 263–264, 264;\ndual-memory theory 265, 266;\nencoding specificity principle 287,\n287–288, 289–290; eyewitness\ntestimony, accuracy 367; familiarity\nand recollection 306; reconsolidation\n289–290, 291–293\nmental models 491, 681–683\nmental set, problem solving 584–588,\n587, 704; see also functional fixedness\nmentalising 346, 347\nmeta-analysis 36\nmeta-cognition 149, 384, 385–386, 555,\n590\nmeta-memory 380–381\nmetaphor interference effect 480, 480\nmeta-reasoning 589–590, 688, 689,\n690\nmindware 706\nminimalist hypothesis 491–492, 494,\n495, 497\nminimally conscious state 778\nmirror neuron system 161–163, 161\nmisery-is-not-miserly effect 746; see also\nemotion and cognition\nCreated from usyd on 2022-02-18 03:53:17.",
    "940\nSubject index\nmisinformation/misleading effect,\neyewitnesses' memory 365–368, 366,\n368\nmixed-error effect, speech error 527\nmodularity, cognitive system 8, 12; see\nalso cognitive neuropsychology\nmodularity/anatomical modularity,\nassumption 8\nMolaison, Henry Gustav (HM) 297, 297\nMona Lisa (Leonardo da Vinci) 105,\n105\nmonocular (pictorial) cues, depth\nperception 71, 72–74, 72, 73\nmood congruity, memory 736, 737–738\nmood states: judgement/decision\nmaking 743–750, 745, 746, 750\n(see also emotion and cognition);\nmood-state-dependent memory 288,\n736–738, 737\nmoral dilemma: emotion vs cognition\n(reason) 738, 738–740, 743;\ndeontological judgements 739–740,\n743; real-world example: driverless\ncars 741–742, 742; utilitarian\njudgements 739–740, 741–742,\n742, 743 (see also deontological\njudgements)\nmorpheme-exchange errors, speech\nerrors 522\nmorphemes 519, 522\nmorphological level, speech production\n519\nmorphology 433, 462\nmotion parallax 73, 80\nmotion perception 157–163; biological\nmotion 160; brain areas 159, 159;\nhuman motion 157–160, 157, 158;\nmirror neuron system 161–163,\n161; top-down/bottom-up processes\n158–159\nmotion processing, visual 51–54, 52, 53\nmotivated forgetting 284–290; cue-\ndependent forgetting 286–287;\ndirected forgetting 285; recovered\nmemories, truthfulness of 284–285;\nrepression 284–285, 351; suppression,\nthink/no-think paradigm 285–286,\n286\nmotivation, reasoning, decision making\n577, 658–659, 677, 695–697, 708, 746\nmotivational intensity, attention\n731–732, 733–734, 737\nmotor sequence learning 275, 275, 276,\n330–331, 332\nmotor theory, speech perception\n417–410\nMRI; see magnetic resonance imaging\nMüller-Lyer illusion, visual perception\n58, 58, 59, 60, 154\nmulti-attribute utility theory, decision\nmaking 656, 657, 658\nmultifactorial gene-environment\ninteraction model, expertise 617–619,\n617\nmultiple resource theory 215–217, 216\nmultiple spotlights theory, split\nattention 184, 185\nmultiprocess framework, memory 382\nmulti-store model, memory 240–244\nmulti-tasking; see divided attention\nMurdoch, Iris 550, 550\nmusic perception 404–406; see also\nspeech perception\nmutilated draughtboard problem\n577–578, 577\nmyopic misery 746; see also emotion\nand cognition\nmyside bias 696–697; see also informal\nreasoning\nnaming task 434, 534, 535, 538, 543\nnarcissism 747\nnarrative text 507, 510\nnatural frequency hypothesis 631–633,\n632\nnatural sampling 631, 632\nnaturalistic decision-making theory\n659–662, 660, 661; bounded\nrationality 660; decision structuring\n659–660; recognition-primed\ndecision-making model (expert\ndecisions) 660–662, 660\nnegative afterimages, colour vision\n65–66\nneglect, visual attention disorder\n196–197, 197, 198, 199, 200;\nallocentric/object-based 196–197;\negocentric/space-based 196–197;\npseudo-neglect 196; ventral attention\nnetwork damage 198, 199–200\nneologisms 541–542\nnested incremental modelling,\ncomputational modelling 32\nneural correlates of consciousness\n779–783, 781, 782, 783\nneural decoding 19\nneural network models; see\nconnectionism, connectionist\nmodels\nneuroenchantment 25–26, 26\nneurogenesis, hippocampal 352, 353\nneurons 16, 29; brain, organisation 14;\nmotion perception, mirror neuron\nsystem 161–163; object recognition\n111; pattern recognition 96; visual\nform processing 50; visual processing\n(lateral inhibition) 45–46, 46; see also\nsingle-unit recording\nnine-dot problem, representational\nchange theory 579, 580\nnodes 14, 15, 15, 28, 29; Spreading-\nactivation theory 526–527; TRACE\nmodel 420–421, 421\nnon-accidental (invariant) properties,\nobject recognition 107–108\nnon-declarative (implicit) memory 269,\n280, 325–332; vs declarative (explicit)\nmemory 299–300, 300, 328, 332–333;\nimplicit and explicit learning\n269–278; implicit memory bias\n754, 755, 759; levels-of-processing\neffect 263; procedural memory/skill\nlearning 328–332, 330; repetition\npriming 325–328, 328\nnon-focal/focal task 382, 384–385, 385\nnormativism 703\nobject recognition: bottom-up process\n111 (see also bottom-up processing);\nvs face recognition 116–117; holistic\nprocessing, expertise hypothesis\n122–123; interactive-iterative\nframework 115–116, 115, 116; Marr’s\ncomputational approach 105–106;\nperception-action model (see two-\npathway action-perception model);\nreal-world example: shooter bias\nby skin colour 113; recognition-by-\ncomponents theory, Irving Biederman\n106–109, 107; spatial frequency,\ncoarse-to-fine processing 104–105,\n104, 105; top-down processing\n111–116, 112, 114, 115, 116 (see also\ntop-down processing); viewpoint,\ninfluence on 108, 109–111; see also\nface recognition\nobject-based neglect, visual perception\n196–197\nobject-/space-based attention 186–187,\n187, 188, 189\nobsessive-compulsive disorder (OCD)\n380–381, 381\noculomotor cues, depth perception 75\nomission bias 651\nongoing task, prospective memory 377,\n381–382, 383, 384–385, 386, 387, 388\nopen-object illusion 4–5, 4, 12, 80, 443\noperation span 255, 488–489\nopponent-process theory, colour vision\n65–66\noptic array 141; see also invariants,\noptic array\noptic ataxia 57–58, 57, 64, 156–157\noptic chiasm 44\noptic flow 141–142, 142, 145–146, 147,\n148–149\noptimism bias 744, 749\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n941\northographic lexicon 562–563\northographic neighbours 248, 417,\n437–438\northographic neighbours/\nneighbourhood; see also phonological\nneighbours/neighbourhood\northographic working memory\n(grapheme buffer) 560, 560\northography 417, 434, 447, 448\nother-race effect 370–371\nout-of-body experiences, consciousness\n771\noveradditivity/underadditivity 221, 221,\n222\noverconfidence, cognition/\ncomprehension 498, 749\novert attention 165, 167, 170\nown-age bias 370\nparadigm specificity 7, 25, 35\nparafovea, parafoveal processing\n453, 455, 455, 456; see also lexical\nparafoveal-on-foveal effects\nparallel processing 4, 32, 35, 48;\nlanguage comprehension 464–465;\nreading 437, 446, 455; reasoning 685,\n685; vs serial processing 213–214;\nvisual perception 49, 202, 203,\n204, 207, 208, 225; see also serial\nprocessing\nparietal cortex, motion processing 46\nParkinson’s disease 160, 277, 329–330,\n330, 332\nparsing, language comprehension:\ndefined 462; inner voice, implicit\nprosody 463; prosodic cues 404,\n463–464, 466–467, 540, 548–549;\nsyntax and grammar 398, 433, 461,\n462–463\nparsing and prediction, theoretical\napproaches: constraint-based model\n468–470; event-related potentials\n(ERP) studies 475–478, 476; garden-\npath model 465–468; good-enough\nlanguage processing account\n472–475, 474; prediction through\ntop-down processes 476; unrestricted\nrace model 470–472, 471\npart-whole effect, face recognition 117\npart-whole effect, object recognition 117\nparvocellular (P) visual pathway 45, 104\npast experience: functional fixedness\n585–586, 585, 587; mental set\n584–588, 587, 704; see also top-down\nprocessing\nPatient DB 82\nPatient GY 83–84, 84, 86\npattern recognition 95–96, 95,\n607–608; defined 95, 239; expert\ndecision-making 660–661, 661;\nfeature detectors 96; real-world\nexample: forensic fingerprint\nmatching 98; real-world example:\nspammer protection 97\npendulum/two-string problem, insight\n383, 385\nperception: backward masking 780–781,\n782; categorical perception 399,\n405; cross-modal effects 208–212;\nmusic 404–406; speech (see speech\nperception); visual (see visual\nperception); Whorfian hypothesis\n398–400; without awareness and\nsubliminal perception 81–90, 714\nperception without awareness,\nsubliminal perception 81–90, 714;\nblindsight 82–86, 84, 86; real-world\nexample: blindsight patient DB 82,\n89; subliminal perception 87–90, 89\nperception-action model; see two-\npathway action-perception model\nperceptual awareness 88, 89; see also\nperception without awareness,\nsubliminal perception\nPerceptual Awareness Scale, subliminal\nperception 84, 85, 88\nperceptual loop theory, speech errors\n523\nperceptual organisation 96–103;\nfigure-ground segmentation 99–100,\n100–101, 102, 102; Gestalt laws\nof perceptual organisation, law of\nPrägnanz 97, 99, 100, 101; research\nfindings, evaluation 100–103; uniform\nconnectedness 101, 103\nperceptual priming 325–327; see also\npriming\nperceptual span 453\nperipheral vision 73, 165–166, 167,\n170–171, 170, 207–208, 437\npersonal semantics 303\npersonality: agentic personality type\n358; communal personality type\n358; everyday memory 344, 358;\nexpertise, multifactorial gene-\nenvironment interaction model 617,\n618; judgement/decision making 743,\n752, 752\nphenomenal consciousness 768,\n776, 781, 784; see also access\nconsciousness\nphonemes 405, 406–408, 408–409, 418,\n519, 542; dual-route cascaded model\n443; dual-route theory 559–560;\nGanong effect 415; TRACE model\n420, 423, 423\nphonemic restoration effect 414–415,\n416\nphonological dysgraphia 560–561\nphonological dyslexia 445, 448, 450\nphonological level, speech production\n519, 520, 526, 527, 537, 538\nphonological loop: components\n247–248, 248; working memory\nand forgetting 246, 247–249, 248,\n249, 252, 253; working memory and\nwriting 556–557, 556, 558; see also\nworking memory component\nphonological neighbours/\nneighbourhood 417, 436; see\nalso orthographic neighbours/\nneighbourhood\nphonological output lexicon 445, 538\nphonological priming 434–435, 436\nphonological processes, reading\n435–436\nphonological similarity effect,\nphonological loop 248\nphonology 433–434, 433, 436, 447, 448\nphrase 519–520, 522\npictorial (monocular) cues, depth\nperception 71, 72–74, 72, 73\npicture naming tasks, speech\nproduction 534, 535, 538, 543\nplanning-control model, visually\nguided action 152–155; brain areas\n153; evaluation of 154; planning\nand control systems 152–153; see\nalso two-pathway action-perception\nmodel\nplasticity, brain; see brain plasticity\nPopper, Karl 667\npositron emission tomography (PET)\n16, 18\npragmatics 478–487; common ground\n484–487, 485, 486; figurative\nlanguage, metaphors 480–483, 480,\n482, 483; real-world example: autistic\nspectrum disorder 479\npragmatics, language comprehension:\nbrain areas (figurative/literal\nprocessing) 478; common ground\n484–487, 485, 486; common ground–\negocentric heuristic simultaneity 486,\n487; egocentric heuristic 484–486,\n487; figurative language, metaphors\n480–484, 480, 482, 483; intended vs\nliteral meaning 478–479, 480; real-\nworld example: autistic spectrum\ndisorders 479\npredictive inferences 491, 494, 495–496,\n495, 497\npreformulation, speech production 518\nPrice, Jill, highly superior\nautobiographical memory (HSAM)\n348\nprimal sketch, object recognition 105\nCreated from usyd on 2022-02-18 03:53:17.",
    "942\nSubject index\npriming 300, 325–328, 326, 434–435;\nbrain areas 337–338; conceptual\npriming 325–326, 327; motor priming\n142; perceptual priming 325–327;\nphonological 436; priming processes\n327–328; priming–skill learning\ndifferences 331; reading research 434;\nrepetition priming 299, 325–328, 328;\nsemantic priming 316, 439, 440, 440;\nsyntactic priming 518, 547\nprinciple of truth 681, 682\nproactive interferences,\nretention forgetting 281–282, 281,\n282, 283\nproblem solving 574–600; analogical\nproblem solving (see analogical\nproblem solving and reasoning);\nfacilitating insights (hints,\nincubations) 583–584, 583; functional\nfixedness, past experience 585–586,\n585, 587; Gestalt approach (see\nproblem solving, Gestalt theories);\nmental set, past experiences\n584–588, 587, 704; problem types\n(well/ill-defined, knowledge-rich/\nlean) 574, 576; real-world example:\nMonty Hall problem 575–576, 575;\nrepresentational change theory\n579–583; strategies 588–593\nproblem solving, Gestalt theories\n576–588; functional fixedness\n585–588, 585, 587; hints, incubations\n583–584, 583; insight 577–579, 577;\npast experience 584–585; real-world\nexample: magic tricks 582, 582;\nrepresentational change theory\n579–583, 580, 581\nproblem-solving strategies 588–593;\ncognitive miserliness/cognitive\nreflection test 1–2, 592–593; hill-\nclimbing heuristic 589; means–ends\nanalysis 589; meta-reasoning\n589–590; planning, sequential\nprocessing stages 590–592\nproblem space 588\nproblems: knowledge-lean/knowledge-\nrich 574, 588, 588; well-defined /\nill-defined 574, 589\nprocedural memory 31–32, 31, 299, 300;\nand skill learning 325, 328–331\nprocedural similarity, problem solving\n594\nprocess-dissociation procedure 272,\n273, 275\nprocessing-based theoretical account,\nmemory 333–335, 334, 336\nproduction rules 30\nproduction systems, computational\ncognitive science 30–32, 318, 502\npronunciation: phonemes 409; word/\nirregular word/non-word 11, 263,\n435, 442, 443–444, 447, 451–452\nproposition, propositional logic\n501–502, 503, 504–505, 673, 696–697\nproprioception 60, 61, 153\nprosodic cues, language comprehension\n404, 463–464, 466–467, 540, 548–549\nprosopagnosia 118–121, 120, 127,\n128–129; real-world example:\nHeather Sellers 118\nprospect theory, decision making\n642–648, 642, 649, 650, 650;\ndescription-experience gap 646–647;\nframing effect 642; individual\ndifferences 647–648; loss aversion\n644–645; real-world example: expert\nloss/risk (golfing, finance) 645,\n645–646, 647; sunk-cost effect 644,\n644\nprospective memory 375–389; air traffic\naccidents 378–379, 379; evaluation\n387–388; event based vs time based\n376–377; improving 387; obsessive-\ncompulsive disorder (OCD) 380–381,\n381; real-world example: failures\nof 378–381, 379; research findings\n384–386; vs retrospective 376; stages\n377–378, 378; theoretical perspective\n381–389, 381; see also retrospective\nmemory\npseudo-neglect 196\npseudowords 442\npsychological refractory period,\ncognitive bottleneck 222–226, 224\npsychological refractory period (PRP)\n222–226, 224; see also divided\nattention, dual-task performance/\nmulti-tasking\npsychological refractory period (PRP)\neffect 223\npure alexia 9, 12\npure word deafness 430–431\nrationalisation 499, 770\nrationality; see human rationality\nRaven’s Progressive Matrices 593, 594,\n595; see also fluid intelligence\nreaction time: real-world example:\ndriving and mobile phone use\n214–215; real-world example: warning\nsignals promote safe driving 211;\nserial reaction time task, memory\n272–273, 273, 274, 274, 330\nreading: “anglocentricities” in reading\nresearch 433–434; eye-movement\nresearch 453–454; general framework,\nprocesses/structures 433, 433;\nphonological processes 435–436; pure\nalexia 9, 12; reading aloud 442–453;\nresearch methods 434–435, 434; word\nrecognition 436–442\nreading, eye-movement research:\nbasic processes 453–454; E-Z\nReader model 454–457, 455; lexical\nparafoveal-on-foveal effects 455;\nparafovea, parafoveal processing\n453, 455, 455, 456; perceptual span\n453; saccades 453; serial vs parallel\nprocessing 455\nreading aloud: connectionist triangle\nmodel 447–449, 448; deep dyslexia\n445, 448, 450–451; dual-route\ncascaded model 443–477, 444; general\nvs language-specific processes 452;\ngrapheme–phoneme conversion rules\n443–445; lexical/non-lexica routes\n443, 444; orthography–phonology/\nphonology–orthography pathways\n447; phonological dyslexia (lexical\nroute) 445, 448, 450; pronouncing\nnon-words 442, 451–452; surface\ndyslexia (non-lexical route) 444–445,\n448, 449–450; word regularity vs word\nconsistency 451, 451\nreading span 255\nreal-world example: tightrope walking\ndecisions, Nik Wallenda 647, 647\nreappraisal, emotion regulation 724,\n725, 726, 727–728, 727, 730; real\nworld: emotion regulation and\nmental disorder 729\nreasoning: analogical (see analogical\nproblem solving/reasoning); brain\nsystems 690–693; deductive (see\ndeductive reasoning; deductive\nreasoning, theories); human\nrationality 701–708; inductive vs\ndeductive 571, 666, 667; informal\n694–701\nrecall, memory/learning: cued recall\n267, 305, 315, 737, 737, 759; free\nrecall 305, 310, 345, 737, 737, 759;\nserial recall 241, 253, 253, 305\nreceptive field 45, 96\nrecognition heuristic 635–636, 637\nrecognition memory 305, 306–310,\n307, 335; brain areas/mechanisms\n306–310, 309; levels-of-processing,\ndepth 262, 263\nrecognition test, episodic memory\n310\nrecognition-by-components theory\n106–109, 107, 108\nrecognition-primed decision-making\nmodel 660–662, 660\nreconsolidation, memory 290, 291–293;\nsee also consolidation theory, memory\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n943\nrecovered memories 284–285\nrecursion 395, 396\nreflective mind 706, 706, 708\nremember/know procedure, memory\n306, 310\nreminiscence bump 351, 352, 353–355,\n354\nRemote Associates Test 578–579, 587\nrepetition enhancement 327–328, 328,\n331\nrepetition priming; see priming\nrepetition suppression 327–328, 328\nrepetitive transcranial magnetic\nstimulation (rTMS) 16, 21, 50, 112,\n159, 478–479\nreplication crisis, science 34–36, 35; see\nalso meta-analysis\nrepresentational change theory, problem\nsolving 578–583, 580, 581, 583\nrepresentativeness, ecological validity\n345–346\nrepresentativeness heuristic 624–625,\n624–626, 638–639; real-world\nexample: heuristics in medical\ndiagnosis 625–626\nrepression, retention/forgetting\n284–285, 351\nreproductive thinking, reasoning\n576–577\nresearch techniques, brain activity\nstudies 15–26; see also also event-\nrelated functional magnetic\nresonance imaging (efMRI);\nevent-related potentials (ERPs);\nfunctional magnetic resonance\nimaging (fMRI); magneto-\nencephalography (MEG); positron\nemission tomography (PET);\nsingle-unit recording; transcranial\ndirect current stimulation (tDCS);\ntranscranial magnetic stimulation\n(TMS)\nresponse bias 88–89, 89, 90; real-world\nexample: fingerprinting 98, 99; real-\nworld example: shooter bias 113\nresponse modulation, emotion\nregulation 725, 725, 726\nretina-geniculate-striate pathway/\nsystem, eye 44–45\nretinal displacement 146\nretinal flow field 145\nretinal ganglion cells 44\nretinex theory 68–69\nretinopy 44\nretrieval: direct 356, 358–359; generative\n356, 358–359, 360, 360\nretroactive interferences, retention/\nforgetting 281, 281, 282–283, 291,\n292, 368\nretrograde amnesia 290, 292, 298, 302,\n357\nretrospective memory 375, 377, 380;\nprospective vs retrospective memory\n376\nreverse inference 24, 35\nrisk: brain areas (financial decision\nmaking) 652; decision-making\n(mood) 745–747, 745, 751; framing\neffect and risk taking 642–644; losses/\ngains 641; loss/risk aversion 642, 642,\n645–646, 645, 743; omission bias 651;\nrisk taking, individual differences\n647–648\nRI-Val model 505–507, 506\nrTMS; see repetitive transcranial\nmagnetic stimulation\nRussell, Bertrand 666\nRutherford, Ernest 593\nsaccades 543\nsadness 732, 743, 745–746, 745, 746,\n751; see attention; emotion and\ncognition\nsatisficing 656\nsavings method 278\nsaying-is-believing effect 345\nschema 71; brain networks 322–323;\ndefined; double dissociation 323–325;\neyewitness testimony, influence on\n364; Schema theory 498–501\nScrabble 795\nscript/life script 354–355\nsegmentation: auditory 179, 408–409;\nauditory/speech 409–411, 410;\nevent-segmentation theory 507–510;\nrealCAPTCHA, pattern recognition\n99; visual/figure-ground 99, 100–101,\n102\nselective exposure 658–659, 659\nself-memory system model,\nautobiographical memory\n355–359\nsemantic dementia 303, 304, 314,\n319–320, 323–324, 323–325,\n324\nsemantic level, speech production 519,\n537\nsemantic memory 313–325, 333–335;\nautobiographical memory 347;\nBarsalou’s approach, concept use\n316–318; defined 313; hierarchy/\norganisation, concepts 313–315,\n315; hub-and-spoke model, concept\nuse 318–320, 319; schemas vs\nconcepts 322–325 (see also schema;\nSchema theory); semantic distance,\nconcepts 315–316; see also episodic\nmemory\nsemantic priming 316, 435–436, 439,\n440, 440\nsemantic substitutions, speech errors\n521–522\nsemanticisation, of episodic memory 304\nsemantics 434, 447, 448, 448\nsense of agency 773, 775\nsentential context effects (anticipatory\nprocessing) 440–442\nserial dependence 172\nserial processing 4, 8, 32, 225, 454–455;\nlanguage comprehension 464; vs\nparallel processing 213–214; reading\n445–446, 454–455; reasoning\n685, 685; visual perception 125,\n202, 207, 225; see also parallel\nprocessing\nserial reaction time task 272–273, 273,\n274, 274, 330\nserial recall 248, 305\nsexual abuse, motivated forgetting 284,\n285\nshadowing/dichotic listening task\n179–180\nShereshevskii, Solomon 280\nshooter bias 113\nshort-term memory: chunking/chunks\n241–242, 252, 535; echoic memory\n241; iconic memory 240–241;\ninformation decay 242; interferences,\nretention 242–243, 243; vs long-term\nmemory 240–246; in multi-store\nmodel 240, 241–243; see also working\nmemory\nshort-term/long-term memory,\ncomparison 240–246; multi-store\nmodel 240–244; unitary-store model\n244–246\nsignal-detection therapy 98\nsingle case studies vs case series,\nresearch 10–11\nsingle-unit recording 16, 17, 47\nsize constancy, depth perception 78–81,\n78, 79, 81\nskill learning 328–332, 330\nslippery slope argument 700\nsocial cognition 1\nsocial functionalist approach, decision\nmaking 653–654\nsocial rationality 703\nsocial-cultural developmental theory,\nmemory 351\nsolution aversion 696\nsound segregation 179\nspace-/object-based attention 189\nspatial attention 196, 211\nspatial frequency/coarse-to-fine\nprocessing, object recognition\n104–105, 104, 105\nCreated from usyd on 2022-02-18 03:53:17.",
    "944\nSubject index\nspeech and music perception 404–408;\ndifferences (brain area activation)\n405–406; processing stages\nperception/comprehension 406–408,\n406, 407; similarities (categorial\nperception) 404, 405\nspeech as communication 543–549;\naudience design 543–549, 544–547,\n546; common ground 544–545;\ndiscourse markers 549; gesture\n547–548; prosodic cues 548–549\nspeech errors, language production:\nconflict-based monitoring theory\n523–525, 524, 525; error types\n521–523; Freudian slip 521; mixed-\nerror effect 527; morpheme-exchange\nerrors 522; perceptual loop theory\n523; semantic substitutions 521–522;\nspoonerism 521; subject-verb\nagreement errors 522\nspeech output lexicon 430, 431\nspeech perception: basic units\n(phonemes vs syllables) 406, 407;\nbrain areas 405–406; categorical\nperception 405; cognitive\nneuropsychology research 429–432;\ncontext effects 412–416; listening\nas 408–417; processing stages\n406–408, 406, 407; speech and music\nperception 404–408; theories about\n417–429\nspeech perception, cognitive\nneuropsychology research 429–432;\nauditory analysis system 430–431;\ndeep dysphasia 432; pure word\ndeafness 430–431; three-route\nframework 430, 430, 431–432;\ntranscortical sensory aphasia 432;\nword meaning deafness\n431, 432\nspeech perception, context effects:\ndistraction/distractors influence\n413–414, 414; Ganong effect\n415, 422–423; Interactionist vs\nautonomous accounts 415–416;\nphonemic restoration effect 414–415,\n416; real-world misheard lyrics and\nmiscarriages of justice 413\nspeech perception, theories: cohort\nmodel 425–429, 428, 429; motor\ntheory (perception–production\ncoupling) 417–420, 420; orthographic\ninfluences on 417; TRACE model\n420–425, 421, 422, 423\nspeech production: cognitive\nneuropsychological approach\n536–543; speech as communication\n543–549; speech production vs\ncomprehension 517; stages/levels\nof speech production 519 (see also\nmorphological level; phonological\nlevel; semantic level; syntactic level);\ntheories 525–536\nspeech production, cognitive\nneuropsychological approach:\nagrammatism 539–541, 540;\nanomia 537–539; aphasia (Broca's,\nWernicke's, jargon) (see aphasia)\nspeech production theories: Dell's\nspreading-activation theory 519,\n526–530, 533, 536, 538; general\ncognitive processes 535–536;\nWEAVER++ 526, 530–536, 534\nspelling: brain areas, writing and\nreading 562–563, 563; dual-route\ntheory (lexical/non-lexical) 559–562,\n559, 560; lexical-route damage,\nphonological dysgraphia 560; non-\nlexical-route damage effects, surface\ndysgraphia 561; orthographic lexicon\n562–563; orthographic working\nmemory (graphemic buffer) 560\nSPIDER model 214–215\nspillover effect 454–455\nsplit attention 184, 184–186, 185\nsplit-brain patients 792–798; cross-\ncueing and unified control 793,\n797; hemispherectomy and brain\nplasticity 793–794; left hemisphere\n(interpreter) dominance 795–796,\n796; research limitations 796; two\nstream consciousness 793, 794, 797,\n797; Wada test 794\nspoonerism, speech error 521\nspotlight attention 184–185, 186\nspreading activation theories 315–316,\n502, 519, 526–530, 533, 536,\n538\nstandards of coherence 492, 492\nstatus quo bias 651–652, 653; real-world\nexample: politicians’ decision-making\n653–654, 654\nstereopsis 74, 77\nstimulus onset asynchrony (SOA) 223,\n706\nstop-signal task, task-impurity\nproblem 5\nstraw man fallacy 694\nstray-light hypothesis, blindsight 82\nstriatum 274–275, 274, 276, 331–332,\n333; Parkinson's disease 277, 329\nStroop task, task-impurity problem 5,\n5, 258, 756, 756\nstructural similarity, problem solving\n594\nsubadditivity effect 633, 634\nsubject-verb agreement errors, speech\nerrors 522\nsubliminal perception; see perception\nwithout awareness/subliminal\nperception\nsubtractivity assumption 9, 12; see also\ncognitive neuropsychology; plasticity,\nbrain\nsulcus 13, 13\nsunk-cost effect, decision making\n644, 653, 704; real-world example:\npoliticians’ decision-making 653–654,\n654\nsuperficial similarity, problem solving\n594\nsuper-recognisers 125\nsupport theory, judgement 633–634\nsuppression, think/no-think paradigm,\nmemory 285–286, 286\nsurface dysgraphia 561\nsurface dyslexia 444–445, 448, 449–450\nSWIFT model, reading 455, 456, 457\nsyllogism/syllogistic reasoning 678–680,\n679, 684, 686, 687, 697, 698; see also\ndeductive reasoning\nsynaesthesia 280\nsynchrony, binding-by synchrony\nhypothesis 54\nsyndrome: anarchic-hand syndrome\n795; Anton's syndrome 131;\nAsperger syndrome 479; Charles\nBonnet syndrome 131; defined 10;\ndysexecutive syndrome 251, 260, 277,\n557; Korsakoff’s syndrome 297–298,\n325\nsyntactic level, speech production 519,\n527\nsyntactic priming, speech production\n518, 547\nsyntactic processing, language 398,\n467\nsyntax 398, 433, 461; grammar and\n462–463; see also grammar; parsing\ntacit knowledge, visual perception 182\ntake-the-best strategy, heuristics 635,\n636, 637\ntangent point 147, 147, 149; real-world\nexample: on-road driving 148, 148\ntask processing 4, 4, 16\ntask-impurity problem 5\ntau/tau-dot hypothesis, motion\nperception 149, 151, 152\ntaxi cab problem, judgement 623–624\ntaxi driver test “The Knowledge”\n(London), brain plasticity 610\ntemplate theory, chess 601–604, 603\ntemporal coherence 183\ntemporal ventriloquism 210–211, 210;\nreal-world example: warning signals\npromote safe driving 210\nCreated from usyd on 2022-02-18 03:53:17.",
    "Subject index\n945\ntemporal ventriloquism effect 210–211,\n210\ntesting effect 265–269, 266, 267, 268\ntexture tiling model, visual search\n206–208\ntexture/texture gradient, depth\nperception 72–73, 72, 76\nthinking and reasoning: decision-\nmaking 640–663; expertise 600–618;\njudgement, research and theories\n623–639; problem solving 574–600;\nreasoning 666–708; see also under\ntheir own entries\nthink/no-think paradigm, suppression\nmemory 285–286, 286\nthreaded cognition 217–220, 218\nthree-route framework, speech\nperception 430, 430, 431–432\ntime to contact, visually guided\nmovement 149–152, 152\ntime-based prospective memory\n376–377; see also event-based\nprospective memory\ntip-of-the-tongue state 531–533, 538\nTMS; see transcranial magnetic\nstimulation\nTolman, Edward C. 3\ntop-down processing: (visual) word\nrecognition 436, 437, 437, 438;\nattention 178, 182–183, 192,\n193–194, 196, 197; bilinguality/\nunderstanding non-native speaker\n409, 488, 535; brain mechanism\n599; comprehension 499; conscious\nexperience 777, 781; defined 4, 4;\nemotional experience 718–719,\n718; human-motion perception\n158–159; inattentional blindness 173;\ninformation processing approach 4;\nmemory/retrieval 382, 383, 384–385,\n386; object recognition 111–116, 115;\npattern recognition 96, 98–99; speech\nperception 408, 412, 413, 416, 417,\n420–421, 421, 422–423, 424; visual\nimagery/perception 48, 132, 135–136,\n135, 137; visual search 204, 204\nTower of Hanoi, problem solving task\n588, 588, 590, 591, 592\nTower of London, problem solving task\n590–591, 590\nTRACE model, speech perception\n420–425, 421, 422, 423\ntrait anxiety 753, 758, 760\ntranscortical sensory aphasia 432\ntranscranial direct current stimulation\n(tDCS) 16, 22, 162, 221–222, 320, 728\ntranscranial magnetic stimulation\n(TMS) 16, 20–22, 21, 35; attention\n194, 196; consciousness 782; memory\nforming 320, 327; speech perception,\nreading 418, 436, 449; visual\nperception 48, 50, 51, 62, 145–146\ntransference, unconscious 370\ntransparency assumption 9, 12; see also\ncognitive neuropsychology; plasticity,\nbrain\ntraumatic memory 284, 285; see also\nflashbacks; recovered memories;\nrepression\ntriangle model, connectionism 442,\n447–453, 448\ntrichromacy theory, colour vision\n65, 66\ntripartite model of reasoning 705–706,\n706\nTulving, Endel 287\ntwins/twin studies 125, 258, 259, 610,\n611, 616, 618\ntwo-pathway action-perception model\n46, 46, 55–64, 63, 103–104, 155–157;\naction planning/motor responses\n61; conscious awareness (dorsal/\nventral|) 61–62; differences 56;\nresearch findings 57–58, 58, 62–63,\n63; vision-for-action system (dorsal\nstream) 56, 57; vision-for-reception\nsystem (ventral stream) 55, 58; visual\nillusions 58–61, 59, 60, 61, 64, 153;\nsee also dorsal stream; ventral\nstream\ntwo-string problem, insight 383, 385\nUlysses (James Joyce) 569\nunconscious processing; see subliminal\nperception\nunconscious thought theory, decision\nmaking 662–663\nunconscious transference 370\nunderadditivity/overaddivity 221, 221,\n222\nunderspecification, speech production\n518\nuniform connectedness 101, 103\nuniqueness point 425, 426–427\nunitary-store model, memory 244–246\nuniversal grammar, linguistic universals\n395, 397, 398\nuniversality assumption 8–9, 12; see\nalso cognitive neuropsychology\nunrestricted race model, language\ncomprehension 470–472, 471\nUrbach-Wiethe disease 735\nutilitarian judgements 739–740,\n741–742, 742, 743; see also\ndeontological judgements\nutility, utility theory 641, 655–656,\n657; see also instrumental vs broad\nrationality\nvalence 716\nvegetative state, consciousness 778,\n782, 787, 788; real-world example:\nvegetative state patients and\nconsciousness 778–779, 779; see\nalso brain damage/brain-damaged\npatients\nventral stream/pathway, visual\nperception: action planning/motor\nresponses 62–63, 63; allocentric\ncoding 56; brain-damaged patients\n58, 540, 540; object recognition 104,\n155, 156; perception-action model\n55–57, 56; visual brain, organisation\nof 47–48, 47, 48; visual motion 53;\nsee also dorsal stream; two-pathway\naction-perception model\nventriloquism effect 209–210, 209–212;\nreal-world example: warning signals\npromote safe driving 210; temporal\nventriloquism 210–211, 210\nverb bias 469\nvergence 74, 75\nvergence, depth cues 74–75\nviewpoint, influence on object/face\nrecognition 81, 106, 107, 108,\n109–111, 335, 335\nvision-for-action system 59–60\nvisuo-spatial sketchpad 246, 247,\n249–251, 252–253, 556, 557–558;\nsee also working model\ncomponents\nvisual attention, disorders: biased\nstimuli competition hypothesis 199,\n200; conscious stimuli awareness and\nstimuli processing 198; extinction\n197–198, 199, 200; neglect 196–197,\n197, 198, 199, 200; ventral attention\nnetwork damage 198, 199–200; see\nalso focused visual attention\nvisual buffer 132, 132\nvisual cache, visuo-spatial sketchpad\n249\nvisual cortex 45, 339; damage,\nblindsight 82, 83, 85, 136; neuron\ntypes in 96; object recognition 104,\n111; V1, BA17 (primary), V2, BA18\n(secondary) 14, 45–46, 48, 48, 49,\n49, 52, 53, 54; V3 (form processing),\nV4 (colour processing), V5/MT\n(motion processing) 46–47, 47, 48,\n49, 49, 50–54, 52, 53; visual imagery,\nhallucinations 130–131, 132,\n133–134, 134–135, 135\nvisual crowding 170, 207; see also\nchange blindness\nvisual form agnosia 58\nvisual illusions 58–61, 59, 60, 61,\n64, 153\nCreated from usyd on 2022-02-18 03:53:17.",
    "946\nSubject index\nvisual imagery 130–137; Anton’s\nsyndrome, blindness denial 131;\nfunctions of 131; hallucinations/\nCharles Bonnet syndrome 114,\n130, 131; impairment/lack of\n(aphantasia) 130; theories: depictive\nrepresentation, visual buffer 131–132,\n132; visual perception, resemblances/\ndifferences 130, 132–136, 133, 134,\n135\nvisual pathways/processing 44–55, 781,\n782; brain, areas involved 49; brain,\nfunctional specialisation 48–55;\nbrain areas involved 46–48, 48;\nearly processing (V1, V2) 45–46, 46;\nfeedforward sweep 21, 48, 49,\n781–782; retina-geniculate-striate\npathway (eye to cortex) 44–45;\ntwo-pathway model (vision for\nperception/vision for action) 46, 46,\n55–64, 56, 63, 103–104, 155–157\nvisual perception: brain systems\ninvolved in 44–55; colour vision/\nprocessing 50–51, 64–71; depth\nperception 71–81; perception without\nawareness, subliminal perception\n81–90; two-pathway action-\nperception model 55–64, 63, 103–104,\n155–157\nvisual receptor cells: cones 44, 45, 65,\n66–67; rods 44, 45\nvisual search 200–208; dual-pathways\nmodel 204–206, 204, 205; feature\nintegration theory 202–204, 203, 207;\nreal world example: airport security\nchecks. 201–202, 202; texture tiling\nmodel (foveal/\nperipheral vision) 206–208, 208;\nvisual crowding 208\nvisually guided action 152–157; action\nplan changes 155; brain pathways\n(dorso-dorsal, ventro-dorsal)\n155–157, 156; planning-control\nmodel 152–155\nvisually guided movement 145–152; eye\nand head movements 145, 146, 147,\n148; heading and steering 145–148;\noptic flow information 145–146; path\nand heading judgements 146, 147,\n147; real-world example: on-road\ndriving, drivers' gaze pattern 148,\n148; retinal object displacement 146;\ntangent point 147, 147, 148; time to\ncontact 149–152, 150\nvisuo-spatial sketchpad: language 556,\n557, 558; mental models 682; working\nmemory 245, 249–251, 250, 252; see\nalso working memory components\nWada test 794\nWaldo Emerson, Ralph 748\nWallenda, Nik 647\nWar of the Ghosts, The (North\nAmerican Indian culture) 449, 500\nWason’s selection task 676–678, 676;\nsee also deductive reasoning\nWason’s 2-4-6 task 666–670\nWatson, IBM, AI computer 26, 27\nWatson, John 3, 714\nWEAVER++ 526, 530–536, 534, 537,\n538\nWernicke’s aphasia 536–537\nWho Wants to be a Millionaire (TV\nshow) 649\nWhorf, Benjamin Lee 398\nWhorfian hypothesis, language 398–400\nword consistency vs word regularity\n451, 451\nword meaning deafness 431, 432\nword regularity vs word consistency\n451, 451\nword superiority effect 437, 438\nword-length effect, phonological loop\n248\nword-recognition, reading 453–454;\ninteractive activation model 437,\n437–439; semantic priming 439, 440;\nsentential context effects (anticipatory\nprocessing) 440–442\nworking memory 246–254, 487–490;\nAdaptive Control of Thought-\nRational (ACT-R) 31–32;\ncomponents (see working memory\ncomponents); connectionism/\nconnectionist models 28; deliberate\npractice 613–614; executive\nfunctions 251, 254, 255, 257–262,\n259; individual differences 254–257,\n487–490 (see also working memory\ncapacity); production systems 30;\nreasoning 597–598, 681–682; spelling/\northography 560, 560; threaded\ncognition 217–218, 218, 219; writing\n552, 553, 555–558, 556\nworking memory capacity 254–257;\nimplicit learning 270; inferences,\ndealing with 493; language\ncomprehension differences 487–490;\nparsing and prediction 474–475;\nproblem solving/reasoning 587, 587;\nwriting expertise 494\nworking memory components:\ncentral executive 246–247, 246, 251,\n252–255, 260, 277, 556–557, 556;\nepisodic buffer 247, 252–253, 253;\nphonological loop 246, 247–249,\n248, 252, 253, 556–557, 556, 558;\nvisuo-spatial sketchpad 245, 249–251,\n250, 252, 556, 557, 558, 682; see also\nshort-term memory\nworking memory model 246–254, 246;\nsee also central executive; episodic\nbuffer; phonological loop; visuo-\nspatial sketchpad; working memory\ncomponents\nworking self, self-memory system model\n356, 357, 358\nWorld Trade Centre attack, flashbulb\nmemory 349–350, 349\nwriting: correlation writing/cognitive\nabilities 549; dysexecutive agraphia\n557; individual differences, expertise\ndevelopment 553–555, 554; key\nprocesses, writing models 551–553,\n552, 553; process switching 550,\n552–553, 553; real-world example:\nIris Murdoch, Alzheimer's and\nnovel writing 550, 550; spelling\n(see spelling); spelling/orthography\n558–563; word processing software\nvs by-hand writing 558; working\nmemory influence 555–558, 556\n“Yes It Can” principle, unconsciousness\n769\nzoom-lens attention 184–185, 186\nCreated from usyd on 2022-02-18 03:53:17.",
    "To learn how Next Generation Primal Pictures can help you master\nanatomy and physiology visit www.primalpictures.com/students\nNext Generation Primal Pictures is the cutting-edge suite of digital anatomy\nsolutions for education that saves you time, increases engagement, and\nadvances learning outcomes. Primal brings evidenced-based accuracy to a wide\nrange of offerings that help students in over 1500 colleges and universities\naround the world grasp course material, prepare for lab time, and study for\nexams with confidence.\n-  Empower confidence through evidence-based accuracy with the world’s most\ndetailed, researched, and verified 3D reconstruction of human anatomy.\n-  Access, source and integrate flexible and dynamic 3D anatomy content across\nthe spectrum of gross anatomy, physiology, biomechanics and medical specialties.\nSave, share, or embed in your own online learning environment.\n-  Drive highly engaged learning and better outcomes with vividly detailed\ninteractive images, movies, slides and animations.\n-  Anytime, anywhere access on any device for learning on-the-go, flipped classroom\nand distance learning, review and assessment.\nAchieve Optimal Anatomy\nLearning Outcomes with Next\nGeneration Primal Pictures\nCreated from usyd on 2022-02-18 03:53:44.",
    "http://taylorandfrancis.com\nCreated from usyd on 2022-02-18 03:53:44."
  ],
  "total_pages": 933,
  "headings": [
    {
      "page": 2,
      "title": "Professor Robert Logie, School of Philosophy, Psychology and Language"
    },
    {
      "page": 4,
      "title": "Cognitive Psychology"
    },
    {
      "page": 5,
      "title": "Visit the Companion Website"
    },
    {
      "page": 6,
      "title": "COGNITIVE PSYCHOLOGY"
    },
    {
      "page": 7,
      "title": "2 Park Square, Milton Park, Abingdon, Oxon OX14 4RN"
    },
    {
      "page": 12,
      "title": "7 Long-term memory systems"
    },
    {
      "page": 16,
      "title": "Iris Murdoch"
    },
    {
      "page": 17,
      "title": "2.11 The Müller-Lyer illusion"
    },
    {
      "page": 20,
      "title": "5.11  Performance speed on a detection task as a function of target"
    },
    {
      "page": 22,
      "title": "7.10 Performance accuracy on tool function and tool manipulation"
    },
    {
      "page": 23,
      "title": "8.10 Examples of Egyptian and UK face-matching arrays"
    },
    {
      "page": 25,
      "title": "10.11 Reaction times to name colours when the word presented in"
    },
    {
      "page": 26,
      "title": "12.10 Mean percentages of correct solutions as a function of"
    },
    {
      "page": 32,
      "title": "TEXTBOOK FEATURES"
    },
    {
      "page": 36,
      "title": "COGNITIVE PSYCHOLOGY"
    },
    {
      "page": 61,
      "title": "KEY TERMS"
    },
    {
      "page": 67,
      "title": "KEY TERMS"
    },
    {
      "page": 69,
      "title": "KEY TERM"
    },
    {
      "page": 81,
      "title": "KEY TERM"
    },
    {
      "page": 82,
      "title": "KEY TERM"
    },
    {
      "page": 89,
      "title": "KEY TERM"
    },
    {
      "page": 113,
      "title": "IN THE REAL WORLD: BLINDSIGHT PATIENT DB"
    },
    {
      "page": 124,
      "title": "of Experimental Psychology and Cognitive Neuroscience, Vol. 2: Sensation,"
    },
    {
      "page": 126,
      "title": "PATTERN RECOGNITION"
    },
    {
      "page": 128,
      "title": "IN THE REAL WORLD: HOW CAN WE DISCOURAGE SPAMMERS?"
    },
    {
      "page": 144,
      "title": "IN THE REAL WORLD: SHOOTER BIAS"
    },
    {
      "page": 155,
      "title": "IN REAL LIFE: PASSPORT CONTROL"
    },
    {
      "page": 172,
      "title": "DIRECT PERCEPTION"
    },
    {
      "page": 206,
      "title": "CHAPTER SUMMARY"
    },
    {
      "page": 232,
      "title": "IN THE REAL WORLD: AIRPORT SECURITY CHECKS"
    },
    {
      "page": 242,
      "title": "IN THE REAL WORLD: WARNING SIGNALS PROMOTE SAFE DRIVING"
    },
    {
      "page": 268,
      "title": "PART II"
    },
    {
      "page": 300,
      "title": "KEY TERM"
    },
    {
      "page": 324,
      "title": "CHAPTER SUMMARY"
    },
    {
      "page": 328,
      "title": "IN THE REAL WORLD: THE FAMOUS CASE OF HM"
    },
    {
      "page": 331,
      "title": "DECLARATIVE MEMORY"
    },
    {
      "page": 392,
      "title": "IN THE REAL WORLD: DEPRESSION AND AUTOBIOGRAPHICAL"
    },
    {
      "page": 422,
      "title": "FURTHER READING"
    },
    {
      "page": 448,
      "title": "THEORIES OF SPEECH PERCEPTION"
    },
    {
      "page": 486,
      "title": "E-Z Reader model. The"
    },
    {
      "page": 491,
      "title": "FURTHER READING"
    },
    {
      "page": 581,
      "title": "IN THE REAL WORLD: EFFECTS OF"
    },
    {
      "page": 595,
      "title": "CHAPTER SUMMARY"
    },
    {
      "page": 605,
      "title": "PROBLEM SOLVING: INTRODUCTION"
    },
    {
      "page": 606,
      "title": "IN THE REAL WORLD: MONTY HALL PROBLEM"
    },
    {
      "page": 623,
      "title": "KEY TERMS"
    },
    {
      "page": 654,
      "title": "JUDGEMENT RESEARCH"
    },
    {
      "page": 656,
      "title": "IN THE REAL WORLD:"
    },
    {
      "page": 678,
      "title": "IN THE REAL WORLD: NIK"
    },
    {
      "page": 680,
      "title": "DECISION-MAKING: EMOTIONAL AND SOCIAL"
    },
    {
      "page": 711,
      "title": "IN THE REAL WORLD: INVALID DEDUCTIVE REASONING"
    },
    {
      "page": 725,
      "title": "INFORMAL REASONING"
    },
    {
      "page": 742,
      "title": "Pohl, R.F. (ed.) (2017). Cognitive Illusions: Intriguing Phenomena in Thinking,"
    },
    {
      "page": 749,
      "title": "KEY TERM"
    },
    {
      "page": 756,
      "title": "KEY TERMS"
    },
    {
      "page": 760,
      "title": "KEY TERM"
    },
    {
      "page": 766,
      "title": "KEY TERM"
    },
    {
      "page": 770,
      "title": "KEY TERMS"
    },
    {
      "page": 793,
      "title": "IN THE REAL WORLD: REDUCING ANXIETY AND DEPRESSION"
    },
    {
      "page": 797,
      "title": "FURTHER READING"
    },
    {
      "page": 858,
      "title": "Borghesani, V. & Piazza, M. (2017). The neuro-cognitive"
    },
    {
      "page": 859,
      "title": "Bruno, N. & Cutting, J.E. (1988). Mini-modularity and"
    },
    {
      "page": 863,
      "title": "de Gardelle, V., Sackur, J. & Kouider, S. (2009). Perceptual"
    },
    {
      "page": 865,
      "title": "Eimer, M., Gosling, A. & Duchaine, B. (2012). Electro-"
    },
    {
      "page": 866,
      "title": "Farah, M.J. (1991). Cognitive neuropsychology: Patterns"
    },
    {
      "page": 868,
      "title": "of Experimental Psychology: Human Perception and"
    },
    {
      "page": 870,
      "title": "Groopman, J. (2007). How Doctors Think. New York:"
    },
    {
      "page": 871,
      "title": "Harrison, T.L., Shipstead, Z. & Engle, R.W. (2015). Why is"
    },
    {
      "page": 872,
      "title": "Hodgson, C. & Lambon Ralph, M.A. (2008). Mimicking"
    },
    {
      "page": 873,
      "title": "Ipser, A., Agolli, B., Bajraktari, A., Al-Alawi, F., Djaafara,"
    },
    {
      "page": 874,
      "title": "Jongman, S.R., Roelofs, A. & Scheper, A.R. (2017). Picture"
    },
    {
      "page": 876,
      "title": "Koppenol-Gonzalez, G.V., Bouwmeester, S. & Boonstra,"
    },
    {
      "page": 883,
      "title": "Nairne, J.S. (2015a). Encoding and retrieval: Beyond Tulving"
    },
    {
      "page": 884,
      "title": "Test (RAST). Journal of Experimental Psychology:"
    },
    {
      "page": 885,
      "title": "Parketny, J., Towler, J. & Eimer, M. (2015). The  activation"
    },
    {
      "page": 887,
      "title": "Rakow, T. & Sylark, W.J. (2018). Judgement heuris-"
    },
    {
      "page": 890,
      "title": "Schumacher, E.H., Seymour, T.L., Glass, J.M., Fencsik, D.E.,"
    },
    {
      "page": 891,
      "title": "Shipstead, Z., Harrison, T.L. & Engle, R.W. (2016). Working"
    },
    {
      "page": 892,
      "title": "Psychology: Learning, Memory, and Cognition, 42,"
    },
    {
      "page": 893,
      "title": "Strobach, T., Antonenko, D., Abarrin, M., Escher, M., Flöel,"
    },
    {
      "page": 898,
      "title": "Wing, E.A., Ritchey, M. & Cabeza, R. (2015). Reinstatement"
    },
    {
      "page": 900,
      "title": "Aarts, H. 772"
    },
    {
      "page": 901,
      "title": "Basehore, Z. 635"
    },
    {
      "page": 902,
      "title": "Byrne, M.D. 27"
    },
    {
      "page": 903,
      "title": "Crisp, J. 450–451"
    },
    {
      "page": 904,
      "title": "Elder, J.H. 100"
    },
    {
      "page": 905,
      "title": "Garg, N. 746"
    },
    {
      "page": 906,
      "title": "Harvey, M.I. 484"
    },
    {
      "page": 907,
      "title": "Jones, P.R. 75"
    },
    {
      "page": 908,
      "title": "Land, M.F. 147"
    },
    {
      "page": 909,
      "title": "Marois, R. 225"
    },
    {
      "page": 910,
      "title": "Murphy, C. 320"
    },
    {
      "page": 911,
      "title": "Phillips, J.D. 373"
    },
    {
      "page": 912,
      "title": "Rosenthal, G. 117"
    },
    {
      "page": 913,
      "title": "Skinner, B.F. 393"
    },
    {
      "page": 915,
      "title": "Weller, J.A. 652"
    }
  ],
  "sections": [
    {
      "title": "Professor Robert Logie, School of Philosophy, Psychology and Language",
      "level": 1,
      "page_start": 2,
      "page_end": 3,
      "children": []
    },
    {
      "title": "Cognitive Psychology",
      "level": 1,
      "page_start": 4,
      "page_end": 4,
      "children": []
    },
    {
      "title": "Visit the Companion Website",
      "level": 1,
      "page_start": 5,
      "page_end": 5,
      "children": []
    },
    {
      "title": "COGNITIVE PSYCHOLOGY",
      "level": 1,
      "page_start": 6,
      "page_end": 6,
      "children": []
    },
    {
      "title": "2 Park Square, Milton Park, Abingdon, Oxon OX14 4RN",
      "level": 1,
      "page_start": 7,
      "page_end": 11,
      "children": []
    },
    {
      "title": "7 Long-term memory systems",
      "level": 1,
      "page_start": 12,
      "page_end": 15,
      "children": []
    },
    {
      "title": "Iris Murdoch",
      "level": 1,
      "page_start": 16,
      "page_end": 16,
      "children": []
    },
    {
      "title": "2.11 The Müller-Lyer illusion",
      "level": 2,
      "page_start": 17,
      "page_end": 19,
      "children": []
    },
    {
      "title": "5.11  Performance speed on a detection task as a function of target",
      "level": 2,
      "page_start": 20,
      "page_end": 21,
      "children": []
    },
    {
      "title": "7.10 Performance accuracy on tool function and tool manipulation",
      "level": 2,
      "page_start": 22,
      "page_end": 22,
      "children": []
    },
    {
      "title": "8.10 Examples of Egyptian and UK face-matching arrays",
      "level": 2,
      "page_start": 23,
      "page_end": 24,
      "children": []
    },
    {
      "title": "10.11 Reaction times to name colours when the word presented in",
      "level": 2,
      "page_start": 25,
      "page_end": 25,
      "children": []
    },
    {
      "title": "12.10 Mean percentages of correct solutions as a function of",
      "level": 2,
      "page_start": 26,
      "page_end": 31,
      "children": []
    },
    {
      "title": "TEXTBOOK FEATURES",
      "level": 1,
      "page_start": 32,
      "page_end": 35,
      "children": []
    },
    {
      "title": "COGNITIVE PSYCHOLOGY",
      "level": 1,
      "page_start": 36,
      "page_end": 60,
      "children": []
    },
    {
      "title": "KEY TERMS",
      "level": 1,
      "page_start": 61,
      "page_end": 66,
      "children": []
    },
    {
      "title": "KEY TERMS",
      "level": 1,
      "page_start": 67,
      "page_end": 68,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 69,
      "page_end": 80,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 81,
      "page_end": 81,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 82,
      "page_end": 88,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 89,
      "page_end": 112,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: BLINDSIGHT PATIENT DB",
      "level": 1,
      "page_start": 113,
      "page_end": 123,
      "children": []
    },
    {
      "title": "of Experimental Psychology and Cognitive Neuroscience, Vol. 2: Sensation,",
      "level": 1,
      "page_start": 124,
      "page_end": 125,
      "children": []
    },
    {
      "title": "PATTERN RECOGNITION",
      "level": 1,
      "page_start": 126,
      "page_end": 127,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: HOW CAN WE DISCOURAGE SPAMMERS?",
      "level": 1,
      "page_start": 128,
      "page_end": 143,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: SHOOTER BIAS",
      "level": 1,
      "page_start": 144,
      "page_end": 154,
      "children": []
    },
    {
      "title": "IN REAL LIFE: PASSPORT CONTROL",
      "level": 1,
      "page_start": 155,
      "page_end": 171,
      "children": []
    },
    {
      "title": "DIRECT PERCEPTION",
      "level": 1,
      "page_start": 172,
      "page_end": 205,
      "children": []
    },
    {
      "title": "CHAPTER SUMMARY",
      "level": 1,
      "page_start": 206,
      "page_end": 231,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: AIRPORT SECURITY CHECKS",
      "level": 1,
      "page_start": 232,
      "page_end": 241,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: WARNING SIGNALS PROMOTE SAFE DRIVING",
      "level": 1,
      "page_start": 242,
      "page_end": 267,
      "children": []
    },
    {
      "title": "PART II",
      "level": 1,
      "page_start": 268,
      "page_end": 299,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 300,
      "page_end": 323,
      "children": []
    },
    {
      "title": "CHAPTER SUMMARY",
      "level": 1,
      "page_start": 324,
      "page_end": 327,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: THE FAMOUS CASE OF HM",
      "level": 1,
      "page_start": 328,
      "page_end": 330,
      "children": []
    },
    {
      "title": "DECLARATIVE MEMORY",
      "level": 1,
      "page_start": 331,
      "page_end": 391,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: DEPRESSION AND AUTOBIOGRAPHICAL",
      "level": 1,
      "page_start": 392,
      "page_end": 421,
      "children": []
    },
    {
      "title": "FURTHER READING",
      "level": 1,
      "page_start": 422,
      "page_end": 447,
      "children": []
    },
    {
      "title": "THEORIES OF SPEECH PERCEPTION",
      "level": 1,
      "page_start": 448,
      "page_end": 485,
      "children": []
    },
    {
      "title": "E-Z Reader model. The",
      "level": 1,
      "page_start": 486,
      "page_end": 490,
      "children": []
    },
    {
      "title": "FURTHER READING",
      "level": 1,
      "page_start": 491,
      "page_end": 580,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: EFFECTS OF",
      "level": 1,
      "page_start": 581,
      "page_end": 594,
      "children": []
    },
    {
      "title": "CHAPTER SUMMARY",
      "level": 1,
      "page_start": 595,
      "page_end": 604,
      "children": []
    },
    {
      "title": "PROBLEM SOLVING: INTRODUCTION",
      "level": 1,
      "page_start": 605,
      "page_end": 605,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: MONTY HALL PROBLEM",
      "level": 1,
      "page_start": 606,
      "page_end": 622,
      "children": []
    },
    {
      "title": "KEY TERMS",
      "level": 1,
      "page_start": 623,
      "page_end": 653,
      "children": []
    },
    {
      "title": "JUDGEMENT RESEARCH",
      "level": 1,
      "page_start": 654,
      "page_end": 655,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD:",
      "level": 1,
      "page_start": 656,
      "page_end": 677,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: NIK",
      "level": 1,
      "page_start": 678,
      "page_end": 679,
      "children": []
    },
    {
      "title": "DECISION-MAKING: EMOTIONAL AND SOCIAL",
      "level": 1,
      "page_start": 680,
      "page_end": 710,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: INVALID DEDUCTIVE REASONING",
      "level": 1,
      "page_start": 711,
      "page_end": 724,
      "children": []
    },
    {
      "title": "INFORMAL REASONING",
      "level": 1,
      "page_start": 725,
      "page_end": 741,
      "children": []
    },
    {
      "title": "Pohl, R.F. (ed.) (2017). Cognitive Illusions: Intriguing Phenomena in Thinking,",
      "level": 1,
      "page_start": 742,
      "page_end": 748,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 749,
      "page_end": 755,
      "children": []
    },
    {
      "title": "KEY TERMS",
      "level": 1,
      "page_start": 756,
      "page_end": 759,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 760,
      "page_end": 765,
      "children": []
    },
    {
      "title": "KEY TERM",
      "level": 1,
      "page_start": 766,
      "page_end": 769,
      "children": []
    },
    {
      "title": "KEY TERMS",
      "level": 1,
      "page_start": 770,
      "page_end": 792,
      "children": []
    },
    {
      "title": "IN THE REAL WORLD: REDUCING ANXIETY AND DEPRESSION",
      "level": 1,
      "page_start": 793,
      "page_end": 796,
      "children": []
    },
    {
      "title": "FURTHER READING",
      "level": 1,
      "page_start": 797,
      "page_end": 857,
      "children": []
    },
    {
      "title": "Borghesani, V. & Piazza, M. (2017). The neuro-cognitive",
      "level": 1,
      "page_start": 858,
      "page_end": 858,
      "children": []
    },
    {
      "title": "Bruno, N. & Cutting, J.E. (1988). Mini-modularity and",
      "level": 1,
      "page_start": 859,
      "page_end": 862,
      "children": []
    },
    {
      "title": "de Gardelle, V., Sackur, J. & Kouider, S. (2009). Perceptual",
      "level": 1,
      "page_start": 863,
      "page_end": 864,
      "children": []
    },
    {
      "title": "Eimer, M., Gosling, A. & Duchaine, B. (2012). Electro-",
      "level": 1,
      "page_start": 865,
      "page_end": 865,
      "children": []
    },
    {
      "title": "Farah, M.J. (1991). Cognitive neuropsychology: Patterns",
      "level": 1,
      "page_start": 866,
      "page_end": 867,
      "children": []
    },
    {
      "title": "of Experimental Psychology: Human Perception and",
      "level": 1,
      "page_start": 868,
      "page_end": 869,
      "children": []
    },
    {
      "title": "Groopman, J. (2007). How Doctors Think. New York:",
      "level": 1,
      "page_start": 870,
      "page_end": 870,
      "children": []
    },
    {
      "title": "Harrison, T.L., Shipstead, Z. & Engle, R.W. (2015). Why is",
      "level": 1,
      "page_start": 871,
      "page_end": 871,
      "children": []
    },
    {
      "title": "Hodgson, C. & Lambon Ralph, M.A. (2008). Mimicking",
      "level": 1,
      "page_start": 872,
      "page_end": 872,
      "children": []
    },
    {
      "title": "Ipser, A., Agolli, B., Bajraktari, A., Al-Alawi, F., Djaafara,",
      "level": 1,
      "page_start": 873,
      "page_end": 873,
      "children": []
    },
    {
      "title": "Jongman, S.R., Roelofs, A. & Scheper, A.R. (2017). Picture",
      "level": 1,
      "page_start": 874,
      "page_end": 875,
      "children": []
    },
    {
      "title": "Koppenol-Gonzalez, G.V., Bouwmeester, S. & Boonstra,",
      "level": 1,
      "page_start": 876,
      "page_end": 882,
      "children": []
    },
    {
      "title": "Nairne, J.S. (2015a). Encoding and retrieval: Beyond Tulving",
      "level": 1,
      "page_start": 883,
      "page_end": 883,
      "children": []
    },
    {
      "title": "Test (RAST). Journal of Experimental Psychology:",
      "level": 1,
      "page_start": 884,
      "page_end": 884,
      "children": []
    },
    {
      "title": "Parketny, J., Towler, J. & Eimer, M. (2015). The  activation",
      "level": 1,
      "page_start": 885,
      "page_end": 886,
      "children": []
    },
    {
      "title": "Rakow, T. & Sylark, W.J. (2018). Judgement heuris-",
      "level": 1,
      "page_start": 887,
      "page_end": 889,
      "children": []
    },
    {
      "title": "Schumacher, E.H., Seymour, T.L., Glass, J.M., Fencsik, D.E.,",
      "level": 1,
      "page_start": 890,
      "page_end": 890,
      "children": []
    },
    {
      "title": "Shipstead, Z., Harrison, T.L. & Engle, R.W. (2016). Working",
      "level": 1,
      "page_start": 891,
      "page_end": 891,
      "children": []
    },
    {
      "title": "Psychology: Learning, Memory, and Cognition, 42,",
      "level": 1,
      "page_start": 892,
      "page_end": 892,
      "children": []
    },
    {
      "title": "Strobach, T., Antonenko, D., Abarrin, M., Escher, M., Flöel,",
      "level": 1,
      "page_start": 893,
      "page_end": 897,
      "children": []
    },
    {
      "title": "Wing, E.A., Ritchey, M. & Cabeza, R. (2015). Reinstatement",
      "level": 1,
      "page_start": 898,
      "page_end": 899,
      "children": []
    },
    {
      "title": "Aarts, H. 772",
      "level": 1,
      "page_start": 900,
      "page_end": 900,
      "children": []
    },
    {
      "title": "Basehore, Z. 635",
      "level": 1,
      "page_start": 901,
      "page_end": 901,
      "children": []
    },
    {
      "title": "Byrne, M.D. 27",
      "level": 1,
      "page_start": 902,
      "page_end": 902,
      "children": []
    },
    {
      "title": "Crisp, J. 450–451",
      "level": 1,
      "page_start": 903,
      "page_end": 903,
      "children": []
    },
    {
      "title": "Elder, J.H. 100",
      "level": 1,
      "page_start": 904,
      "page_end": 904,
      "children": []
    },
    {
      "title": "Garg, N. 746",
      "level": 1,
      "page_start": 905,
      "page_end": 905,
      "children": []
    },
    {
      "title": "Harvey, M.I. 484",
      "level": 1,
      "page_start": 906,
      "page_end": 906,
      "children": []
    },
    {
      "title": "Jones, P.R. 75",
      "level": 1,
      "page_start": 907,
      "page_end": 907,
      "children": []
    },
    {
      "title": "Land, M.F. 147",
      "level": 1,
      "page_start": 908,
      "page_end": 908,
      "children": []
    },
    {
      "title": "Marois, R. 225",
      "level": 1,
      "page_start": 909,
      "page_end": 909,
      "children": []
    },
    {
      "title": "Murphy, C. 320",
      "level": 1,
      "page_start": 910,
      "page_end": 910,
      "children": []
    },
    {
      "title": "Phillips, J.D. 373",
      "level": 1,
      "page_start": 911,
      "page_end": 911,
      "children": []
    },
    {
      "title": "Rosenthal, G. 117",
      "level": 1,
      "page_start": 912,
      "page_end": 912,
      "children": []
    },
    {
      "title": "Skinner, B.F. 393",
      "level": 1,
      "page_start": 913,
      "page_end": 914,
      "children": []
    },
    {
      "title": "Weller, J.A. 652",
      "level": 1,
      "page_start": 915,
      "page_end": 933,
      "children": []
    }
  ]
}